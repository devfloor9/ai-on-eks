<!doctype html>
<html lang="ko-KR" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-guidance/dynamic-resource-allocation" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.0">
<title data-rh="true">Amazon EKS에서 GPU를 위한 동적 리소스 할당(Dynamic Resource Allocation) | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation"><meta data-rh="true" property="og:locale" content="ko_KR"><meta data-rh="true" property="og:locale:alternate" content="en_US"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Amazon EKS에서 GPU를 위한 동적 리소스 할당(Dynamic Resource Allocation) | AI on EKS"><meta data-rh="true" name="description" content="TL;DR - EKS에서 DRA를 사용한 동적 GPU 스케줄링"><meta data-rh="true" property="og:description" content="TL;DR - EKS에서 DRA를 사용한 동적 GPU 스케줄링"><link data-rh="true" rel="icon" href="/ai-on-eks/ko/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/guidance/dynamic-resource-allocation" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation" hreflang="ko-KR"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/guidance/dynamic-resource-allocation" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"EKS에서 동적 리소스 할당","item":"https://awslabs.github.io/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation"}]}</script><link rel="stylesheet" href="/ai-on-eks/ko/assets/css/styles.c270b852.css">
<script src="/ai-on-eks/ko/assets/js/runtime~main.84f685ef.js" defer="defer"></script>
<script src="/ai-on-eks/ko/assets/js/main.d98ac8f0.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><div class="theme-announcement-bar announcementBar_mb4j" style="background-color:#667eea;color:#ffffff" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">GenAI on EKS workshop series! <a target="_blank" rel="noopener noreferrer" href="https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=9be4af2e-2339-40ae-b5e9-57b6a7704c36&sc_channel=el" style="color: #ffffff; text-decoration: underline; font-weight: bold; margin-left: 10px;">Register now →</a></div><button type="button" aria-label="닫기" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/ko/"><div class="navbar__logo"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS 로고" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS 로고" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/infra">인프라</a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/blueprints">블루프린트</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/ko/docs/guidance">가이드</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/ai-on-eks/docs/guidance/dynamic-resource-allocation" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en-US">English</a></li><li><a href="/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko-KR">한국어</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="어두운 모드와 밝은 모드 전환하기 (현재 system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/guidance"><span title="AI 워크로드 가이드" class="linkLabel_WmDU">AI 워크로드 가이드</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/guidance/eks-best-practices"><span title="EKS 모범 사례" class="linkLabel_WmDU">EKS 모범 사례</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai-on-eks/ko/docs/guidance/benchmarking"><span title="Amazon EKS에서 LLM 추론 성능 벤치마킹" class="categoryLinkLabel_W154">Amazon EKS에서 LLM 추론 성능 벤치마킹</span></a><button aria-label="사이드바 분류 &#x27;Amazon EKS에서 LLM 추론 성능 벤치마킹&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai-on-eks/ko/docs/guidance/container-startup-time"><span title="Amazon EKS에서 AI/ML 추론 애플리케이션의 콜드 스타트 문제 해결" class="categoryLinkLabel_W154">Amazon EKS에서 AI/ML 추론 애플리케이션의 콜드 스타트 문제 해결</span></a><button aria-label="사이드바 분류 &#x27;Amazon EKS에서 AI/ML 추론 애플리케이션의 콜드 스타트 문제 해결&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation"><span title="EKS에서 동적 리소스 할당" class="linkLabel_WmDU">EKS에서 동적 리소스 할당</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/guidance/networking"><span title="AI를 위한 네트워킹" class="linkLabel_WmDU">AI를 위한 네트워킹</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/guidance/observability"><span title="관측성" class="linkLabel_WmDU">관측성</span></a></li></ul></nav><button type="button" title="사이드바 숨기기" aria-label="사이드바 숨기기" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ai-on-eks/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">EKS에서 동적 리소스 할당</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><header><h1>Amazon EKS에서 GPU를 위한 동적 리소스 할당(Dynamic Resource Allocation)</h1></header>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><strong>TL;DR - EKS에서 DRA를 사용한 동적 GPU 스케줄링</strong></summary><div><div class="collapsibleContent_i85q"><p><strong>DRA는 Kubernetes에서 차세대 GPU 스케줄링 접근 방식입니다.</strong> 동적 리소스 할당(Dynamic Resource Allocation, DRA)은 기존 디바이스 플러그인을 넘어서는 고급 GPU 관리 기능을 제공합니다. 핵심 내용은 다음과 같습니다:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="기존-gpu-스케줄링-대비-dra의-장점">기존 GPU 스케줄링 대비 DRA의 장점<a href="#기존-gpu-스케줄링-대비-dra의-장점" class="hash-link" aria-label="기존 GPU 스케줄링 대비 DRA의 장점에 대한 직접 링크" title="기존 GPU 스케줄링 대비 DRA의 장점에 대한 직접 링크" translate="no">​</a></h3><ul>
<li><strong>세밀한 리소스 제어</strong> - 전체 디바이스가 아닌 특정 GPU 메모리 양을 요청 가능</li>
<li><strong>워크로드별 공유 전략</strong> - 클러스터 전체가 아닌 Pod별로 <code>mps</code>, <code>time-slicing</code>, <code>mig</code>, <code>exclusive</code> 선택 가능</li>
<li><strong>토폴로지 인식 스케줄링</strong> - 멀티 GPU 워크로드를 위한 <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a>, <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a> 및 GPU 인터커넥트 이해</li>
<li><strong>고급 GPU 기능</strong> - <a href="https://aws.amazon.com/ec2/instance-types/p6/" target="_blank" rel="noopener noreferrer">Amazon EC2 P6e-GB200 UltraServers</a>의 <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a>, 멀티 노드 <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> 및 차세대 GPU 기능에 필수</li>
<li><strong>공존 친화적</strong> - 전환 기간 동안 기존 디바이스 플러그인과 함께 실행 가능</li>
</ul><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Amazon EC2 P6e-GB200 UltraServer 요구 사항</div><div class="admonitionContent_BuS1"><ul>
<li><strong>기존 스케줄링 미지원</strong> - Amazon EC2 P6e-GB200 UltraServers는 <strong>DRA가 필수</strong>이며 NVIDIA 디바이스 플러그인 + kube-scheduler와는 작동하지 않습니다</li>
<li><strong>DRA 필수</strong> - 멀티 노드 <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> 및 <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a> 기능은 DRA를 통해서만 사용 가능합니다</li>
</ul></div></div><p><strong>주요 구현 세부 사항:</strong></p><div class="statusGrid_yukc"><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">☸️</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">EKS 컨트롤 플레인</div><div class="badgeValue_YSlu">v1.33+</div><div class="badgeNote_j_gI">DRA 기능 게이트 활성화</div></div></div><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">🖥️</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">EKS 최적화 NVIDIA AMI</div><div class="badgeValue_YSlu">최신 AMI</div><div class="badgeNote_j_gI">드라이버 사전 설치</div></div></div><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">🔗</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">관리형 노드 그룹</div><div class="badgeValue_YSlu">완전한 DRA 지원</div><div class="badgeNote_j_gI">권장 접근 방식</div></div></div><div class="statusBadge_vHeB statusBadgeInfo_l0Xz"><span class="badgeIcon_t9jD">🔧</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">자체 관리형 노드 그룹</div><div class="badgeValue_YSlu">DRA 지원</div><div class="badgeNote_j_gI">수동 구성 필요</div></div></div><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">🛠️</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">NVIDIA GPU Operator</div><div class="badgeValue_YSlu">v25.3.0+</div><div class="badgeNote_j_gI">DRA에 필수</div></div></div><div class="statusBadge_vHeB statusBadgeProduction_H1Xf"><span class="badgeIcon_t9jD">⚡</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">NVIDIA DRA Driver</div><div class="badgeValue_YSlu">v25.3.0+</div><div class="badgeNote_j_gI">핵심 DRA 기능</div></div></div><div class="statusBadge_vHeB statusBadgeWarning_NMyw"><span class="badgeIcon_t9jD">🚧</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">Karpenter DRA 지원</div><div class="badgeValue_YSlu">개발 중</div><div class="badgeNote_j_gI">GitHub Issue #1231</div></div></div><div class="statusBadge_vHeB statusBadgeBeta_HeJs"><span class="badgeIcon_t9jD">🔬</span><div class="badgeContent_otGx"><div class="badgeTitle_t1R8">DRA 상태</div><div class="badgeValue_YSlu">베타 (K8s v1.32+)</div><div class="badgeNote_j_gI">기술 프리뷰</div></div></div></div><ul>
<li><strong>EKS v1.33</strong> - EKS 최적화 구성에서 DRA 기능 게이트 활성화</li>
<li><strong>상세한 DRA 구현</strong> - <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/" target="_blank" rel="noopener noreferrer">Kubernetes DRA 문서</a> 참조</li>
<li><strong>노드 프로비저닝 호환성:</strong>
<ul>
<li><strong>관리형 노드 그룹(Managed Node Groups)</strong> - 완전한 DRA 지원</li>
<li><strong>자체 관리형 노드 그룹(Self-Managed Node Groups)</strong> - DRA 지원 (수동 구성 필요)</li>
<li><strong>Karpenter</strong> - DRA 지원 개발 중 (<a href="https://github.com/kubernetes-sigs/karpenter/issues/1231" target="_blank" rel="noopener noreferrer">Issue #1231</a>)</li>
</ul>
</li>
<li><strong>공존</strong> - 기존 디바이스 플러그인과 DRA를 동시에 실행 가능</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="왜-dra에-karpenter-대신-관리형자체-관리형-노드-그룹인가">왜 DRA에 Karpenter 대신 관리형/자체 관리형 노드 그룹인가?<a href="#왜-dra에-karpenter-대신-관리형자체-관리형-노드-그룹인가" class="hash-link" aria-label="왜 DRA에 Karpenter 대신 관리형/자체 관리형 노드 그룹인가?에 대한 직접 링크" title="왜 DRA에 Karpenter 대신 관리형/자체 관리형 노드 그룹인가?에 대한 직접 링크" translate="no">​</a></h3><ul>
<li><strong>관리형/자체 관리형 노드 그룹</strong> - 완전한 DRA 지원, Capacity Block Reservations에 최적화</li>
<li><strong>Karpenter</strong> - DRA 지원 개발 중, 동적 스케일링이 예약된 GPU 용량과 충돌</li>
<li><strong>EKS 최적화 AMI</strong> - NVIDIA 드라이버가 사전 설치되어 제공</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="기존-gpu-할당과-dra를-함께-사용할-수-있나요">기존 GPU 할당과 DRA를 함께 사용할 수 있나요?<a href="#기존-gpu-할당과-dra를-함께-사용할-수-있나요" class="hash-link" aria-label="기존 GPU 할당과 DRA를 함께 사용할 수 있나요?에 대한 직접 링크" title="기존 GPU 할당과 DRA를 함께 사용할 수 있나요?에 대한 직접 링크" translate="no">​</a></h3><ul>
<li><strong>공존 지원</strong> - 동일한 클러스터에서 동시에 실행 가능</li>
<li><strong>DRA가 미래</strong> - NVIDIA와 Kubernetes는 DRA로 독점 전환 중</li>
<li><strong>마이그레이션 전략</strong> - 새로운 워크로드에 DRA, 기존 워크로드에는 기존 방식 사용</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="준비-상태">준비 상태<a href="#준비-상태" class="hash-link" aria-label="준비 상태에 대한 직접 링크" title="준비 상태에 대한 직접 링크" translate="no">​</a></h3><ul>
<li><strong>기술 프리뷰</strong> - GPU 할당 및 공유 기능은 NVIDIA에서 활발히 개발 중</li>
<li><strong>테스트 및 준비 완료</strong> - 멀티 노드 <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a>를 위한 ComputeDomains 완전 지원</li>
<li><strong>스케줄링 오버헤드</strong> - 클레임 해결 프로세스로 인한 추가 지연 시간</li>
<li><strong>정식 출시</strong> - Kubernetes v1.34 (2025)에서 예상</li>
<li><strong>최신 상태 업데이트</strong> - 현재 개발 진행 상황은 <a href="https://github.com/NVIDIA/k8s-dra-driver-gpu" target="_blank" rel="noopener noreferrer">NVIDIA DRA Driver GitHub</a> 참조</li>
</ul><div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>추가 리소스</div><div class="admonitionContent_BuS1"><p>EKS에서 AI/ML 워크로드에 대한 종합적인 가이드는 <a href="https://docs.aws.amazon.com/eks/latest/best-practices/aiml-compute.html#aiml-dra" target="_blank" rel="noopener noreferrer">AWS EKS Best Practices for AI/ML Compute</a>를 참조하십시오.</p></div></div></div></div></details>
<div class="callout_FLm9 calloutCritical_bQ1o"><div class="calloutHeader_B5_v"><span class="calloutIcon_GXtC">💸</span><h4>엔터프라이즈 GPU 활용 위기</h4></div><div class="calloutContent_aVah"><div class="statHighlight_FjI5"><span class="statNumber_ZY16">60%</span><span class="statLabel_TIh8">GPU 용량 낭비</span></div><p>높은 수요에도 불구하고 엔터프라이즈 AI 플랫폼은 스케줄링 제한으로 인해 GPU 리소스의 절반 이상을 지속적으로 낭비합니다. 이는 수백만 달러의 인프라 비용을 의미합니다.</p></div></div>
<p><strong>높은 수요의 AI 클러스터에서도 GPU 활용률은 종종 40% 미만입니다.</strong> 이는 구성 문제가 아닙니다 - Kubernetes가 GPU 리소스를 추상화하는 방식의 근본적인 한계입니다. 조직들은 GPU 인스턴스에 프리미엄 가격을 지불하면서 대부분의 컴퓨팅 파워를 유휴 상태로 두고 있습니다.</p>
<div class="sectionDivider_z07Q"><div class="dividerLine_oAnl"></div><div class="dividerIcon_Soi9">🎛️</div><div class="dividerLine_oAnl"></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="kubernetes에서의-gpu-스케줄링-과제">Kubernetes에서의 GPU 스케줄링 과제<a href="#kubernetes에서의-gpu-스케줄링-과제" class="hash-link" aria-label="Kubernetes에서의 GPU 스케줄링 과제에 대한 직접 링크" title="Kubernetes에서의 GPU 스케줄링 과제에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="현재-상태-기존-gpu-할당">현재 상태: 기존 GPU 할당<a href="#현재-상태-기존-gpu-할당" class="hash-link" aria-label="현재 상태: 기존 GPU 할당에 대한 직접 링크" title="현재 상태: 기존 GPU 할당에 대한 직접 링크" translate="no">​</a></h3>
<p>Kubernetes는 빠르게 엔터프라이즈 환경에서 AI/ML 워크로드를 오케스트레이션하는 사실상의 표준으로 진화했으며, Amazon EKS는 대규모 GPU 가속 인프라를 관리하는 선도적인 플랫폼으로 부상했습니다. 조직들은 P4d, P5 및 최신 P6 시리즈와 같은 GPU 인스턴스를 활용하여 소규모 추론 서비스부터 대규모 분산 학습 작업까지 모든 것을 EKS 클러스터에서 실행하고 있습니다.</p>
<p>그러나 Kubernetes가 컨테이너화된 워크로드를 관리하는 데 정교함에도 불구하고, 기존 GPU 스케줄링 모델은 놀라울 정도로 원시적이며 상당한 운영 과제를 만들어냅니다. 현재 접근 방식은 GPU를 단위로만 할당할 수 있는 단순하고 원자적인 리소스로 취급하며, 이는 현대 AI 워크로드의 다양하고 진화하는 요구 사항과 근본적으로 맞지 않습니다.</p>
<p><strong>기존 GPU 스케줄링 작동 방식:</strong></p>
<ul>
<li>Pod는 간단한 정수 값을 사용하여 GPU를 요청: <code>nvidia.com/gpu: 1</code></li>
<li>스케줄러는 GPU를 불투명하고 분할 불가능한 리소스로 취급</li>
<li>각 워크로드는 전체 GPU 디바이스에 대한 독점 접근 권한 획득</li>
<li>실제 리소스 요구 사항이나 GPU 토폴로지에 대한 인식 없음</li>
</ul>
<p><strong>이 접근 방식의 문제점:</strong>
현대 AI 워크로드는 이 이진 모델에 맞지 않는 다양한 요구 사항을 가지고 있습니다:</p>
<ul>
<li><strong>소규모 추론 작업</strong>은 2-4GB GPU 메모리만 필요하지만 전체 80GB A100이 할당됨</li>
<li><strong>대규모 학습 작업</strong>은 <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> 또는 <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a>를 통한 조정된 멀티 GPU 통신이 필요</li>
<li><strong>혼합 워크로드</strong>는 GPU를 효율적으로 공유할 수 있지만 별도의 디바이스로 강제됨</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="gpu-활용-위기">GPU 활용 위기<a href="#gpu-활용-위기" class="hash-link" aria-label="GPU 활용 위기에 대한 직접 링크" title="GPU 활용 위기에 대한 직접 링크" translate="no">​</a></h3>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>라이브 환경의 심각한 비효율성</div><div class="admonitionContent_BuS1"><p><strong>높은 수요의 클러스터에서도 GPU 활용률은 종종 40% 미만입니다.</strong> 이는 구성 문제가 아닙니다: Kubernetes가 GPU 리소스를 추상화하는 방식의 근본적인 한계입니다.</p></div></div>
<p><strong>비효율적인 GPU 할당의 일반적인 증상:</strong></p>
<ul>
<li><strong>큐 기아 상태(Queue starvation)</strong> - 소규모 추론 작업이 장시간 실행되는 학습 작업 뒤에서 대기</li>
<li><strong>리소스 단편화(Resource fragmentation)</strong> - GPU 메모리가 노드 전체에 사용할 수 없는 조각으로 분산</li>
<li><strong>토폴로지 무인식(Topology blindness)</strong> - 멀티 GPU 작업이 최적이 아닌 배치를 받아 <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> 성능 저하</li>
<li><strong>비용 폭발(Cost explosion)</strong> - 조직이 스케줄링 비효율성을 해결하기 위해 GPU를 과다 프로비저닝</li>
</ul>
<div class="sectionDivider_z07Q"><div class="dividerLine_oAnl"></div><div class="dividerIcon_Soi9">💎</div><div class="dividerLine_oAnl"></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="동적-리소스-할당dra-소개">동적 리소스 할당(DRA) 소개<a href="#동적-리소스-할당dra-소개" class="hash-link" aria-label="동적 리소스 할당(DRA) 소개에 대한 직접 링크" title="동적 리소스 할당(DRA) 소개에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dra가-변경하는-것">DRA가 변경하는 것<a href="#dra가-변경하는-것" class="hash-link" aria-label="DRA가 변경하는 것에 대한 직접 링크" title="DRA가 변경하는 것에 대한 직접 링크" translate="no">​</a></h3>
<p>동적 리소스 할당은 GPU 스케줄링을 경직된 디바이스 중심 모델에서 유연한 워크로드 인식 접근 방식으로 근본적으로 변환합니다:</p>
<p><strong>기존 접근 방식:</strong></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">limits</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 전체 GPU 획득, 커스터마이징 불가</span><br></span></code></pre></div></div>
<p><strong>DRA 접근 방식:</strong></p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">source</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template  </span><span class="token comment" style="color:#999988;font-style:italic"># 상세한 요구 사항</span><br></span></code></pre></div></div>
<p><em>ResourceClaimTemplate 구성은 아래 예제 섹션을 참조하십시오.</em></p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>네임스페이스 요구 사항</div><div class="admonitionContent_BuS1"><p><strong>중요:</strong> ResourceClaims는 이를 참조하는 Pod와 동일한 네임스페이스에 존재해야 합니다. 네임스페이스 간 리소스 클레임은 지원되지 않습니다.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="주요-dra-혁신">주요 DRA 혁신<a href="#주요-dra-혁신" class="hash-link" aria-label="주요 DRA 혁신에 대한 직접 링크" title="주요 DRA 혁신에 대한 직접 링크" translate="no">​</a></h3>
<div class="dra-innovations-grid"><div class="innovation-card innovation-card--primary"><div class="innovation-card__header"><div class="innovation-card__icon">🎯</div><h4>세밀한 리소스 제어</h4></div><div class="innovation-card__content"><ul class="innovation-card__features"><li>특정 GPU 메모리 양 요청 (예: 사용 가능한 80Gi 중 16Gi)</li><li>메모리 요구 사항과 독립적으로 컴퓨팅   요구 사항 지정</li><li>멀티 GPU 워크로드에 대한 토폴로지 제약 정의</li></ul><div class="innovation-card__note"><p><strong>참고:</strong> ResourceClaims와 Pod는 동일한 네임스페이스에 있어야 합니다</p></div></div></div><div class="innovation-card innovation-card--secondary"><div class="innovation-card__header"><div class="innovation-card__icon">🔄</div><h4>워크로드별 공유 전략</h4></div><div class="innovation-card__content"><div class="strategy-grid"><div class="strategy-item"><p><strong>MPS</strong> - 메모리 격리를 통한 동시 소규모 워크로드</p></div><div class="strategy-item"><p><strong>Time-slicing</strong> - 서로 다른 피크 사용 패턴을 가진 워크로드</p></div><div class="strategy-item"><p><strong>MIG</strong> - 멀티 테넌트 환경에서의 하드웨어 수준 격리</p></div><div class="strategy-item"><p><strong>Exclusive</strong> - 성능이 중요한 학습 작업</p></div></div></div></div><div class="innovation-card innovation-card--success"><div class="innovation-card__header"><div class="innovation-card__icon">🌐</div><h4>토폴로지 인식 스케줄링</h4></div><div class="innovation-card__content"><ul class="innovation-card__features"><li>GPU 간 <a href="https://www.nvidia.com/en-us/data-center/nvlink/">NVLink</a> 연결 이해</li><li><a href="https://aws.amazon.com/ec2/instance-types/p6/">Amazon EC2 P6e-GB200 UltraServer</a> 클러스터에 <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html">IMEX</a> 활용</li><li>분산 학습 워크로드에 대한 배치 최적화</li></ul></div></div><div class="innovation-card innovation-card--warning"><div class="innovation-card__header"><div class="innovation-card__icon">🚀</div><h4>미래 대비 아키텍처</h4></div><div class="innovation-card__content"><ul class="innovation-card__features"><li><a href="https://aws.amazon.com/ec2/instance-types/p6/">Amazon EC2 P6e-GB200 UltraServers</a>와 같은 차세대 시스템에 필수</li><li>멀티 노드 <a href="https://www.nvidia.com/en-us/data-center/nvlink/">NVLink</a>와 같은 고급 기능 활성화</li><li>새로운 GPU 아키텍처 및 공유 기술 지원</li></ul></div></div></div>
<style>
.dra-innovations-grid {
display: grid;
grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
gap: 1.5rem;
margin: 2rem 0;
}

.innovation-card {
background: var(--ifm-background-surface-color);
border: 1px solid var(--ifm-color-emphasis-300);
border-radius: 12px;
padding: 1.5rem;
transition: all 0.3s ease;
box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
}

.innovation-card:hover {
transform: translateY(-4px);
box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
}

.innovation-card--primary {
border-left: 4px solid var(--ifm-color-primary);
}

.innovation-card--secondary {
border-left: 4px solid var(--ifm-color-secondary);
}

.innovation-card--success {
border-left: 4px solid var(--ifm-color-success);
}

.innovation-card--warning {
border-left: 4px solid var(--ifm-color-warning);
}

.innovation-card__header {
display: flex;
align-items: center;
margin-bottom: 1rem;
}

.innovation-card__icon {
font-size: 2rem;
margin-right: 0.75rem;
}

.innovation-card__header h4 {
margin: 0;
font-size: 1.25rem;
font-weight: 600;
}

.innovation-card__content {
color: var(--ifm-color-content-secondary);
}

.innovation-card__features {
margin: 0;
padding-left: 1rem;
}

.innovation-card__features li {
margin-bottom: 0.5rem;
}

.innovation-card__note {
background: var(--ifm-color-warning-contrast-background);
border: 1px solid var(--ifm-color-warning-contrast-border);
border-radius: 6px;
padding: 0.75rem;
margin-top: 1rem;
font-size: 0.875rem;
}

.strategy-grid {
display: grid;
grid-template-columns: 1fr 1fr;
gap: 0.75rem;
}

.strategy-item {
background: var(--ifm-color-emphasis-100);
padding: 0.75rem;
border-radius: 6px;
font-size: 0.875rem;
border-left: 3px solid var(--ifm-color-secondary);
}

@media (max-width: 768px) {
.dra-innovations-grid {
  grid-template-columns: 1fr;
}

.strategy-grid {
  grid-template-columns: 1fr;
}
}
</style>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="imex-computedomains-및-amazon-ec2-p6e-gb200-멀티-노드-스케줄링-이해">IMEX, ComputeDomains 및 Amazon EC2 P6e-GB200 멀티 노드 스케줄링 이해<a href="#imex-computedomains-및-amazon-ec2-p6e-gb200-멀티-노드-스케줄링-이해" class="hash-link" aria-label="IMEX, ComputeDomains 및 Amazon EC2 P6e-GB200 멀티 노드 스케줄링 이해에 대한 직접 링크" title="IMEX, ComputeDomains 및 Amazon EC2 P6e-GB200 멀티 노드 스케줄링 이해에 대한 직접 링크" translate="no">​</a></h3>
<p>**<a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a> (NVIDIA Internode Memory Exchange/Management Service)**는 <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> 멀티 노드 배포에서 GPU 메모리 공유를 위한 NVIDIA의 오케스트레이션 서비스입니다. <a href="https://aws.amazon.com/ec2/instance-types/p6/" target="_blank" rel="noopener noreferrer">Amazon EC2 P6e-GB200 UltraServer</a> 구성에서 IMEX는 노드 간 메모리 내보내기 및 가져오기 작업을 조정하여 수십억 개의 매개변수를 가진 대규모 AI 모델 학습을 위해 여러 컴퓨팅 노드에서 직접 GPU-to-GPU 메모리 접근을 가능하게 합니다.</p>
<p><strong>ComputeDomains</strong>는 <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a> 또는 <a href="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html" target="_blank" rel="noopener noreferrer">IMEX</a>와 같은 고대역폭 연결을 통해 효율적으로 통신할 수 있는 상호 연결된 GPU의 논리적 그룹을 나타냅니다. DRA는 ComputeDomains를 사용하여 GPU 토폴로지를 이해하고 멀티 GPU 조정이 필요한 워크로드가 적절하게 연결된 하드웨어에 스케줄링되도록 합니다.</p>
<p><strong>Amazon EC2 P6e-GB200 멀티 노드 스케줄링</strong>은 DRA의 토폴로지 인식을 활용하여 여러 수퍼칩 노드에서 워크로드를 조정합니다. 기존 GPU 스케줄링은 이러한 복잡한 인터커넥트 관계를 이해할 수 없으므로, 적절한 GPU 토폴로지 선택이 학습 성능에 직접적으로 영향을 미치는 <a href="https://aws.amazon.com/ec2/instance-types/p6/" target="_blank" rel="noopener noreferrer">Amazon EC2 P6e-GB200 UltraServer</a> 시스템에서 분산 학습 작업의 최적 배치를 위해 DRA가 필수적입니다.</p>
<p>자세한 구성 예제 및 구현 가이드는 <a href="https://docs.aws.amazon.com/eks/latest/best-practices/aiml-compute.html#aiml-dra" target="_blank" rel="noopener noreferrer">AWS EKS AI/ML Best Practices 문서</a>를 참조하십시오.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="eks-구현-고려-사항">EKS 구현 고려 사항<a href="#eks-구현-고려-사항" class="hash-link" aria-label="EKS 구현 고려 사항에 대한 직접 링크" title="EKS 구현 고려 사항에 대한 직접 링크" translate="no">​</a></h2>
<p>DRA의 기능과 IMEX 및 ComputeDomains와 같은 고급 기능을 이해했으므로, Amazon EKS에서 DRA를 구현하기 위한 실질적인 고려 사항을 살펴보겠습니다. 다음 섹션에서는 노드 프로비저닝, 마이그레이션 전략 및 DRA 배포 성공을 결정할 EKS 특정 구성에 대한 주요 결정 사항을 다룹니다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="p-시리즈-gpu-인스턴스와-dra를-위한-관리형-노드-그룹-vs-karpenter">P-시리즈 GPU 인스턴스와 DRA를 위한 관리형 노드 그룹 vs Karpenter<a href="#p-시리즈-gpu-인스턴스와-dra를-위한-관리형-노드-그룹-vs-karpenter" class="hash-link" aria-label="P-시리즈 GPU 인스턴스와 DRA를 위한 관리형 노드 그룹 vs Karpenter에 대한 직접 링크" title="P-시리즈 GPU 인스턴스와 DRA를 위한 관리형 노드 그룹 vs Karpenter에 대한 직접 링크" translate="no">​</a></h3>
<p>DRA를 위한 노드 프로비저닝 방법 선택은 단순히 기술적 호환성에 관한 것이 아닙니다. 이는 근본적으로 엔터프라이즈 AI 워크로드에서 GPU 용량이 구매되고 활용되는 방식에 관한 것입니다. <strong>관리형 및 자체 관리형 노드 그룹은 현재 DRA에 권장되는 접근 방식인데, 이는 고급 GPU 인스턴스의 경제성 및 운영 패턴과 일치하기 때문입니다.</strong></p>
<p>그 이유는 다음과 같습니다: 대부분의 대형 GPU 인스턴스(<a href="https://aws.amazon.com/ec2/instance-types/p4/" target="_blank" rel="noopener noreferrer">P4d</a> (A100), <a href="https://aws.amazon.com/ec2/instance-types/p5/" target="_blank" rel="noopener noreferrer">P5</a> (H100), <a href="https://aws.amazon.com/ec2/instance-types/p6/" target="_blank" rel="noopener noreferrer">B200이 탑재된 P6</a>, <a href="https://www.nvidia.com/en-us/data-center/gb200-nvl72/" target="_blank" rel="noopener noreferrer">GB200이 탑재된 P6e</a>)는 온디맨드 가격이 아닌 AWS Capacity Block Reservations를 통해 주로 사용 가능합니다. <strong>조직이 Capacity Blocks를 구매하면 GPU가 실제로 활용되는지 여부와 관계없이 예약이 만료될 때까지 모든 GPU 시간에 대해 비용을 지불하기로 약속합니다.</strong> 이는 워크로드 수요에 따른 동적 스케일링이라는 Karpenter의 핵심 가치 제안과 근본적인 불일치를 만듭니다. 낮은 수요 기간에 노드를 축소해도 비용이 절약되지 않습니다. 실제로 이미 지불하고 있는 예약된 용량을 낭비하는 것입니다.</p>
<p>또한, <strong>Karpenter는 아직 DRA 스케줄링을 지원하지 않아</strong> (<a href="https://github.com/kubernetes-sigs/karpenter/issues/1231" target="_blank" rel="noopener noreferrer">Issue #1231</a>에서 활발히 개발 중) DRA 워크로드와 호환되지 않습니다. Karpenter는 일반 컴퓨팅 워크로드의  동적 스케일링을 통한 비용 최적화에 탁월하지만, <strong>Capacity Block 예약은 ROI를 극대화하기 위해 &quot;상시 가동&quot; 활용 전략이 필요합니다</strong>: 바로 관리형 노드 그룹이 정적 용량 모델로 제공하는 것입니다.</p>
<p><strong>미래는 더 낙관적입니다:</strong> Karpenter의 로드맵에는 Capacity Block 시나리오에 적합한 정적 노드 기능이 포함되어 있습니다. 커뮤니티는 <a href="https://github.com/kubernetes-sigs/karpenter/issues/749" target="_blank" rel="noopener noreferrer">워크로드 없이 수동 노드 프로비저닝</a> 및 <a href="https://github.com/kubernetes-sigs/karpenter/pull/2309" target="_blank" rel="noopener noreferrer">정적 프로비저닝</a>, <a href="https://github.com/kubernetes-sigs/karpenter/pull/2397" target="_blank" rel="noopener noreferrer">수동 노드 프로비저닝</a>과 같은 RFC를 통한 정적 프로비저닝 기능을 적극적으로 개발하고 있습니다. DRA 지원이 이러한 정적 프로비저닝 기능과 함께 추가되면 Karpenter는 Capacity Block ML 예약 인스턴스와 함께 DRA 워크로드에 선호되는 선택이 될 수 있습니다. 그때까지는 <strong>NVIDIA 드라이버가 사전 설치된 EKS 최적화 AMI를 사용하는 관리형 노드 그룹이 DRA 구현을 위한 가장 신뢰할 수 있는 기반을 제공합니다.</strong></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dra와-기존-gpu-할당-공존">DRA와 기존 GPU 할당 공존<a href="#dra와-기존-gpu-할당-공존" class="hash-link" aria-label="DRA와 기존 GPU 할당 공존에 대한 직접 링크" title="DRA와 기존 GPU 할당 공존에 대한 직접 링크" translate="no">​</a></h3>
<p><strong>예, 충돌을 피하기 위해 신중한 구성이 필요합니다.</strong> DRA와 기존 GPU 할당은 동일한 클러스터에서 공존할 수 있지만, 리소스 이중 할당 문제를 방지하기 위해 신중한 설정이 필요합니다. NVIDIA의 DRA 드라이버는 충돌을 방지하기 위해 선택적 활성화가 가능한 GPU Operator와 함께하는 추가 구성 요소로 설계되었습니다.</p>
<p><strong>점진적 마이그레이션을 위한 권장 접근 방식:</strong> NVIDIA DRA 드라이버를 처음에는 특정 하위 시스템만 활성화하도록 구성합니다. 예를 들어, GPU 할당에 기존 디바이스 플러그인을 사용하면서 멀티 노드 NVLink 기능을 위해 DRA의 ComputeDomain 하위 시스템을 활성화하도록 <code>resources.gpus.enabled=false</code>를 설정할 수 있습니다. 이를 통해 팀은 기존 GPU 할당 워크플로우를 위험에 빠뜨리지 않고 DRA의 고급 기능에 대한 운영 경험을 쌓을 수 있습니다.</p>
<p><strong>공존을 위한 주요 고려 사항:</strong></p>
<ul>
<li><strong>동일 디바이스 충돌 방지</strong>: DRA와 디바이스 플러그인이 동일한 GPU 디바이스를 동시에 관리해서는 안 됨</li>
<li><strong>선택적 구성 요소 활성화</strong>: NVIDIA DRA 드라이버의 모듈식 설계를 사용하여 기능을 점진적으로 활성화</li>
<li><strong>노드 셀렉터 관리</strong>: 리소스 할당 충돌을 방지하기 위해 노드 셀렉터를 신중하게 구성</li>
<li><strong>기술 프리뷰 상태</strong>: GPU 할당 및 공유 기능은 기술 프리뷰 상태 (업데이트는 <a href="https://github.com/NVIDIA/k8s-dra-driver-gpu" target="_blank" rel="noopener noreferrer">NVIDIA DRA Driver GitHub</a> 확인)</li>
</ul>
<p><strong>마이그레이션 계획의 경우,</strong> 멀티 노드 <a href="https://www.nvidia.com/en-us/data-center/nvlink/" target="_blank" rel="noopener noreferrer">NVLink</a>를 위한 ComputeDomains와 같은 DRA의 기능으로 시작하고, 핵심 GPU 할당에는 기존 디바이스 플러그인을 유지합니다. DRA의 GPU 할당이 완전히 지원되면 미션 크리티컬한 학습 작업 전에 개발 및 추론 서비스부터 시작하여 점진적으로 워크로드를  마이그레이션합니다. <strong>NVIDIA와 Kubernetes 커뮤니티는 DRA를 디바이스 플러그인의 궁극적인 대체제로 설계했지만</strong>, 전환은 클러스터 안정성을 유지하기 위해 신중한 오케스트레이션이 필요합니다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="시각적-비교-기존-방식-vs-dra">시각적 비교: 기존 방식 vs DRA<a href="#시각적-비교-기존-방식-vs-dra" class="hash-link" aria-label="시각적 비교: 기존 방식 vs DRA에 대한 직접 링크" title="시각적 비교: 기존 방식 vs DRA에 대한 직접 링크" translate="no">​</a></h3>
<p>아래 다이어그램은 DRA가 스케줄링 흐름을 근본적으로 어떻게 변경하는지 보여줍니다:</p>
<ul>
<li><strong>기존 모델</strong>: Pod가 노드 리소스 모델을 통해 전체 GPU를 직접 요청합니다. 스케줄링과 할당은 정적이며 부분 사용이나 워크로드 의도를 표현할 여지가 없습니다.</li>
<li><strong>DRA 모델</strong>: Pod는 템플릿을 통해 의도를 표현합니다; 클레임은 DRA 인식 스케줄러와 디바이스 드라이버의 도움으로 동적으로 생성되고 해결됩니다. 여러 워크로드가 GPU를 안전하고 효율적으로 공유하여 활용률을 극대화할 수 있습니다.</li>
</ul>
<!-- -->
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="기술-역량-비교">기술 역량 비교<a href="#기술-역량-비교" class="hash-link" aria-label="기술 역량 비교에 대한 직접 링크" title="기술 역량 비교에 대한 직접 링크" translate="no">​</a></h3>
<div class="capabilityComparison_G6Wg"><div class="comparisonHeader_puLN"><div>Capability</div><div>🔴 Traditional Device Plugin</div><div>🟢 Dynamic Resource Allocation (DRA)</div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>리소스 요청 모델</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusNone_kihA">❌</span><div class="capabilityDesc_xW7N">단순 정수<div><code>nvidia.com/gpu: 1</code></div></div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">✅</span><div class="capabilityDesc_xW7N">구조화된 클레임<div><code>ResourceClaimTemplate</code></div></div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>GPU 메모리 지정</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusNone_kihA">❌</span><div class="capabilityDesc_xW7N">전부 또는 전무 할당</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">✅</span><div class="capabilityDesc_xW7N">메모리 기반 제약 및 셀렉터</div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>공유 구성</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusLimited_tWm3">⚠️</span><div class="capabilityDesc_xW7N">정적 클러스터 전체 ConfigMaps</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">✅</span><div class="capabilityDesc_xW7N">워크로드별 공유 전략</div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>멀티 GPU 토폴로지 인식</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusNone_kihA">❌</span><div class="capabilityDesc_xW7N">토폴로지 조정 없음</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">✅</span><div class="capabilityDesc_xW7N">NVLink, IMEX용 DeviceClass 셀렉터</div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>런타임 재구성</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusNone_kihA">❌</span><div class="capabilityDesc_xW7N">Pod 삭제 및 재배포 필요</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">✅</span><div class="capabilityDesc_xW7N">재시작 없이 동적 재할당</div></div></div><div class="comparisonRow_muiZ"><div class="capabilityName_VMRR"><strong>MIG 지원</strong></div><div class="traditionalCell_nR1h"><span class="capabilityStatus_V2IX capabilityStatusLimited_tWm3">⚠️</span><div class="capabilityDesc_xW7N">제한적 - 정적 파티션, 수동 설정</div></div><div class="draCell_y36_"><span class="capabilityStatus_V2IX capabilityStatusFull_MpPh">✅</span><div class="capabilityDesc_xW7N">동적 클레임을 통한 완전한 MIG 프로필</div></div></div></div>
<div class="sectionDivider_z07Q"><div class="dividerLine_oAnl"></div><div class="dividerIcon_Soi9">⚙️</div><div class="dividerLine_oAnl"></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dra-실제-작동-원리-완전한-기술-흐름">DRA 실제 작동 원리: 완전한 기술 흐름<a href="#dra-실제-작동-원리-완전한-기술-흐름" class="hash-link" aria-label="DRA 실제 작동 원리: 완전한 기술 흐름에 대한 직접 링크" title="DRA 실제 작동 원리: 완전한 기술 흐름에 대한 직접 링크" translate="no">​</a></h2>
<p>동적 리소스 할당(DRA)은 GPU 및 기타 디바이스 리소스를 처리하기 위한 모듈식 플러그 가능 메커니즘으로 Kubernetes 스케줄링을 확장합니다. 불투명한 하드웨어의 정수 단위를 할당하는 대신, DRA는 런타임에 디바이스 요구 사항을 표현, 매칭 및 프로비저닝하기 위해 <code>ResourceClaims</code>, <code>ResourceClaimTemplates</code>, <code>DeviceClasses</code> 및 <code>ResourceSlices</code>를 도입합니다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="단계별-dra-워크플로우">단계별 DRA 워크플로우<a href="#단계별-dra-워크플로우" class="hash-link" aria-label="단계별 DRA 워크플로우에 대한 직접 링크" title="단계별 DRA 워크플로우에 대한 직접 링크" translate="no">​</a></h3>
<p>DRA는 정교한 오케스트레이션을 통해 Kubernetes가 GPU 리소스를 관리하는 방식을 근본적으로 변경합니다:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-리소스-검색-및-광고">1. 리소스 검색 및 광고<a href="#1-리소스-검색-및-광고" class="hash-link" aria-label="1. 리소스 검색 및 광고에 대한 직접 링크" title="1. 리소스 검색 및 광고에 대한 직접 링크" translate="no">​</a></h4>
<p>NVIDIA DRA 드라이버가 시작되면 각 노드에서 사용 가능한 GPU를 검색하고 Kubernetes API 서버에 디바이스 기능을 광고하는 <strong>ResourceSlices</strong>를 생성합니다.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-deviceclass-등록">2. DeviceClass 등록<a href="#2-deviceclass-등록" class="hash-link" aria-label="2. DeviceClass 등록에 대한 직접 링크" title="2. DeviceClass 등록에 대한 직접 링크" translate="no">​</a></h4>
<p>드라이버는 GPU 리소스를 논리적으로 그룹화하기 위해 하나 이상의 <code>DeviceClass</code> 객체를 등록합니다:</p>
<ul>
<li><code>gpu.nvidia.com</code>: 표준 GPU 리소스</li>
<li><code>mig.nvidia.com</code>: Multi-Instance GPU 파티션</li>
<li><code>compute-domain.nvidia.com</code>: 노드 간 GPU 조정</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-리소스-클레임-생성">3. 리소스 클레임 생성<a href="#3-리소스-클레임-생성" class="hash-link" aria-label="3. 리소스 클레임 생성에 대한 직접 링크" title="3. 리소스 클레임 생성에 대한 직접 링크" translate="no">​</a></h4>
<p><strong>ResourceClaimTemplates</strong>는 각 Pod에 대해 다음을 지정하는 개별 <strong>ResourceClaims</strong>를 생성합니다:</p>
<ul>
<li>특정 GPU 메모리 요구 사항</li>
<li>공유 전략 (MPS, time-slicing, exclusive)</li>
<li>드라이버 버전 및 컴퓨팅 기능</li>
<li>멀티 GPU 워크로드에 대한 토폴로지 제약</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-지능형-스케줄링">4. 지능형 스케줄링<a href="#4-지능형-스케줄링" class="hash-link" aria-label="4. 지능형 스케줄링에 대한 직접 링크" title="4. 지능형 스케줄링에 대한 직접 링크" translate="no">​</a></h4>
<p>DRA 인식 스케줄러는 보류 중인 <code>ResourceClaims</code>를 평가하고 노드 전체에서 사용 가능한 <code>ResourceSlices</code>를 쿼리합니다:</p>
<ul>
<li>CEL 표현식을 사용하여 디바이스 속성 및 제약 조건 매칭</li>
<li>다른 실행 중인 Pod와의 공유 전략 호환성 확인</li>
<li>토폴로지, 가용성 및 정책을 고려하여 최적의 노드 선택</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="5-동적-할당">5. 동적 할당<a href="#5-동적-할당" class="hash-link" aria-label="5. 동적 할당에 대한 직접 링크" title="5. 동적 할당에 대한 직접 링크" translate="no">​</a></h4>
<p>선택된 노드에서 DRA 드라이버는:</p>
<ul>
<li>컨테이너에 대한 디바이스 접근 설정 (예: MIG 인스턴스 마운트 또는 MPS 구성)</li>
<li>클레임 구성에 따라 공유 vs 독점 접근 할당</li>
<li>동시 워크로드 간 GPU 슬라이스를 안전하게 격리</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="솔루션-배포">솔루션 배포<a href="#솔루션-배포" class="hash-link" aria-label="솔루션 배포에 대한 직접 링크" title="솔루션 배포에 대한 직접 링크" translate="no">​</a></h2>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><strong>이 예제에서는 DRA를 지원하는 Amazon EKS에 JARK 클러스터를 프로비저닝합니다</strong></summary><div><div class="collapsibleContent_i85q"><div class="progressSteps_j3Cn"><div class="step_wyHJ stepCurrent_baCR"><div class="stepNumber_JvFJ">1</div><div class="stepContent_kF1B"><h4>사전 요구 사항</h4><p>필수 도구 및 종속성 설치</p></div></div><div class="step_wyHJ"><div class="stepNumber_JvFJ">2</div><div class="stepContent_kF1B"><h4>배포</h4><p>JARK 스택 설치 구성 및 실행</p></div></div><div class="step_wyHJ"><div class="stepNumber_JvFJ">3</div><div class="stepContent_kF1B"><h4>확인</h4><p>DRA 배포 테스트 및 기능 검증</p></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="사전-요구-사항">사전 요구 사항<a href="#사전-요구-사항" class="hash-link" aria-label="사전 요구 사항에 대한 직접 링크" title="사전 요구 사항에 대한 직접 링크" translate="no">​</a></h3><p>머신에 다음 도구가 설치되어 있는지 확인합니다:</p><ul>
<li><strong><a href="https://aws.amazon.com/cli/" target="_blank" rel="noopener noreferrer">AWS CLI</a></strong> - AWS 명령줄 인터페이스</li>
<li><strong>kubectl</strong> - Kubernetes 명령줄 도구</li>
<li><strong>terraform</strong> - Infrastructure as Code 도구</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="배포">배포<a href="#배포" class="hash-link" aria-label="배포에 대한 직접 링크" title="배포에 대한 직접 링크" translate="no">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-저장소-복제">1. 저장소 복제:<a href="#1-저장소-복제" class="hash-link" aria-label="1. 저장소 복제:에 대한 직접 링크" title="1. 저장소 복제:에 대한 직접 링크" translate="no">​</a></h4><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">저장소 복제</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/awslabs/ai-on-eks.git</span><br></span></code></pre></div></div><div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>인증 프로필</div><div class="admonitionContent_BuS1"><p>인증에 프로필을 사용하는 경우 <code>export AWS_PROFILE=&quot;&lt;PROFILE_name&gt;&quot;</code>을 원하는 프로필 이름으로 설정합니다</p></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-구성-검토-및-사용자-정의">2. 구성 검토 및 사용자 정의:<a href="#2-구성-검토-및-사용자-정의" class="hash-link" aria-label="2. 구성 검토 및 사용자 정의:에 대한 직접 링크" title="2. 구성 검토 및 사용자 정의:에 대한 직접 링크" translate="no">​</a></h4><ul>
<li><code>infra/base/terraform/variables.tf</code>에서 사용 가능한 애드온 확인</li>
<li>필요에 따라 <code>infra/jark-stack/terraform/blueprint.tfvars</code>에서 애드온 설정 수정</li>
<li><code>blueprint.tfvars</code>에서 AWS 리전 업데이트</li>
</ul><p><strong>DRA 구성 요소 활성화:</strong></p><p><a href="https://github.com/awslabs/ai-on-eks/blob/main/infra/jark-stack/terraform/blueprint.tfvars" target="_blank" rel="noopener noreferrer"><code>blueprint.tfvars</code></a> 파일에서 다음 줄의 주석을 해제합니다:</p><div class="language-hcl codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">blueprint.tfvars</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-hcl codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token property" style="color:#36acaa">enable_nvidia_dra_driver</span><span class="token plain">         </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token property" style="color:#36acaa">enable_nvidia_gpu_operator</span><span class="token plain">       </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">true</span></span><br></span></code></pre></div></div><div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>자동 설정</div><div class="admonitionContent_BuS1"><p>NVIDIA GPU Operator에는 필요한 모든 구성 요소가 포함됩니다:</p><ul>
<li>NVIDIA Device Plugin</li>
<li>DCGM Exporter</li>
<li>MIG Manager</li>
<li>GPU Feature Discovery</li>
<li>Node Feature Discovery</li>
</ul><p>NVIDIA DRA Driver는 GPU Operator와 병렬로 별도의 Helm 차트로 배포됩니다.</p></div></div><div class="progressSteps_j3Cn"><div class="step_wyHJ stepCompleted_BhoT"><div class="stepNumber_JvFJ">1</div><div class="stepContent_kF1B"><h4>사전 요구 사항</h4><p>필수 도구 및 종속성 설치</p></div></div><div class="step_wyHJ stepCurrent_baCR"><div class="stepNumber_JvFJ">2</div><div class="stepContent_kF1B"><h4>배포</h4><p>JARK 스택 설치 구성 및 실행</p></div></div><div class="step_wyHJ"><div class="stepNumber_JvFJ">3</div><div class="stepContent_kF1B"><h4>확인</h4><p>DRA 배포 테스트 및 기능 검증</p></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-배포-디렉토리로-이동하고-설치-스크립트-실행">3. 배포 디렉토리로 이동하고 설치 스크립트 실행:<a href="#3-배포-디렉토리로-이동하고-설치-스크립트-실행" class="hash-link" aria-label="3. 배포 디렉토리로 이동하고 설치 스크립트 실행:에 대한 직접 링크" title="3. 배포 디렉토리로 이동하고 설치 스크립트 실행:에 대한 직접 링크" translate="no">​</a></h4><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">DRA가 포함된 JARK 스택 배포</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/infra/jark-stack </span><span class="token operator" style="color:#393A34">&amp;&amp;</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> +x install.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./install.sh</span><br></span></code></pre></div></div><p>이 스크립트는 다음 구성 요소를 자동으로 프로비저닝하고 구성합니다:</p><ul>
<li>DRA(동적 리소스 할당) 기능 게이트가 활성화된 Amazon EKS 클러스터</li>
<li>Amazon Linux 2023 GPU AMI를 사용하는 두 개의 GPU 관리형 노드 그룹:</li>
<li>G6 노드 그룹: MPS 및 time-slicing 전략 테스트용</li>
<li>P4d(e) 노드 그룹: MIG 기반 GPU 파티셔닝 테스트용</li>
</ul><blockquote>
<p>두 노드 그룹 모두 불필요한 비용을 피하기 위해 노드 0개로 초기화됩니다.</p>
</blockquote><ul>
<li>MPS/time-slicing을 테스트하려면 EKS 콘솔을 통해 <code>g6</code> 노드 그룹의 <code>min_size</code> 및 <code>desired_size</code>를 수동으로 업데이트합니다</li>
<li>MIG를 테스트하려면 Capacity Block Reservation(CBR)이 필요한 최소 하나의 <code>p4d</code> 또는 <code>p4de</code> 인스턴스가 필요합니다. 파일 편집: <code>infra/base/terraform/eks.tf</code>. 실제 <code>capacity_reservation_id</code>를 설정하고 MIG 노드 그룹의 <code>min_size</code>를 <code>1</code>로 변경합니다</li>
</ul><div class="progressSteps_j3Cn"><div class="step_wyHJ stepCompleted_BhoT"><div class="stepNumber_JvFJ">1</div><div class="stepContent_kF1B"><h4>사전 요구 사항</h4><p>필수 도구 및 종속성 설치</p></div></div><div class="step_wyHJ stepCompleted_BhoT"><div class="stepNumber_JvFJ">2</div><div class="stepContent_kF1B"><h4>배포</h4><p>JARK 스택 설치 구성 및 실행</p></div></div><div class="step_wyHJ stepCurrent_baCR"><div class="stepNumber_JvFJ">3</div><div class="stepContent_kF1B"><h4>확인</h4><p>DRA 배포 테스트 및 기능 검증</p></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-배포-확인">4. 배포 확인<a href="#4-배포-확인" class="hash-link" aria-label="4. 배포 확인에 대한 직접 링크" title="4. 배포 확인에 대한 직접 링크" translate="no">​</a></h4><p>DRA 배포가 올바르게 작동하는지 확인하려면 다음 단계를 따릅니다:</p><p><strong>단계 1: kubectl 접근 구성</strong></p><p>Kubernetes 클러스터에 접근하기 위해 로컬 kubeconfig를 업데이트합니다:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">aws eks update-kubeconfig </span><span class="token parameter variable" style="color:#36acaa">--name</span><span class="token plain"> jark-stack  </span><span class="token comment" style="color:#999988;font-style:italic"># EKS 클러스터 이름으로 교체</span><br></span></code></pre></div></div><p><strong>단계 2: 워커 노드 확인</strong></p><p>먼저 클러스터에서 워커 노드가 실행 중인지 확인합니다:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get nodes</span><br></span></code></pre></div></div><p><strong>예상 출력:</strong> 코어 노드 그룹의 두 개의 x86 인스턴스와 EKS 콘솔을 통해 수동으로 스케일 업한 GPU 인스턴스(g6, p4d 등)가 표시되어야 합니다.</p><p><strong>단계 3: DRA 구성 요소 확인</strong></p><p>NVIDIA GPU Operator 및 NVIDIA DRA Driver를 포함한 모든 배포를 확인하려면 다음 명령을 실행합니다:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get deployments </span><span class="token parameter variable" style="color:#36acaa">-A</span><br></span></code></pre></div></div><p><strong>예상 출력:</strong> 아래 예제를 테스트하기 전에 모든 Pod가 <code>Running</code> 상태여야 합니다.</p><p><strong>테스트를 위한 인스턴스 호환성:</strong></p><ul>
<li><strong>Time-slicing 및 MPS</strong>: 모든 G5 또는 G6 인스턴스</li>
<li><strong>MIG 파티셔닝</strong>: P-시리즈 인스턴스 (P4d 이상)</li>
<li><strong>IMEX 사용 사례</strong>: P6e-GB200 UltraServers</li>
</ul><p>모든 구성 요소가 실행되면 다음 섹션에 언급된 다양한 DRA 예제 테스트를 시작할 수 있습니다.</p></div></div></details>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="구성-요소-아키텍처">구성 요소 아키텍처<a href="#구성-요소-아키텍처" class="hash-link" aria-label="구성 요소 아키텍처에 대한 직접 링크" title="구성 요소 아키텍처에 대한 직접 링크" translate="no">​</a></h3>
<!-- -->
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>NVIDIA 도구</div><div class="admonitionContent_BuS1"><p>NVIDIA DRA Driver는 NVIDIA GPU Operator의 일부가 아닌 독립적인 Helm 차트로 병렬 실행됩니다. 두 구성 요소는 함께 작동하여 종합적인 GPU 관리 기능을 제공합니다.</p></div></div>
<div class="sectionDivider_z07Q"><div class="dividerLine_oAnl"></div><div class="dividerIcon_Soi9">🎲</div><div class="dividerLine_oAnl"></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gpu-공유-전략-기술-심층-분석">GPU 공유 전략: 기술 심층 분석<a href="#gpu-공유-전략-기술-심층-분석" class="hash-link" aria-label="GPU 공유 전략: 기술 심층 분석에 대한 직접 링크" title="GPU 공유 전략: 기술 심층 분석에 대한 직접 링크" translate="no">​</a></h2>
<p>GPU 공유 기술을 이해하는 것은 리소스 활용을 최적화하는 데 중요합니다. 각 전략은 서로 다른 이점을 제공하고 특정 사용 사례를 해결합니다.</p>
<div class="tabs-container"><div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">💎 기본 할당</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">⌛ Time-Slicing</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">🌊 Multi-Process Service (MPS)</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">🏗️ Multi-Instance GPU (MIG)</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="기본-gpu-할당">기본 GPU 할당<a href="#기본-gpu-할당" class="hash-link" aria-label="기본 GPU 할당에 대한 직접 링크" title="기본 GPU 할당에 대한 직접 링크" translate="no">​</a></h3><p>공유 없이 표준 GPU 할당 - 각 워크로드는 완전한 GPU에 대한 독점 접근 권한을 갖습니다. 이는 최대 성능 격리를 제공하는 기존 모델입니다.</p><p><strong>기본 할당 배포 방법:</strong></p><div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">ResourceClaimTemplate</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">기본 Pod</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">basic-gpu-claim-template.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Namespace</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">test1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">test1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> single</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">basic-gpu-pod.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">test1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ctr0</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ubuntu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">22.04</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;bash&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;-c&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">args</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;nvidia-smi -L; trap &#x27;exit 0&#x27; TERM; sleep 9999 &amp; wait&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu0</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu0</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> single</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">NodeGroupType</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g6</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mng</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;nvidia.com/gpu&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Exists&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;NoSchedule&quot;</span></span><br></span></code></pre></div></div></div></div></div><p><strong>예제 배포:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">기본 GPU 할당 배포</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> basic-gpu-claim-template.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> basic-gpu-pod.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-test1 </span><span class="token parameter variable" style="color:#36acaa">-w</span><br></span></code></pre></div></div><p><strong>적합한 사용 사례:</strong></p><ul>
<li>전체 GPU 리소스가 필요한 대규모 모델 학습</li>
<li>GPU 컴퓨팅 및 메모리를 완전히 활용하는 워크로드</li>
<li>최대 성능 격리가 필요한 애플리케이션</li>
<li>GPU 공유용으로 설계되지 않은 레거시 애플리케이션</li>
</ul></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><h3 class="anchor anchorWithStickyNavbar_LWe7" id="time-slicing이란">Time-Slicing이란?<a href="#time-slicing이란" class="hash-link" aria-label="Time-Slicing이란?에 대한 직접 링크" title="Time-Slicing이란?에 대한 직접 링크" translate="no">​</a></h3><p>Time-slicing은 여러 워크로드가 GPU를 번갈아   사용하는 GPU 공유 메커니즘으로, 각 워크로드는 할당된 타임 슬라이스 동안 독점 접근 권한을 갖습니다. 이 접근 방식은 CPU 시분할과 유사하지만 GPU 리소스에 적용됩니다.</p><p><strong>기술적 구현:</strong></p><ul>
<li>GPU 스케줄러는 각 워크로드에 특정 시간 창(일반적으로 1-10ms)을 할당</li>
<li>워크로드의 타임 슬라이스 동안 GPU 컴퓨팅 및 메모리에 대한 완전한 접근 권한</li>
<li>타임 슬라이스 간에 컨텍스트 스위칭 발생, GPU 상태 저장 및 복원</li>
<li>워크로드 간 메모리 격리 없음 - 동일한 GPU 메모리 공간 공유</li>
</ul><p><strong>주요 특성:</strong></p><ul>
<li><strong>시간적 격리</strong>: 워크로드는 시간적으로 격리되지만 메모리에서는 아님</li>
<li><strong>전체 GPU 접근</strong>: 각 워크로드는 슬라이스 동안 완전한 GPU 리소스 획득</li>
<li><strong>컨텍스트 스위칭 오버헤드</strong>: 워크로드 간 전환에 대한 작은 성능 페널티</li>
<li><strong>유연한 할당</strong>: 워크로드 요구 사항에 따라 타임 슬라이스 기간 조정 가능</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dra로-time-slicing-배포-방법">DRA로 Time-Slicing 배포 방법<a href="#dra로-time-slicing-배포-방법" class="hash-link" aria-label="DRA로 Time-Slicing 배포 방법에 대한 직접 링크" title="DRA로 Time-Slicing 배포 방법에 대한 직접 링크" translate="no">​</a></h3><div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">ResourceClaimTemplate</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Pod 구성</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">timeslicing-claim-template.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Namespace</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;shared-gpu&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">opaque</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">driver</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.nvidia.com/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> GpuConfig</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">sharing</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">              </span><span class="token key atrule" style="color:#00a4db">strategy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> TimeSlicing</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">timeslicing-pod.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token comment" style="color:#999988;font-style:italic"># ConfigMap containing Python scripts for timeslicing pods</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ConfigMap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">data</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">inference-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;=== POD 1 STARTING ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;GPU available: {torch.cuda.is_available()}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;GPU count: {torch.cuda.device_count()}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    if torch.cuda.is_available():</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(f&quot;Current GPU: {torch.cuda.get_device_name(device)}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(f&quot;GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        # Simulate inference workload</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        for i in range(20):</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            x = torch.randn(1000, 1000).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            y = torch.mm(x, x.t())</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            print(f&quot;Pod 1 - Iteration {i+1} completed at {time.strftime(&#x27;%H:%M:%S&#x27;)}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            time.sleep(5)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    else:</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(&quot;No GPU available!&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        time.sleep(60)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">training-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;=== POD 2 STARTING ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;GPU available: {torch.cuda.is_available()}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    print(f&quot;GPU count: {torch.cuda.device_count()}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    if torch.cuda.is_available():</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(f&quot;Current GPU: {torch.cuda.get_device_name(device)}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(f&quot;GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        # Simulate training workload with heavier compute</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        for i in range(15):</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            x = torch.randn(2000, 2000).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            y = torch.mm(x, x.t())</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            loss = torch.sum(y)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            print(f&quot;Pod 2 - Training step {i+1}, Loss: {loss.item():.2f} at {time.strftime(&#x27;%H:%M:%S&#x27;)}&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">            time.sleep(5)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    else:</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        print(&quot;No GPU available!&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">        time.sleep(60)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 1 - Inference workload</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">inference</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/inference-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">NodeGroupType</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g6</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mng</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 2 - Training workload</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/training-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">2</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">NodeGroupType</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g6</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mng</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> timeslicing</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span></span><br></span></code></pre></div></div></div></div></div><p><strong>예제 배포:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Time-Slicing GPU 공유 배포</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> timeslicing-claim-template.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> timeslicing-pod.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu </span><span class="token parameter variable" style="color:#36acaa">-w</span><br></span></code></pre></div></div><p><strong>적합한 사용 사례:</strong></p><ul>
<li>산발적인 GPU 사용을 하는 추론 워크로드</li>
<li>개발 및 테스트 환경</li>
<li>서로 다른 피크 사용 시간을 가진 워크로드</li>
<li>메모리 격리가 필요 없는 애플리케이션</li>
</ul><div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Time-Slicing 제한 사항</div><div class="admonitionContent_BuS1"><p>워크로드 간 메모리 또는 장애 격리가 없습니다. 하나의 워크로드가 메모리 고갈 또는 GPU 오류를 통해 다른 워크로드에 영향을 줄 수 있습니다.</p></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><h3 class="anchor anchorWithStickyNavbar_LWe7" id="mps란">MPS란?<a href="#mps란" class="hash-link" aria-label="MPS란?에 대한 직접 링크" title="MPS란?에 대한 직접 링크" translate="no">​</a></h3><p>NVIDIA Multi-Process Service(MPS)는 GPU 접근을 관리하고 GPU 리소스의 공간적 공유를 가능하게 하는 데몬을 생성하여 여러 CUDA 애플리케이션이 동일한 GPU에서 동시에 실행될 수 있도록 하는 GPU 공유 기술입니다.</p><p><strong>기술적 구현:</strong></p><ul>
<li>MPS 데몬은 CUDA 애플리케이션과 GPU 드라이버 사이의 프록시 역할</li>
<li>각 프로세스는 전용 GPU 메모리 할당을 받음</li>
<li>다른 프로세스의 컴퓨팅 커널은 리소스가 허용할 때 동시에 실행 가능</li>
<li>프로세스 간 메모리 격리 유지</li>
<li>하드웨어 스케줄링  으로 진정한 병렬 실행 가능</li>
</ul><p><strong>주요 특성:</strong></p><ul>
<li><strong>공간적 격리</strong>: GPU 컴퓨팅 유닛을 동시에 공유 가능</li>
<li><strong>메모리 격리</strong>: 각 프로세스는 전용 메모리 공간을 가짐</li>
<li><strong>동시 실행</strong>: 여러 커널이 병렬로 실행 가능</li>
<li><strong>낮은 지연 시간</strong>: time-slicing에 비해 감소된 컨텍스트 스위칭</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dra로-mps-배포-방법">DRA로 MPS 배포 방법<a href="#dra로-mps-배포-방법" class="hash-link" aria-label="DRA로 MPS 배포 방법에 대한 직접 링크" title="DRA로 MPS 배포 방법에 대한 직접 링크" translate="no">​</a></h3><div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">ResourceClaimTemplate</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">멀티 컨테이너 Pod</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">mps-claim-template.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Namespace</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;shared-gpu&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">opaque</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">driver</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpu.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.nvidia.com/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> GpuConfig</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">sharing</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">              </span><span class="token key atrule" style="color:#00a4db">strategy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> MPS</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">mps-pod.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token comment" style="color:#999988;font-style:italic"># ConfigMap containing Python scripts for MPS pods</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ConfigMap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">data</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">inference-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== INFERENCE CONTAINER STARTING ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Current GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1024</span><span class="token important">**3:.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Create inference model</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(1000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 500)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(500</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 100)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Run inference</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        for i in range(1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">999999)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">with torch.no_grad()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                x = torch.randn(128</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 1000).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                result = torch.sum(output)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                print(f&quot;Inference Container PID </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Batch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">i</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Result</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">result.item()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> at </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">time.strftime(&#x27;%H</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">%M</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">%S&#x27;)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(2)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">else</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;No GPU available</span><span class="token tag" style="color:#00009f">!</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        time.sleep(60)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">training-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== TRAINING CONTAINER STARTING ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Current GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1024</span><span class="token important">**3:.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Create training model</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(2000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 1000)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(1000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 500)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(500</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        criterion = nn.MSELoss()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        optimizer = torch.optim.Adam(model.parameters()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> lr=0.001)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Run training</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        for epoch in range(1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">999999)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            x = torch.randn(64</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 2000).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            target = torch.randn(64</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.zero_grad()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss = criterion(output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> target)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss.backward()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.step()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            print(f&quot;Training Container PID </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Epoch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">epoch</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Loss</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">loss.item()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.4f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> at </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">time.strftime(&#x27;%H</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">%M</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">%S&#x27;)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(3)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">else</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;No GPU available</span><span class="token tag" style="color:#00009f">!</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        time.sleep(60)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Single Pod with Multiple Containers sharing GPU via MPS</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">multi</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">demo</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Container 1 - Inference workload</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/inference-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">request</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Container 2 - Training workload</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/training-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">request</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> shared</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">NodeGroupType</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> g6</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mng</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mps</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span></span><br></span></code></pre></div></div></div></div></div><p><strong>예제 배포:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">MPS GPU 공유 배포</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> mps-claim-template.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> mps-pod.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mps-gpu </span><span class="token parameter variable" style="color:#36acaa">-w</span><br></span></code></pre></div></div><p><strong>적합한 사용 사례:</strong></p><ul>
<li>여러 소규모 추론 워크로드</li>
<li>동시 모델 서빙 시나리오</li>
<li>GPU 컴퓨팅의 50% 미만을 사용  하는 워크로드</li>
<li>메모리 격리가 필요한 애플리케이션</li>
</ul><div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>MPS 성능 이점</div><div class="admonitionContent_BuS1"><p>MPS는 컨텍스트 스위칭 오버헤드를 제거하고 진정한 병렬 처리를 가능하게 합니다. GPU 컴퓨팅 용량의 50% 미만을 사용하는 워크로드에 이상적입니다.</p></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><h3 class="anchor anchorWithStickyNavbar_LWe7" id="mig란">MIG란?<a href="#mig란" class="hash-link" aria-label="MIG란?에 대한 직접 링크" title="MIG란?에 대한 직접 링크" translate="no">​</a></h3><p>Multi-Instance GPU(MIG)는 NVIDIA A100, H100 및 최신 GPU에서 사용 가능한 하드웨어 수준 GPU 파티셔닝 기술로, 전용 컴퓨팅 유닛, 메모리 및 메모리 대역폭을 가진 더 작고 격리된 GPU 인스턴스를 생성합니다.</p><p><strong>기술적 구현:</strong></p><ul>
<li>하드웨어 수준 파티셔닝으로 별도의 GPU 인스턴스 생성</li>
<li>각 MIG 인스턴스는 전용 스트리밍 멀티프로세서(SM)를 가짐</li>
<li>메모리와 메모리 대역폭은 물리적으로 파티셔닝됨</li>
<li>인스턴스 간 완전한 장애 격리</li>
<li>독립적인 스케줄링 및 실행 컨텍스트</li>
</ul><p><strong>주요 특성:</strong></p><ul>
<li><strong>하드웨어 격리</strong>: 컴퓨팅 및 메모리 리소스의 물리적 분리</li>
<li><strong>장애 격리</strong>: 한 인스턴스의 문제가 다른 인스턴스에 영향을 주지 않음</li>
<li><strong>예측 가능한 성능</strong>: 각 인스턴스에 대해 보장된 리소스</li>
<li><strong>고정 파티셔닝</strong>: 미리 정의된 MIG 프로필 (1g.5gb, 2g.10gb 등)</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="dra로-mig-배포-방법">DRA로 MIG 배포 방법<a href="#dra로-mig-배포-방법" class="hash-link" aria-label="DRA로 MIG 배포 방법에 대한 직접 링크" title="DRA로 MIG 배포 방법에 대한 직접 링크" translate="no">​</a></h3><div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">ResourceClaimTemplate</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">MIG Pod</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">mig-claim-template.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Namespace</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Template for 3g.40gb MIG instance (Large training)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">selectors</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">cel</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">expression</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">              device.attributes[&#x27;gpu.nvidia.com&#x27;].profile == &#x27;3g.40gb&#x27;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Template for 2g.20gb MIG instance (Medium training)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">selectors</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">cel</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">expression</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">              device.attributes[&#x27;gpu.nvidia.com&#x27;].profile == &#x27;2g.20gb&#x27;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Template for 1g.10gb MIG instance (Small inference)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> resource.k8s.io/v1beta1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ResourceClaimTemplate</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">devices</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">requests</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">deviceClassName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig.nvidia.com</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">selectors</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">cel</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">expression</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">              device.attributes[&#x27;gpu.nvidia.com&#x27;].profile == &#x27;1g.10gb&#x27;</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">mig-pod.yaml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token comment" style="color:#999988;font-style:italic"># ConfigMap containing Python scripts for MIG pods</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ConfigMap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">data</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">large-training-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.optim as optim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== LARGE TRAINING POD (3g.40gb) ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Using GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Large model for 3g.40gb instance</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(2048</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 1024)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(1024</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 512)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 256)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        optimizer = optim.Adam(model.parameters())</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        criterion = nn.CrossEntropyLoss()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Model parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">sum(p.numel() for p in model.parameters())</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Training loop</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">for epoch in range(100)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic"># Large batch for 3g.40gb</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            x = torch.randn(256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 2048).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            y = torch.randint(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> (256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">)).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.zero_grad()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss = criterion(output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss.backward()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.step()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">if epoch % 10 == 0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                print(f&quot;Large Training </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> Epoch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">epoch</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Loss</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">loss.item()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.4f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.memory_allocated()/1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(3)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;Large training completed on 3g.40gb MIG instance&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">medium-training-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.optim as optim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== MEDIUM TRAINING POD (2g.20gb) ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Using GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Medium model for 2g.20gb instance</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(1024</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 512)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 256)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        optimizer = optim.Adam(model.parameters())</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        criterion = nn.CrossEntropyLoss()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Model parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">sum(p.numel() for p in model.parameters())</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Training loop</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">for epoch in range(100)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token comment" style="color:#999988;font-style:italic"># Medium batch for 2g.20gb</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            x = torch.randn(128</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 1024).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            y = torch.randint(0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> (128</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">)).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.zero_grad()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss = criterion(output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            loss.backward()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            optimizer.step()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">if epoch % 10 == 0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                print(f&quot;Medium Training </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> Epoch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">epoch</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Loss</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">loss.item()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.4f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.memory_allocated()/1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(4)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;Medium training completed on 2g.20gb MIG instance&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">small-inference-script.py</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import torch.nn as nn</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import time</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token scalar string" style="color:#e3116c">    import os</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    print(f&quot;=== SMALL INFERENCE POD (1g.10gb) ===&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Process ID</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">os.getpid()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU available</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU count</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.device_count()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">if torch.cuda.is_available()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        device = torch.cuda.current_device()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Using GPU</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_name(device)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.get_device_properties(device).total_memory / 1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.1f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Small model for 1g.10gb instance</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        model = nn.Sequential(</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 256)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.ReLU()</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            nn.Linear(256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 10)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        ).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">print(f&quot;Model parameters</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">sum(p.numel() for p in model.parameters())</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Inference loop</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">for i in range(200)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">with torch.no_grad()</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                </span><span class="token comment" style="color:#999988;font-style:italic"># Small batch for 1g.10gb</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                x = torch.randn(32</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> 512).cuda()</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                output = model(x)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                prediction = torch.argmax(output</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dim=1)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                </span><span class="token key atrule" style="color:#00a4db">if i % 20 == 0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">                    print(f&quot;Small Inference </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> Batch </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">i</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">Predictions</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">prediction</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">.tolist()</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">GPU Memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">torch.cuda.memory_allocated()/1e9</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">.2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">GB&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">            time.sleep(2)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">        print(&quot;Small inference completed on 1g.10gb MIG instance&quot;)</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 1: Large training workload (3g.40gb)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">workload-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/large-training-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">large</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">node.kubernetes.io/instance-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> p4de.24xlarge</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 2: Medium training workload (2g.20gb) - can run on SAME GPU as Pod 1</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">workload-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> training</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/medium-training-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">medium</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">node.kubernetes.io/instance-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> p4de.24xlarge</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pod 3: Small inference workload (1g.10gb) - can run on SAME GPU as Pod 1 &amp; 2</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> v1</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pod</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">app</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">inference</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">workload-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> inference</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">restartPolicy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Never</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">containers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">inference</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">container</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvcr.io/nvidia/pytorch</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">25.04</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">py3</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;python&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/scripts/small-inference-script.py&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volumeMounts</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">mountPath</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> /scripts</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">readOnly</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resources</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">claims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">resourceClaims</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">claim</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">resourceClaimTemplateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">small</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">template</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">node.kubernetes.io/instance-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> p4de.24xlarge</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">nvidia.com/gpu.present</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;true&quot;</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">tolerations</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> nvidia.com/gpu</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">operator</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Exists</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">effect</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> NoSchedule</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">volumes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> script</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">volume</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">configMap</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> mig</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">scripts</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">configmap</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">defaultMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0755</span></span><br></span></code></pre></div></div></div></div></div><p><strong>예제 배포:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">MIG GPU 파티셔닝 배포</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> mig-claim-template.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> mig-pod.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mig-gpu </span><span class="token parameter variable" style="color:#36acaa">-w</span><br></span></code></pre></div></div><p><strong>적합한 사용 사례:</strong></p><ul>
<li>엄격한 격리가 필요한 멀티 테넌트 환경</li>
<li>예측 가능한 성능 요구 사항</li>
<li>보장된 리소스가 필요한 워크로드</li>
<li>하드웨어 수준 격리가 필요한 규정 준수 시나리오</li>
</ul><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>MIG 요구 사항</div><div class="admonitionContent_BuS1"><ul>
<li>하드웨어 수준 파티셔닝으로 격리된 GPU 인스턴스 생성</li>
<li>각 MIG 인스턴스는 전용 컴퓨팅 유닛과 메모리를 가짐</li>
<li>인스턴스 간 완전한 장애 격리</li>
<li>동적 재구성을 위해 MIG Manager가 포함된 GPU Operator 필요</li>
</ul></div></div></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="전략-선택-가이드">전략 선택 가이드<a href="#전략-선택-가이드" class="hash-link" aria-label="전략 선택 가이드에 대한 직접 링크" title="전략 선택 가이드에 대한 직접 링크" translate="no">​</a></h3><table><thead><tr><th>워크로드 유형</th><th>권장 전략</th><th>주요 이점</th></tr></thead><tbody><tr><td><strong>소규모 추론 작업</strong></td><td>Time-slicing 또는 MPS</td><td>높은 GPU 활용률</td></tr><tr><td><strong>동시 소규모 모델</strong></td><td>MPS</td><td>진정한 병렬 처리</td></tr><tr><td><strong>멀티 테넌트</strong></td><td>MIG</td><td>하드웨어 격리</td></tr><tr><td><strong>대규모 모델 학습</strong></td><td>기본 할당</td><td>최대 성능</td></tr><tr><td><strong>개발/테스트</strong></td><td>Time-slicing</td><td>유연성과 단순성</td></tr></tbody></table></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="정리">정리<a href="#정리" class="hash-link" aria-label="정리에 대한 직접 링크" title="정리에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dra-구성-요소-제거">DRA 구성 요소 제거<a href="#dra-구성-요소-제거" class="hash-link" aria-label="DRA 구성 요소 제거에 대한 직접 링크" title="DRA 구성 요소 제거에 대한 직접 링크" translate="no">​</a></h3>
<div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">1️⃣ DRA 예제 정리</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">2️⃣ JARK 스택 정리</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><p><strong>모든 DRA 예제 워크로드 제거:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">DRA 워크로드 정리</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv codeBlockLinesWithNumbering_o6Pm" style="counter-reset:line-count 0"><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token comment" style="color:#999988;font-style:italic"># 적절한 정리를 위해 먼저 모든 Pod 삭제</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod inference-pod-1 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod training-pod-2 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod mps-workload </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mps-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod mig-workload </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mig-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete pod basic-gpu-pod </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-test1 --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ResourceClaimTemplates 삭제</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaimtemplate timeslicing-gpu-template </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaimtemplate mps-gpu-template </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mps-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaimtemplate mig-gpu-template </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> mig-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaimtemplate basic-gpu-template </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-test1 --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 남은 ResourceClaims 삭제</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete resourceclaims </span><span class="token parameter variable" style="color:#36acaa">--all</span><span class="token plain"> --all-namespaces --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ConfigMaps 삭제 (스크립트 포함)</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete configmap timeslicing-scripts-configmap </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 마지막으로 네임스페이스 삭제</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete namespace timeslicing-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete namespace mps-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete namespace mig-gpu --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl delete namespace gpu-test1 --ignore-not-found</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain" style="display:inline-block"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 정리 확인</span><span class="token plain"></span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl get resourceclaims --all-namespaces</span></span><br></span><span class="token-line codeLine_lJS_" style="color:#393A34"><span class="codeLineNumber_Tfdd"></span><span class="codeLineContent_feaV"><span class="token plain">kubectl get resourceclaimtemplates --all-namespaces</span></span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p><strong>JARK로 배포된 클러스터의 경우 자동화된 정리 사용:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">JARK 스택 전체 정리</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># JARK 디렉토리로 이동</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/infra/jark-stack/terraform/_LOCAL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 정리 스크립트 실행</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">chmod</span><span class="token plain"> +x cleanup.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./cleanup.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 대안: 수동 terraform destroy</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># terraform destroy -var-file=terraform/blueprint.tfvars -auto-approve</span><br></span></code></pre></div></div><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>전체 인프라 제거</div><div class="admonitionContent_BuS1"><p>이 작업은 전체 EKS 클러스터와 모든 관련 리소스를 제거합니다. 진행하기 전에 중요한 데이터를 백업했는지 확인하십시오.</p></div></div></div></div></div>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary><strong>일반적인 문제 해결</strong></summary><div><div class="collapsibleContent_i85q"><div class="theme-tabs-container tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">🔍 Pending 상태의 Pod</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">⚠️ GPU 공유 충돌</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">📊 성능 문제</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><p><strong>문제:</strong> ResourceClaims가 있는 Pod가 Pending 상태에서 멈춤</p><p><strong>진단:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># ResourceClaim 상태 확인</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get resourceclaims --all-namespaces </span><span class="token parameter variable" style="color:#36acaa">-o</span><span class="token plain"> wide</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># DRA 드라이버 로그 확인</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-operator </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">app</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">nvidia-dra-driver </span><span class="token parameter variable" style="color:#36acaa">--tail</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">100</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># DeviceClasses 존재 확인</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get deviceclasses</span><br></span></code></pre></div></div><p><strong>해결:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># DRA 드라이버 Pod 재시작</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl delete pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> gpu-operator </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">app</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">nvidia-dra-driver</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 노드 GPU 가용성 확인</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl describe nodes </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">grep</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-A</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Allocatable&quot;</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p><strong>문제:</strong> 동일한 GPU에서 호환되지 않는 공유 전략</p><p><strong>진단:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># ResourceSlice 할당 확인</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get resourceslices </span><span class="token parameter variable" style="color:#36acaa">-o</span><span class="token plain"> yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 현재 할당 확인</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get resourceclaims --all-namespaces </span><span class="token parameter variable" style="color:#36acaa">-o</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">jsonpath</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;{range .items[*]}{.metadata.namespace}/{.metadata.name}: {.status.allocation.deviceResults[*].device}{&quot;\n&quot;}{end}&#x27;</span><br></span></code></pre></div></div><p><strong>해결:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 충돌하는 ResourceClaims 제거</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl delete resourceclaim </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">conflicting-claim</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">namespace</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 리소스 정리 대기</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl </span><span class="token function" style="color:#d73a49">wait</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">--for</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">delete resourceclaim </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">claim-name</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">namespace</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">--timeout</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">60s</span><br></span></code></pre></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><p><strong>문제:</strong> 최적이 아닌 GPU 활용률 또는 성능</p><p><strong>모니터링:</strong></p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># GPU 활용률 확인</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl </span><span class="token builtin class-name">exec</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-it</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">gpu-pod</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">namespace</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> -- nvidia-smi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ResourceClaim 할당 모니터링</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get events --field-selector </span><span class="token assign-left variable" style="color:#36acaa">reason</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">ResourceClaimAllocated --sort-by</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;.lastTimestamp&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 공유 전략 효과 확인</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">workload-pod</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">namespace</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">grep</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-i</span><span class="token plain"> gpu</span><br></span></code></pre></div></div><p><strong>최적화:</strong></p><ul>
<li>공유 전략 선택 검토 (MPS vs time-slicing vs exclusive)</li>
<li>워크로드 리소스 요구 사항이 할당과 일치하는지 확인</li>
<li>예측 가능한 격리를 위해 MIG 파티셔닝 고려</li>
</ul></div></div></div></div></div></details>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="결론">결론<a href="#결론" class="hash-link" aria-label="결론에 대한 직접 링크" title="결론에 대한 직접 링크" translate="no">​</a></h2>
<p>동적 리소스 할당은 경직된 GPU 할당에서 지능적인 워크로드 인식 리소스 관리로의 근본적인 전환을 나타냅니다. 구조화된 ResourceClaims와 벤더별 드라이버를 활용함으로써 DRA는 엔터프라이즈 규모의 비용 효율적인 AI/ML 운영에 필요한 GPU 활용률을 실현합니다.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>준비되셨나요? GPU 인프라를 혁신하세요!</div><div class="admonitionContent_BuS1"><p>단순화된 JARK 기반 배포 접근 방식을 통해 조직은 세 단계로 DRA 기능을 구현하여 GPU 인프라를 정적 리소스 풀에서 현대 AI 워크로드에 최적화된 동적이고 지능적인 플랫폼으로 변환할 수 있습니다.</p></div></div>
<p>EKS의 관리형 인프라, NVIDIA의 드라이버 에코시스템 및 Kubernetes의 선언적 모델의 조합은 소규모 추론 작업부터 GB200 수퍼칩에서의 멀티 노드 분산 학습까지 차세대 AI 워크로드를 위한 강력한 기반을 만듭니다.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/guidance/dynamic-resource-allocation.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/ko/docs/guidance/container-startup-time/accelerate-pull-process/prefecthing-images-on-br"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">데이터 볼륨에 컨테이너 이미지 미리 로드</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-on-eks/ko/docs/guidance/networking"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">AI를 위한 네트워킹</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#기존-gpu-스케줄링-대비-dra의-장점" class="table-of-contents__link toc-highlight">기존 GPU 스케줄링 대비 DRA의 장점</a></li><li><a href="#왜-dra에-karpenter-대신-관리형자체-관리형-노드-그룹인가" class="table-of-contents__link toc-highlight">왜 DRA에 Karpenter 대신 관리형/자체 관리형 노드 그룹인가?</a></li><li><a href="#기존-gpu-할당과-dra를-함께-사용할-수-있나요" class="table-of-contents__link toc-highlight">기존 GPU 할당과 DRA를 함께 사용할 수 있나요?</a></li><li><a href="#준비-상태" class="table-of-contents__link toc-highlight">준비 상태</a></li><li><a href="#kubernetes에서의-gpu-스케줄링-과제" class="table-of-contents__link toc-highlight">Kubernetes에서의 GPU 스케줄링 과제</a><ul><li><a href="#현재-상태-기존-gpu-할당" class="table-of-contents__link toc-highlight">현재 상태: 기존 GPU 할당</a></li><li><a href="#gpu-활용-위기" class="table-of-contents__link toc-highlight">GPU 활용 위기</a></li></ul></li><li><a href="#동적-리소스-할당dra-소개" class="table-of-contents__link toc-highlight">동적 리소스 할당(DRA) 소개</a><ul><li><a href="#dra가-변경하는-것" class="table-of-contents__link toc-highlight">DRA가 변경하는 것</a></li><li><a href="#주요-dra-혁신" class="table-of-contents__link toc-highlight">주요 DRA 혁신</a></li><li><a href="#imex-computedomains-및-amazon-ec2-p6e-gb200-멀티-노드-스케줄링-이해" class="table-of-contents__link toc-highlight">IMEX, ComputeDomains 및 Amazon EC2 P6e-GB200 멀티 노드 스케줄링 이해</a></li></ul></li><li><a href="#eks-구현-고려-사항" class="table-of-contents__link toc-highlight">EKS 구현 고려 사항</a><ul><li><a href="#p-시리즈-gpu-인스턴스와-dra를-위한-관리형-노드-그룹-vs-karpenter" class="table-of-contents__link toc-highlight">P-시리즈 GPU 인스턴스와 DRA를 위한 관리형 노드 그룹 vs Karpenter</a></li><li><a href="#dra와-기존-gpu-할당-공존" class="table-of-contents__link toc-highlight">DRA와 기존 GPU 할당 공존</a></li><li><a href="#시각적-비교-기존-방식-vs-dra" class="table-of-contents__link toc-highlight">시각적 비교: 기존 방식 vs DRA</a></li><li><a href="#기술-역량-비교" class="table-of-contents__link toc-highlight">기술 역량 비교</a></li></ul></li><li><a href="#dra-실제-작동-원리-완전한-기술-흐름" class="table-of-contents__link toc-highlight">DRA 실제 작동 원리: 완전한 기술 흐름</a><ul><li><a href="#단계별-dra-워크플로우" class="table-of-contents__link toc-highlight">단계별 DRA 워크플로우</a></li></ul></li><li><a href="#솔루션-배포" class="table-of-contents__link toc-highlight">솔루션 배포</a><ul><li><a href="#사전-요구-사항" class="table-of-contents__link toc-highlight">사전 요구 사항</a></li><li><a href="#배포" class="table-of-contents__link toc-highlight">배포</a></li><li><a href="#구성-요소-아키텍처" class="table-of-contents__link toc-highlight">구성 요소 아키텍처</a></li></ul></li><li><a href="#gpu-공유-전략-기술-심층-분석" class="table-of-contents__link toc-highlight">GPU 공유 전략: 기술 심층 분석</a><ul><li><a href="#기본-gpu-할당" class="table-of-contents__link toc-highlight">기본 GPU 할당</a></li><li><a href="#time-slicing이란" class="table-of-contents__link toc-highlight">Time-Slicing이란?</a></li><li><a href="#dra로-time-slicing-배포-방법" class="table-of-contents__link toc-highlight">DRA로 Time-Slicing 배포 방법</a></li><li><a href="#mps란" class="table-of-contents__link toc-highlight">MPS란?</a></li><li><a href="#dra로-mps-배포-방법" class="table-of-contents__link toc-highlight">DRA로 MPS 배포 방법</a></li><li><a href="#mig란" class="table-of-contents__link toc-highlight">MIG란?</a></li><li><a href="#dra로-mig-배포-방법" class="table-of-contents__link toc-highlight">DRA로 MIG 배포 방법</a></li><li><a href="#전략-선택-가이드" class="table-of-contents__link toc-highlight">전략 선택 가이드</a></li></ul></li><li><a href="#정리" class="table-of-contents__link toc-highlight">정리</a><ul><li><a href="#dra-구성-요소-제거" class="table-of-contents__link toc-highlight">DRA 구성 요소 제거</a></li></ul></li><li><a href="#결론" class="table-of-contents__link toc-highlight">결론</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">참여하기</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © ${new Date().getFullYear()} Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>