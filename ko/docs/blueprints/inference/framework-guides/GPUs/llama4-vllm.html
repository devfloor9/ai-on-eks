<!doctype html>
<html lang="ko-KR" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blueprints/inference/framework-guides/GPUs/llama4-vllm" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.0">
<title data-rh="true">Llama 4 with vLLM on EKS | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm"><meta data-rh="true" property="og:locale" content="ko_KR"><meta data-rh="true" property="og:locale:alternate" content="en_US"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Llama 4 with vLLM on EKS | AI on EKS"><meta data-rh="true" name="description" content="Deploy Llama 4 Scout and Maverick models using vLLM on Amazon EKS with GPU acceleration."><meta data-rh="true" property="og:description" content="Deploy Llama 4 Scout and Maverick models using vLLM on Amazon EKS with GPU acceleration."><link data-rh="true" rel="icon" href="/ai-on-eks/ko/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm" hreflang="ko-KR"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"EKSì—ì„œì˜ ì¶”ë¡ ","item":"https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/"},{"@type":"ListItem","position":2,"name":"Framework-Specific Deployment Guides","item":"https://awslabs.github.io/ai-on-eks/ko/docs/category/framework-specific-deployment-guides"},{"@type":"ListItem","position":3,"name":"EKSì—ì„œì˜ GPU ì¶”ë¡ ","item":"https://awslabs.github.io/ai-on-eks/ko/docs/category/gpu-inference-on-eks"},{"@type":"ListItem","position":4,"name":"Llama 4 with vLLM on EKS","item":"https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm"}]}</script><link rel="stylesheet" href="/ai-on-eks/ko/assets/css/styles.c270b852.css">
<script src="/ai-on-eks/ko/assets/js/runtime~main.84f685ef.js" defer="defer"></script>
<script src="/ai-on-eks/ko/assets/js/main.62626cce.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="ë³¸ë¬¸ìœ¼ë¡œ ê±´ë„ˆë›°ê¸°"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">ë³¸ë¬¸ìœ¼ë¡œ ê±´ë„ˆë›°ê¸°</a></div><div class="theme-announcement-bar announcementBar_mb4j" style="background-color:#667eea;color:#ffffff" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">GenAI on EKS workshop series! <a target="_blank" rel="noopener noreferrer" href="https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=9be4af2e-2339-40ae-b5e9-57b6a7704c36&sc_channel=el" style="color: #ffffff; text-decoration: underline; font-weight: bold; margin-left: 10px;">Register now â†’</a></div><button type="button" aria-label="ë‹«ê¸°" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="ë©”ì¸" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="ì‚¬ì´ë“œë°” í¼ì¹˜ê±°ë‚˜ ì ‘ê¸°" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/ko/"><div class="navbar__logo"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS ë¡œê³ " class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS ë¡œê³ " class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/infra">ì¸í”„ë¼</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/ko/docs/blueprints">ë¸”ë£¨í”„ë¦°íŠ¸</a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/guidance">ê°€ì´ë“œ</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>í•œêµ­ì–´</a><ul class="dropdown__menu"><li><a href="/ai-on-eks/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en-US">English</a></li><li><a href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko-KR">í•œêµ­ì–´</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="ì–´ë‘ìš´ ëª¨ë“œì™€ ë°ì€ ëª¨ë“œ ì „í™˜í•˜ê¸° (í˜„ì¬ system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="ë§¨ ìœ„ë¡œ ìŠ¤í¬ë¡¤í•˜ê¸°" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="ë¬¸ì„œ ì‚¬ì´ë“œë°”" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/blueprints"><span title="ê°œìš”" class="linkLabel_WmDU">ê°œìš”</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai-on-eks/ko/docs/blueprints/inference"><span title="EKSì—ì„œì˜ ì¶”ë¡ " class="categoryLinkLabel_W154">EKSì—ì„œì˜ ì¶”ë¡ </span></a><button aria-label="ì‚¬ì´ë“œë°” ë¶„ë¥˜ &#x27;EKSì—ì„œì˜ ì¶”ë¡ &#x27; ì ‘ê¸°" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai-on-eks/ko/docs/category/framework-specific-deployment-guides"><span title="Framework-Specific Deployment Guides" class="categoryLinkLabel_W154">Framework-Specific Deployment Guides</span></a><button aria-label="ì‚¬ì´ë“œë°” ë¶„ë¥˜ &#x27;Framework-Specific Deployment Guides&#x27; ì ‘ê¸°" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai-on-eks/ko/docs/category/gpu-inference-on-eks"><span title="EKSì—ì„œì˜ GPU ì¶”ë¡ " class="categoryLinkLabel_W154">EKSì—ì„œì˜ GPU ì¶”ë¡ </span></a><button aria-label="ì‚¬ì´ë“œë°” ë¶„ë¥˜ &#x27;EKSì—ì„œì˜ GPU ì¶”ë¡ &#x27; ì ‘ê¸°" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve"><span title="RayServeì™€ vLLM" class="linkLabel_WmDU">RayServeì™€ vLLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer"><span title="NVIDIA Triton Serverì™€ vLLM" class="linkLabel_WmDU">NVIDIA Triton Serverì™€ vLLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus"><span title="GPUì—ì„œì˜ Stable Diffusion" class="linkLabel_WmDU">GPUì—ì„œì˜ Stable Diffusion</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3"><span title="Amazon EKSì—ì„œì˜ NVIDIA NIM LLM" class="linkLabel_WmDU">Amazon EKSì—ì„œì˜ NVIDIA NIM LLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator"><span title="EKSì˜ NVIDIA NIM Operator" class="linkLabel_WmDU">EKSì˜ NVIDIA NIM Operator</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/ray-vllm-deepseek"><span title="EKSì—ì„œì˜ DeepSeek-R1" class="linkLabel_WmDU">EKSì—ì„œì˜ DeepSeek-R1</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo"><span title="Amazon EKSì˜ NVIDIA Dynamo" class="linkLabel_WmDU">Amazon EKSì˜ NVIDIA Dynamo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research"><span title="EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant" class="linkLabel_WmDU">EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm"><span title="Llama 4 with vLLM on EKS" class="linkLabel_WmDU">Llama 4 with vLLM on EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/aibrix-deepseek-distill"><span title="EKSì˜ AIBrix" class="linkLabel_WmDU">EKSì˜ AIBrix</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai-on-eks/ko/docs/category/neuron-inference-on-eks"><span title="EKSì—ì„œì˜ Neuron ì¶”ë¡ " class="categoryLinkLabel_W154">EKSì—ì„œì˜ Neuron ì¶”ë¡ </span></a><button aria-label="ì‚¬ì´ë“œë°” ë¶„ë¥˜ &#x27;EKSì—ì„œì˜ Neuron ì¶”ë¡ &#x27; í¼ì¹˜ê¸°" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/inference-charts"><span title="ì¶”ë¡  ì°¨íŠ¸" class="linkLabel_WmDU">ì¶”ë¡  ì°¨íŠ¸</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai-on-eks/ko/docs/category/training-on-eks"><span title="EKSì—ì„œì˜ í•™ìŠµ" class="categoryLinkLabel_W154">EKSì—ì„œì˜ í•™ìŠµ</span></a><button aria-label="ì‚¬ì´ë“œë°” ë¶„ë¥˜ &#x27;EKSì—ì„œì˜ í•™ìŠµ&#x27; í¼ì¹˜ê¸°" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway"><span title="ê²Œì´íŠ¸ì›¨ì´" class="categoryLinkLabel_W154">ê²Œì´íŠ¸ì›¨ì´</span></a></div></li></ul></nav><button type="button" title="ì‚¬ì´ë“œë°” ìˆ¨ê¸°ê¸°" aria-label="ì‚¬ì´ë“œë°” ìˆ¨ê¸°ê¸°" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="íƒìƒ‰ ê²½ë¡œ"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="í™ˆ" class="breadcrumbs__link" href="/ai-on-eks/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/ko/docs/blueprints/inference"><span>EKSì—ì„œì˜ ì¶”ë¡ </span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/ko/docs/category/framework-specific-deployment-guides"><span>Framework-Specific Deployment Guides</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/ko/docs/category/gpu-inference-on-eks"><span>EKSì—ì„œì˜ GPU ì¶”ë¡ </span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Llama 4 with vLLM on EKS</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">ì´ í˜ì´ì§€ì—ì„œ</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-danger admonition_xJq3 alert alert--danger"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"></path></svg></span>ìœ„í—˜</div><div class="admonitionContent_BuS1"><p>Use of Llama 4 models is governed by the <a href="https://www.llama.com/llama4/license/" target="_blank" rel="noopener noreferrer">Meta Llama License</a>.
Please visit <a href="https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct" target="_blank" rel="noopener noreferrer">Hugging Face</a> and accept the license before requesting access.</p></div></div>
<header><h1>Llama 4 Inference with vLLM on Amazon EKS</h1></header>
<p>In this guide, we&#x27;ll explore deploying <a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/" target="_blank" rel="noopener noreferrer">Llama 4</a> models using <a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">vLLM</a> inference engine on <a href="https://aws.amazon.com/eks/" target="_blank" rel="noopener noreferrer">Amazon EKS</a>.</p>
<p>Llama 4 introduces a <strong>Mixture of Experts (MoE)</strong> architecture, where only a subset of parameters are active per token, enabling efficient inference for its large total parameter count. Two model variants are available:</p>
<ul>
<li><strong>Llama 4 Scout</strong> (17B active / 109B total, 16 experts) - Mid-size multimodal model</li>
<li><strong>Llama 4 Maverick</strong> (17B active / 400B total, 128 experts) - Large multimodal model</li>
</ul>
<p>Both models support multimodal inputs (text and images) and provide OpenAI-compatible API endpoints via vLLM.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-gpu-memory-requirements">Understanding GPU Memory Requirements<a href="#understanding-gpu-memory-requirements" class="hash-link" aria-label="Understanding GPU Memory Requirementsì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Understanding GPU Memory Requirementsì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h2>
<p>Deploying MoE models requires loading all expert weights into GPU memory, even though only a subset is active per token. This means total parameter count determines memory requirements, not active parameters.</p>
<table><thead><tr><th>Model</th><th>Total Params</th><th>Experts</th><th>BF16 Memory</th><th>FP8 Memory</th><th>Recommended GPU Instance</th></tr></thead><tbody><tr><td>Scout 17B-16E</td><td>~109B</td><td>16</td><td>~220 GiB</td><td>~110 GiB</td><td>p4d.24xlarge (8x A100 40GB = 320 GiB)</td></tr><tr><td>Maverick 17B-128E</td><td>~400B</td><td>128</td><td>~800 GiB</td><td>~400 GiB</td><td>p5.48xlarge (8x H100 80GB = 640 GiB, <strong>FP8 required</strong>)</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>ê²½ê³ </div><div class="admonitionContent_BuS1"><p><strong>Maverick on GPU requires FP8 quantization.</strong> The BF16 model weights (~800 GiB) exceed the p5.48xlarge total GPU memory (640 GiB). Use the FP8-quantized variant (<code>meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8</code>) which fits within 640 GiB.</p><p>For running Maverick without quantization, consider <a href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2">Trainium2 deployment</a> which provides 1.5 TiB HBM memory.</p></div></div>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>Deploying the Inference-Ready EKS Cluster</span></h2><span class="icon_PckA">ğŸ‘ˆ</span></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-llama-4-scout-17b-16e">Deploy Llama 4 Scout (17B-16E)<a href="#deploy-llama-4-scout-17b-16e" class="hash-link" aria-label="Deploy Llama 4 Scout (17B-16E)ì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Deploy Llama 4 Scout (17B-16E)ì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-create-hugging-face-token-secret">Step 1: Create Hugging Face Token Secret<a href="#step-1-create-hugging-face-token-secret" class="hash-link" aria-label="Step 1: Create Hugging Face Token Secretì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Step 1: Create Hugging Face Token Secretì— ëŒ€í•œ ì§ì ‘   ë§í¬" translate="no">â€‹</a></h3>
<p>Create a <a href="https://huggingface.co/docs/hub/en/security-tokens" target="_blank" rel="noopener noreferrer">Hugging Face access token</a> and store it as a Kubernetes secret:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl create secret generic hf-token --from-literal</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">token</span><span class="token operator" style="color:#393A34">=</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">your-huggingface-token</span><span class="token operator" style="color:#393A34">&gt;</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-deploy-with-helm">Step 2: Deploy with Helm<a href="#step-2-deploy-with-helm" class="hash-link" aria-label="Step 2: Deploy with Helmì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Step 2: Deploy with Helmì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">helm repo </span><span class="token function" style="color:#d73a49">add</span><span class="token plain"> ai-on-eks https://awslabs.github.io/ai-on-eks-charts/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm repo update</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> llama4-scout ai-on-eks/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-4-scout-17b-lws-vllm.yaml</span><br></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>ì •ë³´</div><div class="admonitionContent_BuS1"><p>The Scout model uses <strong>LeaderWorkerSet (LWS)</strong> for multi-node tensor parallelism across 8 GPUs. Model download and initialization may take several minutes on first deployment.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-verify-deployment">Step 3: Verify Deployment<a href="#step-3-verify-deployment" class="hash-link" aria-label="Step 3: Verify Deploymentì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Step 3: Verify Deploymentì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Check pod status</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> app.kubernetes.io/component</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">llama-4-scout</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Watch logs for model loading progress</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> app.kubernetes.io/component</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">llama-4-scout </span><span class="token parameter variable" style="color:#36acaa">-f</span><br></span></code></pre></div></div>
<p>Wait until you see the vLLM server ready message in the logs:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">INFO:     Uvicorn running on http://0.0.0.0:8000</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-llama-4-maverick-17b-128e-on-gpu">Deploy Llama 4 Maverick (17B-128E) on GPU<a href="#deploy-llama-4-maverick-17b-128e-on-gpu" class="hash-link" aria-label="Deploy Llama 4 Maverick (17B-128E) on GPUì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Deploy Llama 4 Maverick (17B-128E) on GPUì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h2>
<p>Maverick requires FP8 quantization on GPU due to its large model size (~800 GiB BF16).</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">helm </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> llama4-maverick ai-on-eks/inference-charts </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--values</span><span class="token plain"> https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-4-maverick-17b-lws-vllm.yaml</span><br></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>ê²½ê³ </div><div class="admonitionContent_BuS1"><p>Maverick deployment requires <strong>p5.48xlarge</strong> instances (8x H100 80GB). Ensure your AWS account has sufficient <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-resource-limits.html" target="_blank" rel="noopener noreferrer">service quota</a> for P5 instances in your region.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="test-the-model">Test the Model<a href="#test-the-model" class="hash-link" aria-label="Test the Modelì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Test the Modelì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="port-forward">Port Forward<a href="#port-forward" class="hash-link" aria-label="Port Forwardì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Port Forwardì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward svc/llama-4-scout </span><span class="token number" style="color:#36acaa">8000</span><span class="token plain">:8000</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="chat-completion-request">Chat Completion Request<a href="#chat-completion-request" class="hash-link" aria-label="Chat Completion Requestì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Chat Completion Requestì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST http://localhost:8000/v1/chat/completions </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Content-Type: application/json&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;model&quot;: &quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;messages&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">      {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What are the key differences between Mixture of Experts and dense transformer models?&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;max_tokens&quot;: 512,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;temperature&quot;: 0.7</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">  }&#x27;</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="list-available-models">List Available Models<a href="#list-available-models" class="hash-link" aria-label="List Available Modelsì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="List Available Modelsì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> http://localhost:8000/v1/models </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> json.tool</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="multimodal-request-text--image">Multimodal Request (Text + Image)<a href="#multimodal-request-text--image" class="hash-link" aria-label="Multimodal Request (Text + Image)ì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Multimodal Request (Text + Image)ì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h3>
<p>Llama 4 supports vision inputs. You can send image URLs alongside text:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST http://localhost:8000/v1/chat/completions </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Content-Type: application/json&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;model&quot;: &quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;messages&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">      {</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        &quot;role&quot;: &quot;user&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        &quot;content&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">          {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What do you see in this image?&quot;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">          {&quot;type&quot;: &quot;image_url&quot;, &quot;image_url&quot;: {&quot;url&quot;: &quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg&quot;}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">      }</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;max_tokens&quot;: 256</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">  }&#x27;</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-open-webui">Deploy Open WebUI<a href="#deploy-open-webui" class="hash-link" aria-label="Deploy Open WebUIì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Deploy Open WebUIì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h2>
<p><a href="https://github.com/open-webui/open-webui" target="_blank" rel="noopener noreferrer">Open WebUI</a> provides a ChatGPT-style interface for interacting with the model.</p>
<p>The inference-ready cluster includes Open WebUI. To access it:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward svc/open-webui </span><span class="token number" style="color:#36acaa">8080</span><span class="token plain">:80 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> open-webui</span><br></span></code></pre></div></div>
<p>Open <a href="http://localhost:8080" target="_blank" rel="noopener noreferrer">http://localhost:8080</a> in your browser and register a new account. The model will appear in the model selector.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="monitoring">Monitoring<a href="#monitoring" class="hash-link" aria-label="Monitoringì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Monitoringì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="check-inference-logs">Check Inference Logs<a href="#check-inference-logs" class="hash-link" aria-label="Check Inference Logsì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Check Inference Logsì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># View vLLM logs for throughput and latency metrics</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> app.kubernetes.io/component</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">llama-4-scout </span><span class="token parameter variable" style="color:#36acaa">--tail</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">100</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Watch for token generation throughput</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> app.kubernetes.io/component</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">llama-4-scout </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">grep</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;tokens/s&quot;</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="gpu-utilization">GPU Utilization<a href="#gpu-utilization" class="hash-link" aria-label="GPU Utilizationì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="GPU Utilizationì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h3>
<p>If the observability stack is enabled on your cluster, access Grafana for GPU metrics:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward svc/kube-prometheus-stack-grafana </span><span class="token number" style="color:#36acaa">3000</span><span class="token plain">:80 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> monitoring</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cleanup">Cleanup<a href="#cleanup" class="hash-link" aria-label="Cleanupì— ëŒ€í•œ ì§ì ‘ ë§í¬" title="Cleanupì— ëŒ€í•œ ì§ì ‘ ë§í¬" translate="no">â€‹</a></h2>
<p>Remove the model deployment:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Remove Scout</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm uninstall llama4-scout</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Remove Maverick (if deployed)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm uninstall llama4-maverick</span><br></span></code></pre></div></div>
<p>To destroy the entire cluster infrastructure:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/infra/solutions/inference-ready-cluster</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./cleanup.sh</span><br></span></code></pre></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>í˜ì´ì§€ í¸ì§‘</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="ë¬¸ì„œ í˜ì´ì§€"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research"><div class="pagination-nav__sublabel">ì´ì „</div><div class="pagination-nav__label">EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/aibrix-deepseek-distill"><div class="pagination-nav__sublabel">ë‹¤ìŒ</div><div class="pagination-nav__label">EKSì˜ AIBrix</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#understanding-gpu-memory-requirements" class="table-of-contents__link toc-highlight">Understanding GPU Memory Requirements</a><ul><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#deploy-the-cluster" class="table-of-contents__link toc-highlight">Deploy the Cluster</a></li><li><a href="#configure-kubectl" class="table-of-contents__link toc-highlight">Configure kubectl</a></li><li><a href="#verify-eks-auto-mode-resources" class="table-of-contents__link toc-highlight">Verify EKS Auto Mode Resources</a></li></ul></li><li><a href="#deploy-llama-4-scout-17b-16e" class="table-of-contents__link toc-highlight">Deploy Llama 4 Scout (17B-16E)</a><ul><li><a href="#step-1-create-hugging-face-token-secret" class="table-of-contents__link toc-highlight">Step 1: Create Hugging Face Token Secret</a></li><li><a href="#step-2-deploy-with-helm" class="table-of-contents__link toc-highlight">Step 2: Deploy with Helm</a></li><li><a href="#step-3-verify-deployment" class="table-of-contents__link toc-highlight">Step 3: Verify Deployment</a></li></ul></li><li><a href="#deploy-llama-4-maverick-17b-128e-on-gpu" class="table-of-contents__link toc-highlight">Deploy Llama 4 Maverick (17B-128E) on GPU</a></li><li><a href="#test-the-model" class="table-of-contents__link toc-highlight">Test the Model</a><ul><li><a href="#port-forward" class="table-of-contents__link toc-highlight">Port Forward</a></li><li><a href="#chat-completion-request" class="table-of-contents__link toc-highlight">Chat Completion Request</a></li><li><a href="#list-available-models" class="table-of-contents__link toc-highlight">List Available Models</a></li><li><a href="#multimodal-request-text--image" class="table-of-contents__link toc-highlight">Multimodal Request (Text + Image)</a></li></ul></li><li><a href="#deploy-open-webui" class="table-of-contents__link toc-highlight">Deploy Open WebUI</a></li><li><a href="#monitoring" class="table-of-contents__link toc-highlight">Monitoring</a><ul><li><a href="#check-inference-logs" class="table-of-contents__link toc-highlight">Check Inference Logs</a></li><li><a href="#gpu-utilization" class="table-of-contents__link toc-highlight">GPU Utilization</a></li></ul></li><li><a href="#cleanup" class="table-of-contents__link toc-highlight">Cleanup</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">ì°¸ì—¬í•˜ê¸°</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with â¤ï¸ at AWS  <br> Â© ${new Date().getFullYear()} Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>