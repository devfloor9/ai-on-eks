<!doctype html>
<html lang="ko-KR" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.0">
<title data-rh="true">Amazon EKS에서의 NVIDIA NIM LLM | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3"><meta data-rh="true" property="og:locale" content="ko_KR"><meta data-rh="true" property="og:locale:alternate" content="en_US"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Amazon EKS에서의 NVIDIA NIM LLM | AI on EKS"><meta data-rh="true" name="description" content="EKS에서 ML 모델을 배포하려면 GPU 또는 Neuron 인스턴스에 대한 접근이 필요합니다. 배포가 작동하지 않는 경우, 이러한 리소스에 대한 접근 권한이 없기 때문인 경우가 많습니다. 또한 일부 배포 패턴은 Karpenter 자동 스케일링과 정적 노드 그룹에 의존합니다. 노드가 초기화되지 않으면 Karpenter 또는 노드 그룹의 로그를 확인하여 문제를 해결하세요."><meta data-rh="true" property="og:description" content="EKS에서 ML 모델을 배포하려면 GPU 또는 Neuron 인스턴스에 대한 접근이 필요합니다. 배포가 작동하지 않는 경우, 이러한 리소스에 대한 접근 권한이 없기 때문인 경우가 많습니다. 또한 일부 배포 패턴은 Karpenter 자동 스케일링과 정적 노드 그룹에 의존합니다. 노드가 초기화되지 않으면 Karpenter 또는 노드 그룹의 로그를 확인하여 문제를 해결하세요."><link data-rh="true" rel="icon" href="/ai-on-eks/ko/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3" hreflang="ko-KR"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"EKS에서의 추론","item":"https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/"},{"@type":"ListItem","position":2,"name":"Framework-Specific Deployment Guides","item":"https://awslabs.github.io/ai-on-eks/ko/docs/category/framework-specific-deployment-guides"},{"@type":"ListItem","position":3,"name":"EKS에서의 GPU 추론","item":"https://awslabs.github.io/ai-on-eks/ko/docs/category/gpu-inference-on-eks"},{"@type":"ListItem","position":4,"name":"Amazon EKS에서의 NVIDIA NIM LLM","item":"https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3"}]}</script><link rel="stylesheet" href="/ai-on-eks/ko/assets/css/styles.c270b852.css">
<script src="/ai-on-eks/ko/assets/js/runtime~main.84f685ef.js" defer="defer"></script>
<script src="/ai-on-eks/ko/assets/js/main.62626cce.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><div class="theme-announcement-bar announcementBar_mb4j" style="background-color:#667eea;color:#ffffff" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">GenAI on EKS workshop series! <a target="_blank" rel="noopener noreferrer" href="https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=9be4af2e-2339-40ae-b5e9-57b6a7704c36&sc_channel=el" style="color: #ffffff; text-decoration: underline; font-weight: bold; margin-left: 10px;">Register now →</a></div><button type="button" aria-label="닫기" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/ko/"><div class="navbar__logo"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS 로고" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS 로고" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/infra">인프라</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/ko/docs/blueprints">블루프린트</a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/guidance">가이드</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/ai-on-eks/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en-US">English</a></li><li><a href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko-KR">한국어</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="어두운 모드와 밝은 모드 전환하기 (현재 system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/blueprints"><span title="개요" class="linkLabel_WmDU">개요</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai-on-eks/ko/docs/blueprints/inference"><span title="EKS에서의 추론" class="categoryLinkLabel_W154">EKS에서의 추론</span></a><button aria-label="사이드바 분류 &#x27;EKS에서의 추론&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai-on-eks/ko/docs/category/framework-specific-deployment-guides"><span title="Framework-Specific Deployment Guides" class="categoryLinkLabel_W154">Framework-Specific Deployment Guides</span></a><button aria-label="사이드바 분류 &#x27;Framework-Specific Deployment Guides&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai-on-eks/ko/docs/category/gpu-inference-on-eks"><span title="EKS에서의 GPU 추론" class="categoryLinkLabel_W154">EKS에서의 GPU 추론</span></a><button aria-label="사이드바 분류 &#x27;EKS에서의 GPU 추론&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve"><span title="RayServe와 vLLM" class="linkLabel_WmDU">RayServe와 vLLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer"><span title="NVIDIA Triton Server와 vLLM" class="linkLabel_WmDU">NVIDIA Triton Server와 vLLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus"><span title="GPU에서의 Stable Diffusion" class="linkLabel_WmDU">GPU에서의 Stable Diffusion</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3"><span title="Amazon EKS에서의 NVIDIA NIM LLM" class="linkLabel_WmDU">Amazon EKS에서의 NVIDIA NIM LLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator"><span title="EKS의 NVIDIA NIM Operator" class="linkLabel_WmDU">EKS의 NVIDIA NIM Operator</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/ray-vllm-deepseek"><span title="EKS에서의 DeepSeek-R1" class="linkLabel_WmDU">EKS에서의 DeepSeek-R1</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo"><span title="Amazon EKS의 NVIDIA Dynamo" class="linkLabel_WmDU">Amazon EKS의 NVIDIA Dynamo</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research"><span title="EKS의 NVIDIA Enterprise RAG 및 AI-Q Research Assistant" class="linkLabel_WmDU">EKS의 NVIDIA Enterprise RAG 및 AI-Q Research Assistant</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm"><span title="Llama 4 with vLLM on EKS" class="linkLabel_WmDU">Llama 4 with vLLM on EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/aibrix-deepseek-distill"><span title="EKS의 AIBrix" class="linkLabel_WmDU">EKS의 AIBrix</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai-on-eks/ko/docs/category/neuron-inference-on-eks"><span title="EKS에서의 Neuron 추론" class="categoryLinkLabel_W154">EKS에서의 Neuron 추론</span></a><button aria-label="사이드바 분류 &#x27;EKS에서의 Neuron 추론&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/inference/inference-charts"><span title="추론 차트" class="linkLabel_WmDU">추론 차트</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai-on-eks/ko/docs/category/training-on-eks"><span title="EKS에서의 학습" class="categoryLinkLabel_W154">EKS에서의 학습</span></a><button aria-label="사이드바 분류 &#x27;EKS에서의 학습&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway"><span title="게이트웨이" class="categoryLinkLabel_W154">게이트웨이</span></a></div></li></ul></nav><button type="button" title="사이드바 숨기기" aria-label="사이드바 숨기기" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ai-on-eks/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/ko/docs/blueprints/inference"><span>EKS에서의 추론</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/ko/docs/category/framework-specific-deployment-guides"><span>Framework-Specific Deployment Guides</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/ko/docs/category/gpu-inference-on-eks"><span>EKS에서의 GPU 추론</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Amazon EKS에서의 NVIDIA NIM LLM</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>경고</div><div class="admonitionContent_BuS1"><p>EKS에서 ML 모델을 배포하려면 GPU 또는 Neuron 인스턴스에 대한 접근이 필요합니다. 배포가 작동하지 않는 경우, 이러한 리소스에 대한 접근 권한이 없기 때문인 경우가 많습니다. 또한 일부 배포 패턴은 Karpenter 자동 스케일링과 정적 노드 그룹에 의존합니다. 노드가 초기화되지 않으면 Karpenter 또는 노드 그룹의 로그를 확인하여 문제를 해결하세요.</p></div></div>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>경고</div><div class="admonitionContent_BuS1"><p>참고: NVIDIA NIM을 구현하기 전에, 이것이 <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener noreferrer">NVIDIA AI Enterprise</a>의 일부이며, 프로덕션 사용 시 잠재적인 비용과 라이선스가 발생할 수 있음을 알아두세요.</p><p>평가를 위해 NVIDIA는 NVIDIA AI Enterprise를 90일 동안 사용해 볼 수 있는 무료 평가 라이선스도 제공하며, 회사 이메일로 <a href="https://enterpriseproductregistration.nvidia.com/?LicType=EVAL&amp;ProductFamily=NVAIEnterprise" target="_blank" rel="noopener noreferrer">등록</a>할 수 있습니다.</p></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>정보</div><div class="admonitionContent_BuS1"><p>관측성, 로깅 및 확장성 측면의 개선 사항을 통합하기 위해 이 블루프린트를 적극적으로 개선하고 있습니다.</p></div></div>
<header><h1>Amazon EKS에서의 NVIDIA NIM LLM 배포</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="nvidia-nim이란">NVIDIA NIM이란?<a href="#nvidia-nim이란" class="hash-link" aria-label="NVIDIA NIM이란?에 대한 직접 링크" title="NVIDIA NIM이란?에 대한 직접 링크" translate="no">​</a></h2>
<p>NVIDIA NIM은 IT 및 DevOps 팀이 자체 관리 환경에서 대규모 언어 모델(LLM)을 쉽게 자체 호스팅할 수 있게 하면서, 개발자에게는 비즈니스를 혁신할 수 있는 강력한 코파일럿, 챗봇 및 AI 어시스턴트를 구축할 수 있는 업계 표준 API를 제공합니다. NVIDIA의 최첨단 GPU 가속과 확장 가능한 배포를 활용하여 NIM은 비교할 수 없는 성능으로 추론에 대한 가장 빠른 경로를 제공합니다.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="왜-nim인가">왜 NIM인가?<a href="#왜-nim인가" class="hash-link" aria-label="왜 NIM인가?에 대한 직접 링크" title="왜 NIM인가?에 대한 직접 링크" translate="no">​</a></h2>
<p>NIM은 실행 엔진 및 런타임 운영과 같은 모델 추론 내부를 추상화합니다. 또한 TRT-LLM, vLLM 또는 기타 옵션 중 가장 성능이 좋은 옵션입니다.</p>
<p>NIM은 모델/모델 패밀리별로 컨테이너 이미지로 패키징됩니다. 각 NIM 컨테이너는 <code>meta/llama3-8b-instruct</code>와 같은 모델과 함께 제공됩니다. 이러한 컨테이너에는 충분한 GPU 메모리가 있는 모든 NVIDIA GPU에서 실행되는 런타임이 포함되어 있지만, 일부 모델/GPU 조합은 최적화되어 있습니다. NIM은 사용 가능한 경우 로컬 파일 시스템 캐시를 활용하여 NVIDIA NGC Catalog에서 모델을 자동으로 다운로드합니다.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="amazon-eks에서의-이-배포-패턴-개요">Amazon EKS에서의 이 배포 패턴 개요<a href="#amazon-eks에서의-이-배포-패턴-개요" class="hash-link" aria-label="Amazon EKS에서의 이 배포 패턴 개요에 대한 직접 링크" title="Amazon EKS에서의 이 배포 패턴 개요에 대한 직 접 링크" translate="no">​</a></h2>
<p>이 패턴은 NVIDIA NIM, Amazon Elastic Kubernetes Service(EKS) 및 다양한 AWS 서비스의 기능을 결합하여 고성능 및 비용 최적화된 모델 서빙 인프라를 제공합니다.</p>
<ol>
<li>
<p>NVIDIA NIM 컨테이너 이미지: NVIDIA NIM은 컨테이너화된 환경에서 Llama3와 같은 LLM 모델을 호스팅하는 간소화된 접근 방식을 제공합니다. 이를 통해 고객은 기존 인프라와의 원활한 통합을 보장하면서 프라이빗 모델을 활용할 수 있습니다. NIM 배포에 대한 자세한 설정 단계를 안내합니다.</p>
</li>
<li>
<p>인스턴스 수준 스케일링을 위한 Karpenter: 오픈소스 노드 프로비저닝 프로젝트인 Karpenter는 Amazon EKS 클러스터의 인스턴스 수준에서 빠르고 효율적인 스케일링을 가능하게 합니다. 이를 통해 모델 서빙 인프라가 동적 워크로드 요구에 적응하여 리소스 활용 및 비용 효율성을 최적화할 수 있습니다.</p>
</li>
<li>
<p>스팟 인스턴스: LLM이 상태 비저장이라는 점을 고려하여 고객은 스팟 인스턴스를 활용하여 비용을 크게 절감할 수 있습니다.</p>
</li>
<li>
<p>Amazon Elastic File System(EFS): Amazon EFS는 Amazon EKS와 함께 사용할 수 있는 확장 가능하고 탄력적인 파일 스토리지를 제공합니다. 여러 파드가 동시에 동일한 파일 시스템에 접근할 수 있어 클러스터 전체에서 모델 아티팩트, 데이터셋 및 기타 영구 데이터를 저장하고 공유하는 데 이상적입니다. EFS는 파일을 추가하고 제거함에 따라 자동으로 증가하고 축소되어 용량 계획 및 관리가 필요 없습니다.</p>
</li>
<li>
<p>EKS Blueprints를 사용한 Terraform: 이 솔루션의 배포 및 관리를 간소화하기 위해 Terraform과 EKS Blueprints를 활용합니다. 이 Infrastructure-as-Code 접근 방식은 전체 스택의 자동화된 프로비저닝을 가능하게 하여 일관성, 재현성 및 효율적인 리소스 관리를 보장합니다.</p>
</li>
</ol>
<p>이러한 구성 요소를 결합하여 제안된 솔루션은 대규모 언어 모델에 맞춤화된 강력하고 비용 효율적인 모델 서빙 인프라를 제공합니다. NVIDIA NIM의 원활한 통합과 Karpenter를 통한 Amazon EKS의 확장성으로 고객은 인프라 비용을 최소화하면서 높은 성능을 달성할 수 있습니다.</p>
<p><img decoding="async" loading="lazy" alt="NIM on EKS Architecture" src="/ai-on-eks/ko/assets/images/nim-on-eks-arch-c9a91bdfa99f2f904c3fe9c6e2547bcd.png" width="2674" height="1466" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="솔루션-배포">솔루션 배포<a href="#솔루션-배포" class="hash-link" aria-label="솔루션 배포에 대한 직접 링크" title="솔루션 배포에 대한 직접 링크" translate="no">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="사전-요구-사항">사전 요구 사항<a href="#사전-요구-사항" class="hash-link" aria-label="사전 요구 사항에 대한 직접 링크" title="사전 요구 사항에 대한 직접 링크" translate="no">​</a></h3>
<p>NVIDIA NIM을 시작하기 전에 다음 사항이 준비되어 있는지 확인하세요:</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>NVIDIA NIM 계정 설정 세부 정보를 보려면 클릭하세요</summary><div><div class="collapsibleContent_i85q"><p><strong>NVIDIA AI Enterprise 계정</strong></p><ul>
<li>NVIDIA AI Enterprise 계정에 등록하세요. 계정이 없다면 이 <a href="https://enterpriseproductregistration.nvidia.com/?LicType=EVAL&amp;ProductFamily=NVAIEnterprise" target="_blank" rel="noopener noreferrer">링크</a>를 사용하여 평가판 계정에 가입할 수 있습니다.</li>
</ul><p><strong>NGC API 키</strong></p><ol>
<li>
<p>NVIDIA AI Enterprise 계정에 로그인합니다</p>
</li>
<li>
<p>NGC(NVIDIA GPU Cloud) <a href="https://org.ngc.nvidia.com/" target="_blank" rel="noopener noreferrer">포털</a>로 이동합니다</p>
</li>
<li>
<p>개인 API 키를 생성합니다:</p>
<ul>
<li>계정 설정으로 이동하거나 직접 <a href="https://org.ngc.nvidia.com/setup/personal-keys" target="_blank" rel="noopener noreferrer">https://org.ngc.nvidia.com/setup/personal-keys</a> 로 이동합니다</li>
<li>&quot;Generate Personal Key&quot;를 클릭합니다</li>
<li>&quot;Services Included&quot; 드롭다운에서 최소한 &quot;NGC Catalog&quot;가 선택되어 있는지 확인합니다</li>
<li>API 키를 복사하고 안전하게 저장합니다. 키는 <code>nvapi-</code> 접두사가 있어야 합니다</li>
</ul>
<p><img decoding="async" loading="lazy" alt="NGC API KEY" src="/ai-on-eks/ko/assets/images/nim-ngc-api-key-8f10f8d047f3721dbeddd112c6b69a81.png" width="2822" height="1524" class="img_ev3q"></p>
</li>
</ol><p><strong>NGC API 키 검증 및 이미지 풀 테스트</strong></p><p>API 키가 유효하고 올바르게 작동하는지 확인하려면:</p><ol>
<li>NGC API 키를 환경 변수로 설정합니다:</li>
</ol><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">NGC_API_KEY</span><span class="token operator" style="color:#393A34">=</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">your_api_key_here</span><span class="token operator" style="color:#393A34">&gt;</span><br></span></code></pre></div></div><ol start="2">
<li>NVIDIA Container Registry로 Docker 인증을 수행합니다:</li>
</ol><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">echo</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;</span><span class="token string variable" style="color:#36acaa">$NGC_API_KEY</span><span class="token string" style="color:#e3116c">&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">docker</span><span class="token plain"> login nvcr.io </span><span class="token parameter variable" style="color:#36acaa">--username</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;$oauthtoken&#x27;</span><span class="token plain"> --password-stdin</span><br></span></code></pre></div></div><ol start="3">
<li>NGC에서 이미지 풀을 테스트합니다:</li>
</ol><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">docker</span><span class="token plain"> pull nvcr.io/nim/meta/llama3-8b-instruct:latest</span><br></span></code></pre></div></div><p>완료될 때까지 기다릴 필요 없이, API 키가 이미지를 풀할 수 있는지 확인만 하면 됩니다.</p></div></div></details>
<p>이 튜토리얼을 실행하려면 다음이 필요합니다</p>
<ul>
<li>관리자와 동등한 권한이 있는 활성 AWS 계  정</li>
<li><a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html" target="_blank" rel="noopener noreferrer">aws cli</a></li>
<li><a href="https://Kubernetes.io/docs/tasks/tools/" target="_blank" rel="noopener noreferrer">kubectl</a></li>
<li><a href="https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli" target="_blank" rel="noopener noreferrer">Terraform</a></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="배포">배포<a href="#배포" class="hash-link" aria-label="배포에 대한 직접 링크" title="배포에 대한 직접 링크" translate="no">​</a></h3>
<p>저장소 복제</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/awslabs/ai-on-eks.git</span><br></span></code></pre></div></div>
<p><strong>1. NGC API 키 구성</strong></p>
<p><a href="https://docs.nvidia.com/ai-enterprise/deployment-guide-spark-rapids-accelerator/0.1.0/appendix-ngc.html" target="_blank" rel="noopener noreferrer">NVIDIA</a>에서 NGC API 키를 검색하고 환경 변수로 설정합니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">TF_VAR_ngc_api_key</span><span class="token operator" style="color:#393A34">=</span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">replace-with-your-NGC-API-KEY</span><span class="token operator" style="color:#393A34">&gt;</span><br></span></code></pre></div></div>
<p><strong>2. 설치</strong></p>
<p>중요 참고 사항: 블루프린트를 배포하기 전에 <code>blueprint.tfvars</code> 파일에서 리전을 업데이트해야 합니다. 또한 불일치를 방지하기 위해 로컬 리전 설정이 지정된 리전과 일치하는지 확인하세요. 예를 들어, <code>export AWS_DEFAULT_REGION=&quot;&lt;REGION&gt;&quot;</code>을 원하는 리전으로 설정하세요:</p>
<p>설치 스크립트를 실행합니다:</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>정보</div><div class="admonitionContent_BuS1"><p>이 패턴은 <code>nvcr.io/nim/meta/llama3-8b-instruct</code>라는 모델을 배포합니다. <code>blueprint.tfvars</code> 파일에서 <code>nim_models</code> 변수를 수정하여 더 많은 모델을 추가할 수 있습니다. 이 패턴을 사용하여 여러 모델을 동시에 배포할 수 있습니다.</p></div></div>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>주의</div><div class="admonitionContent_BuS1"><p>이러한 변수를 통해 추가 모델을 활성화하기 전에 각 모델에 충분한 GPU를 지정했는지 확인하세요. 또한 AWS 계정이 충분한 GPU에 접근할 수 있는지 확인하세요.
이 패턴은 Karpenter를 사용하여 GPU 노드를 스케일링하며, 기본적으로 G5 인스턴스로 제한됩니다. 필요한 경우 Karpenter 노드 풀을 수정하여 p4 및 p5와 같은 다른 인스턴스를 포함할 수 있습니다.</p></div></div>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/infra/nvidia-triton-server</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">TF_VAR_enable_nvidia_nim</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">true</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">TF_VAR_enable_nvidia_triton_server</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">false</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./install.sh</span><br></span></code></pre></div></div>
<p>이 프로세스는 완료하는 데 약 20분이 소요됩니다.</p>
<p><strong>3. 설치 확인</strong></p>
<p>설치가 완료되면 출력에서 configure_kubectl 명령을 찾을 수 있습니다. 다음을 실행하여 EKS 클러스터 접근을 구성합니다</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># EKS로 인증하기 위한 k8s 설정 파일 생성</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">aws eks </span><span class="token parameter variable" style="color:#36acaa">--region</span><span class="token plain"> us-west-2 update-kubeconfig </span><span class="token parameter variable" style="color:#36acaa">--name</span><span class="token plain"> nvidia-triton-server</span><br></span></code></pre></div></div>
<p>배포된 파드의 상태를 확인합니다</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get all </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> nim</span><br></span></code></pre></div></div>
<p>다음과 유사한 출력이 표시됩니다:</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>배포 세부 정보를 보려면 클릭하세요</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">NAME                               READY   STATUS    RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pod/nim-llm-llama3-8b-instruct-0   1/1     Running   0          4h2m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                     TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">service/nim-llm-llama3-8b-instruct       ClusterIP   172.20.5.230   &lt;none&gt;        8000/TCP   4h2m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">service/nim-llm-llama3-8b-instruct-sts   ClusterIP   None           &lt;none&gt;        8000/TCP   4h2m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                          READY   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">statefulset.apps/nim-llm-llama3-8b-instruct   1/1     4h2m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                                             REFERENCE                                TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">horizontalpodautoscaler.autoscaling/nim-llm-llama3-8b-instruct   StatefulSet/nim-llm-llama3-8b-instruct   2/5       1         5         1          4h2m</span><br></span></code></pre></div></div></div></div></details>
<p><code>llama3-8b-instruct</code> 모델은 <code>nim</code> 네임스페이스에 StatefulSet으로 배포됩니다. 실행 중에 Karpenter가 GPU를 프로비저닝합니다.
Karpenter가 프로비저닝한 노드를 확인합니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get </span><span class="token function" style="color:#d73a49">node</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">type</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">karpenter </span><span class="token parameter variable" style="color:#36acaa">-L</span><span class="token plain"> node.kubernetes.io/instance-type</span><br></span></code></pre></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                         STATUS   ROLES    AGE     VERSION               INSTANCE-TYPE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ip-100-64-77-39.us-west-2.compute.internal   Ready    &lt;none&gt;   4m46s   v1.30.0-eks-036c24b   g5.2xlarge</span><br></span></code></pre></div></div>
<p><strong>4. 배포된 모델 확인</strong></p>
<p><code>nim</code> 네임스페이스의 모든 파드가 <code>1/1</code> 상태로 준비되면 아래 명령을 사용하여 트래픽을 처리할 준비가 되었는지 확인합니다. 확인하려면 kubectl을 사용하여 port-forward로 모델 서빙 서비스를 노출합니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> nim service/nim-llm-llama3-8b-instruct </span><span class="token number" style="color:#36acaa">8000</span><br></span></code></pre></div></div>
<p>그런 다음 curl 명령으로 간단한 HTTP 요청을 통해 배포된 모델을 호출할 수 있습니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;POST&#x27;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;http://localhost:8000/v1/completions&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;accept: application/json&#x27;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;Content-Type: application/json&#x27;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">      &quot;model&quot;: &quot;meta/llama3-8b-instruct&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">      &quot;prompt&quot;: &quot;Once upon a time&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">      &quot;max_tokens&quot;: 64</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">      }&#x27;</span><br></span></code></pre></div></div>
<p>다음과 유사한 출력이 표시됩니다</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;id&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;cmpl-63a0b66aeda1440c8b6ca1ce3583b173&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;object&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;text_completion&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;created&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1719742336</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;model&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;meta/llama3-8b-instruct&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;choices&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">&quot;index&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">&quot;text&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;, there was a young man named Jack who lived in a small village at the foot of a vast and ancient forest. Jack was a curious and adventurous soul, always eager to explore the world beyond his village. One day, he decided to venture into the forest, hoping to discover its secrets.\nAs he wandered deeper into&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">&quot;logprobs&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token null keyword" style="color:#00009f">null</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">&quot;finish_reason&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;length&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token property" style="color:#36acaa">&quot;stop_reason&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token null keyword" style="color:#00009f">null</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">&quot;usage&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;prompt_tokens&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;total_tokens&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">69</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token property" style="color:#36acaa">&quot;completion_tokens&quot;</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">64</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="nim으로-배포된-llama3-모델-테스트">NIM으로 배포된 Llama3 모델 테스트<a href="#nim으로-배포된-llama3-모델-테스트" class="hash-link" aria-label="NIM으로 배포된 Llama3 모델 테스트에 대한 직접 링크" title="NIM으로 배포된 Llama3 모델 테스트에 대한 직접 링크" translate="no">​</a></h3>
<p>방금 배포한 Llama3를 테스트할 시간입니다. 먼저 테  스트를 위한 간단한 환경을 설정합니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/blueprints/inference/nvidia-nim/nim-client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> venv .venv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">source</span><span class="token plain"> .venv/bin/activate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> openai</span><br></span></code></pre></div></div>
<p>prompts.txt에 프롬프트를 준비해 두었으며, 20개의 프롬프트가 포함되어 있습니다. 다음 명령을 프롬프트와 함께 실행하여 생성된 출력을 확인할 수 있습니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python3 client.py --input-prompts prompts.txt --results-file results.txt</span><br></span></code></pre></div></div>
<p>아래와 같은 출력이 표시됩니다:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Loading inputs from `prompts.txt`...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 14: 4.68s (4678.46ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 10: 6.43s (6434.32ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 3: 7.82s (7824.33ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 1: 8.54s (8540.69ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 5: 8.81s (8807.52ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 12: 8.95s (8945.85ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 18: 9.77s (9774.75ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 16: 9.99s (9994.51ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 6: 10.26s (10263.60ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 0: 10.27s (10274.35ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 4: 10.65s (10654.39ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 17: 10.75s (10746.08ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 11: 10.86s (10859.91ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 15: 10.86s (10857.15ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 8: 11.07s (11068.78ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 2: 12.11s (12105.07ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 19: 12.64s (12636.42ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 9: 13.37s (13370.75ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 13: 13.57s (13571.28ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Model meta/llama3-8b-instruct - Request 7: 14.90s (14901.51ms)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Storing results into `results.txt`...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Accumulated time for all requests: 206.31 seconds (206309.73 milliseconds)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">PASS: NVIDIA NIM example</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Actual execution time used with concurrency 20 is: 14.92 seconds (14.92 milliseconds)</span><br></span></code></pre></div></div>
<p><code>results.txt</code>의 출력은 다음과 같이 표시됩니다</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>부분 출력을 보려면 클릭하세요</summary><div><div class="collapsibleContent_i85q"><div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">The key differences between traditional machine learning models and very large language models (vLLM) are:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. **Scale**: vLLMs are massive, with billions of parameters, whereas traditional models typically have millions.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. **Training data**: vLLMs are trained on vast amounts of text data, often sourced from the internet, whereas traditional models are trained on smaller, curated datasets.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. **Architecture**: vLLMs often use transformer architectures, which are designed for sequential data like text, whereas traditional models may use feedforward networks or recurrent neural networks.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. **Training objectives**: vLLMs are often trained using masked language modeling or next sentence prediction tasks, whereas traditional models may use classification, regression, or clustering objectives.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. **Evaluation metrics**: vLLMs are typically evaluated using metrics like perplexity, accuracy, or fluency, whereas traditional models may use metrics like accuracy, precision, or recall.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">6. **Interpretability**: vLLMs are often less interpretable due to their massive size and complex architecture, whereas traditional models may be more interpretable due to their smaller size and simpler architecture.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">These differences enable vLLMs to excel in tasks like language translation, text generation, and conversational AI, whereas traditional models are better suited for tasks like image classification or regression.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">=========</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TensorRT (Triton Runtime) optimizes LLM (Large Language Model) inference on NVIDIA hardware by:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. **Model Pruning**: Removing unnecessary weights and connections to reduce model size and computational requirements.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. **Quantization**: Converting floating-point models to lower-precision integer formats (e.g., INT8) to reduce memory bandwidth and improve performance.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. **Kernel Fusion**: Combining multiple kernel launches into a single launch to reduce overhead and improve parallelism.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. **Optimized Tensor Cores**: Utilizing NVIDIA&#x27;s Tensor Cores for matrix multiplication, which provides significant performance boosts.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. **Batching**: Processing multiple input batches concurrently to improve throughput.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">6. **Mixed Precision**: Using a combination of floating-point and integer precision to balance accuracy and performance.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">7. **Graph Optimization**: Reordering and reorganizing the computation graph to minimize memory access and optimize data transfer.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">By applying these optimizations, TensorRT can significantly accelerate LLM inference on NVIDIA hardware, achieving faster inference times and improved performance.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">=========</span><br></span></code></pre></div></div></div></div></details>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="open-webui-배포">Open WebUI 배포<a href="#open-webui-배포" class="hash-link" aria-label="Open WebUI 배포에 대한 직접 링크" title="Open WebUI 배포에 대한 직접 링크" translate="no">​</a></h2>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>정보</div><div class="admonitionContent_BuS1"><p><a href="https://github.com/open-webui/open-webui" target="_blank" rel="noopener noreferrer">Open WebUI</a>는 OpenAI API 서버 및 Ollama와 호환되는 모델에서만 작동합니다.</p></div></div>
<p><strong>1. WebUI 배포</strong></p>
<p>다음 명령을 실행하여 <a href="https://github.com/open-webui/open-webui" target="_blank" rel="noopener noreferrer">Open WebUI</a>를 배포합니다:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> ai-on-eks/blueprints/inference/nvidia-nim/openai-webui-deployment.yaml</span><br></span></code></pre></div></div>
<p><strong>2. WebUI에 접근하기 위한 Port Forward</strong></p>
<p>kubectl port-forward를 사용하여 로컬에서 WebUI에 접근합니다:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward svc/open-webui </span><span class="token number" style="color:#36acaa">8081</span><span class="token plain">:80 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> openai-webui</span><br></span></code></pre></div></div>
<p><strong>3. WebUI 접근</strong></p>
<p>브라우저를 열고 <a href="http://localhost:8081" target="_blank" rel="noopener noreferrer">http://localhost:8081</a> 로 이동합니다</p>
<p><strong>4. 가입</strong></p>
<p>이름, 이메일 및 임의의 비밀번호로 가입합니다.</p>
<p><strong>5. 새 채팅 시작</strong></p>
<p>New Chat을 클릭하고 아래 스크린샷과 같이 드롭다운 메뉴에서 모델을 선택합니다:</p>
<p><img decoding="async" loading="lazy" alt="alt text" src="/ai-on-eks/ko/assets/images/openweb-ui-nim-1-7fddca9b300b28af7260b0bc12b69ff0.png" width="2076" height="936" class="img_ev3q"></p>
<p><strong>6. 테스트 프롬프트 입력</strong></p>
<p>프롬프트를 입력하면 아래와 같이 스트리밍 결과가 표시됩니다:</p>
<p><img decoding="async" loading="lazy" alt="alt text" src="/ai-on-eks/ko/assets/images/openweb-ui-nim-2-e9a836cbafc53c50b8437d766b3adbd4.png" width="2738" height="1382" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="nvidia-genai-perf-도구를-사용한-성능-테스트">NVIDIA GenAI-Perf 도구를 사용한 성능 테스트<a href="#nvidia-genai-perf-도구를-사용한-성능-테스트" class="hash-link" aria-label="NVIDIA GenAI-Perf 도구를 사용한 성능 테스트에 대한 직접 링크" title="NVIDIA GenAI-Perf 도구를 사용한 성능 테스트에 대한 직접 링크" translate="no">​</a></h2>
<p><a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/client/src/c%2B%2B/perf_analyzer/genai-perf/README.html" target="_blank" rel="noopener noreferrer">GenAI-Perf</a>는 추론 서버를 통해 제공되는 생성형 AI 모델의 처리량과 지연 시간을 측정하기 위한 명령줄 도구입니다.</p>
<p>GenAI-Perf는 추론 서버로 배포된 다른 모델과 벤치마크하는 표준 도구로 사용할 수 있습니다. 그러나 이 도구에는 GPU가 필요합니다. 더 쉽게 사용할 수 있도록 도구를 실행하기 위한 사전 구성된 매니페스트 <code>genaiperf-deploy.yaml</code>을 제공합니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/blueprints/inference/nvidia-nim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> genaiperf-deploy.yaml</span><br></span></code></pre></div></div>
<p>파드가 실행 상태 <code>1/1</code>로 준비되면 파드에 접속할 수 있습니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">POD_NAME</span><span class="token operator" style="color:#393A34">=</span><span class="token variable" style="color:#36acaa">$(</span><span class="token variable" style="color:#36acaa">kubectl get po </span><span class="token variable parameter variable" style="color:#36acaa">-l</span><span class="token variable" style="color:#36acaa"> </span><span class="token variable assign-left variable" style="color:#36acaa">app</span><span class="token variable operator" style="color:#393A34">=</span><span class="token variable" style="color:#36acaa">tritonserver </span><span class="token variable parameter variable" style="color:#36acaa">-ojsonpath</span><span class="token variable operator" style="color:#393A34">=</span><span class="token variable string" style="color:#e3116c">&#x27;{.items[0].metadata.name}&#x27;</span><span class="token variable" style="color:#36acaa">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl </span><span class="token builtin class-name">exec</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-it</span><span class="token plain"> </span><span class="token variable" style="color:#36acaa">$POD_NAME</span><span class="token plain"> -- </span><span class="token function" style="color:#d73a49">bash</span><br></span></code></pre></div></div>
<p>배포된 NIM Llama3 모델에 대해 테스트를 실행합니다</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">genai-perf </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> meta/llama3-8b-instruct </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --service-kind openai </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--endpoint</span><span class="token plain"> v1/completions </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --endpoint-type completions </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --num-prompts </span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --random-seed </span><span class="token number" style="color:#36acaa">123</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --synthetic-input-tokens-mean </span><span class="token number" style="color:#36acaa">200</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --synthetic-input-tokens-stddev </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --output-tokens-mean </span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --output-tokens-stddev </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--tokenizer</span><span class="token plain"> hf-internal-testing/llama-tokenizer </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--concurrency</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --measurement-interval </span><span class="token number" style="color:#36acaa">4000</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --profile-export-file my_profile_export.json </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">--url</span><span class="token plain"> nim-llm-llama3-8b-instruct.nim:8000</span><br></span></code></pre></div></div>
<p>다음과 유사한 출력이 표시됩니다</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token number" style="color:#36acaa">2024</span><span class="token plain">-07-11 03:32 </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">INFO</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> genai_perf.parser:166 - Model name </span><span class="token string" style="color:#e3116c">&#x27;meta/llama3-8b-instruct&#x27;</span><span class="token plain"> cannot be used to create artifact directory. Instead, </span><span class="token string" style="color:#e3116c">&#x27;meta_llama3-8b-instruct&#x27;</span><span class="token plain"> will be used.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token number" style="color:#36acaa">2024</span><span class="token plain">-07-11 03:32 </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">INFO</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> genai_perf.wrapper:137 - Running Perf Analyzer </span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;perf_analyzer -m meta/llama3-8b-instruct --async --input-data artifacts/meta_llama3-8b-instruct-openai-completions-concurrency10/llm_inputs.json --endpoint v1/completions --service-kind openai -u nim-llm.nim:8000 --measurement-interval 4000 --stability-percentage 999 --profile-export-file artifacts/meta_llama3-8b-instruct-openai-completions-concurrency10/my_profile_export.json -i http --concurrency-range 10&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                                      LLM Metrics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">┃            Statistic ┃           avg ┃           min ┃           max ┃           p99 ┃           p90 ┃           p75 ┃</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│ Request latency </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ns</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> │ </span><span class="token number" style="color:#36acaa">3,934</span><span class="token plain">,624,446 │ </span><span class="token number" style="color:#36acaa">3,897</span><span class="token plain">,758,114 │ </span><span class="token number" style="color:#36acaa">3,936</span><span class="token plain">,987,882 │ </span><span class="token number" style="color:#36acaa">3,936</span><span class="token plain">,860,185 │ </span><span class="token number" style="color:#36acaa">3,936</span><span class="token plain">,429,317 │ </span><span class="token number" style="color:#36acaa">3,936</span><span class="token plain">,333,682 │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│     Num output token │           </span><span class="token number" style="color:#36acaa">112</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">105</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">119</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">119</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">117</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">115</span><span class="token plain"> │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│      Num input token │           </span><span class="token number" style="color:#36acaa">200</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">200</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">200</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">200</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">200</span><span class="token plain"> │           </span><span class="token number" style="color:#36acaa">200</span><span class="token plain"> │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└──────────────────────┴───────────────┴───────────────┴───────────────┴───────────────┴─  ──────────────┴───────────────┘</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Output token throughput </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">per sec</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">: </span><span class="token number" style="color:#36acaa">284.64</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Request throughput </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">per sec</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">: </span><span class="token number" style="color:#36acaa">2.54</span><br></span></code></pre></div></div>
<p>Request latency, Out token throughput, Request throughput를 포함하여 genai-perf가 수집하는 <a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/client/src/c%2B%2B/perf_analyzer/genai-perf/README.html#metrics" target="_blank" rel="noopener noreferrer">메트릭</a>을 볼 수 있습니다.</p>
<p>명령줄 옵션을 이해하려면 <a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/client/src/c%2B%2B/perf_analyzer/genai-perf/README.html#command-line-options" target="_blank" rel="noopener noreferrer">이 문서</a>를 참조하세요.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="관측성">관측성<a href="#관측성" class="hash-link" aria-label="관측성에 대한 직접 링크" title="관측성에 대한 직접 링크" translate="no">​</a></h2>
<p>이 블루프린트의 일부로 모니터링 및 관측성을 위한 Prometheus 서버와 Grafana 배포를 제공하는 Kube Prometheus 스택도 배포했습니다.</p>
<p>먼저 Kube Prometheus 스택에서 배포한 서비스를 확인합니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get svc </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> monitoring</span><br></span></code></pre></div></div>
<p>다음과 유사한 출력이 표시됩니다:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kube-prometheus-stack-grafana                    ClusterIP   172.20.225.77    &lt;none&gt;        80/TCP              10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kube-prometheus-stack-kube-state-metrics         ClusterIP   172.20.237.248   &lt;none&gt;        8080/TCP            10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kube-prometheus-stack-operator                   ClusterIP   172.20.118.163   &lt;none&gt;        443/TCP             10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kube-prometheus-stack-prometheus                 ClusterIP   172.20.132.214   &lt;none&gt;        9090/TCP,8080/TCP   10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kube-prometheus-stack-prometheus-node-exporter   ClusterIP   172.20.213.178   &lt;none&gt;        9100/TCP            10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prometheus-adapter                               ClusterIP   172.20.171.163   &lt;none&gt;        443/TCP             10m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prometheus-operated                              ClusterIP   None             &lt;none&gt;        9090/TCP            10m</span><br></span></code></pre></div></div>
<p>NVIDIA NIM LLM 서비스는 포트 <code>8000</code>의 <code>nim-llm-llama3-8b-instruct</code> 서비스에서 <code>/metrics</code> 엔드포인트를 통해 메트릭을 노출합니다. 다음을 실행하여 확인합니다</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get svc </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> nim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> nim svc/nim-llm-llama3-8b-instruct </span><span class="token number" style="color:#36acaa">8000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> localhost:8000/metrics </span><span class="token comment" style="color:#999988;font-style:italic"># 다른 터미널에서 실행</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="grafana-대시보드">Grafana 대시보드<a href="#grafana-대시보드" class="hash-link" aria-label="Grafana 대시보드에 대한 직접 링크" title="Grafana 대시보드에 대한 직접 링크" translate="no">​</a></h3>
<p>NIM 상태를 더 잘 시각화하기 위해 사전 구성된 Grafana 대시보드를 제공합니다. 아래 Grafana 대시보드에는 여러 중요한 메트릭이 포함되어 있습니다:</p>
<ul>
<li><strong>Time to First Token(TTFT)</strong>: 모델에 대한 초기 추론 요청과 첫 번째 토큰 반환 사이의 지연 시간.</li>
<li><strong>Inter-Token Latency(ITL)</strong>: 첫 번째 토큰 이후 각 토큰 사이의 지연 시간.</li>
<li><strong>Total Throughput</strong>: NIM에서 초당 생성되는 총 토큰 수.</li>
</ul>
<p>더 많은 메트릭 설명은 이 <a href="https://docs.nvidia.com/nim/large-language-models/latest/observability.html" target="_blank" rel="noopener noreferrer">문서</a>에서 찾을 수 있습니다.</p>
<p><img decoding="async" loading="lazy" alt="NVIDIA LLM Server" src="/ai-on-eks/ko/assets/images/nim-dashboard-c8dad192e95da70bd2474db5a466b448.png" width="3300" height="1730" class="img_ev3q"></p>
<p>Time-to-First-Token, Inter-Token-Latency, KV Cache Utilization 메트릭 등을 모니터링할 수 있습니다.</p>
<p><img decoding="async" loading="lazy" alt="NVIDIA NIM Metrics" src="/ai-on-eks/ko/assets/images/nim-dashboard-2-7fa24a28624902d2a665f515ab2b4fd1.png" width="3300" height="1730" class="img_ev3q"></p>
<p>이러한 메트릭을 모니터링하기 위해 Grafana 대시보드를 보려면 아래 단계를 따르세요:</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>세부 정보를 보려면 클릭하세요</summary><div><div class="collapsibleContent_i85q"><p><strong>1. Grafana 비밀번호 검색</strong></p><p>비밀번호는 AWS Secret Manager에 저장되어 있습니다. 아래 Terraform 명령이 시크릿 이름을 보여줍니다.</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">terraform output grafana_secret_name</span><br></span></code></pre></div></div><p>그런 다음 출력된 시크릿 이름을 사용하여 아래 명령을 실행합니다,</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">aws secretsmanager get-secret-value --secret-id </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">grafana_secret_name_output</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">--region</span><span class="token plain"> </span><span class="token variable" style="color:#36acaa">$AWS_REGION</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">--query</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;SecretString&quot;</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">--output</span><span class="token plain"> text</span><br></span></code></pre></div></div><p><strong>2. Grafana 서비스   노출</strong></p><p>port-forward를 사용하여 Grafana 서비스를 노출합니다.</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward svc/kube-prometheus-stack-grafana </span><span class="token number" style="color:#36acaa">3000</span><span class="token plain">:80 </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> monitoring</span><br></span></code></pre></div></div><p><strong>3. Grafana에 로그인:</strong></p><ul>
<li>웹 브라우저를 열고 <a href="http://localhost:3000" target="_blank" rel="noopener noreferrer">http://localhost:3000</a>으로 이동합니다.</li>
<li>사용자 이름 <code>admin</code>과 AWS Secrets Manager에서 검색한 비밀번호로 로그인합니다.</li>
</ul><p><strong>4. NIM 모니터링 대시보드 열기:</strong></p><ul>
<li>로그인한 후 왼쪽 사이드바에서 &quot;Dashboards&quot;를 클릭하고 &quot;nim&quot;을 검색합니다</li>
<li>목록에서 <code>NVIDIA NIM Monitoring</code> 대시보드를 찾을 수 있습니다</li>
<li>클릭하여 대시보드로 진입합니다.</li>
</ul><p>이제 Grafana 대시보드에 표시된 메트릭을 볼 수 있으며, NVIDIA NIM 서비스 배포의 성능을 모니터링할 수 있습니다.</p></div></div></details>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>정보</div><div class="admonitionContent_BuS1"><p>이 가이드 작성 시점에서 NVIDIA도 예제 Grafana 대시보드를 제공합니다. <a href="https://docs.nvidia.com/nim/large-language-models/latest/observability.html#grafana" target="_blank" rel="noopener noreferrer">여기</a>에서 확인할 수 있습니다.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="정리">정리<a href="#정리" class="hash-link" aria-label="정리에 대한 직접 링크" title="정리에 대한 직접 링크" translate="no">​</a></h2>
<p>이 배포에서 생성된 모든 리소스를 제거하려면 다음을 실행합니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./cleanup.sh</span><br></span></code></pre></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">GPU에서의 Stable Diffusion</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">EKS의 NVIDIA NIM Operator</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#nvidia-nim이란" class="table-of-contents__link toc-highlight">NVIDIA NIM이란?</a></li><li><a href="#왜-nim인가" class="table-of-contents__link toc-highlight">왜 NIM인가?</a></li><li><a href="#amazon-eks에서의-이-배포-패턴-개요" class="table-of-contents__link toc-highlight">Amazon EKS에서의 이 배포 패턴 개요</a></li><li><a href="#솔루션-배포" class="table-of-contents__link toc-highlight">솔루션 배포</a><ul><li><a href="#사전-요구-사항" class="table-of-contents__link toc-highlight">사전 요구 사항</a></li><li><a href="#배포" class="table-of-contents__link toc-highlight">배포</a></li><li><a href="#nim으로-배포된-llama3-모델-테스트" class="table-of-contents__link toc-highlight">NIM으로 배포된 Llama3 모델 테스트</a></li></ul></li><li><a href="#open-webui-배포" class="table-of-contents__link toc-highlight">Open WebUI 배포</a></li><li><a href="#nvidia-genai-perf-도구를-사용한-성능-테스트" class="table-of-contents__link toc-highlight">NVIDIA GenAI-Perf 도구를 사용한 성능 테스트</a></li><li><a href="#관측성" class="table-of-contents__link toc-highlight">관측성</a><ul><li><a href="#grafana-대시보드" class="table-of-contents__link toc-highlight">Grafana 대시보드</a></li></ul></li><li><a href="#정리" class="table-of-contents__link toc-highlight">정리</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">참여하기</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © ${new Date().getFullYear()} Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>