<!doctype html>
<html lang="ko-KR" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blueprints/training/Neuron/RayTrain-Llama2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.0">
<title data-rh="true">RayTrain-Llama2 | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2"><meta data-rh="true" property="og:locale" content="ko_KR"><meta data-rh="true" property="og:locale:alternate" content="en_US"><meta data-rh="true" name="docusaurus_locale" content="ko"><meta data-rh="true" name="docsearch:language" content="ko"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="RayTrain-Llama2 | AI on EKS"><meta data-rh="true" name="description" content="EKS에서 ML 모델을 배포하려면 GPU 또는 Neuron 인스턴스에 대한 접근 권한이 필요합니다. 배포가 작동하지 않는 경우 이러한 리소스에 대한 접근 권한이 없기 때문인 경우가 많습니다. 또한 일부 배포 패턴은 Karpenter 자동 스케일링과 정적 노드 그룹에 의존합니다. 노드가 초기화되지 않으면 Karpenter 또는 노드 그룹의 로그를 확인하여 문제를 해결하세요."><meta data-rh="true" property="og:description" content="EKS에서 ML 모델을 배포하려면 GPU 또는 Neuron 인스턴스에 대한 접근 권한이 필요합니다. 배포가 작동하지 않는 경우 이러한 리소스에 대한 접근 권한이 없기 때문인 경우가 많습니다. 또한 일부 배포 패턴은 Karpenter 자동 스케일링과 정적 노드 그룹에 의존합니다. 노드가 초기화되지 않으면 Karpenter 또는 노드 그룹의 로그를 확인하여 문제를 해결하세요."><link data-rh="true" rel="icon" href="/ai-on-eks/ko/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/training/Neuron/RayTrain-Llama2" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2" hreflang="ko-KR"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/training/Neuron/RayTrain-Llama2" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"EKS에서의 학습","item":"https://awslabs.github.io/ai-on-eks/ko/docs/category/training-on-eks"},{"@type":"ListItem","position":2,"name":"RayTrain을 활용한 Trn1에서의 Llama-2","item":"https://awslabs.github.io/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2"}]}</script><link rel="stylesheet" href="/ai-on-eks/ko/assets/css/styles.c270b852.css">
<script src="/ai-on-eks/ko/assets/js/runtime~main.84f685ef.js" defer="defer"></script>
<script src="/ai-on-eks/ko/assets/js/main.d98ac8f0.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="본문으로 건너뛰기"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">본문으로 건너뛰기</a></div><div class="theme-announcement-bar announcementBar_mb4j" style="background-color:#667eea;color:#ffffff" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">GenAI on EKS workshop series! <a target="_blank" rel="noopener noreferrer" href="https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=9be4af2e-2339-40ae-b5e9-57b6a7704c36&sc_channel=el" style="color: #ffffff; text-decoration: underline; font-weight: bold; margin-left: 10px;">Register now →</a></div><button type="button" aria-label="닫기" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="메인" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="사이드바 펼치거나 접기" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/ko/"><div class="navbar__logo"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS 로고" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/ko/img/header-icon.png" alt="AIoEKS 로고" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/infra">인프라</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/ko/docs/blueprints">블루프린트</a><a class="navbar__item navbar__link" href="/ai-on-eks/ko/docs/guidance">가이드</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>한국어</a><ul class="dropdown__menu"><li><a href="/ai-on-eks/docs/blueprints/training/Neuron/RayTrain-Llama2" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en-US">English</a></li><li><a href="/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="ko-KR">한국어</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="어두운 모드와 밝은 모드 전환하기 (현재 system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="맨 위로 스크롤하기" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="문서 사이드바" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/ko/docs/blueprints"><span title="개요" class="linkLabel_WmDU">개요</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai-on-eks/ko/docs/blueprints/inference"><span title="EKS에서의 추론" class="categoryLinkLabel_W154">EKS에서의 추론</span></a><button aria-label="사이드바 분류 &#x27;EKS에서의 추론&#x27; 펼치기" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai-on-eks/ko/docs/category/training-on-eks"><span title="EKS에서의 학습" class="categoryLinkLabel_W154">EKS에서의 학습</span></a><button aria-label="사이드바 분류 &#x27;EKS에서의 학습&#x27; 접기" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/training/GPUs/bionemo"><span title="GPU" class="categoryLinkLabel_W154">GPU</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2"><span title="Neuron" class="categoryLinkLabel_W154">Neuron</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2"><span title="RayTrain을 활용한 Trn1에서의 Llama-2" class="linkLabel_WmDU">RayTrain을 활용한 Trn1에서의 Llama-2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2"><span title="Trn1에서 Nemo-Megatron을 활용한 Llama-2" class="linkLabel_WmDU">Trn1에서 Nemo-Megatron을 활용한 Llama-2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/training/Neuron/BERT-Large"><span title="Trainium에서의 BERT-Large" class="linkLabel_WmDU">Trainium에서의 BERT-Large</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama-LoRA-Finetuning"><span title="LoRA를 활용한 Llama 3 파인튜닝" class="linkLabel_WmDU">LoRA를 활용한 Llama 3 파인튜닝</span></a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway"><span title="게이트웨이" class="categoryLinkLabel_W154">게이트웨이</span></a></div></li></ul></nav><button type="button" title="사이드바 숨기기" aria-label="사이드바 숨기기" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="탐색 경로"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="홈" class="breadcrumbs__link" href="/ai-on-eks/ko/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/ko/docs/category/training-on-eks"><span>EKS에서의 학습</span></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Neuron</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">RayTrain을 활용한 Trn1에서의 Llama-2</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">이 페이지에서</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>경고</div><div class="admonitionContent_BuS1"><p>EKS에서 ML 모델을 배포하려면 GPU 또는 Neuron 인스턴스에 대한 접근 권한이 필요합니다. 배포가 작동하지 않는 경우 이러한 리소스에 대한 접근 권한이 없기 때문인 경우가 많습니다. 또한 일부 배포 패턴은 Karpenter 자동 스케일링과 정적 노드 그룹에 의존합니다. 노드가 초기화되지 않으면 Karpenter 또는 노드 그룹의 로그를 확인하여 문제를 해결하세요.</p></div></div>
<div class="theme-admonition theme-admonition-danger admonition_xJq3 alert alert--danger"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"></path></svg></span>위험</div><div class="admonitionContent_BuS1"><p>참고: 이 Llama-2 모델의 사용은 Meta 라이선스의 적용을 받습니다.
모델 가중치와 토크나이저를 다운로드하려면 <a href="https://ai.meta.com/" target="_blank" rel="noopener noreferrer">웹사이트</a>를 방문하여 접근 권한을 요청하기 전에 라이선스에 동의해야 합니다.</p></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>정보</div><div class="admonitionContent_BuS1"><p>이 블루프린트는 관측성, 로깅 및 확장성 측면의 개선 사항을 통합하기 위해 적극적으로 개선 중입니다.</p></div></div>
<header><h1>RayTrain과 KubeRay를 활용한 Trn1에서의 Llama2 분산 사전 훈련</h1></header>
<p>이 종합 가이드는 Amazon EKS의 KubeRay 클러스터 내에서 AWS Trainium (Trn1) 인스턴스와 AWS Neuron SDK를 사용하여 <code>Llama2-7B</code> 언어 모델을 사전 훈련하는 과정을 안내합니다. 이것은 KubeRay의 분산 훈련 기능에 최적화된 원본 <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/libraries/neuronx-distributed/tutorials/training_llama2_7b.html#llama2-7b-tp-zero1-tutorial" target="_blank" rel="noopener noreferrer">Llama2 사전 훈련 튜토리얼</a>의 맞춤형 버전입니다.</p>
<p><img decoding="async" loading="lazy" alt="Llama2-RayTrain" src="/ai-on-eks/ko/assets/images/Llama2-RayTrain-Trn1-d93433eba0c8e8e7c617a9fa1b17f249.png" width="14330" height="7927" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="llama-2란">Llama-2란?<a href="#llama-2란" class="hash-link" aria-label="Llama-2란?에 대한 직접 링크" title="Llama-2란?에 대한 직접 링크" translate="no">​</a></h3>
<p>Llama-2는 텍스트 생성, 요약, 번역, 질의응답 등 다양한 자연어 처리(NLP) 작업을 위해 설계된 최첨단 대규모 언어 모델(LLM)입니다. 특정 사용 사례에 맞게 파인튜닝할 수 있는 강력한 도구입니다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="분산-훈련을-위한-raytrain과-kuberay의-장점">분산 훈련을 위한 RayTrain과 KubeRay의 장점<a href="#분산-훈련을-위한-raytrain과-kuberay의-장점" class="hash-link" aria-label="분산 훈련을 위한 RayTrain과 KubeRay의 장점에 대한 직접 링크" title="분산 훈련을 위한 RayTrain과 KubeRay의 장점에 대한 직접 링크" translate="no">​</a></h3>
<p>Llama-2와 같은 대규모 모델은 방대한 컴퓨팅 및 메모리 요구사항으로 인해 분산 훈련이 필수적입니다. RayTrain과 KubeRay의 조합은 특히 AWS Trainium과 함께 활용할 때 이러한 요구사항을 효율적이고 효과적으로 처리하기 위한 강력한 프레임워크를 제공합니다:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="raytrain">RayTrain:<a href="#raytrain" class="hash-link" aria-label="RayTrain:에 대한 직접 링크" title="RayTrain:에 대한 직접 링크" translate="no">​</a></h4>
<ul>
<li><strong>간소화된 분산 훈련</strong>: RayTrain은 분산 훈련의 복잡성을 추상화하는 Ray 프레임워크 기반의 고수준 라이브러리입니다. 최소한의 코드 변경으로 여러 노드에 걸쳐 Llama-2 훈련을 확장할 수 있습니다. Ray의 액터 기반 아키텍처와 태스크 기반 병렬 처리는 분산 워크로드의 효율적인 실행을 가능하게 합니다.</li>
<li><strong>유연한 전략</strong>: RayTrain은 데이터 병렬 처리와 모델 병렬 처리와 같은 다양한 분산 훈련 전략을 지원합니다. 데이터 병렬 처리는 데이터셋을 여러 노드에 분할하고, 모델 병렬 처리는 모델 자체를 분할합니다. 이러한 유연성으로 모델의 특정 요구사항과 훈련 환경의 아키텍처에 따라 훈련을 최적화할 수 있습니다.</li>
<li><strong>장애 허용</strong>: RayTrain에는 내장된 장애 허용 메커니즘이 포함되어 있습니다. 노드가 실패하면 Ray가 다른 사용 가능한 노드에서 태스크를 재스케줄링하여 훈련 작업이 중단 없이 계속됩니다. 이 기능은 대규모 분산 훈련 환경에서 견고성을 유지하는 데 중요합니다.</li>
<li><strong>사용 편의성</strong>: RayTrain은 분산 훈련 작업의 설정과 실행을 단순화하는 직관적인 API를 제공합니다. Hugging Face Transformers와 같은 인기 있는 머신 러닝 라이브러리와의 통합으로 광범위한 수정 없이 기존 워크플로우에 RayTrain을 쉽게 통합할 수 있습니다.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="kuberay">KubeRay:<a href="#kuberay" class="hash-link" aria-label="KubeRay:에 대한 직접 링크" title="KubeRay:에 대한 직접 링크" translate="no">​</a></h4>
<ul>
<li><strong>Kubernetes와의 통합</strong>: KubeRay는 Kubernetes의 네이티브 기능을 활용하여 Ray 클러스터를 배포, 관리 및 확장합니다. 이 통합으로 Kubernetes의 강력한 오케스트레이션 기능을 사용하여 Ray 워크로드를 효과적으로 처리할 수 있습니다.</li>
<li><strong>동적 스케일링</strong>: KubeRay는 Ray 클러스터의 동적 스케일링을 지원합니다. Ray의 내장 오토스케일러가 워크로드 요구에 따라 추가 액터 레플리카를 요청할 수 있으며, Karpenter나 Cluster Autoscaler와 같은 Kubernetes 도구가 이러한 요구를 충족하기 위해 새 노드 생성을 관리합니다.</li>
<li><strong>수평 스케일링</strong>: 컴퓨팅 부하가 증가함에 따라 더 많은 워커 노드를 추가하여 Ray 클러스터를 수평으로 확장합니다. 이를 통해 대규모 분산 훈련 및 추론 작업을 효율적으로 처리할 수 있습니다.</li>
<li><strong>Custom Resource Definitions (CRDs)</strong>: KubeRay는 Kubernetes CRD를 활용하여 Ray 클러스터와 작업을 정의하고 관리합니다. 이는 Kubernetes 에코시스템 내에서 Ray 워크로드를 처리하는 표준화된 방법을 제공합니다.</li>
<li><strong>장애 허용</strong>: KubeRay는 Kubernetes의 자가 치유 기능을 활용합니다. Ray 헤드 노드나 워커 노드가 실패하면 Kubernetes가 자동으로 실패한 구성 요소를 다시 시작하여 최소한의 다운타임과 지속적인 운영을 보장 합니다.</li>
<li><strong>분산 스케줄링</strong>: Ray의 액터 기반 모델과 분산 태스크 스케줄링이 Kubernetes의 오케스트레이션과 결합되어 노드 장애 발생 시에도 고가용성과 효율적인 태스크 실행을 보장합니다.</li>
<li><strong>선언적 구성</strong>: KubeRay를 사용하면 선언적 YAML 구성을 사용하여 Ray 클러스터와 작업을 정의할 수 있습니다. 이는 배포 및 관리 프로세스를 단순화하여 Ray 클러스터를 더 쉽게 설정하고 유지 관리할 수 있게 합니다.</li>
<li><strong>통합 로깅 및 모니터링</strong>: KubeRay는 Prometheus 및 Grafana와 같은 Kubernetes의 로깅 및 모니터링 도구와 통합됩니다. 이는 Ray 클러스터의 성능과 상태에 대한 포괄적인 인사이트를 제공하여 디버깅과 최적화를 용이하게 합니다.</li>
<li><strong>스팟 인스턴스</strong>: Kubernetes의 스팟 인스턴스 지원을 사용하여 비용 효율적으로 Ray 클러스터를 실행합니다. 이를 통해 필요에 따라 확장하는 능력을 유지하면서 저비용 컴퓨팅 리소스를 활용할 수 있습니다.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aws-trainium">AWS Trainium:<a href="#aws-trainium" class="hash-link" aria-label="AWS Trainium:에 대한 직접 링크" title="AWS Trainium:에 대한 직접 링크" translate="no">​</a></h4>
<ul>
<li><strong>딥러닝에 최적화</strong>: AWS Trainium 기반 Trn1 인스턴스는 딥러닝 워크로드를 위해 특별히 설계되었습니다. 높은 처리량과 낮은 지연 시간을 제공하여 Llama-2와 같은 대규모 모델 훈련에 이상적입니다. Trainium 칩은 기존 프로세서에 비해 상당한 성능 향상을 제공하여 훈련 시간을 단축합니다.</li>
<li><strong>Neuron SDK</strong>: AWS Neuron SDK는 Trainium에 맞게 딥러닝 모델을 최적화하도록 맞춤화되어 있습니다. 고급 컴파일러 최적화와 혼합 정밀도 훈련 지원과 같은 기능을 포함하여 정확도를 유지하면서 훈련 워크로드를 더욱 가속화할 수 있습니다.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="이-조합이-강력한-이유">이 조합이 강력한 이유<a href="#이-조합이-강력한-이유" class="hash-link" aria-label="이 조합이 강력한 이유에 대한 직접 링크" title="이 조합이 강력한 이유에 대한 직접 링크" translate="no">​</a></h3>
<ul>
<li><strong>간소화된 스케일링</strong>: RayTrain과 KubeRay는 여러 노드에 걸친 Llama-2 훈련 스케일링 프로세스를 단순화합니다. Ray의 효율적인 분산 실행과 KubeRay의 Kubernetes 네이티브 오케스트레이션으로 Trn1 인스턴스에서 AWS Trainium의 전체 성능을 활용하기 위해 훈련 워크로드를 쉽게 확장할 수 있습니다.</li>
<li><strong>최적화된 성능</strong>: Neuron SDK는 Trainium의 아키텍처에 맞게 특별히 최적화하여 훈련 작업의 성능을 향상시킵니다. Ray의 효율적인 분산 태스크 관리와 KubeRay의 리소스 오케스트레이션과 결합하여 이 설정은 최적의 훈련 성능을 보장합니다.</li>
<li><strong>비용 효율성</strong>: Ray의 오토스케일링 기능과 Kubernetes의 리소스 관리는 리소스를 효율적으로 할당하고 수요에 따라 클러스터를 확장하여 비용을 최적화하는 데 도움이 됩니다. 이를 통해 필요한 리소스만 사용하여 불필요한 지출을 줄일 수 있습니다.</li>
</ul>
<p>이 기술 조합을 사용하면 분산 훈련과 하드웨어의 최신 발전을 활용하여 Llama-2를 효율적이고 효과적으로 사전 훈련할 수 있습니다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="volcano란">Volcano란?<a href="#volcano란" class="hash-link" aria-label="Volcano란?에 대한 직접 링크" title="Volcano란?에 대한 직접 링크" translate="no">​</a></h3>
<p>Volcano는 Kubernetes 기반의 오픈소스 배치 스케줄링 시  스템으로, 고성능 컴퓨팅(HPC) 및 머신 러닝 워크로드를 관리하기 위해 특별히 설계되었습니다. Gang 스케줄링, 공정 공유, 선점과 같은 고급 스케줄링 기능을 제공하며, 이는 Kubernetes 환경에서 대규모 분산 훈련 작업을 효율적으로 실행하는 데 필수적입니다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="volcano의-gang-스케줄링-작동-방식">Volcano의 Gang 스케줄링 작동 방식<a href="#volcano의-gang-스케줄링-작동-방식" class="hash-link" aria-label="Volcano의 Gang 스케줄링 작동 방식에 대한 직접 링크" title="Volcano의 Gang 스케줄링 작동 방식에 대한 직접 링크" translate="no">​</a></h3>
<p>Volcano의 Gang 스케줄링은 작업(또는 &quot;Gang&quot;)의 모든 파드가 동시에 스케줄링되도록 보장합니다. 이는 여러 파드가 올바르게 작동하기 위해 함께 시작해야 하는 분산 훈련 워크로드에 중요합니다. Gang의 파드 중 하나라도 리소스 제약으로 인해 스케줄링할 수 없는 경우 Gang의 어떤 파드도 시작되지 않습니다. 이는 부분 실행을 방지하고 실행이 시작되기 전에 작업에 필요한 모든 리소스가 사용 가능하도록 보장합니다.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-솔루션-배포">1. 솔루션 배포<a href="#1-솔루션-배포" class="hash-link" aria-label="1. 솔루션 배포에 대한 직접 링크" title="1. 솔루션 배포에 대한 직접 링크" translate="no">​</a></h2>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>사전 요구사항</span></h2><span class="icon_PckA">👈</span></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-docker-이미지-빌드-선택-단계">2. Docker 이미지 빌드 (선택 단계)<a href="#2-docker-이미지-빌드-선택-단계" class="hash-link" aria-label="2. Docker 이미지 빌드 (선택 단계)에 대한 직접 링크" title="2. Docker 이미지 빌드 (선택 단계)에 대한 직접 링크" translate="no">​</a></h2>
<p>블루프린트 배포를 단순화하기 위해 이미 Docker 이미지를 빌드하여 퍼블릭 ECR에서 사용할 수 있도록 했습니다.
Docker 이미지를 커스터마이징하려면 <code>Dockerfile</code>을 업데이트하고 선택 단계를 따라 Docker 이미지를 빌드할 수 있습니다.
새로 생성된 이미지와 자체 프라이빗 ECR을 사용하여 RayCluster YAML 파일 <code>llama2-pretrain-trn1-raycluster.yaml</code>도 수정해야 합니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> ai/training/raytrain-llama2-pretrain-trn1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./kuberay-trn1-llama2-pretrain-build-image.sh</span><br></span></code></pre></div></div>
<p>이 스크립트를 실행한 후 생성된 Docker 이미지 URL과 태그를 기록하세요.
다음 단계에서 이 정보가 필요합니다.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-kuberay-operator로-ray-클러스터-시작">3. KubeRay Operator로 Ray 클러스터 시작<a href="#3-kuberay-operator로-ray-클러스터-시작" class="hash-link" aria-label="3. KubeRay Operator로 Ray 클러스터 시작에 대한 직접 링크" title="3. KubeRay Operator로 Ray 클러스터 시작에 대한 직접 링크" translate="no">​</a></h2>
<p>2단계를 건너뛰는 경우 YAML 파일을 수정할 필요가 없습니다.
파일에 <code>kubectl apply</code> 명령을 실행하면 우리가 게시한 퍼블릭 ECR 이미지를 사용합니다.</p>
<p><strong>2단계</strong>에서 커스텀 Docker 이미지를 빌드한 경우 이전 단계에서 얻은 Docker 이미지 URL과 태그로 <code>ai/training/raytrain-llama2-pretrain-trn1/llama2-pretrain-trn1-raycluster.yaml</code> 파일을 업데이트하세요.</p>
<p>YAML 파일을 업데이트한 후(필요한 경우) 다음 명령을 실행하여 EKS 클러스터에서 KubeRay 클러스터 파드를 시작합니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> llama2-pretrain-trn1-raycluster.yaml</span><br></span></code></pre></div></div>
<p><strong>파드 상태 확인:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;ray.io/cluster=kuberay-trn1&quot;</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="volcano를-사용한-ray-헤드-및-워커-파드의-gang-스케줄링">Volcano를 사용한 Ray 헤드 및 워커 파드의 Gang 스케줄링<a href="#volcano를-사용한-ray-헤드-및-워커-파드의-gang-스케줄링" class="hash-link" aria-label="Volcano를 사용한 Ray 헤드 및 워커 파드의 Gang 스케줄링에 대한 직접 링크" title="Volcano를 사용한 Ray 헤드 및 워커 파드의 Gang 스케줄링에 대한 직접 링크" translate="no">​</a></h3>
<p>Llama2 훈련을 위한 Ray 클러스터 배포 컨텍스트에서 Volcano는 Ray 헤드 및 워커 파드가 함께 효율적으로 스케줄링되도록 하는 데 중요합니다.
일반적으로 x86 인스턴스에서 실행되는 Ray 헤드 파드는 분산 훈련을 조정하고, AWS Trainium (Trn1) 인스턴스에서 실행되는 워커 파드는 계산 집약적인 작업을 수행합니다.
<strong>Volcano의 Gang 스케줄링</strong>을 활용하여 헤드와 모든 워커 파드에 필요한 리소스가 동시에 할당되도록 하여 분산 훈련 작업이 지연 없이 시작될 수 있습니다.</p>
<p>다음은 Llama2 훈련을 위한 RayCluster와 Volcano를 통합하는 예제 구성입니다:</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>정보</div><div class="admonitionContent_BuS1"><p>Terraform 블루프린트가 <code>default</code> 네임스페이스에 <code>fsx-claim</code> <strong>PVC</strong>를 생성하기 때문에 이 배포에 default 네임스페이스를 사용합니다.</p><p>전용 네임스페이스에 클러스터를 배포하려면 PVC가 네임스페이스에 바인딩되므로 FSX for Lustre 파일 시스템도 동일한 네임스페이스에 생성되어야 합니다.</p></div></div>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Volcano와 KubeRay 문서: https://docs.ray.io/en/master/cluster/kubernetes/k8s-ecosystem/volcano.html</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> scheduling.volcano.sh/v1beta1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Queue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llama2</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">queue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> default</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">weight</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">capability</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">cpu</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;500&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">memory</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> 1500Gi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ray.io/v1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> RayCluster</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> kuberay</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">trn1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> default</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">labels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">ray.io/scheduler-name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> volcano</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">volcano.sh/queue-name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llama2</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">training</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">queue</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">rayVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> 2.22.0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">headGroupSpec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">...</span><br></span></code></pre></div></div>
<p>Running 상태의 ray-head 파드 1개와 ray-worker 파드 2개가 표시되어야 합니다:</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>경고</div><div class="admonitionContent_BuS1"><p>이미지를 가져오고 파드가 준비되기까지 최대 10분이 소요될 수 있습니다.</p></div></div>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                    READY   STATUS    RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kuberay-trn1-head-67t46                 </span><span class="token number" style="color:#36acaa">0</span><span class="token plain">/1     Pending   </span><span class="token number" style="color:#36acaa">0</span><span class="token plain">          2m50s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kuberay-trn1-worker-workergroup-fz8bs   </span><span class="token number" style="color:#36acaa">0</span><span class="token plain">/1     Pending   </span><span class="token number" style="color:#36acaa">0</span><span class="token plain">          2m50s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kuberay-trn1-worker-workergroup-gpnxh   </span><span class="token number" style="color:#36acaa">0</span><span class="token plain">/1     Pending   </span><span class="token number" style="color:#36acaa">0</span><span class="token plain">          2m50s</span><br></span></code></pre></div></div>
<p>헤드 파드의 로그 확인:</p>
<p>Ray 헤드가 시작되었고 클러스터가 작동 중임을 나타내는 메시지를 찾습니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs kuberay-trn1-head-xxxxx</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ray-대시보드-접근-포트-포워딩">Ray 대시보드 접근 (포트 포워딩):<a href="#ray-대시보드-접근-포트-포워딩" class="hash-link" aria-label="Ray 대시보드 접근 (포트 포워딩):에 대한 직접 링크" title="Ray 대시보드 접근 (포트 포워딩):에 대한 직접 링크" translate="no">​</a></h3>
<p>Ray 대시보드는 클러스터 상태와 작업 진행 상황에 대한 귀중한 인사이트를 제공합니다. 접근하려면:</p>
<p><strong>포트 포워딩:</strong></p>
<p>로컬 머신에서 클러스터 내 헤드 파드로 Ray 대시보드 포트(8265)를 포워딩합니다.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward service/kuberay-trn1-head-svc </span><span class="token number" style="color:#36acaa">8265</span><span class="token plain">:8265</span><br></span></code></pre></div></div>
<p>브라우저를 열고 웹 브라우저에서 <a href="http://localhost:8265" target="_blank" rel="noopener noreferrer">http://localhost:8265</a>로 이동하여 대시보드를 확인합니다.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-fsx-공유-파일-시스템에서-사전-훈련-데이터-생성">4. FSx 공유 파일 시스템에서 사전 훈련 데이터 생성<a href="#4-fsx-공유-파일-시스템에서-사전-훈련-데이터-생성" class="hash-link" aria-label="4. FSx 공유 파일 시스템에서 사전 훈련 데이터 생성에 대한 직접 링크" title="4. FSx 공유 파일 시스템에서 사전  훈련 데이터 생성에 대한 직접 링크" translate="no">​</a></h2>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>경고</div><div class="admonitionContent_BuS1"><p>데이터 생성 단계는 FSx for Lustre에 모든 데이터를 생성하는 데 최대 20분이 소요될 수 있습니다.</p></div></div>
<p>이 단계에서는 KubeRay의 Job 사양을 활용하여 데이터 생성 프로세스를 시작합니다. Ray 헤드 파드에 직접 작업을 제출합니다. 이 작업은 모델을 훈련할 준비를 하는 데 핵심적인 역할을 합니다.</p>
<p>기존 RayCluster에 작업을 제출하기 위해 <code>clusterSelector</code>를 사용하는 아래 <code>RayJob</code> 정의 사양을 확인하세요.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># ----------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># RayJob: llama2-generate-pretraining-test-data</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 설명:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 이 RayJob은 Llama2 모델 훈련에 필요한 사전 훈련 테스트 데이터를 생성하는</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 역할을 합니다. 지정된 데이터셋에서 데이터를 소싱하고 처리하여 후속 훈련 단계에서</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 사용할 수 있도록 준비합니다. 이 작업은 이러한 데이터 준비 단계를 수행하는</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Python 스크립트(`get_dataset.py`)를 실행합니다.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 사용법:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># `kubectl apply -f 1-llama2-pretrain-trn1-rayjob-create-test-data.yaml`을 사용하여</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Kubernetes 클러스터에 이 구성을 적용합니다.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Ray 클러스터(`kuberay-trn1`)가 지정된 네임스페이스에서 실행 중이고 접근 가능한지 확인하세요.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ----------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ray.io/v1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> RayJob</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llama2</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">generate</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pretraining</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">test</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> default</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">submissionMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> K8sJobMode</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">entrypoint</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;python3 get_dataset.py&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">runtimeEnvYAML</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    working_dir: /llama2_pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    env_vars:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      PYTHONUNBUFFERED: &#x27;0&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    resources:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      requests:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">        cpu: &quot;6&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">        memory: &quot;30Gi&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">clusterSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">ray.io/cluster</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> kuberay</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">trn1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">rayClusterNamespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> default  </span><span class="token comment" style="color:#999988;font-style:italic"># RayCluster가 배포된 네임스페이스로 대체</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">ttlSecondsAfterFinished</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">60</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 완료 후 파드의 생존 시간(초)</span><br></span></code></pre></div></div>
<p>다음 명령을 실행하여 테스트 데이터 생성 Ray 작업을 실행합니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain">-llama2-pretrain-trn1-rayjob-create-test-data.yaml</span><br></span></code></pre></div></div>
<p><strong>내부에서 일어나는 일:</strong></p>
<p><strong>작업 시작:</strong> kubectl을 사용하여 KubeRay 작업 사양을 제출합니다. <code>kuberay-trn1</code> 클러스터의 Ray 헤드 파드가 이 작업을 수신하고 실행합니다.</p>
<p><strong>데이터 생성:</strong> 작업이 <code>ai/training/raytrain-llama2-pretrain-trn1/llama2_pretrain/get_dataset.py</code> 스크립트를 실행하며, Hugging Face datasets 라이브러리의 기능을 활용하여 원시 영어 Wikipedia 데이터셋(&quot;wikicorpus&quot;)을 가져오고 처리합니다.</p>
<p><strong>토큰화:</strong> 스크립트는 Hugging Face transformers의 사전 훈련된 토크나이저를 사용하여 텍스트를 토큰화합니다. 토큰화는 모델이 이해할 수 있도록 텍스트를 더 작은 단위(단어 또는 하위 단어)로 분해합니다.</p>
<p><strong>데이터 저장:</strong> 토큰화된 데이터는 깔끔하게 정리되어 FSx for Lustre 공유 파일 시스템 내의 특정 디렉토리(<code>/shared/wikicorpus_llama2_7B_tokenized_4k/</code>)에 저장됩니다. 이를 통해 클러스터의 모든 워커 노드가 사전 훈련 중에 이 표준화된 데이터에 쉽게 접근할 수 있습니다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="작업-모니터링">작업 모니터링:<a href="#작업-모니터링" class="hash-link" aria-label="작업 모니터링:에 대한 직접 링크" title="작업 모니터링:에 대한 직접 링크" translate="no">​</a></h3>
<p>작업 진행 상황을 추적하려면:</p>
<p><strong>Ray 대시보드</strong>: Ray 헤드 파드의 IP 주소와 포트 8265를 통해 접근할 수 있는 Ray 대시보드로 이동합니다. 작업 상태에 대한 실시간 업데이트를 확인할 수 있습니다.</p>
<p><img decoding="async" loading="lazy" alt="데이터셋 준비" src="/ai-on-eks/ko/assets/images/raytrain-testdata-raydash1-b4670a064fa2d403d5710ccbaf639df7.png" width="3022" height="934" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="데이터셋 준비" src="/ai-on-eks/ko/assets/images/raytrain-testdata-raydash2-d587f6edbefc961341e179b801414f5d.png" width="3022" height="934" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="데이터셋 준비" src="/ai-on-eks/ko/assets/images/raytrain-testdata-raydash3-09f961034e80ed2f517469333f748079.png" width="3022" height="1642" class="img_ev3q"></p>
<p>또는 터미널에서 다음 명령을 사용할 수 있습니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">grep</span><span class="token plain"> llama2</span><br></span></code></pre></div></div>
<p><strong>출력:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">llama2-generate-pretraining-test-data-g6ccl   1/1     Running   0             5m5s</span><br></span></code></pre></div></div>
<p>다음 스크린샷은 Lens K8s IDE에서 파드의 로그를 보여줍니다.</p>
<p><img decoding="async" loading="lazy" alt="데이터셋 준비" src="/ai-on-eks/ko/assets/images/raytrain-testdata-lens-7a27be9b9fca7ff7389068a5e8e1f06b.png" width="3022" height="1628" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-사전-컴파일-작업-실행-최적화-단계">5. 사전 컴파일 작업 실행 (최적화 단계)<a href="#5-사전-컴파일-작업-실행-최적화-단계" class="hash-link" aria-label="5. 사전 컴파일 작업 실행 (최적화 단계)에 대한 직접 링크" title="5. 사전 컴파일 작업 실행 (최적화 단계)에 대한 직접 링크" translate="no">​</a></h2>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>정보</div><div class="admonitionContent_BuS1"><p>사전 컴파일 작업은 최대 6분이 소요될 수 있습니다</p></div></div>
<p>실제 훈련을 시작하기 전에 Neuron SDK에 맞게 모델을 최적화하기 위한 사전 컴파일 단계를 수행합니다. 이를 통해 모델이 <code>Trn1</code> 인스턴스에서 더 효율적으로 실행됩니다. 이 스크립트는 Neuron SDK를 사용하여 모델의 연산 그래프를 컴파일하고 최적화하여 Trn1 프로세서에서 효율적인 훈련을 위해 준비합니다.</p>
<p>이 단계에서는 Neuron SDK가 <code>Llama2</code> 사전 훈련과 관련된 연산 그래프를 식별, 컴파일 및 캐시하는 사전 컴파일 작업을 실행합니다.</p>
<p>사전 컴파일 작업을 실행하기 위한 아래 <code>RayJob</code> 정의 사양을 확인하세요:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># ----------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># RayJob: llama2-precompilation-job</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 설명:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 이 RayJob은 Llama2 모델 훈련에 필요한 사전 컴파일 단계를 담당합니다.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># AWS Neuron 장치를 사용하여 모델을 병렬로 컴파일하기 위해 `--neuron_parallel_compile`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 옵션과 함께 Python 스크립트(`ray_train_llama2.py`)를 실행합니다. 이 단계는</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># AWS 인프라에서 효율적인 훈련을 위해 모델을 최적화하는 데 중요합니다.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 사용법:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># `kubectl apply -f 2-llama2-pretrain-trn1-rayjob-precompilation.yaml`을 사용하여</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Kubernetes 클러스터에 이 구성을 적용합니다.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Ray 클러스터(`kuberay-trn1`)가 지정된 네임스페이스에서 실행 중이고 접근 가능한지 확인하세요.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ----------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ray.io/v1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> RayJob</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llama2</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">precompilation</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">job</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> default</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">submissionMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> K8sJobMode</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">entrypoint</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;NEURON_NUM_DEVICES=32 python3 /llama2_pretrain/ray_train_llama2.py --neuron_parallel_compile&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">runtimeEnvYAML</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    working_dir: /llama2_pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    env_vars:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      PYTHONUNBUFFERED: &#x27;0&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">clusterSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">ray.io/cluster</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> kuberay</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">trn1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">rayClusterNamespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> default  </span><span class="token comment" style="color:#999988;font-style:italic"># RayCluster가 배포된 네임스페이스로 대체</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">ttlSecondsAfterFinished</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">60</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 완료 후 파드의 생존 시간(초)</span><br></span></code></pre></div></div>
<p>다음 명령을 실행하여 사전 컴파일 작업을 실행합니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token plain">-llama2-pretrain-trn1-rayjob-precompilation.yaml</span><br></span></code></pre></div></div>
<p><strong>확인 단계:</strong></p>
<p>작업 진행 상황을 모니터링하고 올바르게 실행되고 있는지 확인하려면 다음 명령과 도구를 사용하세요:</p>
<p><strong>Ray 대시보드:</strong> Ray 헤드 파드의 IP 주소와 포트 <code>8265</code>를 통해 Ray 대시보드에 접근하여 작업 상태에 대한 실시간 업데이트를 확인합니다.</p>
<p><img decoding="async" loading="lazy" alt="사전 컴파일 진행 상황" src="/ai-on-eks/ko/assets/images/raytrain-precomplilation1-777f1caf778704cc0021889c8968ec58.png" width="3814" height="1818" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="사전 컴파일 진행 상황" src="/ai-on-eks/ko/assets/images/raytrain-precomplilation2-705da082daec14cb61c6b27f566e0dab.png" width="3814" height="1818" class="img_ev3q"></p>
<p>다음 스크린샷은 Lens K8s IDE에서 파드의 로그를 보여줍니다.</p>
<p><img decoding="async" loading="lazy" alt="사전 컴파일 진행 상황" src="/ai-on-eks/ko/assets/images/raytrain-precomplilation3-fe1f06d03638e88e965c106514105218.png" width="1922" height="907" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-분산-사전-훈련-작업-실행">6. 분산 사전 훈련 작업 실행<a href="#6-분산-사전-훈련-작업-실행" class="hash-link" aria-label="6. 분산 사전 훈련 작업 실행에 대한 직접 링크" title="6. 분산 사전 훈련 작업 실행에 대한 직접 링크" translate="no">​</a></h2>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>경고</div><div class="admonitionContent_BuS1"><p>이 작업은 여러 시간 동안 실행될 수 있으므로 손실이 감소하고 모델이 학습하고 있음을 확인한 후 Ctrl+C를 사용하여 작업을 취소해도 됩니다.</p></div></div>
<p>이제 Llama 2 모델의 실제 훈련을 시작할 준비가 되었습니다! 이 단계는 RayJob을 사용하여 분산 사전 훈련 작업을 실행하는 것을 포함합니다. 이 작업은 AWS Neuron 장치를 활용하여 준비된 데이터셋으로 모델을 효율적으로 훈련합니다.</p>
<p>사전 훈련 작업을 실행하기 위한 아래 <code>RayJob</code> 정의 사양을 확인하세요:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># ----------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># RayJob: llama2-pretraining-job</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 설명:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 이 RayJob은 Llama2 모델의 주요 사전 훈련 단계를 담당합니다.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># AWS Neuron 장치를 사용하여 사전 훈련을 수행하기 위해 Python 스크립트(`ray_train_llama2.py`)를</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 실행합니다. 이 단계는 준비된 데이터셋으로 언어 모델을 훈련하는 데 중요합니다.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 사용법:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># `kubectl apply -f 3-llama2-pretrain-trn1-rayjob.yaml`을 사용하여</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Kubernetes 클러스터에 이 구성을 적용합니다.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Ray 클러스터(`kuberay-trn1`)가 지정된 네임스페이스에서 실행 중이고 접근 가능한지 확인하세요.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># ----------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">---</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">apiVersion</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> ray.io/v1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">kind</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> RayJob</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">metadata</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llama2</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">pretraining</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">job</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">namespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> default</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">submissionMode</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> K8sJobMode</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">entrypoint</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;NEURON_NUM_DEVICES=32 python3 ray_train_llama2.py&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">runtimeEnvYAML</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">|</span><span class="token scalar string" style="color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    working_dir: /llama2_pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">    env_vars:</span><br></span><span class="token-line" style="color:#393A34"><span class="token scalar string" style="color:#e3116c">      PYTHONUNBUFFERED: &#x27;0&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">clusterSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">ray.io/cluster</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> kuberay</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">trn1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">rayClusterNamespace</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> default  </span><span class="token comment" style="color:#999988;font-style:italic"># RayCluster가 배포된 네임스페이스로 대체</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">shutdownAfterJobFinishes</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">activeDeadlineSeconds</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">600</span><span class="token plain">   </span><span class="token comment" style="color:#999988;font-style:italic"># 작업이 600초(10분)보다 오래 실행되면 종료됩니다</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">ttlSecondsAfterFinished</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">60</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 완료 후 파드의 생존 시간(초)</span><br></span></code></pre></div></div>
<p>다음 명령을 실행하여 사전 훈련 작업을 실행합니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">3</span><span class="token plain">-llama2-pretrain-trn1-rayjob.yaml</span><br></span></code></pre></div></div>
<p><strong>진행 상황 모니터링:</strong></p>
<p>Ray 대시보드를 사용하거나 터미널에 출력되는 로그를 관찰하여 훈련 작업의 진행 상황을 모니터링할 수 있습니다. 모델이 얼마나 잘 학습하고 있는지 평가하기 위해 훈련 손실, 학습률 및 기타 메트릭과 같은 정보를 찾아보세요.</p>
<p><img decoding="async" loading="lazy" alt="훈련 진행 상황" src="/ai-on-eks/ko/assets/images/raytrain-training-progress1-a0075f05772879597fe736982d834b18.png" width="3814" height="1818" class="img_ev3q"></p>
<p><strong>Ray 대시보드:</strong> Ray 헤드 파드의 IP 주소와 포트 8265를 통해 Ray 대시보드에 접근하여 작업 상태에 대한 실시간 업데이트를 확인합니다.</p>
<p><img decoding="async" loading="lazy" alt="훈련 진행 상황 Ray 대시보드" src="/ai-on-eks/ko/assets/images/raytrain-training-progress2-52bb1ff83523781d2048dbf00670e901.png" width="3814" height="1818" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="훈련 진행 상황 Ray 대시보드" src="/ai-on-eks/ko/assets/images/raytrain-training-progress3-b614686ce3efb30717a77a20ddfe39a6.png" width="3814" height="1818" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="정리">정리<a href="#정리" class="hash-link" aria-label="정리에 대한 직접 링크" title="정리에 대한 직접 링크" translate="no">​</a></h3>
<p>이 솔루션을 사용하여 생성된 리소스를 제거하려면 정리 스크립트를 실행합니다:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># RayCluster 리소스 삭제:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> ai/training/raytrain-llama2-pretrain-trn1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl delete </span><span class="token parameter variable" style="color:#36acaa">-f</span><span class="token plain"> llama2-pretrain-trn1-raycluster.yaml</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># EKS 클러스터 및 관련 리소스 정리:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks/infra/trainium-inferentia</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./cleanup.sh</span><br></span></code></pre></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/blueprints/training/Neuron/RayTrain-Llama2.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>페이지 편집</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="문서 페이지"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/ko/docs/blueprints/training/GPUs/slinky-slurm"><div class="pagination-nav__sublabel">이전</div><div class="pagination-nav__label">EKS에서의 Slurm</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2"><div class="pagination-nav__sublabel">다음</div><div class="pagination-nav__label">Trn1에서 Nemo-Megatron을 활용한 Llama-2</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#llama-2란" class="table-of-contents__link toc-highlight">Llama-2란?</a></li><li><a href="#분산-훈련을-위한-raytrain과-kuberay의-장점" class="table-of-contents__link toc-highlight">분산 훈련을 위한 RayTrain과 KubeRay의 장점</a></li><li><a href="#이-조합이-강력한-이유" class="table-of-contents__link toc-highlight">이 조합이 강력한 이유</a></li><li><a href="#volcano란" class="table-of-contents__link toc-highlight">Volcano란?</a></li><li><a href="#volcano의-gang-스케줄링-작동-방식" class="table-of-contents__link toc-highlight">Volcano의 Gang 스케줄링 작동 방식</a></li><li><a href="#1-솔루션-배포" class="table-of-contents__link toc-highlight">1. 솔루션 배포</a><ul><li><a href="#리소스-확인" class="table-of-contents__link toc-highlight">리소스 확인</a></li></ul></li><li><a href="#2-docker-이미지-빌드-선택-단계" class="table-of-contents__link toc-highlight">2. Docker 이미지 빌드 (선택 단계)</a></li><li><a href="#3-kuberay-operator로-ray-클러스터-시작" class="table-of-contents__link toc-highlight">3. KubeRay Operator로 Ray 클러스터 시작</a><ul><li><a href="#volcano를-사용한-ray-헤드-및-워커-파드의-gang-스케줄링" class="table-of-contents__link toc-highlight">Volcano를 사용한 Ray 헤드 및 워커 파드의 Gang 스케줄링</a></li><li><a href="#ray-대시보드-접근-포트-포워딩" class="table-of-contents__link toc-highlight">Ray 대시보드 접근 (포트 포워딩):</a></li></ul></li><li><a href="#4-fsx-공유-파일-시스템에서-사전-훈련-데이터-생성" class="table-of-contents__link toc-highlight">4. FSx 공유 파일 시스템에서 사전 훈련 데이터 생성</a><ul><li><a href="#작업-모니터링" class="table-of-contents__link toc-highlight">작업 모니터링:</a></li></ul></li><li><a href="#5-사전-컴파일-작업-실행-최적화-단계" class="table-of-contents__link toc-highlight">5. 사전 컴파일 작업 실행 (최적화 단계)</a></li><li><a href="#6-분산-사전-훈련-작업-실행" class="table-of-contents__link toc-highlight">6. 분산 사전 훈련 작업 실행</a><ul><li><a href="#정리" class="table-of-contents__link toc-highlight">정리</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">참여하기</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © ${new Date().getFullYear()} Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>