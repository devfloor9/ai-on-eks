{"searchDocs":[{"title":"EKSì—ì„œì˜ ì¶”ë¡ ","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference","content":"","keywords":"","version":"Next"},{"title":"ì´ ì„¹ì…˜ì˜ ë‚´ìš©â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ ì¶”ë¡ ","url":"/ai-on-eks/ko/docs/blueprints/inference#ì´-ì„¹ì…˜ì˜-ë‚´ìš©","content":" ì´ ì„¹ì…˜ì—ì„œëŠ” EKSì—ì„œ ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì‹¤ìš©ì ì¸ ë°°í¬ ê°€ì´ë“œì™€ Helm ì°¨íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ LLM, Diffusion ëª¨ë¸ ë˜ëŠ” ì»¤ìŠ¤í…€ AI ëª¨ë¸ì„ ë°°í¬í•˜ë“ , ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ êµ¬ì„±ê³¼ ë‹¨ê³„ë³„ ì§€ì¹¨ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"ì¶”ë¡  ì°¨íŠ¸â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ ì¶”ë¡ ","url":"/ai-on-eks/ko/docs/blueprints/inference#ì¶”ë¡ -ì°¨íŠ¸","content":" ìµœì ì˜ ì„±ëŠ¥ì„ ìœ„í•œ ì‚¬ì „ êµ¬ì„±ëœ ê°’ê³¼ í•¨ê»˜ EKSì—ì„œ ì¸ê¸° ìˆëŠ” AI ëª¨ë¸ì„ ë°°í¬í•˜ê¸° ìœ„í•œ Helm ì°¨íŠ¸ì…ë‹ˆë‹¤.  ì œê³µ ë‚´ìš©:  vLLM, Ray-vLLM, Triton, Diffusersë¥¼ ìœ„í•œ ì¦‰ì‹œ ë°°í¬ ê°€ëŠ¥í•œ Helm ì°¨íŠ¸ì¸ê¸° ëª¨ë¸(Llama, DeepSeek, Mistral, Stable Diffusion ë“±)ì„ ìœ„í•œ ì‚¬ì „ êµ¬ì„±ëœ values íŒŒì¼GPU(NVIDIA) ë° Neuron(AWS Inferentia/Trainium) ë°°í¬ ëª¨ë‘ ì§€ì›í—¬ìŠ¤ ì²´í¬, ì˜¤í† ìŠ¤ì¼€ì¼ë§, ëª¨ë‹ˆí„°ë§ì´ í¬í•¨ëœ êµ¬ì„±  ì‚¬ìš© ì‚¬ë¡€:  ì˜¤í”ˆì†ŒìŠ¤ LLMì˜ ë¹ ë¥¸ ë°°í¬ì¡°ì§ ì „ì²´ì˜ í‘œì¤€í™”ëœ ë°°í¬ íŒ¨í„´ì»¤ìŠ¤í…€ ëª¨ë¸ ë°°í¬ë¥¼ ìœ„í•œ ì°¸ì¡° êµ¬í˜„  ì¶”ë¡  ì°¨íŠ¸ ì‚´í´ë³´ê¸° â†’    ","version":"Next","tagName":"h2"},{"title":"í”„ë ˆì„ì›Œí¬ë³„ ë°°í¬ ê°€ì´ë“œâ€‹","type":1,"pageTitle":"EKSì—ì„œì˜ ì¶”ë¡ ","url":"/ai-on-eks/ko/docs/blueprints/inference#í”„ë ˆì„ì›Œí¬ë³„-ë°°í¬-ê°€ì´ë“œ","content":" EKSì—ì„œ íŠ¹ì • í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ ë°°í¬ì— ëŒ€í•œ ìƒì„¸ ê°€ì´ë“œë¡œ, í•˜ë“œì›¨ì–´ ìœ í˜•ë³„ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"GPU ë°°í¬â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ ì¶”ë¡ ","url":"/ai-on-eks/ko/docs/blueprints/inference#gpu-ë°°í¬","content":" NVIDIA GPUì—ì„œ ëª¨ë¸ì„ ë°°í¬í•˜ê¸° ìœ„í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œ:  AIBrix DeepSeek Distill - AIBrix ìµœì í™”ë¡œ DeepSeek R1 Distill Llama 8B ë°°í¬NVIDIA Dynamo - NVIDIA Dynamo í”„ë ˆì„ì›Œí¬ë¡œ ëª¨ë¸ ë°°í¬NVIDIA NIM Llama 3 - NVIDIA NIMì„ ì‚¬ìš©í•˜ì—¬ Llama 3 ë°°í¬NVIDIA NIM Operator - NVIDIA NIM ë°°í¬ë¥¼ ìœ„í•œ Kubernetes ì˜¤í¼ë ˆì´í„°vLLMê³¼ NVIDIA Triton Server - Tritonê³¼ vLLMì„ ì‚¬ìš©í•œ ì¶”ë¡ vLLMê³¼ Ray Serve - Ray Serveì™€ vLLMì„ ì‚¬ìš©í•œ í™•ì¥ ê°€ëŠ¥í•œ ì¶”ë¡   ","version":"Next","tagName":"h3"},{"title":"Neuron ë°°í¬â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ ì¶”ë¡ ","url":"/ai-on-eks/ko/docs/blueprints/inference#neuron-ë°°í¬","content":" AWS Inferentia ë° Trainiumì—ì„œ ëª¨ë¸ì„ ë°°í¬í•˜ê¸° ìœ„í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œ:  Inferentia2ì—ì„œì˜ Mistral 7B - AWS Inferentia 2ì—ì„œ Mistral 7B ë°°í¬Inferentia2ì—ì„œì˜ Llama 2 - AWS Inferentia 2ì—ì„œ Llama 2 13B ë°°í¬Inferentia2ì—ì„œì˜ Llama 3 - AWS Inferentia 2ì—ì„œ Llama 3 ë°°í¬Ray Serve ê³ ê°€ìš©ì„± - Neuronì—ì„œ ê³ ê°€ìš©ì„± Ray Serve ë°°í¬Inferentia2ì—ì„œì˜ Stable Diffusion - AWS Inferentia 2ì—ì„œ Stable Diffusion ë°°í¬Inferentia2ì—ì„œì˜ vLLM Ray - AWS Inferentia 2ì—ì„œ Rayì™€ vLLM ë°°í¬    ","version":"Next","tagName":"h3"},{"title":"ì‹œì‘í•˜ê¸°â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ ì¶”ë¡ ","url":"/ai-on-eks/ko/docs/blueprints/inference#ì‹œì‘í•˜ê¸°","content":" ì¸í”„ë¼ ì„¤ì • - AI/ML ì›Œí¬ë¡œë“œì— ìµœì í™”ëœ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ í”„ë¡œë¹„ì €ë‹í•˜ê¸° ìœ„í•´ ì¶”ë¡  ì¤€ë¹„ í´ëŸ¬ìŠ¤í„°ë¡œ ì‹œì‘í•˜ì„¸ìš” ë°°í¬ ë°©ë²• ì„ íƒ: ì¸ê¸° ëª¨ë¸ì˜ ë¹ ë¥¸ ë°°í¬ â†’ ì¶”ë¡  ì°¨íŠ¸ ì‚¬ìš©íŠ¹ì • í”„ë ˆì„ì›Œí¬ ë˜ëŠ” ì»¤ìŠ¤í…€ êµ¬ì„± â†’ ìœ„ì˜ í”„ë ˆì„ì›Œí¬ë³„ ê°€ì´ë“œ ì°¸ì¡° ë°°í¬ ìµœì í™” - ê°€ì´ë˜ìŠ¤ ì„¹ì…˜ì˜ ëª¨ë²” ì‚¬ë¡€ë¥¼ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•˜ê³  ë¹„ìš©ì„ ì ˆê°í•˜ì„¸ìš”    ","version":"Next","tagName":"h2"},{"title":"ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ ì¶”ë¡ ","url":"/ai-on-eks/ko/docs/blueprints/inference#ë„ì›€ì´-í•„ìš”í•˜ì‹ ê°€ìš”","content":" ì¸í”„ë¼ ì„¤ì •: í´ëŸ¬ìŠ¤í„° ì„¤ì • ë° êµ¬ì„±ì€ ì¶”ë¡  ì¸í”„ë¼ ì°¸ì¡°ìµœì í™”: ì„±ëŠ¥ íŠœë‹ ë° ëª¨ë²” ì‚¬ë¡€ëŠ” ê°€ì´ë˜ìŠ¤ ì„¹ì…˜ í™•ì¸ì´ìŠˆ: GitHub Issuesì—ì„œ ë²„ê·¸ ë¦¬í¬íŠ¸ ë˜ëŠ” ê¸°ëŠ¥ ìš”ì²­ì»¤ë®¤ë‹ˆí‹°: GitHub Discussionsì—ì„œ í† ë¡  ì°¸ì—¬ ","version":"Next","tagName":"h2"},{"title":"AIBrix","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/aibrix-deepseek-distill","content":"","keywords":"","version":"Next"},{"title":"ê¸°ëŠ¥â€‹","type":1,"pageTitle":"AIBrix","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/aibrix-deepseek-distill#ê¸°ëŠ¥","content":" LLM ê²Œì´íŠ¸ì›¨ì´ ë° ë¼ìš°íŒ…: ì—¬ëŸ¬ ëª¨ë¸ê³¼ ë ˆí”Œë¦¬ì¹´ì— ê±¸ì³ íŠ¸ë˜í”½ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  ì „ë‹¬í•©ë‹ˆë‹¤.ê³ ë°€ë„ LoRA ê´€ë¦¬: ëª¨ë¸ì˜ ê²½ëŸ‰ ì €ìˆœìœ„ ì ì‘(Low-Rank Adaptation)ì„ ê°„ì†Œí™”ëœ ë°©ì‹ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤.ë¶„ì‚° ì¶”ë¡ : ì—¬ëŸ¬ ë…¸ë“œì— ê±¸ì³ ëŒ€ê·œëª¨ ì›Œí¬ë¡œë“œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.LLM ì•± ë§ì¶¤í˜• ì˜¤í† ìŠ¤ì¼€ì¼ëŸ¬: ì‹¤ì‹œê°„ ìˆ˜ìš”ì— ë”°ë¼ ì¶”ë¡  ë¦¬ì†ŒìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ í™•ì¥í•©ë‹ˆë‹¤.í†µí•© AI ëŸ°íƒ€ì„: ë©”íŠ¸ë¦­ í‘œì¤€í™”, ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ê´€ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë‹¤ìš©ë„ ì‚¬ì´ë“œì¹´ì…ë‹ˆë‹¤.ì´ê¸°ì¢… GPU ì¶”ë¡ : ì´ê¸°ì¢… GPUë¥¼ ì‚¬ìš©í•œ ë¹„ìš© íš¨ìœ¨ì ì¸ SLO ê¸°ë°˜ LLM ì¶”ë¡ ì…ë‹ˆë‹¤.GPU í•˜ë“œì›¨ì–´ ì¥ì•  ê°ì§€: GPU í•˜ë“œì›¨ì–´ ë¬¸ì œë¥¼ ì‚¬ì „ì— ê°ì§€í•©ë‹ˆë‹¤.  ì†”ë£¨ì…˜ ë°°í¬ ğŸ‘ˆ  ","version":"Next","tagName":"h3"},{"title":"AIBrix ì„¤ì¹˜ í™•ì¸â€‹","type":1,"pageTitle":"AIBrix","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/aibrix-deepseek-distill#aibrix-ì„¤ì¹˜-í™•ì¸","content":" ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ AIBrix ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.  kubectl get pods -n aibrix-system   ëª¨ë“  Podê°€ Running ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì‹­ì‹œì˜¤.  AIBrix ì‹œìŠ¤í…œì—ì„œ ëª¨ë¸ ì‹¤í–‰â€‹  ì´ì œ EKSì˜ AIBrixë¥¼ ì‚¬ìš©í•˜ì—¬ Deepseek-Distill-llama-8b ëª¨ë¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.  ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.  kubectl apply -f blueprints/inference/aibrix/deepseek-distill.yaml   ì´ ëª…ë ¹ì€ deepseek-aibrix ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ëª¨ë¸ì„ ë°°í¬í•©ë‹ˆë‹¤. ëª‡ ë¶„ ë™ì•ˆ ê¸°ë‹¤ë¦° í›„ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.  kubectl get pods -n deepseek-aibrix   Podê°€ Running ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì‹­ì‹œì˜¤.  ê²Œì´íŠ¸ì›¨ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì ‘ê·¼â€‹  ê²Œì´íŠ¸ì›¨ì´(Gateway)ëŠ” LLM ìš”ì²­ì„ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©° ë™ì  ëª¨ë¸ ë° LoRA ì–´ëŒ‘í„° ê²€ìƒ‰, ìš”ì²­ ìˆ˜ ë° í† í° ì‚¬ìš©ëŸ‰ ì˜ˆì‚°ì— ëŒ€í•œ ì‚¬ìš©ì êµ¬ì„±, ìŠ¤íŠ¸ë¦¬ë° ë° prefix-cache ì¸ì‹, ì´ê¸°ì¢… GPU í•˜ë“œì›¨ì–´ì™€ ê°™ì€ ê³ ê¸‰ ë¼ìš°íŒ… ì „ëµ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ê²Œì´íŠ¸ì›¨ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì— ì ‘ê·¼í•˜ë ¤ë©´ ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.  kubectl -n envoy-gateway-system port-forward service/envoy-aibrix-system-aibrix-eg-903790dc 8888:80 &amp;   port-forwardê°€ ì‹¤í–‰ë˜ë©´ ê²Œì´íŠ¸ì›¨ì´ì— ìš”ì²­ì„ ì „ì†¡í•˜ì—¬ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ENDPOINT=&quot;localhost:8888&quot; curl -v http://${ENDPOINT}/v1/completions \\ -H &quot;Content-Type: application/json&quot; \\ -d '{ &quot;model&quot;: &quot;deepseek-r1-distill-llama-8b&quot;, &quot;prompt&quot;: &quot;San Francisco is a&quot;, &quot;max_tokens&quot;: 128, &quot;temperature&quot;: 0 }'   ì •ë¦¬ ğŸ‘ˆ  ì£¼ì˜ AWS ê³„ì •ì— ì›ì¹˜ ì•ŠëŠ” ìš”ê¸ˆì´ ë¶€ê³¼ë˜ì§€ ì•Šë„ë¡ ì´ ë°°í¬ ì¤‘ì— ìƒì„±ëœ ëª¨ë“  AWS ë¦¬ì†ŒìŠ¤ë¥¼ ì‚­ì œí•˜ì‹­ì‹œì˜¤. ","version":"Next","tagName":"h3"},{"title":"Envoy gateway","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway","content":"","keywords":"","version":"Next"},{"title":"Envoy AI Gatewayì˜ ì£¼ìš” ëª©í‘œâ€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#envoy-ai-gatewayì˜-ì£¼ìš”-ëª©í‘œ","content":" LLM/AI íŠ¸ë˜í”½ì˜ ë¼ìš°íŒ… ë° ê´€ë¦¬ë¥¼ ìœ„í•œ í†µí•© ë ˆì´ì–´ ì œê³µì„œë¹„ìŠ¤ ì•ˆì •ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ìë™ í˜ì¼ì˜¤ë²„ ë©”ì»¤ë‹ˆì¦˜ ì§€ì›LLM/AI íŠ¸ë˜í”½ì— ëŒ€í•œ ì—…ìŠ¤íŠ¸ë¦¼ ì¸ì¦ì„ í¬í•¨í•œ ì—”ë“œíˆ¬ì—”ë“œ ë³´ì•ˆ ë³´ì¥ì‚¬ìš©ëŸ‰ ì œí•œ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì§€ì›í•˜ê¸° ìœ„í•œ ì •ì±… í”„ë ˆì„ì›Œí¬ êµ¬í˜„GenAI ê´€ë ¨ ë¼ìš°íŒ… ë° ì„œë¹„ìŠ¤ í’ˆì§ˆ ìš”êµ¬ì‚¬í•­ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹° ìœ¡ì„±  ","version":"Next","tagName":"h2"},{"title":"Envoy Gateway ê¸°ë³¸ ì‚¬í•­â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#envoy-gateway-ê¸°ë³¸-ì‚¬í•­","content":" Envoy Gatewayì— ì´ë¯¸ ìµìˆ™í•˜ë‹¤ë©´ ì´ ì„¹ì…˜ì„ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Envoy AI GatewayëŠ” í‘œì¤€ Kubernetes Gateway APIì™€ Envoy Gateway í™•ì¥ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë¯€ë¡œ ê¸°ë³¸ Envoy Gateway í”„ë¦¬ë¯¸í‹°ë¸Œë¥¼ ìˆ™ì§€í•´ì•¼ í•©ë‹ˆë‹¤:  GatewayClass - Gatewayë¥¼ ê´€ë¦¬í•˜ëŠ” ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. Envoy AI GatewayëŠ” Envoy Gatewayì™€ ë™ì¼í•œ GatewayClassë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.Gateway - íŠ¸ë˜í”½ì˜ ì§„ì…ì ì…ë‹ˆë‹¤. Gateway ë¦¬ì†ŒìŠ¤ëŠ” ë¦¬ìŠ¤ë„ˆ(HTTP/HTTPS í¬íŠ¸)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. Gatewayë¥¼ ìƒì„±í•˜ë©´ Envoy Gatewayê°€ ì‹¤ì œ Envoy í”„ë¡ì‹œ íŒŒë“œì™€ í•´ë‹¹ Kubernetes Service(ì¼ë°˜ì ìœ¼ë¡œ LoadBalancer)ë¥¼ ë°°í¬í•©ë‹ˆë‹¤. ì´ëŠ” Network Load Balancerì™€ ìœ ì‚¬í•©ë‹ˆë‹¤(ê¸°ìˆ ì ìœ¼ë¡œ Kubernetes í´ëŸ¬ìŠ¤í„° ì™¸ë¶€ì˜ íŠ¸ë˜í”½ì„ ìˆ˜ë½í•˜ë ¤ë©´ Envoy Gatewayì— NLBë¥¼ ì—°ê²°í•´ì•¼ í•˜ì§€ë§Œ).HTTPRoute - í˜¸ìŠ¤íŠ¸ëª…, ê²½ë¡œ ë˜ëŠ” í—¤ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ HTTP íŠ¸ë˜í”½ì„ ë¼ìš°íŒ…í•˜ëŠ” ì§€ì¹¨ì…ë‹ˆë‹¤. ê°œë…ì ìœ¼ë¡œ ALBì˜ ì¸ê·¸ë ˆìŠ¤ ê·œì¹™ ë˜ëŠ” ë¦¬ìŠ¤ë„ˆ ê·œì¹™ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.Backend - Kubernetes Service ë˜ëŠ” ì™¸ë¶€ ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.BackendTrafficPolicy - HTTPRouteì˜ íƒ€ì„ì•„ì›ƒ, ì¬ì‹œë„, ì†ë„ ì œí•œê³¼ ê°™ì€ ì—°ê²° ë™ì‘ì„ êµ¬ì„±í•©ë‹ˆë‹¤.ClientTrafficPolicy - Envoy í”„ë¡ì‹œ ì„œë²„ê°€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ í´ë¼ì´ì–¸íŠ¸ì™€ ì‘ë™í•˜ëŠ” ë°©ì‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.EnvoyExtensionPolicy - Envoyì˜ íŠ¸ë˜í”½ ì²˜ë¦¬ ê¸°ëŠ¥ì„ í™•ì¥í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.  Envoy AI GatewayëŠ” ë‹¤ìŒ CRDë¥¼ ë„ì…í•©ë‹ˆë‹¤:  AIGatewayRoute - AI íŠ¸ë˜í”½ì— ëŒ€í•œ í†µí•© API ë° ë¼ìš°íŒ… ê·œì¹™ì„ ì •ì˜í•©ë‹ˆë‹¤AIServiceBackend - Bedrockê³¼ ê°™ì€ ê°œë³„ AI ì„œë¹„ìŠ¤ ë°±ì—”ë“œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤BackendSecurityPolicy - ë°±ì—”ë“œ ì ‘ê·¼ì— ëŒ€í•œ ì¸ì¦ì„ êµ¬ì„±í•©ë‹ˆë‹¤BackendTLSPolicy - ë°±ì—”ë“œ ì—°ê²°ì— ëŒ€í•œ TLS íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤    ì´ envoy gateway ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” Amazon EKSì— Envoy AI Gatewayë¥¼ ë°°í¬í•˜ê³  ë‘ ê°€ì§€ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:  ë‹¤ì¤‘ ëª¨ë¸ ë¼ìš°íŒ…ì†ë„ ì œí•œ  ì†”ë£¨ì…˜ ë°°í¬ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"ì…€í”„ í˜¸ìŠ¤íŒ… ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ì…€í”„-í˜¸ìŠ¤íŒ…-ëª¨ë¸-ë°°í¬","content":" Envoy AI gatewayëŠ” í˜„ì¬ OpenAI API ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì…€í”„ í˜¸ìŠ¤íŒ… ëª¨ë¸ì„ ì§€ì›í•©ë‹ˆë‹¤. AI on EKS Inference Chartsë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ê°œì˜ ëª¨ë¸ì„ ë°°í¬í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"1. Hugging Face í† í° ì‹œí¬ë¦¿ ìƒì„±â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#1-hugging-face-í† í°-ì‹œí¬ë¦¿-ìƒì„±","content":" Hugging Face í† í°ìœ¼ë¡œ Kubernetes ì‹œí¬ë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤:  kubectl create secret generic hf-token --from-literal=token=your_huggingface_token   ","version":"Next","tagName":"h3"},{"title":"2. ì‚¬ì „ êµ¬ì„±ëœ ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#2-ì‚¬ì „-êµ¬ì„±ëœ-ëª¨ë¸-ë°°í¬","content":" ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì „ êµ¬ì„±ëœ ëª¨ë¸ ì¤‘ì—ì„œ ì„ íƒí•˜ì—¬ ë°°í¬í•©ë‹ˆë‹¤:  ê²½ê³  ì´ëŸ¬í•œ ë°°í¬ì—ëŠ” í™œì„±í™”í•´ì•¼ í•˜ëŠ” GPU/Neuron ë¦¬ì†ŒìŠ¤ê°€ í•„ìš”í•˜ë©° CPU ì „ìš© ì¸ìŠ¤í„´ìŠ¤ë³´ë‹¤ ë¹„ìš©ì´ ë” ë§ì´ ë“­ë‹ˆë‹¤.  # helm ì°¨íŠ¸ ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update   # ëª¨ë¸ 1: qwen3 ëª¨ë¸ ë°°í¬ helm install qwen3-1.7b ai-on-eks/inference-charts -f https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-qwen3-1.7b-vllm.yaml \\ --set nameOverride=qwen3 \\ --set fullnameOverride=qwen3 \\ --set inference.serviceName=qwen3 # ëª¨ë¸ 2: gpt oss ëª¨ë¸ ë°°í¬ helm install gpt-oss ai-on-eks/inference-charts -f https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-gpt-oss-20b-vllm.yaml \\ --set nameOverride=gpt-oss \\ --set fullnameOverride=gpt-oss \\ --set inference.serviceName=gpt-oss   ëª¨ë¸ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸  kubectl get pod   NAME READY STATUS RESTARTS AGE gpt-oss-67c5bcdd5c-lx9vh 1/1 Running 0 44h qwen3-b5fdf6bd5-cxkwd 1/1 Running 0 44h   ","version":"Next","tagName":"h3"},{"title":"AWS Bedrock ëª¨ë¸ì— ëŒ€í•œ ì ‘ê·¼ í™œì„±í™”â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#aws-bedrock-ëª¨ë¸ì—-ëŒ€í•œ-ì ‘ê·¼-í™œì„±í™”","content":" ëª¨ë“  Amazon Bedrock íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ì— ëŒ€í•œ ì ‘ê·¼ì€ ì˜¬ë°”ë¥¸ AWS Marketplace ê¶Œí•œì´ ìˆìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë©ë‹ˆë‹¤. Amazon Bedrockì˜ ëª¨ë¸ ì ‘ê·¼ ê´€ë¦¬ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ Amazon Bedrock íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ì— ì ‘ê·¼ì„ ê²€í† í•˜ì„¸ìš”.  Model IDë¥¼ í¬í•¨í•œ ê´€ë ¨ ëª¨ë¸ ì •ë³´ì™€ Amazon Bedrockì„ í†µí•´ ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ ëª©ë¡ì€ Amazon Bedrockì—ì„œ ì§€ì›ë˜ëŠ” íŒŒìš´ë°ì´ì…˜ ëª¨ë¸ì„ ê²€í† í•˜ì„¸ìš”.  ","version":"Next","tagName":"h3"},{"title":"ë‹¤ì¤‘ ëª¨ë¸ ë¼ìš°íŒ…â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ë‹¤ì¤‘-ëª¨ë¸-ë¼ìš°íŒ…","content":" x-ai-eg-model í—¤ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ë¥¸ AI ëª¨ë¸ë¡œ ìš”ì²­ì„ ë¼ìš°íŒ…í•©ë‹ˆë‹¤. ì´ í—¤ë”ë¥¼ í†µí•´ Envoy AI gatewayëŠ” ê²Œì´íŠ¸ì›¨ì´ ë‚´ì— êµ¬ì„±ëœ ì ì ˆí•œ ë¼ìš°íŠ¸ë¥¼ ì‹ë³„í•˜ê³  í´ë¼ì´ì–¸íŠ¸ íŠ¸ë˜í”½ì„ ê´€ë ¨ ë°±ì—”ë“œ kubernetes ì„œë¹„ìŠ¤ë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤. ì´ ê²½ìš° ì…€í”„ í˜¸ìŠ¤íŒ… ëª¨ë¸ ë˜ëŠ” Amazon Bedrock ëª¨ë¸ì„ ë…¸ì¶œí•˜ëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ê³µí†µ ê²Œì´íŠ¸ì›¨ì´ ì¸í”„ë¼ ë°°í¬â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ê³µí†µ-ê²Œì´íŠ¸ì›¨ì´-ì¸í”„ë¼-ë°°í¬","content":" cd ../../blueprints/gateways/envoy-ai-gateway kubectl apply -f gateway.yaml   serviceaccount/ai-gateway-dataplane-aws created gatewayclass.gateway.networking.k8s.io/envoy-gateway created envoyproxy.gateway.envoyproxy.io/ai-gateway created gateway.gateway.networking.k8s.io/ai-gateway created clienttrafficpolicy.gateway.envoyproxy.io/ai-gateway-buffer-limit created   ","version":"Next","tagName":"h3"},{"title":"ëª¨ë¸ ë°±ì—”ë“œ êµ¬ì„±â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ëª¨ë¸-ë°±ì—”ë“œ-êµ¬ì„±","content":" kubectl apply -f model-backends.yaml   backend.gateway.envoyproxy.io/gpt-oss-backend created aiservicebackend.aigateway.envoyproxy.io/gpt-oss created backend.gateway.envoyproxy.io/qwen3-backend created aiservicebackend.aigateway.envoyproxy.io/qwen3 created backend.gateway.envoyproxy.io/bedrock-backend created aiservicebackend.aigateway.envoyproxy.io/bedrock created backendsecuritypolicy.aigateway.envoyproxy.io/bedrock-policy created backendtlspolicy.gateway.networking.k8s.io/bedrock-tls created   ","version":"Next","tagName":"h3"},{"title":"ëª¨ë¸ ë¼ìš°íŠ¸ êµ¬ì„±â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ëª¨ë¸-ë¼ìš°íŠ¸-êµ¬ì„±","content":" kubectl apply -f multi-model-routing/ai-gateway-route.yaml   aigatewayroute.aigateway.envoyproxy.io/multi-model-route created   ","version":"Next","tagName":"h3"},{"title":"í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#í…ŒìŠ¤íŠ¸","content":" python3 multi-model-routing/client.py   ì˜ˆìƒ ì¶œë ¥:  ğŸš€ AI Gateway Multi-Model Routing Test ============================================================ Gateway URL: http://k8s-envoygat-envoydef-xxxxxxxxxx-xxxxxxxxxxxxxxxx.elb.us-west-2.amazonaws.com === Testing Qwen3 1.7B === Status Code: 200 âœ… SUCCESS: Qwen3 - [response content] === Testing Self-hosted GPT === Status Code: 200 âœ… SUCCESS: GPT - [response content] === Testing Bedrock Claude === Status Code: 200 âœ… SUCCESS: Bedrock Claude - [response content] ğŸ¯ Final Results: â€¢ Qwen3 1.7B: âœ… PASS â€¢ GPT OSS 20B: âœ… PASS â€¢ Bedrock Claude: âœ… PASS ğŸ“Š Summary: 3/3 models working   ","version":"Next","tagName":"h2"},{"title":"ì†ë„ ì œí•œâ€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ì†ë„-ì œí•œ","content":" AI ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ìë™ ì¶”ì  ê¸°ëŠ¥ì´ ìˆëŠ” í† í° ê¸°ë°˜ ì†ë„ ì œí•œì…ë‹ˆë‹¤.  ê¸°ëŠ¥:  í† í° ê¸°ë°˜ ì†ë„ ì œí•œ (ì…ë ¥, ì¶œë ¥ ë° ì´ í† í°)x-user-id í—¤ë”ë¥¼ ì‚¬ìš©í•œ ì‚¬ìš©ì ê¸°ë°˜ ì†ë„ ì œí•œë¶„ì‚° ì†ë„ ì œí•œì„ ìœ„í•œ Redis ë°±ì—”ë“œ (ìë™ ë°°í¬ë¨)ì‹œê°„ ì°½ë‹¹ ì‚¬ìš©ìë³„ êµ¬ì„± ê°€ëŠ¥í•œ ì œí•œ  ","version":"Next","tagName":"h2"},{"title":"ì†ë„ ì œí•œ êµ¬ì„±â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ì†ë„-ì œí•œ-êµ¬ì„±","content":" kubectl apply -f rate-limiting/ai-gateway-route.yaml kubectl apply -f rate-limiting/ai-gateway-rate-limit.yaml kubectl apply -f rate-limiting/backend-traffic-policy.yaml   ","version":"Next","tagName":"h3"},{"title":"ì†ë„ ì œí•œ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ì†ë„-ì œí•œ-í…ŒìŠ¤íŠ¸","content":" python3 rate-limiting/client.py   ","version":"Next","tagName":"h3"},{"title":"êµ¬ì„± ì„¸ë¶€ ì •ë³´â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#êµ¬ì„±-ì„¸ë¶€-ì •ë³´","content":" ","version":"Next","tagName":"h2"},{"title":"ë¼ìš°íŒ… êµ¬ì„±â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ë¼ìš°íŒ…-êµ¬ì„±","content":" AI GatewayëŠ” x-ai-eg-model í—¤ë”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš”ì²­ì„ ë¼ìš°íŒ…í•©ë‹ˆë‹¤:  í—¤ë” ê°’\të°±ì—”ë“œ\tì—”ë“œí¬ì¸íŠ¸\tëª¨ë¸ ìœ í˜•Qwen/Qwen3-1.7B\tqwen3\t/v1/chat/completions\tì…€í”„ í˜¸ìŠ¤íŒ… openai/gpt-oss-20b\tgpt-oss\t/v1/chat/completions\tì…€í”„ í˜¸ìŠ¤íŒ… anthropic.claude-3-haiku-20240307-v1:0\tbedrock\t/anthropic/v1/messages\tAWS Bedrock  ","version":"Next","tagName":"h3"},{"title":"Bedrock í†µí•© ì„¸ë¶€ ì •ë³´â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#bedrock-í†µí•©-ì„¸ë¶€-ì •ë³´","content":" ì¸ì¦: Pod Identity (ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ìë™ êµ¬ì„±ë¨)ìŠ¤í‚¤ë§ˆ: ë„¤ì´í‹°ë¸Œ Bedrock ì§€ì›ì„ ìœ„í•œ AWSAnthropicì—”ë“œí¬ì¸íŠ¸: /anthropic/v1/messages (Anthropic Messages API í˜•ì‹)ë¦¬ì „: backend-security-policy.yamlì—ì„œ êµ¬ì„± ê°€ëŠ¥ (ê¸°ë³¸ê°’: us-west-2)  ","version":"Next","tagName":"h3"},{"title":"ë¦¬ì†ŒìŠ¤â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ë¦¬ì†ŒìŠ¤","content":" Envoy AI Gateway ë¬¸ì„œEnvoy Gateway ë¬¸ì„œAWS Bedrock ë¬¸ì„œ  ","version":"Next","tagName":"h2"},{"title":"ì¤‘ìš” ì°¸ê³ ì‚¬í•­â€‹","type":1,"pageTitle":"Envoy gateway","url":"/ai-on-eks/ko/docs/blueprints/gateways/envoy-gateway#ì¤‘ìš”-ì°¸ê³ ì‚¬í•­","content":" ë‹¤ì¤‘ ëª¨ë¸ ë¼ìš°íŒ…: ë°°í¬ëœ AI ëª¨ë¸ ì„œë¹„ìŠ¤ì™€ AWS Bedrock ì ‘ê·¼ ê¶Œí•œ í•„ìš”ì†ë„ ì œí•œ: ì‹¤ì œ í† í° ì‚¬ìš© ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ëŠ” ì‹¤ì œ AI ëª¨ë¸ê³¼ ì €ì¥ì„ ìœ„í•œ Redis í•„ìš”Bedrock í†µí•©: AWS Bedrock API ì ‘ê·¼, ì ì ˆí•œ IAM ì„¤ì • ë° Pod Identity êµ¬ì„± í•„ìš”ì¸ì¦: Bedrockìš© Pod IdentityëŠ” ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ë°°í¬í•  ë•Œ ìë™ìœ¼ë¡œ êµ¬ì„±ë¨  ì´ê²ƒì€ ì‹¤ì œ AI ëª¨ë¸ ë°°í¬ ë° AWS Bedrock í†µí•©ê³¼ í•¨ê»˜ AI Gateway ê¸°ëŠ¥ì„ ë³´ì—¬ì£¼ëŠ” ì‘ë™í•˜ëŠ” êµ¬ì„± ì˜ˆì œì…ë‹ˆë‹¤. ","version":"Next","tagName":"h2"},{"title":"AI on EKS","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints","content":"","keywords":"","version":"Next"},{"title":"ê¸°ë°˜ ì¸í”„ë¼â€‹","type":1,"pageTitle":"AI on EKS","url":"/ai-on-eks/ko/docs/blueprints#ê¸°ë°˜-ì¸í”„ë¼","content":" AIoEKSì˜ í•µì‹¬ì€ ì›í•˜ëŠ” í™˜ê²½ì„ êµ¬ì„±í•˜ê¸° ìœ„í•´ ì¡°í•©í•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆ ì„¸íŠ¸ì…ë‹ˆë‹¤. ì‹¤í—˜, í•™ìŠµ, ì¶”ë¡  í™˜ê²½ì„ ë¹ ë¥´ê²Œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì•ìœ¼ë¡œ ë” ë§ì€ ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ì¶”ê°€í•  ì˜ˆì •ì´ë©°, ì›í•˜ëŠ” ëŒ€ë¡œ í™˜ê²½ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•  ì¤€ë¹„ê°€ ë˜ì…¨ë‹¤ë©´, ì¸í”„ë¼ ì„¹ì…˜ì„ í™•ì¸í•˜ì„¸ìš”.  ","version":"Next","tagName":"h2"},{"title":"í•™ìŠµ (Training)â€‹","type":1,"pageTitle":"AI on EKS","url":"/ai-on-eks/ko/docs/blueprints#í•™ìŠµ-training","content":" ìƒì„±í˜• AIì—ì„œì˜ í•™ìŠµì€ ë°©ëŒ€í•œ ë°ì´í„°ì—ì„œ í•™ìŠµí•˜ì—¬ ì¸ê°„ê³¼ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•˜ë„ë¡ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ ê³¼ì •ì€ BERT-Largeë‚˜ Llama2 ê°™ì€ ëª¨ë¸ì˜ ê¸°ë°˜ì„ í˜•ì„±í•˜ë©°, í…ìŠ¤íŠ¸ ìš”ì•½, ë²ˆì—­ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.  ìš°ë¦¬ í”Œë«í¼ì€ PyTorch, TensorFlow, TensorRT, vLLM ë“± ë‹¤ì–‘í•œ ML í”„ë ˆì„ì›Œí¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. JupyterHubë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜•ìœ¼ë¡œ í˜‘ì—…í•˜ë©° ëª¨ë¸ì„ ê°œë°œí•  ìˆ˜ ìˆìœ¼ë©°, ë°ì´í„° ë¶„ì„, ëª¨ë¸ êµ¬ì¶•, ì‹¤í—˜ ì‹¤í–‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. í•™ìŠµ ë‹¨ê³„ëŠ” Kubeflow ë° Rayì™€ë„ í†µí•©ë˜ì–´ ë°ì´í„° ì „ì²˜ë¦¬ë¶€í„° í•™ìŠµ ë° í‰ê°€ê¹Œì§€ ë³µì¡í•œ ë¨¸ì‹  ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•˜ëŠ” ê°•ë ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.  LLMì˜ ì„¸ê³„ì— ë›°ì–´ë“¤ì–´ íŠ¹ì • ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ì¤€ë¹„ê°€ ë˜ì…¨ë‚˜ìš”? ì¢…í•©ì ì¸ í•™ìŠµ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.  ","version":"Next","tagName":"h2"},{"title":"ì¶”ë¡  (Inference)â€‹","type":1,"pageTitle":"AI on EKS","url":"/ai-on-eks/ko/docs/blueprints#ì¶”ë¡ -inference","content":" ì¶”ë¡ ì€ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì´ë‚˜ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ìƒì„±í˜• AIì—ì„œ ì¶”ë¡ ì€ ëª¨ë¸ì´ í…ìŠ¤íŠ¸ ìƒì„±, ë²ˆì—­, ìš”ì•½ ë“±ì˜ ì‘ì—…ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. í™•ì¥ ê°€ëŠ¥í•œ ì¶”ë¡  í”Œë«í¼ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì€ ë†’ì€ ìˆ˜ìš”ë¥¼ ì²˜ë¦¬í•˜ê³  ë‚®ì€ ì§€ì—° ì‹œê°„ì„ ë³´ì¥í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.  RayServe, NVIDIA Triton Inference Server, KServe ë“±ì˜ ë°°í¬ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ê³ ì„±ëŠ¥ ëª¨ë¸ ì„œë¹™ì„ ë³´ì¥í•˜ì„¸ìš”. ë˜í•œ AWS Neuron(Inferentiaìš©) ë° NVIDIA GPUë¥¼ ì‚¬ìš©í•œ ìµœì í™” ê¸°ë²•ë„ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ìŠ¤í† ë¦¬ì§€ ë° ë°ì´í„° ê´€ë¦¬â€‹","type":1,"pageTitle":"AI on EKS","url":"/ai-on-eks/ko/docs/blueprints#ìŠ¤í† ë¦¬ì§€-ë°-ë°ì´í„°-ê´€ë¦¬","content":" íš¨ìœ¨ì ì¸ ë°ì´í„° ìŠ¤í† ë¦¬ì§€ ë° ê´€ë¦¬ëŠ” ì„±ê³µì ì¸ AI/ML ìš´ì˜ì˜ ê¸°ë³¸ì…ë‹ˆë‹¤. ìš°ë¦¬ í”Œë«í¼ì€ S3, EBS, EFS, FSx ë“± AWS ìŠ¤í† ë¦¬ì§€ ì†”ë£¨ì…˜ê³¼ í†µí•©ë©ë‹ˆë‹¤. MLflowë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë° ë²„ì „ ê´€ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê³ , Amazon ECRë¡œ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ìˆ™ë ¨ëœ ì‹¤ë¬´ìë“  ì´ ë¶„ì•¼ì— ì²˜ìŒ ì…ë¬¸í•œ ë¶„ì´ë“ , AI on EKSëŠ” ì–¸ì–´ ëª¨ë¸ë§ì˜ ìµœì‹  ë°œì „ì„ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. ê° ì„¹ì…˜ì„ íƒìƒ‰í•˜ì—¬ ì—¬ì •ì„ ì‹œì‘í•˜ê³ , Amazon EKSì—ì„œ ê°•ë ¥í•œ AI ëª¨ë¸ì„ êµ¬ì¶•, íŒŒì¸íŠœë‹, ë°°í¬í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì„¸ìš”. ","version":"Next","tagName":"h2"},{"title":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research","content":"","keywords":"","version":"Next"},{"title":"NVIDIA AI-Q Research Assistantë€?â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#nvidia-ai-q-research-assistantë€","content":" NVIDIA AI-Q Research AssistantëŠ” ì–´ë””ì„œë‚˜ ì‘ë™í•  ìˆ˜ ìˆê³ , ìì²´ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì •ë³´ë¥¼ ì œê³µë°›ìœ¼ë©°, ëª‡ ì‹œê°„ ë¶„ëŸ‰ì˜ ì—°êµ¬ë¥¼ ëª‡ ë¶„ ë§Œì— ì¢…í•©í•  ìˆ˜ ìˆëŠ” ë§ì¶¤í˜• AI ì—°êµ¬ì›ì„ ìƒì„±í•˜ëŠ” AI ê¸°ë°˜ ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. AI-Q NVIDIA Blueprintë¥¼ í†µí•´ ê°œë°œìëŠ” AI ì—ì´ì „íŠ¸ë¥¼ ì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„°ì— ì—°ê²°í•˜ê³  ì¶”ë¡  ë° ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì„±ê³¼ ì •ë°€ë„ë¡œ ì‹¬ì¸µì ì¸ ì†ŒìŠ¤ ìë£Œë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì£¼ìš” ê¸°ëŠ¥â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì£¼ìš”-ê¸°ëŠ¥","content":" ê³ ê¸‰ ì—°êµ¬ ìë™í™”:  ë¹ ë¥¸ ë³´ê³ ì„œ í•©ì„±ì„ ìœ„í•œ 5ë°° ë¹ ë¥¸ í† í° ìƒì„±ë” ë‚˜ì€ ì˜ë¯¸ë¡ ì  ì •í™•ë„ë¡œ 15ë°° ë¹ ë¥¸ ë°ì´í„° ìˆ˜ì§‘íš¨ìœ¨ì„±ê³¼ ì •ë°€ë„ë¡œ ë‹¤ì–‘í•œ ë°ì´í„° ì„¸íŠ¸ ìš”ì•½ìë™ìœ¼ë¡œ í¬ê´„ì ì¸ ì—°êµ¬ ë³´ê³ ì„œ ìƒì„±  NVIDIA NeMo Agent Toolkit:  ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ê°œë°œ ë° ìµœì í™” ìš©ì´ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ì— ê±¸ì³ ì›Œí¬í”Œë¡œìš° í†µí•©, í‰ê°€, ê°ì‚¬ ë° ë””ë²„ê·¸ìµœì í™” ê¸°íšŒ ì‹ë³„ê° ì‘ì—…ì— ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ì™€ ë„êµ¬ë¥¼ ìœ ì—°í•˜ê²Œ ì„ íƒí•˜ê³  ì—°ê²°  NVIDIA NeMo Retrieverë¥¼ í†µí•œ ê³ ê¸‰ ì˜ë¯¸ë¡ ì  ì¿¼ë¦¬:  ë©€í‹°ëª¨ë‹¬ PDF ë°ì´í„° ì¶”ì¶œ ë° ê²€ìƒ‰ (í…ìŠ¤íŠ¸, í‘œ, ì°¨íŠ¸, ì¸í¬ê·¸ë˜í”½)15ë°° ë¹ ë¥¸ ì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„° ìˆ˜ì§‘3ë°° ë‚®ì€ ê²€ìƒ‰ ì§€ì—° ì‹œê°„ë‹¤êµ­ì–´ ë° êµì°¨ ì–¸ì–´ ì§€ì›ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ë¦¬ë­í‚¹GPU ê°€ì† ì¸ë±ìŠ¤ ìƒì„± ë° ê²€ìƒ‰  Llama Nemotronì„ í†µí•œ ë¹ ë¥¸ ì¶”ë¡ :  ìµœê³ ì˜ ì •í™•ë„ì™€ ìµœì € ì§€ì—° ì‹œê°„ ì¶”ë¡  ê¸°ëŠ¥Llama-3.3-Nemotron-Super-49B-v1.5 ì¶”ë¡  ëª¨ë¸ ì‚¬ìš©ë°ì´í„° ì†ŒìŠ¤ ë¶„ì„ ë° íŒ¨í„´ ì‹ë³„í¬ê´„ì ì¸ ì—°êµ¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì†”ë£¨ì…˜ ì œì•ˆì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„°ë¡œ ì§€ì›ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ìƒì„±  ì›¹ ê²€ìƒ‰ í†µí•©:  Tavily APIë¡œ êµ¬ë™ë˜ëŠ” ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰í˜„ì¬ ì •ë³´ë¡œ ì˜¨í”„ë ˆë¯¸ìŠ¤ ì†ŒìŠ¤ ë³´ì™„ë‚´ë¶€ ë¬¸ì„œë¥¼ ë„˜ì–´ ì—°êµ¬ í™•ì¥  ","version":"Next","tagName":"h3"},{"title":"AI-Q êµ¬ì„± ìš”ì†Œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ai-q-êµ¬ì„±-ìš”ì†Œ","content":" ê³µì‹ AI-Q ì•„í‚¤í…ì²˜ì— ë”°ë¥´ë©´:  1. NVIDIA AI Workbench  ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ ê°„ì†Œí™”ëœ ê°œë°œ í™˜ê²½ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë° ì‚¬ìš©ì ì •ì˜ë‹¤ì–‘í•œ LLMì˜ ì†ì‰¬ìš´ êµ¬ì„±NVIDIA NeMo Agent Toolkit í†µí•©  2. NVIDIA RAG Blueprint  ëŒ€ê·œëª¨ ì˜¨í”„ë ˆë¯¸ìŠ¤ ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ì„¸íŠ¸ ì¿¼ë¦¬ë¥¼ ìœ„í•œ ì†”ë£¨ì…˜í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, í‘œ ë° ì°¨íŠ¸ ì¶”ì¶œ ì§€ì›GPU ê°€ì†ì„ í†µí•œ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ë° ê²€ìƒ‰AI-Qì˜ ì—°êµ¬ ê¸°ëŠ¥ì„ ìœ„í•œ ê¸°ë°˜  3. NVIDIA NeMo Retriever Microservices  ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ìˆ˜ì§‘ê·¸ë˜í”½ ìš”ì†Œ ê°ì§€í‘œ êµ¬ì¡° ì¶”ì¶œí…ìŠ¤íŠ¸ ì¸ì‹ì„ ìœ„í•œ PaddleOCR15ë°° ë¹ ë¥¸ ë°ì´í„° ìˆ˜ì§‘  4. NVIDIA NIM Microservices  LLM ë° ë¹„ì „ ëª¨ë¸ì„ ìœ„í•œ ìµœì í™”ëœ ì¶”ë¡  ì»¨í…Œì´ë„ˆLlama-3.3-Nemotron-Super-49B-v1.5 ì¶”ë¡  ëª¨ë¸ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ Llama-3.3-70B-Instruct ëª¨ë¸GPU ê°€ì† ì¶”ë¡   5. ì›¹ ê²€ìƒ‰ (Tavily)  ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì˜¨í”„ë ˆë¯¸ìŠ¤ ì†ŒìŠ¤ ë³´ì™„ë‚´ë¶€ ë¬¸ì„œë¥¼ ë„˜ì–´ ì—°êµ¬ í™•ì¥ì›¹ ë³´ê°• ì—°êµ¬ ë³´ê³ ì„œ ì§€ì›  ","version":"Next","tagName":"h3"},{"title":"NVIDIA Enterprise RAG Blueprintë€?â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#nvidia-enterprise-rag-blueprintë€","content":" NVIDIA Enterprise RAG BlueprintëŠ” ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë‘ë¥¼ ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•˜ê³  ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥í•œ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ì™„ì „í•œ ê¸°ë°˜ì„ ì œê³µí•˜ëŠ” í”„ë¡œë•ì…˜ ì¤€ë¹„ ì°¸ì¡° ì›Œí¬í”Œë¡œìš°ì…ë‹ˆë‹¤. NVIDIA NeMo Retriever ëª¨ë¸ê³¼ NVIDIA Llama Nemotron ëª¨ë¸ë¡œ êµ¬ë™ë˜ëŠ” ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” ë†’ì€ ì •í™•ë„, ê°•ë ¥í•œ ì¶”ë¡  ë° ì—”í„°í”„ë¼ì´ì¦ˆ ê·œëª¨ì˜ ì²˜ë¦¬ëŸ‰ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ìˆ˜ì§‘, ê³ ê¸‰ ê²€ìƒ‰, ë¦¬ë­í‚¹ ë° ë°˜ì˜ ê¸°ìˆ ì— ëŒ€í•œ ë‚´ì¥ ì§€ì›ê³¼ LLM ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°ì™€ì˜ ì›í™œí•œ í†µí•©ì„ í†µí•´ ìˆ˜ë°±ë§Œ ê°œì˜ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸, í‘œ, ì°¨íŠ¸, ì˜¤ë””ì˜¤ ë° ì¸í¬ê·¸ë˜í”½ì— ê±¸ì³ ì–¸ì–´ ëª¨ë¸ì„ ì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„°ì— ì—°ê²°í•˜ì—¬ ì§„ì •í•œ ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ë° ìƒì„±ì  ì‘ë‹µì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì£¼ìš” ê¸°ëŠ¥â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì£¼ìš”-ê¸°ëŠ¥-1","content":" ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬:  í…ìŠ¤íŠ¸, í‘œ, ì°¨íŠ¸ ë° ì¸í¬ê·¸ë˜í”½ì´ í¬í•¨ëœ ë©€í‹°ëª¨ë‹¬ PDF ë°ì´í„° ì¶”ì¶œì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜ì§‘ ì§€ì›ì‚¬ìš©ì ì •ì˜ ë©”íƒ€ë°ì´í„° ì§€ì›ë¬¸ì„œ ìš”ì•½ì—”í„°í”„ë¼ì´ì¦ˆ ê·œëª¨ë¡œ ìˆ˜ë°±ë§Œ ê°œì˜ ë¬¸ì„œ ì§€ì›  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë° ê²€ìƒ‰:  ë¬¸ì„œ ì„¸íŠ¸ì— ê±¸ì¹œ ë‹¤ì¤‘ ì»¬ë ‰ì…˜ ê²€ìƒ‰ ê°€ëŠ¥ë°€ì§‘ ë° í¬ì†Œ ê²€ìƒ‰ì„ í†µí•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ë¦¬ë­í‚¹GPU ê°€ì† ì¸ë±ìŠ¤ ìƒì„± ë° ê²€ìƒ‰í”ŒëŸ¬ê·¸ ê°€ëŠ¥ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì•„í‚¤í…ì²˜: ElasticSearch ì§€ì›Milvus ì§€ì›OpenSearch Serverless ì§€ì› (ì´ ë°°í¬ì—ì„œ ì‚¬ìš©) ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ ìœ„í•œ ì¿¼ë¦¬ ë¶„í•´ë™ì  ë©”íƒ€ë°ì´í„° í•„í„° ìƒì„±  ë©€í‹°ëª¨ë‹¬ ë° ê³ ê¸‰ ìƒì„±:  ë‹µë³€ ìƒì„±ì—ì„œ ì„ íƒì  Vision Language Model (VLM) ì§€ì›VLMì„ í†µí•œ ì˜µíŠ¸ì¸ ì´ë¯¸ì§€ ìº¡ì…˜ëŒ€í™”í˜• Q&amp;Aë¥¼ ìœ„í•œ ë‹¤ì¤‘ í„´ ëŒ€í™”ë™ì‹œ ì‚¬ìš©ìë¥¼ ìœ„í•œ ë‹¤ì¤‘ ì„¸ì…˜ ì§€ì›ì„ íƒì  ë°˜ì˜ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ  ê±°ë²„ë„ŒìŠ¤ ë° ì•ˆì „:  ì„ íƒì  í”„ë¡œê·¸ë˜ë° ê°€ëŠ¥ ê°€ë“œë ˆì¼ë¡œ ì½˜í…ì¸  ì•ˆì „ ê°œì„ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë³´ì•ˆ ê¸°ëŠ¥ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ë° ê·œì • ì¤€ìˆ˜ ì œì–´  ê´€ì¸¡ì„± ë° í…”ë ˆë©”íŠ¸ë¦¬:  í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ í¬í•¨ (RAGAS í”„ë ˆì„ì›Œí¬)ë¶„ì‚° ì¶”ì ì„ ìœ„í•œ OpenTelemetry ì§€ì›ì¶”ì  ì‹œê°í™”ë¥¼ ìœ„í•œ Zipkin í†µí•©ë©”íŠ¸ë¦­ ë° ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ Grafana ëŒ€ì‹œë³´ë“œì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë° ìµœì í™” ë„êµ¬  ê°œë°œì ê¸°ëŠ¥:  í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ìš© ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ í¬í•¨DRAë¥¼ ì‚¬ìš©í•œ GPU ê³µìœ ë¥¼ ìœ„í•œ NIM Operator ì§€ì›ë„¤ì´í‹°ë¸Œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì›ì‰¬ìš´ í†µí•©ì„ ìœ„í•œ OpenAI í˜¸í™˜ APIë¶„í•´ ê°€ëŠ¥í•˜ê³  ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ê¸°ëŠ¥ í™•ì¥ì„ ìœ„í•œ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ  ","version":"Next","tagName":"h3"},{"title":"Enterprise RAG ì‚¬ìš© ì‚¬ë¡€â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#enterprise-rag-ì‚¬ìš©-ì‚¬ë¡€","content":" Enterprise RAG BlueprintëŠ” ë…ë¦½ì ìœ¼ë¡œ ë˜ëŠ” ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì˜ êµ¬ì„± ìš”ì†Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  ë¬¸ì„œ ì €ì¥ì†Œ ì „ë°˜ì˜ ì—”í„°í”„ë¼ì´ì¦ˆ ê²€ìƒ‰ì¡°ì§ ì§€ì‹ ë² ì´ìŠ¤ìš© ì§€ì‹ ì–´ì‹œìŠ¤í„´íŠ¸ë„ë©”ì¸ë³„ ì• í”Œë¦¬ì¼€ì´ì…˜ìš© ìƒì„±í˜• ì½”íŒŒì¼ëŸ¿íŠ¹ì • ì‚°ì—…ì— ë§ì¶¤í™”ëœ ìˆ˜ì§ AI ì›Œí¬í”Œë¡œìš°ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì˜ ê¸°ë°˜ êµ¬ì„± ìš”ì†Œ (AI-Q Research Assistantì²˜ëŸ¼)ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ì‘ë‹µì„ í†µí•œ ê³ ê° ì§€ì› ìë™í™”ëŒ€ê·œëª¨ ë¬¸ì„œ ë¶„ì„ ë° ìš”ì•½  ì—”í„°í”„ë¼ì´ì¦ˆ ê²€ìƒ‰, ì§€ì‹ ì–´ì‹œìŠ¤í„´íŠ¸, ìƒì„±í˜• ì½”íŒŒì¼ëŸ¿ ë˜ëŠ” ìˆ˜ì§ AI ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•˜ë“ , RAGìš© NVIDIA AI BlueprintëŠ” í”„ë¡œí† íƒ€ì…ì—ì„œ í”„ë¡œë•ì…˜ìœ¼ë¡œ ìì‹  ìˆê²Œ ì´ë™í•˜ëŠ” ë° í•„ìš”í•œ ëª¨ë“  ê²ƒì„ ì œê³µí•©ë‹ˆë‹¤. ë…ë¦½ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜, ë‹¤ë¥¸ NVIDIA Blueprintì™€ ê²°í•©í•˜ê±°ë‚˜, ë” ê³ ê¸‰ ì¶”ë¡  ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ì— í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ê°œìš”â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ê°œìš”","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” **NVIDIA AI-Q Research Assistant**ë¥¼ Amazon EKSì— êµ¬í˜„í•˜ë©°, í¬ê´„ì ì¸ ì—°êµ¬ ê¸°ëŠ¥ì„ ìœ„í•´ NVIDIA RAG Blueprintì™€ AI-Q êµ¬ì„± ìš”ì†Œë¥¼ ê²°í•©í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë°°í¬ ì˜µì…˜â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ë°°í¬-ì˜µì…˜","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” ì‚¬ìš© ì‚¬ë¡€ì— ë”°ë¼ ë‘ ê°€ì§€ ë°°í¬ ëª¨ë“œë¥¼ ì§€ì›í•©ë‹ˆë‹¤:  ì˜µì…˜ 1: Enterprise RAG Blueprint  ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ì²˜ë¦¬ì™€ í•¨ê»˜ NVIDIA Enterprise RAG Blueprint ë°°í¬NeMo Retriever ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë° OpenSearch í†µí•© í¬í•¨ì í•© ìš©ë„: ì‚¬ìš©ì ì •ì˜ RAG ì• í”Œë¦¬ì¼€ì´ì…˜, ë¬¸ì„œ Q&amp;A ì‹œìŠ¤í…œ, ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•  ì˜µì…˜ 2: ì „ì²´ AI-Q Research Assistant  ì˜µì…˜ 1ì˜ ëª¨ë“  ê²ƒì— AI-Q êµ¬ì„± ìš”ì†Œ ì¶”ê°€Tavily APIë¥¼ í†µí•œ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ìœ¼ë¡œ ìë™í™”ëœ ì—°êµ¬ ë³´ê³ ì„œ ìƒì„± ì¶”ê°€ì í•© ìš©ë„: í¬ê´„ì ì¸ ì—°êµ¬ ì‘ì—…, ìë™í™”ëœ ë³´ê³ ì„œ ìƒì„±, ì›¹ ë³´ê°• ì—°êµ¬  ë‘ ë°°í¬ ëª¨ë‘ Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§ê³¼ ì—”í„°í”„ë¼ì´ì¦ˆ ë³´ì•ˆ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤. ì˜µì…˜ 1ë¡œ ì‹œì‘í•˜ì—¬ í•„ìš”ì— ë”°ë¼ ë‚˜ì¤‘ì— AI-Q êµ¬ì„± ìš”ì†Œë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ë°°í¬ ì ‘ê·¼ ë°©ì‹â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ë°°í¬-ì ‘ê·¼-ë°©ì‹","content":" ì´ ì„¤ì • í”„ë¡œì„¸ìŠ¤ì˜ ì´ìœ ëŠ”?ì´ êµ¬í˜„ì€ ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ í¬í•¨í•˜ì§€ë§Œ ì—¬ëŸ¬ ê°€ì§€ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤:  ì™„ì „í•œ ì¸í”„ë¼: VPC, EKS í´ëŸ¬ìŠ¤í„°, OpenSearch Serverless ë° ëª¨ë‹ˆí„°ë§ ìŠ¤íƒì„ ìë™ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥: ë³´ì•ˆ, ëª¨ë‹ˆí„°ë§ ë° í™•ì¥ì„± ê¸°ëŠ¥ í¬í•¨AWS í†µí•©: Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§, EKS Pod Identity ì¸ì¦ ë° ê´€ë¦¬í˜• AWS ì„œë¹„ìŠ¤ í™œìš©ì¬í˜„ ê°€ëŠ¥: Infrastructure as Codeë¡œ í™˜ê²½ ì „ë°˜ì— ê±¸ì³ ì¼ê´€ëœ ë°°í¬ ë³´ì¥  ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” ê¸°ëŠ¥â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì£¼ìš”-ê¸°ëŠ¥-2","content":" ì„±ëŠ¥ ìµœì í™”:  Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§: ì›Œí¬ë¡œë“œ ìš”êµ¬ì— ë”°ë¥¸ ë™ì  GPU ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ì§€ëŠ¥í˜• ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ: ìµœì ì˜ GPU ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•(G5, P4, P5) ìë™ ì„ íƒë¹ˆ íŒ¨í‚¹: ì—¬ëŸ¬ ì›Œí¬ë¡œë“œì— ê±¸ì¹œ íš¨ìœ¨ì ì¸ GPU í™œìš©  ì—”í„°í”„ë¼ì´ì¦ˆ ì¤€ë¹„:  OpenSearch Serverless: ìë™ í™•ì¥ì„ í†µí•œ ê´€ë¦¬í˜• ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤Pod Identity ì¸ì¦: Podì—ì„œ ì•ˆì „í•œ AWS IAM ì•¡ì„¸ìŠ¤ë¥¼ ìœ„í•œ EKS Pod Identityê´€ì¸¡ì„± ìŠ¤íƒ: GPU ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ Prometheus, Grafana ë° DCGMë³´ì•ˆ ì•¡ì„¸ìŠ¤: ì œì–´ëœ ì„œë¹„ìŠ¤ ì•¡ì„¸ìŠ¤ë¥¼ ìœ„í•œ Kubernetes í¬íŠ¸ í¬ì›Œë”©  ","version":"Next","tagName":"h3"},{"title":"ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì•„í‚¤í…ì²˜","content":" ","version":"Next","tagName":"h2"},{"title":"AI-Q Research Assistant ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ai-q-research-assistant-ì•„í‚¤í…ì²˜","content":" ë°°í¬ëŠ” Karpenter ê¸°ë°˜ ë™ì  í”„ë¡œë¹„ì €ë‹ê³¼ í•¨ê»˜ Amazon EKSë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:    ","version":"Next","tagName":"h3"},{"title":"Enterprise RAG Blueprint ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#enterprise-rag-blueprint-ì•„í‚¤í…ì²˜","content":"   RAG íŒŒì´í”„ë¼ì¸ì€ ì—¬ëŸ¬ íŠ¹ìˆ˜ NIM ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ë¥¼ í†µí•´ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤:  1. Llama-3.3-Nemotron-Super-49B-v1.5  ê³ ê¸‰ ì¶”ë¡  ëª¨ë¸RAG ë° ë³´ê³ ì„œ ì‘ì„± ëª¨ë‘ë¥¼ ìœ„í•œ ê¸°ë³¸ ì¶”ë¡  ë° ìƒì„±ì¿¼ë¦¬ ì¬ì‘ì„± ë° ë¶„í•´í•„í„° í‘œí˜„ì‹ ìƒì„±  2. ì„ë² ë”© ë° ë¦¬ë­í‚¹  LLama 3.2 NV-EmbedQA: 2048ì°¨ì› ì„ë² ë”©LLama 3.2 NV-RerankQA: ê´€ë ¨ì„± ì ìˆ˜ ë§¤ê¸°ê¸°  3. NV-Ingest íŒŒì´í”„ë¼ì¸  PaddleOCR: ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œPage Elements: ë¬¸ì„œ ë ˆì´ì•„ì›ƒ ì´í•´Graphic Elements: ì°¨íŠ¸ ë° ë‹¤ì´ì–´ê·¸ë¨ ê°ì§€Table Structure: í‘œ í˜•ì‹ ë°ì´í„° ì¶”ì¶œ  4. AI-Q Research Assistant êµ¬ì„± ìš”ì†Œ  ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ Llama-3.3-70B-Instruct ëª¨ë¸ (ì„ íƒ ì‚¬í•­, 2 GPU)Tavily APIë¥¼ í†µí•œ ì›¹ ê²€ìƒ‰ì—°êµ¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ ë°±ì—”ë“œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì‚¬ì „-ìš”êµ¬-ì‚¬í•­","content":" ì¤‘ìš” - ë¹„ìš© ì •ë³´ ì´ ë°°í¬ëŠ” ìƒë‹¹í•œ ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆëŠ” GPU ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ìì„¸í•œ ë¹„ìš© ì¶”ì •ì€ ì´ ê°€ì´ë“œ ëì˜ ë¹„ìš© ê³ ë ¤ ì‚¬í•­ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤. ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•ŒëŠ” í•­ìƒ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ì‹­ì‹œì˜¤.  ì‹œìŠ¤í…œ ìš”êµ¬ ì‚¬í•­: AWS CLI ì•¡ì„¸ìŠ¤ê°€ ìˆëŠ” ëª¨ë“  Linux/macOS ì‹œìŠ¤í…œ  ë‹¤ìŒ ë„êµ¬ë¥¼ ì„¤ì¹˜í•˜ì‹­ì‹œì˜¤:  AWS CLI: ì ì ˆí•œ ê¶Œí•œìœ¼ë¡œ êµ¬ì„±ë¨ (ì„¤ì¹˜ ê°€ì´ë“œ)kubectl: Kubernetes ëª…ë ¹ì¤„ ë„êµ¬ (ì„¤ì¹˜ ê°€ì´ë“œ)helm: Kubernetes íŒ¨í‚¤ì§€ ê´€ë¦¬ì (ì„¤ì¹˜ ê°€ì´ë“œ)terraform: Infrastructure as code ë„êµ¬ (ì„¤ì¹˜ ê°€ì´ë“œ)git: ë²„ì „ ì œì–´ (ì„¤ì¹˜ ê°€ì´ë“œ)  ","version":"Next","tagName":"h2"},{"title":"í•„ìˆ˜ API í† í°â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#í•„ìˆ˜-api-í† í°","content":" NGC API í† í°: NVIDIA NIM ì»¨í…Œì´ë„ˆ ë° AI Foundation ëª¨ë¸ì— ì•¡ì„¸ìŠ¤í•˜ëŠ” ë° í•„ìš” ë¨¼ì € ë‹¤ìŒ ì˜µì…˜ ì¤‘ í•˜ë‚˜ë¥¼ í†µí•´ ê°€ì…í•˜ì‹­ì‹œì˜¤ (API í‚¤ëŠ” ì´ëŸ¬í•œ ê³„ì • ì¤‘ í•˜ë‚˜ê°€ ìˆì–´ì•¼ë§Œ ì‘ë™í•©ë‹ˆë‹¤): ì˜µì…˜ 1 - NVIDIA Developer Program (ë¹ ë¥¸ ì‹œì‘): ì—¬ê¸°ì—ì„œ ê°€ì…POC ë° ê°œë°œ ì›Œí¬ë¡œë“œìš© ë¬´ë£Œ ê³„ì •í…ŒìŠ¤íŠ¸ ë° í‰ê°€ì— ì´ìƒì  ì˜µì…˜ 2 - NVIDIA AI Enterprise (í”„ë¡œë•ì…˜): AWS Marketplaceë¥¼ í†µí•´ êµ¬ë…ì „ì²´ ì§€ì› ë° SLAê°€ í¬í•¨ëœ ì—”í„°í”„ë¼ì´ì¦ˆ ë¼ì´ì„ ìŠ¤í”„ë¡œë•ì…˜ ë°°í¬ì— í•„ìš” ê·¸ëŸ° ë‹¤ìŒ API í‚¤ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤: ì˜µì…˜ 1 ë˜ëŠ” 2ë¥¼ í†µí•´ ê°€ì…í•œ í›„ NGC Personal Keysì—ì„œ API í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ì´ í‚¤ë¥¼ ì˜ ë³´ê´€í•˜ì‹­ì‹œì˜¤ - ë°°í¬ ì‹œ í•„ìš”í•©ë‹ˆë‹¤ Tavily API í‚¤: AI-Q Research Assistantì— ì„ íƒ ì‚¬í•­ AI-Qì—ì„œ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”AI-QëŠ” ì´ í‚¤ ì—†ì´ë„ RAG ì „ìš© ëª¨ë“œë¡œ ì‘ë™ ê°€ëŠ¥Enterprise RAG ì „ìš© ë°°í¬ì—ëŠ” í•„ìš” ì—†ìŒTavilyì—ì„œ ê³„ì • ìƒì„±ëŒ€ì‹œë³´ë“œì—ì„œ API í‚¤ ìƒì„±ì´ í‚¤ë¥¼ ì˜ ë³´ê´€í•˜ì‹­ì‹œì˜¤ - AI-Qì—ì„œ ì›¹ ê²€ìƒ‰ì„ ì›í•˜ë©´ ë°°í¬ ì‹œ í•„ìš”í•©ë‹ˆë‹¤  ","version":"Next","tagName":"h3"},{"title":"GPU ì¸ìŠ¤í„´ìŠ¤ ì•¡ì„¸ìŠ¤â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#gpu-ì¸ìŠ¤í„´ìŠ¤-ì•¡ì„¸ìŠ¤","content":" AWS ê³„ì •ì´ GPU ì¸ìŠ¤í„´ìŠ¤ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” Karpenter NodePoolì„ í†µí•´ ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ì œí’ˆêµ°ì„ ì§€ì›í•©ë‹ˆë‹¤:  ì§€ì›ë˜ëŠ” GPU ì¸ìŠ¤í„´ìŠ¤ ì œí’ˆêµ°:  ì¸ìŠ¤í„´ìŠ¤ ì œí’ˆêµ°\tGPU ìœ í˜•\tì„±ëŠ¥ í”„ë¡œíŒŒì¼\tì‚¬ìš© ì‚¬ë¡€G5 (ê¸°ë³¸)\tNVIDIA A10G\të¹„ìš© íš¨ìœ¨ì , 24GB VRAM\tì¼ë°˜ ì›Œí¬ë¡œë“œ, ê°œë°œ G6e\tNVIDIA L40S\tê· í˜• ì¡íŒ, 48GB VRAM\tê³ ë©”ëª¨ë¦¬ ëª¨ë¸ P4d/P4de\tNVIDIA A100\tê³ ì„±ëŠ¥, 40/80GB VRAM\tëŒ€ê·œëª¨ ë°°í¬ P5/P5e/P5en\tNVIDIA H100\tì´ˆê³ ì„±ëŠ¥, 80GB VRAM\tìµœëŒ€ ì„±ëŠ¥  ì°¸ê³ : G5 ì¸ìŠ¤í„´ìŠ¤ëŠ” ì ‘ê·¼ ê°€ëŠ¥í•œ ì‹œì‘ì ì„ ì œê³µí•˜ê¸° ìœ„í•´ Helm ê°’ì— ë¯¸ë¦¬ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Helm ê°’ íŒŒì¼ì˜ nodeSelectorë¥¼ í¸ì§‘í•˜ì—¬ P4/P5/G6e ì¸ìŠ¤í„´ìŠ¤ë¡œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ - ì¸í”„ë¼ ë³€ê²½ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.  GPU ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì‚¬ìš©ì ì •ì˜ (ì„ íƒ ì‚¬í•­) ğŸ‘ˆ  ","version":"Next","tagName":"h3"},{"title":"ì‹œì‘í•˜ê¸°â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì‹œì‘í•˜ê¸°","content":" ì‹œì‘í•˜ë ¤ë©´ ì €ì¥ì†Œë¥¼ í´ë¡ í•˜ì‹­ì‹œì˜¤:  git clone https://github.com/awslabs/ai-on-eks.git cd ai-on-eks   ","version":"Next","tagName":"h2"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ë°°í¬","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” ë‘ ê°€ì§€ ë°°í¬ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤:  ì˜µì…˜ A: ìë™í™”ëœ ë°°í¬ (ê¶Œì¥) ğŸ‘ˆ  ì˜µì…˜ B: ìˆ˜ë™ ë°°í¬ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"ì„œë¹„ìŠ¤ ì•¡ì„¸ìŠ¤â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì„œë¹„ìŠ¤-ì•¡ì„¸ìŠ¤","content":" ë°°í¬ê°€ ì™„ë£Œë˜ë©´ í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ë¡œ ì„œë¹„ìŠ¤ì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤.  í¬íŠ¸ í¬ì›Œë”© ëª…ë ¹ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‚¬ìš©â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì• í”Œë¦¬ì¼€ì´ì…˜-ì‚¬ìš©","content":" RAG í”„ë¡ íŠ¸ì—”ë“œ (http://localhost:3001):  UIë¥¼ í†µí•´ ì§ì ‘ ë¬¸ì„œ ì—…ë¡œë“œìˆ˜ì§‘ëœ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸ë‹¤ì¤‘ í„´ ëŒ€í™” í…ŒìŠ¤íŠ¸ì¸ìš© ë° ì†ŒìŠ¤ ë³´ê¸°  AI-Q Research Assistant (http://localhost:3000):  ì—°êµ¬ ì£¼ì œ ë° ì§ˆë¬¸ ì •ì˜ì—…ë¡œë“œëœ ë¬¸ì„œì™€ ì›¹ ê²€ìƒ‰ ëª¨ë‘ í™œìš©ìë™ìœ¼ë¡œ í¬ê´„ì ì¸ ì—°êµ¬ ë³´ê³ ì„œ ìƒì„±ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸°  Ingestor API (http://localhost:8082/docs):  í”„ë¡œê·¸ë˜ë§¤í‹± ë¬¸ì„œ ìˆ˜ì§‘ë°°ì¹˜ ì—…ë¡œë“œ ê¸°ëŠ¥ì»¬ë ‰ì…˜ ê´€ë¦¬OpenAPI ë¬¸ì„œ ë³´ê¸°  ","version":"Next","tagName":"h3"},{"title":"ë°ì´í„° ìˆ˜ì§‘â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ë°ì´í„°-ìˆ˜ì§‘","content":" RAG(ë° ì„ íƒì ìœ¼ë¡œ AI-Q)ë¥¼ ë°°í¬í•œ í›„ OpenSearch ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì§€ì›ë˜ëŠ” íŒŒì¼ ìœ í˜•â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì§€ì›ë˜ëŠ”-íŒŒì¼-ìœ í˜•","content":" RAG íŒŒì´í”„ë¼ì¸ì€ ë‹¤ìŒì„ í¬í•¨í•œ ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ìˆ˜ì§‘ì„ ì§€ì›í•©ë‹ˆë‹¤:  PDF ë¬¸ì„œí…ìŠ¤íŠ¸ íŒŒì¼ (.txt, .md)ì´ë¯¸ì§€ (.jpg, .png)Office ë¬¸ì„œ (.docx, .pptx)HTML íŒŒì¼  NeMo Retriever ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ëŠ” ì´ëŸ¬í•œ ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸, í‘œ, ì°¨íŠ¸ ë° ì´ë¯¸ì§€ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ìˆ˜ì§‘ ë°©ë²•â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ìˆ˜ì§‘-ë°©ë²•","content":" ë¬¸ì„œë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë‘ ê°€ì§€ ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤:  ë°©ë²• 1: UI ì—…ë¡œë“œ (í…ŒìŠ¤íŠ¸/ì†Œê·œëª¨ ë°ì´í„°ì…‹)â€‹  í”„ë¡ íŠ¸ì—”ë“œ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ì§ì ‘ ê°œë³„ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤:  RAG í”„ë¡ íŠ¸ì—”ë“œ (http://localhost:3001) - ê°œë³„ ë¬¸ì„œ í…ŒìŠ¤íŠ¸ì— ì´ìƒì AIRA í”„ë¡ íŠ¸ì—”ë“œ (http://localhost:3000) - ì—°êµ¬ ì‘ì—…ìš© ë¬¸ì„œ ì—…ë¡œë“œ  ì´ ë°©ë²•ì€ ë‹¤ìŒì— ì í•©í•©ë‹ˆë‹¤:  RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ì†Œê·œëª¨ ë¬¸ì„œ ì»¬ë ‰ì…˜ (100ê°œ ë¯¸ë§Œ)ë¹ ë¥¸ ì‹¤í—˜ì„ì‹œ ë¬¸ì„œ ì—…ë¡œë“œ  ë°©ë²• 2: S3 ë°°ì¹˜ ìˆ˜ì§‘ (í”„ë¡œë•ì…˜/ëŒ€ê·œëª¨ ë°ì´í„°ì…‹)â€‹  S3 ë°°ì¹˜ ìˆ˜ì§‘ ëª…ë ¹ ğŸ‘ˆ  ","version":"Next","tagName":"h3"},{"title":"ìˆ˜ì§‘ í™•ì¸â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ìˆ˜ì§‘-í™•ì¸","content":" ìˆ˜ì§‘ í›„ ë¬¸ì„œê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤:  RAG í”„ë¡ íŠ¸ì—”ë“œë¥¼ í†µí•´: http://localhost:3001 ë¡œ ì´ë™í•˜ì—¬ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸Ingestor APIë¥¼ í†µí•´: http://localhost:8082/docsì—ì„œ ì»¬ë ‰ì…˜ í†µê³„ í™•ì¸OpenSearchë¥¼ í†µí•´: AWS ì½˜ì†”ì„ ì‚¬ìš©í•˜ì—¬ OpenSearch ì»¬ë ‰ì…˜ì— ì§ì ‘ ì¿¼ë¦¬  ","version":"Next","tagName":"h3"},{"title":"ê´€ì¸¡ì„±â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ê´€ì¸¡ì„±","content":" RAG ë° AI-Q ë°°í¬ì—ëŠ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§, ìš”ì²­ ì¶”ì  ë° ë©”íŠ¸ë¦­ ë³´ê¸°ë¥¼ ìœ„í•œ ë‚´ì¥ ê´€ì¸¡ì„± ë„êµ¬ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì•¡ì„¸ìŠ¤â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ëª¨ë‹ˆí„°ë§-ì„œë¹„ìŠ¤-ì•¡ì„¸ìŠ¤","content":" ìë™í™”ëœ ì ‘ê·¼ ë°©ì‹ (ê¶Œì¥):  blueprints ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ê³  í¬íŠ¸ í¬ì›Œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤:  cd ../../blueprints/inference/nvidia-deep-research   ./app.sh port start observability   ì´ê²ƒì€ ìë™ìœ¼ë¡œ í¬íŠ¸ í¬ì›Œë”©í•©ë‹ˆë‹¤:  Zipkin: http://localhost:9411 - RAG ë¶„ì‚° ì¶”ì Grafana: http://localhost:8080 - RAG ë©”íŠ¸ë¦­ ë° ëŒ€ì‹œë³´ë“œPhoenix: http://localhost:6006 - AI-Q ì›Œí¬í”Œë¡œìš° ì¶”ì  (ë°°í¬ëœ ê²½ìš°)  ìƒíƒœ í™•ì¸:  ./app.sh port status   ê´€ì¸¡ì„± í¬íŠ¸ í¬ì›Œë”© ì¤‘ì§€:  ./app.sh port stop observability   ìˆ˜ë™ kubectl ëª…ë ¹ ğŸ‘ˆ  ","version":"Next","tagName":"h3"},{"title":"ëª¨ë‹ˆí„°ë§ UIâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ëª¨ë‹ˆí„°ë§-ui","content":" í¬íŠ¸ í¬ì›Œë”©ì´ í™œì„±í™”ë˜ë©´:  Zipkin UI (RAG ì¶”ì ): http://localhost:9411 ì—”ë“œíˆ¬ì—”ë“œ ìš”ì²­ ì¶”ì  ë³´ê¸°ì§€ì—° ì‹œê°„ ë³‘ëª© í˜„ìƒ ë¶„ì„ë‹¤ì¤‘ ì„œë¹„ìŠ¤ ìƒí˜¸ ì‘ìš© ë””ë²„ê·¸ Grafana UI (RAG ë©”íŠ¸ë¦­): http://localhost:8080 ê¸°ë³¸ ìê²© ì¦ëª…: admin/adminRAG ë©”íŠ¸ë¦­ì„ ìœ„í•œ ì‚¬ì „ êµ¬ì¶•ëœ ëŒ€ì‹œë³´ë“œGPU ì‚¬ìš©ë¥  ë° ì²˜ë¦¬ëŸ‰ ëª¨ë‹ˆí„°ë§ Phoenix UI (AI-Q ì¶”ì ): http://localhost:6006 ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì‹œê°í™”LLM í˜¸ì¶œ ì¶”ì ì—°êµ¬ ë³´ê³ ì„œ ìƒì„± ë¶„ì„  ì°¸ê³ : ì´ëŸ¬í•œ ê´€ì¸¡ì„± ë„êµ¬ ì‚¬ìš©ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ëŠ” ë‹¤ìŒì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤: Zipkinì—ì„œ ì¶”ì  ë³´ê¸°Grafana ëŒ€ì‹œë³´ë“œì—ì„œ ë©”íŠ¸ë¦­ ë³´ê¸°  ëŒ€ì•ˆ: ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ë¥¼ ê³µê°œì ìœ¼ë¡œ ë…¸ì¶œí•´ì•¼ í•˜ëŠ” ê²½ìš° ì ì ˆí•œ ì¸ì¦ ë° ë³´ì•ˆ ì œì–´ê°€ ìˆëŠ” Ingress ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì •ë¦¬","content":" ","version":"Next","tagName":"h2"},{"title":"ì• í”Œë¦¬ì¼€ì´ì…˜ë§Œ ì œê±°â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì• í”Œë¦¬ì¼€ì´ì…˜ë§Œ-ì œê±°","content":" ì¸í”„ë¼ë¥¼ ìœ ì§€í•˜ë©´ì„œ RAG ë° AI-Q ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì œê±°í•˜ë ¤ë©´:  ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ê¶Œì¥):  cd ../../blueprints/inference/nvidia-deep-research   ./app.sh cleanup   ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:  ëª¨ë“  í¬íŠ¸ í¬ì›Œë”© í”„ë¡œì„¸ìŠ¤ ì¤‘ì§€AIRA ë° RAG Helm ë¦´ë¦¬ìŠ¤ ì œê±°ë¡œì»¬ í¬íŠ¸ í¬ì›Œë”© PID íŒŒì¼ ì œê±°  ìˆ˜ë™ ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ë¦¬:  # blueprints ë””ë ‰í† ë¦¬ë¡œ ì´ë™ cd ../../blueprints/inference/nvidia-deep-research # í¬íŠ¸ í¬ì›Œë”© ì¤‘ì§€ ./app.sh port stop all # AIRA ì œê±° (ë°°í¬ëœ ê²½ìš°) helm uninstall aira -n nv-aira # RAG ì œê±° helm uninstall rag -n rag   (ì„ íƒ ì‚¬í•­) ë°°í¬ ì¤‘ì— ìƒì„±ëœ ì„ì‹œ íŒŒì¼ ì •ë¦¬:  rm /tmp/.port-forward-*.pid   ì°¸ê³ : ì´ê²ƒì€ ì• í”Œë¦¬ì¼€ì´ì…˜ë§Œ ì œê±°í•©ë‹ˆë‹¤. EKS í´ëŸ¬ìŠ¤í„°ì™€ ì¸í”„ë¼ëŠ” ê³„ì† ì‹¤í–‰ë©ë‹ˆë‹¤. GPU ë…¸ë“œëŠ” 5-10ë¶„ ë‚´ì— Karpenterì— ì˜í•´ ì¢…ë£Œë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì¸í”„ë¼ ì •ë¦¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì¸í”„ë¼-ì •ë¦¬","content":" ì „ì²´ EKS í´ëŸ¬ìŠ¤í„° ë° ëª¨ë“  ì¸í”„ë¼ êµ¬ì„± ìš”ì†Œë¥¼ ì œê±°í•˜ë ¤ë©´:  # infra ë””ë ‰í† ë¦¬ë¡œ ì´ë™ cd ../../../infra/nvidia-deep-research # ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ./cleanup.sh   ê²½ê³ : ì´ê²ƒì€ ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œí•©ë‹ˆë‹¤: EKS í´ëŸ¬ìŠ¤í„° ë° ëª¨ë“  ì›Œí¬ë¡œë“œOpenSearch Serverless ì»¬ë ‰ì…˜ ë° ë°ì´í„°VPC ë° ë„¤íŠ¸ì›Œí‚¹ ë¦¬ì†ŒìŠ¤ëª¨ë“  ê´€ë ¨ AWS ë¦¬ì†ŒìŠ¤ ì§„í–‰í•˜ê¸° ì „ì— ì¤‘ìš”í•œ ë°ì´í„°ë¥¼ ë°±ì—…í•˜ì‹­ì‹œì˜¤.  ì†Œìš” ì‹œê°„: ì „ì²´ í•´ì œì— ~10-15ë¶„  ","version":"Next","tagName":"h3"},{"title":"ë¹„ìš© ê³ ë ¤ ì‚¬í•­â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ë¹„ìš©-ê³ ë ¤-ì‚¬í•­","content":" ì´ ë°°í¬ì˜ ì˜ˆìƒ ë¹„ìš© ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"ì°¸ì¡°â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ì°¸ì¡°","content":" ","version":"Next","tagName":"h2"},{"title":"ê³µì‹ NVIDIA ë¦¬ì†ŒìŠ¤â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ê³µì‹-nvidia-ë¦¬ì†ŒìŠ¤","content":" ë¬¸ì„œ:  NVIDIA AI-Q Research Assistant GitHub: ê³µì‹ AI-Q ë¸”ë£¨í”„ë¦°íŠ¸ ì €ì¥ì†ŒNVIDIA AI-Q on AI Foundation: AI-Q ë¸”ë£¨í”„ë¦°íŠ¸ ì¹´ë“œ ë° í˜¸ìŠ¤íŒ… ë²„ì „NVIDIA RAG Blueprint: ì™„ì „í•œ RAG í”Œë«í¼ ë¬¸ì„œNVIDIA NIM Documentation: NIM ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì°¸ì¡°NVIDIA AI Enterprise: ì—”í„°í”„ë¼ì´ì¦ˆ AI í”Œë«í¼  ëª¨ë¸:  Llama-3.3-Nemotron-Super-49B-v1.5: ê³ ê¸‰ ì¶”ë¡  ëª¨ë¸ (490ì–µ íŒŒë¼ë¯¸í„°)Llama-3.3-70B-Instruct: ëª…ë ¹ì–´ ë”°ë¥´ê¸° ëª¨ë¸  ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë° Helm ì°¨íŠ¸:  NVIDIA NGC Catalog: ê³µì‹ ì»¨í…Œì´ë„ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬RAG Blueprint Helm Chart: Kubernetes ë°°í¬NVIDIA NIM Containers: ìµœì í™”ëœ ì¶”ë¡  ì»¨í…Œì´ë„ˆ  ","version":"Next","tagName":"h3"},{"title":"AI-on-EKS ë¸”ë£¨í”„ë¦°íŠ¸ ë¦¬ì†ŒìŠ¤â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ai-on-eks-ë¸”ë£¨í”„ë¦°íŠ¸-ë¦¬ì†ŒìŠ¤","content":" AI-on-EKS ë¸”ë£¨í”„ë¦°íŠ¸ ë¦¬ì†ŒìŠ¤:  AI-on-EKS Repository: ë©”ì¸ ë¸”ë£¨í”„ë¦°íŠ¸ ì €ì¥ì†ŒInfrastructure &amp; Deployment Code: Karpenterì™€ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í¬í•¨í•œ Terraform ìë™í™”Usage Guide: ë°°í¬ í›„ ì‚¬ìš©, ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ì¸¡ì„±  ë¬¸ì„œ:  Infrastructure &amp; Deployment Guide: ë‹¨ê³„ë³„ ì¸í”„ë¼ ë° ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬Usage Guide: ì„œë¹„ìŠ¤ ì•¡ì„¸ìŠ¤, ë°ì´í„° ìˆ˜ì§‘, ëª¨ë‹ˆí„°ë§OpenSearch Integration: Pod Identity ì¸ì¦ ì„¤ì •Karpenter Configuration: P4/P5 GPU ì§€ì›  ","version":"Next","tagName":"h3"},{"title":"ê´€ë ¨ ê¸°ìˆ â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ê´€ë ¨-ê¸°ìˆ ","content":" Kubernetes ë° AWS:  Amazon EKS: ê´€ë¦¬í˜• Kubernetes ì„œë¹„ìŠ¤Karpenter: Kubernetes ë…¸ë“œ ì˜¤í† ìŠ¤ì¼€ì¼ë§OpenSearch Serverless: ê´€ë¦¬í˜• ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤EKS Pod Identity: Podìš© IAM ì¸ì¦  AI/ML ë„êµ¬:  NVIDIA DCGM: GPU ëª¨ë‹ˆí„°ë§Prometheus: ë©”íŠ¸ë¦­ ìˆ˜ì§‘Grafana: ì‹œê°í™” ëŒ€ì‹œë³´ë“œ  ","version":"Next","tagName":"h3"},{"title":"ë‹¤ìŒ ë‹¨ê³„â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Enterprise RAG ë° AI-Q Research Assistant","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-deep-research#ë‹¤ìŒ-ë‹¨ê³„","content":" ê¸°ëŠ¥ íƒìƒ‰: ë‹¤ì–‘í•œ íŒŒì¼ ìœ í˜•ìœ¼ë¡œ ë©€í‹°ëª¨ë‹¬ ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ë°°í¬ í™•ì¥: ë‹¤ì¤‘ ë¦¬ì „ ë˜ëŠ” ë‹¤ì¤‘ í´ëŸ¬ìŠ¤í„° ì„¤ì • êµ¬ì„±ì• í”Œë¦¬ì¼€ì´ì…˜ í†µí•©: ì• í”Œë¦¬ì¼€ì´ì…˜ì„ RAG API ì—”ë“œí¬ì¸íŠ¸ì— ì—°ê²°ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§: ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•´ Grafana ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ì‚¬ìš©ì ì •ì˜ ëª¨ë¸: ìì²´ ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ë¡œ êµì²´ë³´ì•ˆ ê°•í™”: ì¸ì¦, ì†ë„ ì œí•œ ë° ì¬í•´ ë³µêµ¬ ì¶”ê°€    ì´ ë°°í¬ëŠ” NVIDIA Enterprise RAG Blueprint ë° NVIDIA AI-Q Research Assistantë¥¼ Karpenter ìë™ í™•ì¥, OpenSearch Serverless í†µí•© ë° ì›í™œí•œ AWS ì„œë¹„ìŠ¤ í†µí•©ì„ í¬í•¨í•œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ê¸°ëŠ¥ê³¼ í•¨ê»˜ Amazon EKSì— ì œê³µí•©ë‹ˆë‹¤. ","version":"Next","tagName":"h2"},{"title":"Llama 4 Inference with vLLM on Amazon EKS","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm","content":"","keywords":"","version":"Next"},{"title":"Understanding GPU Memory Requirementsâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#understanding-gpu-memory-requirements","content":" Deploying MoE models requires loading all expert weights into GPU memory, even though only a subset is active per token. This means total parameter count determines memory requirements, not active parameters.  Model\tTotal Params\tExperts\tBF16 Memory\tFP8 Memory\tRecommended GPU InstanceScout 17B-16E\t~109B\t16\t~220 GiB\t~110 GiB\tp4d.24xlarge (8x A100 40GB = 320 GiB) Maverick 17B-128E\t~400B\t128\t~800 GiB\t~400 GiB\tp5.48xlarge (8x H100 80GB = 640 GiB, FP8 required)  ê²½ê³  Maverick on GPU requires FP8 quantization. The BF16 model weights (~800 GiB) exceed the p5.48xlarge total GPU memory (640 GiB). Use the FP8-quantized variant (meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8) which fits within 640 GiB. For running Maverick without quantization, consider Trainium2 deployment which provides 1.5 TiB HBM memory.  Deploying the Inference-Ready EKS Cluster ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"Deploy Llama 4 Scout (17B-16E)â€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#deploy-llama-4-scout-17b-16e","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1: Create Hugging Face Token Secretâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#step-1-create-hugging-face-token-secret","content":" Create a Hugging Face access token and store it as a Kubernetes secret:  kubectl create secret generic hf-token --from-literal=token=&lt;your-huggingface-token&gt;   ","version":"Next","tagName":"h3"},{"title":"Step 2: Deploy with Helmâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#step-2-deploy-with-helm","content":" helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update helm install llama4-scout ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-4-scout-17b-lws-vllm.yaml   ì •ë³´ The Scout model uses LeaderWorkerSet (LWS) for multi-node tensor parallelism across 8 GPUs. Model download and initialization may take several minutes on first deployment.  ","version":"Next","tagName":"h3"},{"title":"Step 3: Verify Deploymentâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#step-3-verify-deployment","content":" # Check pod status kubectl get pods -l app.kubernetes.io/component=llama-4-scout # Watch logs for model loading progress kubectl logs -l app.kubernetes.io/component=llama-4-scout -f   Wait until you see the vLLM server ready message in the logs:  INFO: Uvicorn running on http://0.0.0.0:8000   ","version":"Next","tagName":"h3"},{"title":"Deploy Llama 4 Maverick (17B-128E) on GPUâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#deploy-llama-4-maverick-17b-128e-on-gpu","content":" Maverick requires FP8 quantization on GPU due to its large model size (~800 GiB BF16).  helm install llama4-maverick ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-4-maverick-17b-lws-vllm.yaml   ê²½ê³  Maverick deployment requires p5.48xlarge instances (8x H100 80GB). Ensure your AWS account has sufficient service quota for P5 instances in your region.  ","version":"Next","tagName":"h2"},{"title":"Test the Modelâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#test-the-model","content":" ","version":"Next","tagName":"h2"},{"title":"Port Forwardâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#port-forward","content":" kubectl port-forward svc/llama-4-scout 8000:8000   ","version":"Next","tagName":"h3"},{"title":"Chat Completion Requestâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#chat-completion-request","content":" curl -X POST http://localhost:8000/v1/chat/completions \\ -H &quot;Content-Type: application/json&quot; \\ -d '{ &quot;model&quot;: &quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;, &quot;messages&quot;: [ {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What are the key differences between Mixture of Experts and dense transformer models?&quot;} ], &quot;max_tokens&quot;: 512, &quot;temperature&quot;: 0.7 }'   ","version":"Next","tagName":"h3"},{"title":"List Available Modelsâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#list-available-models","content":" curl http://localhost:8000/v1/models | python3 -m json.tool   ","version":"Next","tagName":"h3"},{"title":"Multimodal Request (Text + Image)â€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#multimodal-request-text--image","content":" Llama 4 supports vision inputs. You can send image URLs alongside text:  curl -X POST http://localhost:8000/v1/chat/completions \\ -H &quot;Content-Type: application/json&quot; \\ -d '{ &quot;model&quot;: &quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;, &quot;messages&quot;: [ { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [ {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What do you see in this image?&quot;}, {&quot;type&quot;: &quot;image_url&quot;, &quot;image_url&quot;: {&quot;url&quot;: &quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg&quot;}} ] } ], &quot;max_tokens&quot;: 256 }'   ","version":"Next","tagName":"h3"},{"title":"Deploy Open WebUIâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#deploy-open-webui","content":" Open WebUI provides a ChatGPT-style interface for interacting with the model.  The inference-ready cluster includes Open WebUI. To access it:  kubectl port-forward svc/open-webui 8080:80 -n open-webui   Open http://localhost:8080 in your browser and register a new account. The model will appear in the model selector.  ","version":"Next","tagName":"h2"},{"title":"Monitoringâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#monitoring","content":" ","version":"Next","tagName":"h2"},{"title":"Check Inference Logsâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#check-inference-logs","content":" # View vLLM logs for throughput and latency metrics kubectl logs -l app.kubernetes.io/component=llama-4-scout --tail=100 # Watch for token generation throughput kubectl logs -l app.kubernetes.io/component=llama-4-scout -f | grep &quot;tokens/s&quot;   ","version":"Next","tagName":"h3"},{"title":"GPU Utilizationâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#gpu-utilization","content":" If the observability stack is enabled on your cluster, access Grafana for GPU metrics:  kubectl port-forward svc/kube-prometheus-stack-grafana 3000:80 -n monitoring   ","version":"Next","tagName":"h3"},{"title":"Cleanupâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on Amazon EKS","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/llama4-vllm#cleanup","content":" Remove the model deployment:  # Remove Scout helm uninstall llama4-scout # Remove Maverick (if deployed) helm uninstall llama4-maverick   To destroy the entire cluster infrastructure:  cd ai-on-eks/infra/solutions/inference-ready-cluster ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3","content":"","keywords":"","version":"Next"},{"title":"NVIDIA NIMì´ë€?â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#nvidia-nimì´ë€","content":" NVIDIA NIMì€ IT ë° DevOps íŒ€ì´ ìì²´ ê´€ë¦¬ í™˜ê²½ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì‰½ê²Œ ìì²´ í˜¸ìŠ¤íŒ…í•  ìˆ˜ ìˆê²Œ í•˜ë©´ì„œ, ê°œë°œìì—ê²ŒëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ í˜ì‹ í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ì½”íŒŒì¼ëŸ¿, ì±—ë´‡ ë° AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” ì—…ê³„ í‘œì¤€ APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. NVIDIAì˜ ìµœì²¨ë‹¨ GPU ê°€ì†ê³¼ í™•ì¥ ê°€ëŠ¥í•œ ë°°í¬ë¥¼ í™œìš©í•˜ì—¬ NIMì€ ë¹„êµí•  ìˆ˜ ì—†ëŠ” ì„±ëŠ¥ìœ¼ë¡œ ì¶”ë¡ ì— ëŒ€í•œ ê°€ì¥ ë¹ ë¥¸ ê²½ë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì™œ NIMì¸ê°€?â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#ì™œ-nimì¸ê°€","content":" NIMì€ ì‹¤í–‰ ì—”ì§„ ë° ëŸ°íƒ€ì„ ìš´ì˜ê³¼ ê°™ì€ ëª¨ë¸ ì¶”ë¡  ë‚´ë¶€ë¥¼ ì¶”ìƒí™”í•©ë‹ˆë‹¤. ë˜í•œ TRT-LLM, vLLM ë˜ëŠ” ê¸°íƒ€ ì˜µì…˜ ì¤‘ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ì˜µì…˜ì…ë‹ˆë‹¤.  NIMì€ ëª¨ë¸/ëª¨ë¸ íŒ¨ë°€ë¦¬ë³„ë¡œ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¡œ íŒ¨í‚¤ì§•ë©ë‹ˆë‹¤. ê° NIM ì»¨í…Œì´ë„ˆëŠ” meta/llama3-8b-instructì™€ ê°™ì€ ëª¨ë¸ê³¼ í•¨ê»˜ ì œê³µë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì»¨í…Œì´ë„ˆì—ëŠ” ì¶©ë¶„í•œ GPU ë©”ëª¨ë¦¬ê°€ ìˆëŠ” ëª¨ë“  NVIDIA GPUì—ì„œ ì‹¤í–‰ë˜ëŠ” ëŸ°íƒ€ì„ì´ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ, ì¼ë¶€ ëª¨ë¸/GPU ì¡°í•©ì€ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. NIMì€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ ìºì‹œë¥¼ í™œìš©í•˜ì—¬ NVIDIA NGC Catalogì—ì„œ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Amazon EKSì—ì„œì˜ ì´ ë°°í¬ íŒ¨í„´ ê°œìš”â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#amazon-eksì—ì„œì˜-ì´-ë°°í¬-íŒ¨í„´-ê°œìš”","content":" ì´ íŒ¨í„´ì€ NVIDIA NIM, Amazon Elastic Kubernetes Service(EKS) ë° ë‹¤ì–‘í•œ AWS ì„œë¹„ìŠ¤ì˜ ê¸°ëŠ¥ì„ ê²°í•©í•˜ì—¬ ê³ ì„±ëŠ¥ ë° ë¹„ìš© ìµœì í™”ëœ ëª¨ë¸ ì„œë¹™ ì¸í”„ë¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  NVIDIA NIM ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€: NVIDIA NIMì€ ì»¨í…Œì´ë„ˆí™”ëœ í™˜ê²½ì—ì„œ Llama3ì™€ ê°™ì€ LLM ëª¨ë¸ì„ í˜¸ìŠ¤íŒ…í•˜ëŠ” ê°„ì†Œí™”ëœ ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê³ ê°ì€ ê¸°ì¡´ ì¸í”„ë¼ì™€ì˜ ì›í™œí•œ í†µí•©ì„ ë³´ì¥í•˜ë©´ì„œ í”„ë¼ì´ë¹— ëª¨ë¸ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. NIM ë°°í¬ì— ëŒ€í•œ ìì„¸í•œ ì„¤ì • ë‹¨ê³„ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤. ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ì¤€ ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ Karpenter: ì˜¤í”ˆì†ŒìŠ¤ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ í”„ë¡œì íŠ¸ì¸ KarpenterëŠ” Amazon EKS í´ëŸ¬ìŠ¤í„°ì˜ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ì¤€ì—ì„œ ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ìŠ¤ì¼€ì¼ë§ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ ì„œë¹™ ì¸í”„ë¼ê°€ ë™ì  ì›Œí¬ë¡œë“œ ìš”êµ¬ì— ì ì‘í•˜ì—¬ ë¦¬ì†ŒìŠ¤ í™œìš© ë° ë¹„ìš© íš¨ìœ¨ì„±ì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤: LLMì´ ìƒíƒœ ë¹„ì €ì¥ì´ë¼ëŠ” ì ì„ ê³ ë ¤í•˜ì—¬ ê³ ê°ì€ ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ë¹„ìš©ì„ í¬ê²Œ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Amazon Elastic File System(EFS): Amazon EFSëŠ” Amazon EKSì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í™•ì¥ ê°€ëŠ¥í•˜ê³  íƒ„ë ¥ì ì¸ íŒŒì¼ ìŠ¤í† ë¦¬ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì—¬ëŸ¬ íŒŒë“œê°€ ë™ì‹œì— ë™ì¼í•œ íŒŒì¼ ì‹œìŠ¤í…œì— ì ‘ê·¼í•  ìˆ˜ ìˆì–´ í´ëŸ¬ìŠ¤í„° ì „ì²´ì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸, ë°ì´í„°ì…‹ ë° ê¸°íƒ€ ì˜êµ¬ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê³µìœ í•˜ëŠ” ë° ì´ìƒì ì…ë‹ˆë‹¤. EFSëŠ” íŒŒì¼ì„ ì¶”ê°€í•˜ê³  ì œê±°í•¨ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì¦ê°€í•˜ê³  ì¶•ì†Œë˜ì–´ ìš©ëŸ‰ ê³„íš ë° ê´€ë¦¬ê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤. EKS Blueprintsë¥¼ ì‚¬ìš©í•œ Terraform: ì´ ì†”ë£¨ì…˜ì˜ ë°°í¬ ë° ê´€ë¦¬ë¥¼ ê°„ì†Œí™”í•˜ê¸° ìœ„í•´ Terraformê³¼ EKS Blueprintsë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì´ Infrastructure-as-Code ì ‘ê·¼ ë°©ì‹ì€ ì „ì²´ ìŠ¤íƒì˜ ìë™í™”ëœ í”„ë¡œë¹„ì €ë‹ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì¼ê´€ì„±, ì¬í˜„ì„± ë° íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.  ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†Œë¥¼ ê²°í•©í•˜ì—¬ ì œì•ˆëœ ì†”ë£¨ì…˜ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— ë§ì¶¤í™”ëœ ê°•ë ¥í•˜ê³  ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸ ì„œë¹™ ì¸í”„ë¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤. NVIDIA NIMì˜ ì›í™œí•œ í†µí•©ê³¼ Karpenterë¥¼ í†µí•œ Amazon EKSì˜ í™•ì¥ì„±ìœ¼ë¡œ ê³ ê°ì€ ì¸í”„ë¼ ë¹„ìš©ì„ ìµœì†Œí™”í•˜ë©´ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#ì†”ë£¨ì…˜-ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#ì‚¬ì „-ìš”êµ¬-ì‚¬í•­","content":" NVIDIA NIMì„ ì‹œì‘í•˜ê¸° ì „ì— ë‹¤ìŒ ì‚¬í•­ì´ ì¤€ë¹„ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:  NVIDIA NIM ê³„ì • ì„¤ì • ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ë ¤ë©´ í´ë¦­í•˜ì„¸ìš” NVIDIA AI Enterprise ê³„ì • NVIDIA AI Enterprise ê³„ì •ì— ë“±ë¡í•˜ì„¸ìš”. ê³„ì •ì´ ì—†ë‹¤ë©´ ì´ ë§í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€íŒ ê³„ì •ì— ê°€ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. NGC API í‚¤ NVIDIA AI Enterprise ê³„ì •ì— ë¡œê·¸ì¸í•©ë‹ˆë‹¤ NGC(NVIDIA GPU Cloud) í¬í„¸ë¡œ ì´ë™í•©ë‹ˆë‹¤ ê°œì¸ API í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤: ê³„ì • ì„¤ì •ìœ¼ë¡œ ì´ë™í•˜ê±°ë‚˜ ì§ì ‘ https://org.ngc.nvidia.com/setup/personal-keys ë¡œ ì´ë™í•©ë‹ˆë‹¤&quot;Generate Personal Key&quot;ë¥¼ í´ë¦­í•©ë‹ˆë‹¤&quot;Services Included&quot; ë“œë¡­ë‹¤ìš´ì—ì„œ ìµœì†Œí•œ &quot;NGC Catalog&quot;ê°€ ì„ íƒë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤API í‚¤ë¥¼ ë³µì‚¬í•˜ê³  ì•ˆì „í•˜ê²Œ ì €ì¥í•©ë‹ˆë‹¤. í‚¤ëŠ” nvapi- ì ‘ë‘ì‚¬ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤ NGC API í‚¤ ê²€ì¦ ë° ì´ë¯¸ì§€ í’€ í…ŒìŠ¤íŠ¸ API í‚¤ê°€ ìœ íš¨í•˜ê³  ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´: NGC API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤: export NGC_API_KEY=&lt;your_api_key_here&gt; NVIDIA Container Registryë¡œ Docker ì¸ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤: echo &quot;$NGC_API_KEY&quot; | docker login nvcr.io --username '$oauthtoken' --password-stdin NGCì—ì„œ ì´ë¯¸ì§€ í’€ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤: docker pull nvcr.io/nim/meta/llama3-8b-instruct:latest ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦´ í•„ìš” ì—†ì´, API í‚¤ê°€ ì´ë¯¸ì§€ë¥¼ í’€í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.  ì´ íŠœí† ë¦¬ì–¼ì„ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤  ê´€ë¦¬ìì™€ ë™ë“±í•œ ê¶Œí•œì´ ìˆëŠ” í™œì„± AWS ê³„ì •aws clikubectlTerraform  ","version":"Next","tagName":"h3"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#ë°°í¬","content":" ì €ì¥ì†Œ ë³µì œ  git clone https://github.com/awslabs/ai-on-eks.git   1. NGC API í‚¤ êµ¬ì„±  NVIDIAì—ì„œ NGC API í‚¤ë¥¼ ê²€ìƒ‰í•˜ê³  í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤:  export TF_VAR_ngc_api_key=&lt;replace-with-your-NGC-API-KEY&gt;   2. ì„¤ì¹˜  ì¤‘ìš” ì°¸ê³  ì‚¬í•­: ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ë°°í¬í•˜ê¸° ì „ì— blueprint.tfvars íŒŒì¼ì—ì„œ ë¦¬ì „ì„ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ ë¶ˆì¼ì¹˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë¡œì»¬ ë¦¬ì „ ì„¤ì •ì´ ì§€ì •ëœ ë¦¬ì „ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, export AWS_DEFAULT_REGION=&quot;&lt;REGION&gt;&quot;ì„ ì›í•˜ëŠ” ë¦¬ì „ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”:  ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:  ì •ë³´ ì´ íŒ¨í„´ì€ nvcr.io/nim/meta/llama3-8b-instructë¼ëŠ” ëª¨ë¸ì„ ë°°í¬í•©ë‹ˆë‹¤. blueprint.tfvars íŒŒì¼ì—ì„œ nim_models ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ë” ë§ì€ ëª¨ë¸ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ëª¨ë¸ì„ ë™ì‹œì— ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì£¼ì˜ ì´ëŸ¬í•œ ë³€ìˆ˜ë¥¼ í†µí•´ ì¶”ê°€ ëª¨ë¸ì„ í™œì„±í™”í•˜ê¸° ì „ì— ê° ëª¨ë¸ì— ì¶©ë¶„í•œ GPUë¥¼ ì§€ì •í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ë˜í•œ AWS ê³„ì •ì´ ì¶©ë¶„í•œ GPUì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì´ íŒ¨í„´ì€ Karpenterë¥¼ ì‚¬ìš©í•˜ì—¬ GPU ë…¸ë“œë¥¼ ìŠ¤ì¼€ì¼ë§í•˜ë©°, ê¸°ë³¸ì ìœ¼ë¡œ G5 ì¸ìŠ¤í„´ìŠ¤ë¡œ ì œí•œë©ë‹ˆë‹¤. í•„ìš”í•œ ê²½ìš° Karpenter ë…¸ë“œ í’€ì„ ìˆ˜ì •í•˜ì—¬ p4 ë° p5ì™€ ê°™ì€ ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  cd ai-on-eks/infra/nvidia-triton-server export TF_VAR_enable_nvidia_nim=true export TF_VAR_enable_nvidia_triton_server=false ./install.sh   ì´ í”„ë¡œì„¸ìŠ¤ëŠ” ì™„ë£Œí•˜ëŠ” ë° ì•½ 20ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤.  3. ì„¤ì¹˜ í™•ì¸  ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´ ì¶œë ¥ì—ì„œ configure_kubectl ëª…ë ¹ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ EKS í´ëŸ¬ìŠ¤í„° ì ‘ê·¼ì„ êµ¬ì„±í•©ë‹ˆë‹¤  # EKSë¡œ ì¸ì¦í•˜ê¸° ìœ„í•œ k8s ì„¤ì • íŒŒì¼ ìƒì„± aws eks --region us-west-2 update-kubeconfig --name nvidia-triton-server   ë°°í¬ëœ íŒŒë“œì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤  kubectl get all -n nim   ë‹¤ìŒê³¼ ìœ ì‚¬í•œ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:  ë°°í¬ ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ë ¤ë©´ í´ë¦­í•˜ì„¸ìš” NAME READY STATUS RESTARTS AGE pod/nim-llm-llama3-8b-instruct-0 1/1 Running 0 4h2m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/nim-llm-llama3-8b-instruct ClusterIP 172.20.5.230 &lt;none&gt; 8000/TCP 4h2m service/nim-llm-llama3-8b-instruct-sts ClusterIP None &lt;none&gt; 8000/TCP 4h2m NAME READY AGE statefulset.apps/nim-llm-llama3-8b-instruct 1/1 4h2m NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE horizontalpodautoscaler.autoscaling/nim-llm-llama3-8b-instruct StatefulSet/nim-llm-llama3-8b-instruct 2/5 1 5 1 4h2m   llama3-8b-instruct ëª¨ë¸ì€ nim ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— StatefulSetìœ¼ë¡œ ë°°í¬ë©ë‹ˆë‹¤. ì‹¤í–‰ ì¤‘ì— Karpenterê°€ GPUë¥¼ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤. Karpenterê°€ í”„ë¡œë¹„ì €ë‹í•œ ë…¸ë“œë¥¼ í™•ì¸í•©ë‹ˆë‹¤.  kubectl get node -l type=karpenter -L node.kubernetes.io/instance-type   NAME STATUS ROLES AGE VERSION INSTANCE-TYPE ip-100-64-77-39.us-west-2.compute.internal Ready &lt;none&gt; 4m46s v1.30.0-eks-036c24b g5.2xlarge   4. ë°°í¬ëœ ëª¨ë¸ í™•ì¸  nim ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ëª¨ë“  íŒŒë“œê°€ 1/1 ìƒíƒœë¡œ ì¤€ë¹„ë˜ë©´ ì•„ë˜ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ íŠ¸ë˜í”½ì„ ì²˜ë¦¬í•  ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. í™•ì¸í•˜ë ¤ë©´ kubectlì„ ì‚¬ìš©í•˜ì—¬ port-forwardë¡œ ëª¨ë¸ ì„œë¹™ ì„œë¹„ìŠ¤ë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤.  kubectl port-forward -n nim service/nim-llm-llama3-8b-instruct 8000   ê·¸ëŸ° ë‹¤ìŒ curl ëª…ë ¹ìœ¼ë¡œ ê°„ë‹¨í•œ HTTP ìš”ì²­ì„ í†µí•´ ë°°í¬ëœ ëª¨ë¸ì„ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  curl -X 'POST' \\ &quot;http://localhost:8000/v1/completions&quot; \\ -H 'accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ &quot;model&quot;: &quot;meta/llama3-8b-instruct&quot;, &quot;prompt&quot;: &quot;Once upon a time&quot;, &quot;max_tokens&quot;: 64 }'   ë‹¤ìŒê³¼ ìœ ì‚¬í•œ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤  { &quot;id&quot;: &quot;cmpl-63a0b66aeda1440c8b6ca1ce3583b173&quot;, &quot;object&quot;: &quot;text_completion&quot;, &quot;created&quot;: 1719742336, &quot;model&quot;: &quot;meta/llama3-8b-instruct&quot;, &quot;choices&quot;: [ { &quot;index&quot;: 0, &quot;text&quot;: &quot;, there was a young man named Jack who lived in a small village at the foot of a vast and ancient forest. Jack was a curious and adventurous soul, always eager to explore the world beyond his village. One day, he decided to venture into the forest, hoping to discover its secrets.\\nAs he wandered deeper into&quot;, &quot;logprobs&quot;: null, &quot;finish_reason&quot;: &quot;length&quot;, &quot;stop_reason&quot;: null } ], &quot;usage&quot;: { &quot;prompt_tokens&quot;: 5, &quot;total_tokens&quot;: 69, &quot;completion_tokens&quot;: 64 } }   ","version":"Next","tagName":"h3"},{"title":"NIMìœ¼ë¡œ ë°°í¬ëœ Llama3 ëª¨ë¸ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#nimìœ¼ë¡œ-ë°°í¬ëœ-llama3-ëª¨ë¸-í…ŒìŠ¤íŠ¸","content":" ë°©ê¸ˆ ë°°í¬í•œ Llama3ë¥¼ í…ŒìŠ¤íŠ¸í•  ì‹œê°„ì…ë‹ˆë‹¤. ë¨¼ì € í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤.  cd ai-on-eks/blueprints/inference/nvidia-nim/nim-client python3 -m venv .venv source .venv/bin/activate pip install openai   prompts.txtì— í”„ë¡¬í”„íŠ¸ë¥¼ ì¤€ë¹„í•´ ë‘ì—ˆìœ¼ë©°, 20ê°œì˜ í”„ë¡¬í”„íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì„ í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ ì‹¤í–‰í•˜ì—¬ ìƒì„±ëœ ì¶œë ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  python3 client.py --input-prompts prompts.txt --results-file results.txt   ì•„ë˜ì™€ ê°™ì€ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:  Loading inputs from `prompts.txt`... Model meta/llama3-8b-instruct - Request 14: 4.68s (4678.46ms) Model meta/llama3-8b-instruct - Request 10: 6.43s (6434.32ms) Model meta/llama3-8b-instruct - Request 3: 7.82s (7824.33ms) Model meta/llama3-8b-instruct - Request 1: 8.54s (8540.69ms) Model meta/llama3-8b-instruct - Request 5: 8.81s (8807.52ms) Model meta/llama3-8b-instruct - Request 12: 8.95s (8945.85ms) Model meta/llama3-8b-instruct - Request 18: 9.77s (9774.75ms) Model meta/llama3-8b-instruct - Request 16: 9.99s (9994.51ms) Model meta/llama3-8b-instruct - Request 6: 10.26s (10263.60ms) Model meta/llama3-8b-instruct - Request 0: 10.27s (10274.35ms) Model meta/llama3-8b-instruct - Request 4: 10.65s (10654.39ms) Model meta/llama3-8b-instruct - Request 17: 10.75s (10746.08ms) Model meta/llama3-8b-instruct - Request 11: 10.86s (10859.91ms) Model meta/llama3-8b-instruct - Request 15: 10.86s (10857.15ms) Model meta/llama3-8b-instruct - Request 8: 11.07s (11068.78ms) Model meta/llama3-8b-instruct - Request 2: 12.11s (12105.07ms) Model meta/llama3-8b-instruct - Request 19: 12.64s (12636.42ms) Model meta/llama3-8b-instruct - Request 9: 13.37s (13370.75ms) Model meta/llama3-8b-instruct - Request 13: 13.57s (13571.28ms) Model meta/llama3-8b-instruct - Request 7: 14.90s (14901.51ms) Storing results into `results.txt`... Accumulated time for all requests: 206.31 seconds (206309.73 milliseconds) PASS: NVIDIA NIM example Actual execution time used with concurrency 20 is: 14.92 seconds (14.92 milliseconds)   results.txtì˜ ì¶œë ¥ì€ ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œë©ë‹ˆë‹¤  ë¶€ë¶„ ì¶œë ¥ì„ ë³´ë ¤ë©´ í´ë¦­í•˜ì„¸ìš” The key differences between traditional machine learning models and very large language models (vLLM) are: 1. **Scale**: vLLMs are massive, with billions of parameters, whereas traditional models typically have millions. 2. **Training data**: vLLMs are trained on vast amounts of text data, often sourced from the internet, whereas traditional models are trained on smaller, curated datasets. 3. **Architecture**: vLLMs often use transformer architectures, which are designed for sequential data like text, whereas traditional models may use feedforward networks or recurrent neural networks. 4. **Training objectives**: vLLMs are often trained using masked language modeling or next sentence prediction tasks, whereas traditional models may use classification, regression, or clustering objectives. 5. **Evaluation metrics**: vLLMs are typically evaluated using metrics like perplexity, accuracy, or fluency, whereas traditional models may use metrics like accuracy, precision, or recall. 6. **Interpretability**: vLLMs are often less interpretable due to their massive size and complex architecture, whereas traditional models may be more interpretable due to their smaller size and simpler architecture. These differences enable vLLMs to excel in tasks like language translation, text generation, and conversational AI, whereas traditional models are better suited for tasks like image classification or regression. ========= TensorRT (Triton Runtime) optimizes LLM (Large Language Model) inference on NVIDIA hardware by: 1. **Model Pruning**: Removing unnecessary weights and connections to reduce model size and computational requirements. 2. **Quantization**: Converting floating-point models to lower-precision integer formats (e.g., INT8) to reduce memory bandwidth and improve performance. 3. **Kernel Fusion**: Combining multiple kernel launches into a single launch to reduce overhead and improve parallelism. 4. **Optimized Tensor Cores**: Utilizing NVIDIA's Tensor Cores for matrix multiplication, which provides significant performance boosts. 5. **Batching**: Processing multiple input batches concurrently to improve throughput. 6. **Mixed Precision**: Using a combination of floating-point and integer precision to balance accuracy and performance. 7. **Graph Optimization**: Reordering and reorganizing the computation graph to minimize memory access and optimize data transfer. By applying these optimizations, TensorRT can significantly accelerate LLM inference on NVIDIA hardware, achieving faster inference times and improved performance. =========   ","version":"Next","tagName":"h3"},{"title":"Open WebUI ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#open-webui-ë°°í¬","content":" ì •ë³´ Open WebUIëŠ” OpenAI API ì„œë²„ ë° Ollamaì™€ í˜¸í™˜ë˜ëŠ” ëª¨ë¸ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.  1. WebUI ë°°í¬  ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ Open WebUIë¥¼ ë°°í¬í•©ë‹ˆë‹¤:  kubectl apply -f ai-on-eks/blueprints/inference/nvidia-nim/openai-webui-deployment.yaml   2. WebUIì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ Port Forward  kubectl port-forwardë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ WebUIì— ì ‘ê·¼í•©ë‹ˆë‹¤:  kubectl port-forward svc/open-webui 8081:80 -n openai-webui   3. WebUI ì ‘ê·¼  ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  http://localhost:8081 ë¡œ ì´ë™í•©ë‹ˆë‹¤  4. ê°€ì…  ì´ë¦„, ì´ë©”ì¼ ë° ì„ì˜ì˜ ë¹„ë°€ë²ˆí˜¸ë¡œ ê°€ì…í•©ë‹ˆë‹¤.  5. ìƒˆ ì±„íŒ… ì‹œì‘  New Chatì„ í´ë¦­í•˜ê³  ì•„ë˜ ìŠ¤í¬ë¦°ìƒ·ê³¼ ê°™ì´ ë“œë¡­ë‹¤ìš´ ë©”ë‰´ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤:    6. í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì…ë ¥  í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤:    ","version":"Next","tagName":"h2"},{"title":"NVIDIA GenAI-Perf ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#nvidia-genai-perf-ë„êµ¬ë¥¼-ì‚¬ìš©í•œ-ì„±ëŠ¥-í…ŒìŠ¤íŠ¸","content":" GenAI-PerfëŠ” ì¶”ë¡  ì„œë²„ë¥¼ í†µí•´ ì œê³µë˜ëŠ” ìƒì„±í˜• AI ëª¨ë¸ì˜ ì²˜ë¦¬ëŸ‰ê³¼ ì§€ì—° ì‹œê°„ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ëª…ë ¹ì¤„ ë„êµ¬ì…ë‹ˆë‹¤.  GenAI-PerfëŠ” ì¶”ë¡  ì„œë²„ë¡œ ë°°í¬ëœ ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë²¤ì¹˜ë§ˆí¬í•˜ëŠ” í‘œì¤€ ë„êµ¬ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ë„êµ¬ì—ëŠ” GPUê°€ í•„ìš”í•©ë‹ˆë‹¤. ë” ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì‚¬ì „ êµ¬ì„±ëœ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ genaiperf-deploy.yamlì„ ì œê³µí•©ë‹ˆë‹¤.  cd ai-on-eks/blueprints/inference/nvidia-nim kubectl apply -f genaiperf-deploy.yaml   íŒŒë“œê°€ ì‹¤í–‰ ìƒíƒœ 1/1ë¡œ ì¤€ë¹„ë˜ë©´ íŒŒë“œì— ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  export POD_NAME=$(kubectl get po -l app=tritonserver -ojsonpath='{.items[0].metadata.name}') kubectl exec -it $POD_NAME -- bash   ë°°í¬ëœ NIM Llama3 ëª¨ë¸ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤  genai-perf \\ -m meta/llama3-8b-instruct \\ --service-kind openai \\ --endpoint v1/completions \\ --endpoint-type completions \\ --num-prompts 100 \\ --random-seed 123 \\ --synthetic-input-tokens-mean 200 \\ --synthetic-input-tokens-stddev 0 \\ --output-tokens-mean 100 \\ --output-tokens-stddev 0 \\ --tokenizer hf-internal-testing/llama-tokenizer \\ --concurrency 10 \\ --measurement-interval 4000 \\ --profile-export-file my_profile_export.json \\ --url nim-llm-llama3-8b-instruct.nim:8000   ë‹¤ìŒê³¼ ìœ ì‚¬í•œ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤  2024-07-11 03:32 [INFO] genai_perf.parser:166 - Model name 'meta/llama3-8b-instruct' cannot be used to create artifact directory. Instead, 'meta_llama3-8b-instruct' will be used. 2024-07-11 03:32 [INFO] genai_perf.wrapper:137 - Running Perf Analyzer : 'perf_analyzer -m meta/llama3-8b-instruct --async --input-data artifacts/meta_llama3-8b-instruct-openai-completions-concurrency10/llm_inputs.json --endpoint v1/completions --service-kind openai -u nim-llm.nim:8000 --measurement-interval 4000 --stability-percentage 999 --profile-export-file artifacts/meta_llama3-8b-instruct-openai-completions-concurrency10/my_profile_export.json -i http --concurrency-range 10' LLM Metrics â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“ â”ƒ Statistic â”ƒ avg â”ƒ min â”ƒ max â”ƒ p99 â”ƒ p90 â”ƒ p75 â”ƒ â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”© â”‚ Request latency (ns) â”‚ 3,934,624,446 â”‚ 3,897,758,114 â”‚ 3,936,987,882 â”‚ 3,936,860,185 â”‚ 3,936,429,317 â”‚ 3,936,333,682 â”‚ â”‚ Num output token â”‚ 112 â”‚ 105 â”‚ 119 â”‚ 119 â”‚ 117 â”‚ 115 â”‚ â”‚ Num input token â”‚ 200 â”‚ 200 â”‚ 200 â”‚ 200 â”‚ 200 â”‚ 200 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Output token throughput (per sec): 284.64 Request throughput (per sec): 2.54   Request latency, Out token throughput, Request throughputë¥¼ í¬í•¨í•˜ì—¬ genai-perfê°€ ìˆ˜ì§‘í•˜ëŠ” ë©”íŠ¸ë¦­ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ëª…ë ¹ì¤„ ì˜µì…˜ì„ ì´í•´í•˜ë ¤ë©´ ì´ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.  ","version":"Next","tagName":"h2"},{"title":"ê´€ì¸¡ì„±â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#ê´€ì¸¡ì„±","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ì˜ ì¼ë¶€ë¡œ ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡ì„±ì„ ìœ„í•œ Prometheus ì„œë²„ì™€ Grafana ë°°í¬ë¥¼ ì œê³µí•˜ëŠ” Kube Prometheus ìŠ¤íƒë„ ë°°í¬í–ˆìŠµë‹ˆë‹¤.  ë¨¼ì € Kube Prometheus ìŠ¤íƒì—ì„œ ë°°í¬í•œ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤:  kubectl get svc -n monitoring   ë‹¤ìŒê³¼ ìœ ì‚¬í•œ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:  NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-prometheus-stack-grafana ClusterIP 172.20.225.77 &lt;none&gt; 80/TCP 10m kube-prometheus-stack-kube-state-metrics ClusterIP 172.20.237.248 &lt;none&gt; 8080/TCP 10m kube-prometheus-stack-operator ClusterIP 172.20.118.163 &lt;none&gt; 443/TCP 10m kube-prometheus-stack-prometheus ClusterIP 172.20.132.214 &lt;none&gt; 9090/TCP,8080/TCP 10m kube-prometheus-stack-prometheus-node-exporter ClusterIP 172.20.213.178 &lt;none&gt; 9100/TCP 10m prometheus-adapter ClusterIP 172.20.171.163 &lt;none&gt; 443/TCP 10m prometheus-operated ClusterIP None &lt;none&gt; 9090/TCP 10m   NVIDIA NIM LLM ì„œë¹„ìŠ¤ëŠ” í¬íŠ¸ 8000ì˜ nim-llm-llama3-8b-instruct ì„œë¹„ìŠ¤ì—ì„œ /metrics ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•´ ë©”íŠ¸ë¦­ì„ ë…¸ì¶œí•©ë‹ˆë‹¤. ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ í™•ì¸í•©ë‹ˆë‹¤  kubectl get svc -n nim kubectl port-forward -n nim svc/nim-llm-llama3-8b-instruct 8000 curl localhost:8000/metrics # ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰   ","version":"Next","tagName":"h2"},{"title":"Grafana ëŒ€ì‹œë³´ë“œâ€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#grafana-ëŒ€ì‹œë³´ë“œ","content":" NIM ìƒíƒœë¥¼ ë” ì˜ ì‹œê°í™”í•˜ê¸° ìœ„í•´ ì‚¬ì „ êµ¬ì„±ëœ Grafana ëŒ€ì‹œë³´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì•„ë˜ Grafana ëŒ€ì‹œë³´ë“œì—ëŠ” ì—¬ëŸ¬ ì¤‘ìš”í•œ ë©”íŠ¸ë¦­ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:  Time to First Token(TTFT): ëª¨ë¸ì— ëŒ€í•œ ì´ˆê¸° ì¶”ë¡  ìš”ì²­ê³¼ ì²« ë²ˆì§¸ í† í° ë°˜í™˜ ì‚¬ì´ì˜ ì§€ì—° ì‹œê°„.Inter-Token Latency(ITL): ì²« ë²ˆì§¸ í† í° ì´í›„ ê° í† í° ì‚¬ì´ì˜ ì§€ì—° ì‹œê°„.Total Throughput: NIMì—ì„œ ì´ˆë‹¹ ìƒì„±ë˜ëŠ” ì´ í† í° ìˆ˜.  ë” ë§ì€ ë©”íŠ¸ë¦­ ì„¤ëª…ì€ ì´ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.    Time-to-First-Token, Inter-Token-Latency, KV Cache Utilization ë©”íŠ¸ë¦­ ë“±ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•´ Grafana ëŒ€ì‹œë³´ë“œë¥¼ ë³´ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:  ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ë ¤ë©´ í´ë¦­í•˜ì„¸ìš” 1. Grafana ë¹„ë°€ë²ˆí˜¸ ê²€ìƒ‰ ë¹„ë°€ë²ˆí˜¸ëŠ” AWS Secret Managerì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ Terraform ëª…ë ¹ì´ ì‹œí¬ë¦¿ ì´ë¦„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. terraform output grafana_secret_name ê·¸ëŸ° ë‹¤ìŒ ì¶œë ¥ëœ ì‹œí¬ë¦¿ ì´ë¦„ì„ ì‚¬ìš©í•˜ì—¬ ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤, aws secretsmanager get-secret-value --secret-id &lt;grafana_secret_name_output&gt; --region $AWS_REGION --query &quot;SecretString&quot; --output text 2. Grafana ì„œë¹„ìŠ¤ ë…¸ì¶œ port-forwardë¥¼ ì‚¬ìš©í•˜ì—¬ Grafana ì„œë¹„ìŠ¤ë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤. kubectl port-forward svc/kube-prometheus-stack-grafana 3000:80 -n monitoring 3. Grafanaì— ë¡œê·¸ì¸: ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  http://localhost:3000ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.ì‚¬ìš©ì ì´ë¦„ adminê³¼ AWS Secrets Managerì—ì„œ ê²€ìƒ‰í•œ ë¹„ë°€ë²ˆí˜¸ë¡œ ë¡œê·¸ì¸í•©ë‹ˆë‹¤. 4. NIM ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì—´ê¸°: ë¡œê·¸ì¸í•œ í›„ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ &quot;Dashboards&quot;ë¥¼ í´ë¦­í•˜ê³  &quot;nim&quot;ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤ëª©ë¡ì—ì„œ NVIDIA NIM Monitoring ëŒ€ì‹œë³´ë“œë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤í´ë¦­í•˜ì—¬ ëŒ€ì‹œë³´ë“œë¡œ ì§„ì…í•©ë‹ˆë‹¤. ì´ì œ Grafana ëŒ€ì‹œë³´ë“œì— í‘œì‹œëœ ë©”íŠ¸ë¦­ì„ ë³¼ ìˆ˜ ìˆìœ¼ë©°, NVIDIA NIM ì„œë¹„ìŠ¤ ë°°í¬ì˜ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì •ë³´ ì´ ê°€ì´ë“œ ì‘ì„± ì‹œì ì—ì„œ NVIDIAë„ ì˜ˆì œ Grafana ëŒ€ì‹œë³´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ NVIDIA NIM LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-llama3#ì •ë¦¬","content":" ì´ ë°°í¬ì—ì„œ ìƒì„±ëœ ëª¨ë“  ë¦¬ì†ŒìŠ¤ë¥¼ ì œê±°í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Amazon EKSì˜ NVIDIA Dynamo","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo","content":"","keywords":"","version":"Next"},{"title":"ë¹ ë¥¸ ì‹œì‘â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ë¹ ë¥¸-ì‹œì‘","content":" ì¦‰ì‹œ ì‹œì‘í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ìµœì†Œí•œì˜ ëª…ë ¹ ì‹œí€€ìŠ¤ì…ë‹ˆë‹¤:  # 1. í´ë¡  ë° ì´ë™ git clone https://github.com/awslabs/ai-on-eks.git &amp;&amp; cd ai-on-eks/infra/nvidia-dynamo # 2. ì¸í”„ë¼ ë° í”Œë«í¼ ë°°í¬ (15-30ë¶„) ./install.sh # 3. ì‚¬ì „ ë¹Œë“œëœ NGC ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  ì˜ˆì œ ë°°í¬ cd ../../blueprints/inference/nvidia-dynamo ./deploy.sh # ì˜ˆì œë¥¼ ì„ íƒí•˜ëŠ” ëŒ€í™”í˜• ë©”ë‰´ # ./deploy.sh vllm # ëŒ€í™”í˜• ì„¤ì •ìœ¼ë¡œ vLLM ë°°í¬ # 4. ë°°í¬ í…ŒìŠ¤íŠ¸ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ëŒ€ê¸°) kubectl port-forward svc/vllm-frontend 8000:8000 -n dynamo-cloud curl http://localhost:8000/health   ì‚¬ì „ ìš”êµ¬ ì‚¬í•­: AWS CLI, kubectl, helm, terraform, git, NGC API í† í°, HuggingFace í† í° (ì•„ë˜ ìì„¸í•œ ì„¤ì •)    ","version":"Next","tagName":"h2"},{"title":"NVIDIA Dynamoë€?â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#nvidia-dynamoë€","content":" NVIDIA DynamoëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ë° ìƒì„±í˜• AI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ê³¼ í™•ì¥ì„±ì„ ìµœì í™”í•˜ë„ë¡ ì„¤ê³„ëœ ì˜¤í”ˆ ì†ŒìŠ¤ ì¶”ë¡  í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. Apache 2.0 ë¼ì´ì„ ìŠ¤ í•˜ì— ë¦´ë¦¬ìŠ¤ëœ DynamoëŠ” ì—¬ëŸ¬ GPUì™€ ë…¸ë“œì— ê±¸ì³ ë³µì¡í•œ AI ì›Œí¬ë¡œë“œë¥¼ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ëŠ” ë°ì´í„°ì„¼í„° ê·œëª¨ì˜ ë¶„ì‚° ì¶”ë¡  ì„œë¹™ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì¶”ë¡  ê·¸ë˜í”„ë€?â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì¶”ë¡ -ê·¸ë˜í”„ë€","content":" **ì¶”ë¡  ê·¸ë˜í”„(Inference Graph)**ëŠ” ìƒí˜¸ ì—°ê²°ëœ ë…¸ë“œë¥¼ í†µí•´ AI ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì„ ì •ì˜í•˜ëŠ” ê³„ì‚° ì›Œí¬í”Œë¡œìš°ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ë³µì¡í•œ ë‹¤ë‹¨ê³„ AI ì‘ì—…ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤:  LLM ì²´ì¸: ì—¬ëŸ¬ ì–¸ì–´ ëª¨ë¸ì„ í†µí•œ ìˆœì°¨ì  ì²˜ë¦¬ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬: í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë° ì˜¤ë””ì˜¤ ì²˜ë¦¬ ê²°í•©ì‚¬ìš©ì ì •ì˜ ì¶”ë¡  íŒŒì´í”„ë¼ì¸: íŠ¹ì • AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ë§ì¶¤í˜• ì›Œí¬í”Œë¡œìš°ë¶„ë¦¬ëœ ì„œë¹™: ìµœì ì˜ ë¦¬ì†ŒìŠ¤ í™œìš©ì„ ìœ„í•´ prefillê³¼ decode ë‹¨ê³„ ë¶„ë¦¬  ","version":"Next","tagName":"h3"},{"title":"ê°œìš”â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ê°œìš”","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” NVIDIA NGC ì¹´íƒˆë¡œê·¸ì˜ **ê³µì‹ NVIDIA Dynamo Helm ì°¨íŠ¸**ë¥¼ ì‚¬ìš©í•˜ë©°, Amazon EKSì—ì„œì˜ ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ìˆœí™”í•˜ê¸° ìœ„í•œ ì¶”ê°€ ì…¸ ìŠ¤í¬ë¦½íŠ¸ì™€ Terraform ìë™í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë°°í¬ ì ‘ê·¼ ë°©ì‹â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ë°°í¬-ì ‘ê·¼-ë°©ì‹","content":" ì´ ì„¤ì • í”„ë¡œì„¸ìŠ¤ì˜ ì´ìœ ëŠ”?ì´ êµ¬í˜„ì€ ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ í¬í•¨í•˜ì§€ë§Œ ê°„ë‹¨í•œ Helm ì „ìš© ë°°í¬ì— ë¹„í•´ ì—¬ëŸ¬ ê°€ì§€ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤:  ì™„ì „í•œ ì¸í”„ë¼: VPC, EKS í´ëŸ¬ìŠ¤í„°, ECR ë¦¬í¬ì§€í† ë¦¬ ë° ëª¨ë‹ˆí„°ë§ ìŠ¤íƒì„ ìë™ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í”„ë¡œë•ì…˜ ì¤€ë¹„: ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë³´ì•ˆ, ëª¨ë‹ˆí„°ë§ ë° í™•ì¥ì„± ê¸°ëŠ¥ í¬í•¨AWS í†µí•©: EKS ì˜¤í† ìŠ¤ì¼€ì¼ë§, EFA ë„¤íŠ¸ì›Œí‚¹ ë° AWS ì„œë¹„ìŠ¤ í™œìš©ì‚¬ìš©ì ì •ì˜ ê°€ëŠ¥: GPU ë…¸ë“œ í’€, ë„¤íŠ¸ì›Œí‚¹ ë° ë¦¬ì†ŒìŠ¤ í• ë‹¹ì˜ ë¯¸ì„¸ ì¡°ì • ê°€ëŠ¥ì¬í˜„ ê°€ëŠ¥: Infrastructure as Codeë¡œ í™˜ê²½ ì „ë°˜ì— ê±¸ì³ ì¼ê´€ëœ ë°°í¬ ë³´ì¥  ë” ê°„ë‹¨í•œ ë°°í¬ì˜ ê²½ìš°: EKS í´ëŸ¬ìŠ¤í„°ê°€ ì´ë¯¸ ìˆê³  ìµœì†Œí•œì˜ ì„¤ì •ì„ ì„ í˜¸í•˜ëŠ” ê²½ìš° ì†ŒìŠ¤ ì €ì¥ì†Œì—ì„œ ì§ì ‘ Dynamo Helm ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” ì™„ì „í•œ í”„ë¡œë•ì…˜ ì¤€ë¹„ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.  LLM ë° ìƒì„±í˜• AI ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì ì  ë³´í¸í™”ë¨ì— ë”°ë¼ íš¨ìœ¨ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•˜ë©° ì €ì§€ì—° ì¶”ë¡  ì†”ë£¨ì…˜ì— ëŒ€í•œ ìˆ˜ìš”ê°€ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ì¶”ë¡  ì‹œìŠ¤í…œì€ íŠ¹íˆ ë¶„ì‚° ë‹¤ì¤‘ ë…¸ë“œ í™˜ê²½ì—ì„œ ì´ëŸ¬í•œ ìš”êµ¬ë¥¼ ì¶©ì¡±í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. NVIDIA DynamoëŠ” Amazon S3, Elastic Fabric Adapter (EFA) ë° Amazon EKSì™€ ê°™ì€ AWS ì„œë¹„ìŠ¤ë¥¼ ì§€ì›í•˜ì—¬ ì„±ëŠ¥ê³¼ í™•ì¥ì„±ì„ ìµœì í™”í•˜ëŠ” í˜ì‹ ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•¨ìœ¼ë¡œì¨ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” ê¸°ëŠ¥â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì£¼ìš”-ê¸°ëŠ¥","content":" ì„±ëŠ¥ ìµœì í™”:  ë¶„ë¦¬ëœ ì„œë¹™: ìµœì ì˜ ë¦¬ì†ŒìŠ¤ í™œìš©ì„ ìœ„í•´ ë‹¤ë¥¸ GPUì—ì„œ prefillê³¼ decode ë‹¨ê³„ ë¶„ë¦¬ë™ì  GPU ìŠ¤ì¼€ì¤„ë§: NVIDIA Dynamo Plannerë¥¼ í†µí•œ ì‹¤ì‹œê°„ ìˆ˜ìš” ê¸°ë°˜ ì§€ëŠ¥í˜• ë¦¬ì†ŒìŠ¤ í• ë‹¹ìŠ¤ë§ˆíŠ¸ ìš”ì²­ ë¼ìš°íŒ…: ê´€ë ¨ ìºì‹œëœ ë°ì´í„°ê°€ ìˆëŠ” ì›Œì»¤ë¡œ ìš”ì²­ì„ ë¼ìš°íŒ…í•˜ì—¬ KV ìºì‹œ ì¬ê³„ì‚° ìµœì†Œí™”ê°€ì†í™”ëœ ë°ì´í„° ì „ì†¡: NVIDIA NIXL ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•œ ì €ì§€ì—° í†µì‹ íš¨ìœ¨ì ì¸ KV ìºì‹œ ê´€ë¦¬: KV Cache Block Managerë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ê³„ì¸µ ì „ë°˜ì˜ ì§€ëŠ¥í˜• ì˜¤í”„ë¡œë”©  ì¸í”„ë¼ ì¤€ë¹„:  ì¶”ë¡  ì—”ì§„ ë¶ˆê°€ì§€ë¡ : TensorRT-LLM, vLLM, SGLang ë° ê¸°íƒ€ ëŸ°íƒ€ì„ ì§€ì›ëª¨ë“ˆì‹ ì„¤ê³„: ê¸°ì¡´ AI ìŠ¤íƒì— ë§ëŠ” êµ¬ì„± ìš”ì†Œ ì„ íƒì—”í„°í”„ë¼ì´ì¦ˆê¸‰: ì™„ì „í•œ ëª¨ë‹ˆí„°ë§, ë¡œê¹… ë° ë³´ì•ˆ í†µí•©Amazon EKS ìµœì í™”: EKS ì˜¤í† ìŠ¤ì¼€ì¼ë§, GPU ì§€ì› ë° AWS ì„œë¹„ìŠ¤ í™œìš©  ","version":"Next","tagName":"h3"},{"title":"ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì•„í‚¤í…ì²˜","content":" ë°°í¬ëŠ” ë‹¤ìŒ êµ¬ì„± ìš”ì†Œì™€ í•¨ê»˜ Amazon EKSë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:    ì£¼ìš” êµ¬ì„± ìš”ì†Œ:  VPC ë° ë„¤íŠ¸ì›Œí‚¹: ì €ì§€ì—° ë…¸ë“œ ê°„ í†µì‹ ì„ ìœ„í•œ EFA ì§€ì›ì´ ìˆëŠ” í‘œì¤€ VPCEKS í´ëŸ¬ìŠ¤í„°: Karpenterë¥¼ ì‚¬ìš©í•˜ëŠ” GPU ì§€ì› ë…¸ë“œ ê·¸ë£¹ì´ ìˆëŠ” ê´€ë¦¬í˜• KubernetesDynamo Platform: Operator, API Store ë° ì§€ì› ì„œë¹„ìŠ¤ (NATS, PostgreSQL, MinIO)ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ: Prometheus, Grafana ë° AI/ML ê´€ì¸¡ì„±ìŠ¤í† ë¦¬ì§€: ê³µìœ  ëª¨ë¸ ìŠ¤í† ë¦¬ì§€ ë° ìºì‹±ì„ ìœ„í•œ Amazon EFS  ","version":"Next","tagName":"h2"},{"title":"ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì‚¬ì „-ìš”êµ¬-ì‚¬í•­","content":" ì‹œìŠ¤í…œ ìš”êµ¬ ì‚¬í•­: Ubuntu 22.04 ë˜ëŠ” 24.04 (NVIDIA DynamoëŠ” ê³µì‹ì ìœ¼ë¡œ ì´ëŸ¬í•œ ë²„ì „ë§Œ ì§€ì›)  ì„¤ì • í˜¸ìŠ¤íŠ¸ì— ë‹¤ìŒ ë„êµ¬ë¥¼ ì„¤ì¹˜í•˜ì‹­ì‹œì˜¤ (ê¶Œì¥: EKS ë° ECR ê¶Œí•œì´ ìˆëŠ” t3.xlarge ì´ìƒì˜ EC2 ì¸ìŠ¤í„´ìŠ¤):  AWS CLI: ì ì ˆí•œ ê¶Œí•œìœ¼ë¡œ êµ¬ì„±ë¨ (ì„¤ì¹˜ ê°€ì´ë“œ)kubectl: Kubernetes ëª…ë ¹ì¤„ ë„êµ¬ (ì„¤ì¹˜ ê°€ì´ë“œ)helm: Kubernetes íŒ¨í‚¤ì§€ ê´€ë¦¬ì (ì„¤ì¹˜ ê°€ì´ë“œ)terraform: Infrastructure as code ë„êµ¬ (ì„¤ì¹˜ ê°€ì´ë“œ)git: ë²„ì „ ì œì–´ (ì„¤ì¹˜ ê°€ì´ë“œ)Python 3.10+: pip ë° venv í¬í•¨ (ì„¤ì¹˜ ê°€ì´ë“œ)EKS í´ëŸ¬ìŠ¤í„°: ë²„ì „ 1.33 (í…ŒìŠ¤íŠ¸ ë° ì§€ì›ë¨)  ","version":"Next","tagName":"h2"},{"title":"í•„ìˆ˜ API í† í°â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#í•„ìˆ˜-api-í† í°","content":" NGC API í† í°: NVIDIAì˜ ì‚¬ì „ ë¹Œë“œëœ Dynamo ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì— ì•¡ì„¸ìŠ¤í•˜ëŠ” ë° í•„ìš” NVIDIA NGCì— ê°€ì…ê³„ì • ì„¤ì •ì—ì„œ API í‚¤ ìƒì„±NGC_API_KEY í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ê±°ë‚˜ ì„¤ì¹˜ ì¤‘ì— ì œê³µ HuggingFace í† í°: ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— í•„ìš” HuggingFaceì—ì„œ ê³„ì • ìƒì„±ëª¨ë¸ ì½ê¸° ê¶Œí•œì´ ìˆëŠ” ì•¡ì„¸ìŠ¤ í† í° ìƒì„±HF_TOKEN í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ê±°ë‚˜ ë°°í¬ ì¤‘ ëŒ€í™”í˜•ìœ¼ë¡œ ì œê³µ  ì†”ë£¨ì…˜ ë°°í¬ ğŸ‘ˆ  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ìš© ê°€ëŠ¥í•œ ì˜ˆì œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì‚¬ìš©-ê°€ëŠ¥í•œ-ì˜ˆì œ","content":" ","version":"Next","tagName":"h2"},{"title":"í”„ë¡œë•ì…˜ ì¤€ë¹„ ì˜ˆì œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#í”„ë¡œë•ì…˜-ì¤€ë¹„-ì˜ˆì œ","content":" ë‹¤ìŒ ì˜ˆì œëŠ” ì™„ì „íˆ í…ŒìŠ¤íŠ¸ë˜ì—ˆê³  í¬ê´„ì ì¸ ë¬¸ì„œì™€ í•¨ê»˜ í”„ë¡œë•ì…˜ ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŠµë‹ˆë‹¤:  ì˜ˆì œ\tëŸ°íƒ€ì„\tëª¨ë¸\tì•„í‚¤í…ì²˜\të…¸ë“œ ìœ í˜•\tì£¼ìš” ê¸°ëŠ¥hello-world\tCPU\tN/A\tì§‘ê³„\tCPU\tê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸ vllm\tvLLM\tQwen3-0.6B\tì§‘ê³„\tG5 GPU\tOpenAI API, ê· í˜• ì¡íŒ ì„±ëŠ¥ sglang\tSGLang\tDeepSeek-R1-Distill-8B\tì§‘ê³„\tG5 GPU\tRadixAttention ìºì‹± trtllm\tTensorRT-LLM\tDeepSeek-R1-Distill-8B\tì§‘ê³„\tG5 GPU\tìµœëŒ€ ì¶”ë¡  ì„±ëŠ¥ multi-replica-vllm\tvLLM\të‹¤ì¤‘ ëª¨ë¸\të‹¤ì¤‘ ë ˆí”Œë¦¬ì¹´ HA\tG5 GPU\tKV ë¼ìš°íŒ…, ë¡œë“œ ë°¸ëŸ°ì‹±  ","version":"Next","tagName":"h3"},{"title":"ê³ ê¸‰ ì˜ˆì œ (ë² íƒ€)â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ê³ ê¸‰-ì˜ˆì œ-ë² íƒ€","content":" ì´ëŸ¬í•œ ì˜ˆì œëŠ” ê³ ê¸‰ Dynamo ê¸°ëŠ¥ì„ ì‹œì—°í•˜ë©° ì‹¤í—˜ì  ì›Œí¬ë¡œë“œì— ì í•©í•©ë‹ˆë‹¤:  ì˜ˆì œ\tëŸ°íƒ€ì„\tì•„í‚¤í…ì²˜\tì‚¬ìš© ì‚¬ë¡€\tì£¼ìš” ê¸°ëŠ¥vllm-disagg\tvLLM\të¶„ë¦¬\të†’ì€ ì²˜ë¦¬ëŸ‰\të³„ë„ì˜ prefill/decode ì›Œì»¤ sglang-disagg\tSGLang\të¶„ë¦¬\të©”ëª¨ë¦¬ ìµœì í™”\tRadixAttention + ë¶„ë¦¬ trtllm-disagg\tTensorRT-LLM\të¶„ë¦¬\tì´ˆê³ ì„±ëŠ¥\tTRT-LLM + ë¶„ë¦¬ kv-routing\të‹¤ì¤‘ ëŸ°íƒ€ì„\tì§€ëŠ¥í˜• ë¼ìš°íŒ…\tìºì‹œ ìµœì í™”\tKV ì¸ì‹ ìš”ì²­ ë¼ìš°íŒ…  ","version":"Next","tagName":"h3"},{"title":"ì˜ˆì œ í•˜ì´ë¼ì´íŠ¸â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì˜ˆì œ-í•˜ì´ë¼ì´íŠ¸","content":" hello-world: ì™„ë²½í•œ ì‹œì‘ì   Dynamo í”Œë«í¼ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ CPU ì „ìš© ë°°í¬ë¹ ë¥¸ ë°°í¬ (~2ë¶„)GPU ë˜ëŠ” ëª¨ë¸ ì¢…ì†ì„± ì—†ìŒCI/CD ê²€ì¦ì— ì´ìƒì   vllm: ëŒ€ë¶€ë¶„ì˜ ì‚¬ìš© ì‚¬ë¡€ì— ê¶Œì¥  OpenAI í˜¸í™˜ API (/v1/chat/completions, /v1/models)ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì‘ì€ ëª¨ë¸ (Qwen3-0.6B)í”„ë¡œë•ì…˜ ì¤€ë¹„ í—¬ìŠ¤ ì²´í¬G5 GPU ìµœì í™”  sglang: ê³ ê¸‰ ìºì‹± ê¸°ëŠ¥  ë°˜ë³µ ì¿¼ë¦¬ì—ì„œ 2-10ë°° ì†ë„ í–¥ìƒì„ ìœ„í•œ RadixAttentionêµ¬ì¡°í™”ëœ ìƒì„± ì§€ì› (JSON/XML)ê³ ê¸‰ ë©”ëª¨ë¦¬ ê´€ë¦¬ìºì‹œ ì¤‘ì‹¬ ì›Œí¬ë¡œë“œì— ì í•©  trtllm: ìµœëŒ€ ì„±ëŠ¥  NVIDIA TensorRT-LLM ìµœì í™” ì»¤ë„ìµœê³  ì²˜ë¦¬ëŸ‰ ë° ìµœì € ì§€ì—° ì‹œê°„ì‚¬ìš©ì ì •ì˜ CUDA ì»¤ë„í”„ë¡œë•ì…˜ ì„œë¹™ì— ìµœì   multi-replica-vllm: ê³ ê°€ìš©ì„± ë°°í¬  KV ë¼ìš°íŒ…ì´ ìˆëŠ” ì—¬ëŸ¬ ë…ë¦½ ì›Œì»¤ ë ˆí”Œë¦¬ì¹´ìë™ ë¡œë“œ ë°¸ëŸ°ì‹± ë° ì¥ì•  ì¡°ì¹˜ì§€ëŠ¥í˜• ìºì‹œ ì¸ì‹ ìš”ì²­ ë¼ìš°íŒ…ê³ ê°€ìš©ì„±ì´ í•„ìš”í•œ í”„ë¡œë•ì…˜ ì›Œí¬ë¡œë“œì— ì´ìƒì   í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ëª¨ë“  9ê°œ ì˜ˆì œëŠ” GPU ë…¸ë“œê°€ ìˆëŠ” EKS í´ëŸ¬ìŠ¤í„°ì—ì„œ ì² ì €íˆ í…ŒìŠ¤íŠ¸ë˜ê³  ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. ê° ì˜ˆì œì—ëŠ” ì ì ˆí•œ í—¬ìŠ¤ ì²´í¬, OpenAI í˜¸í™˜ API ì—”ë“œí¬ì¸íŠ¸ ë° í”„ë¡œë•ì…˜ ì¤€ë¹„ êµ¬ì„±ì´ í¬í•¨ë©ë‹ˆë‹¤. ìì„¸í•œ ê²€ì¦ ê²°ê³¼ëŠ” í…ŒìŠ¤íŠ¸ ìš”ì•½ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h3"},{"title":"í…ŒìŠ¤íŠ¸ ë° ê²€ì¦â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#í…ŒìŠ¤íŠ¸-ë°-ê²€ì¦","content":" ","version":"Next","tagName":"h2"},{"title":"ìë™í™”ëœ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ìë™í™”ëœ-í…ŒìŠ¤íŠ¸","content":" ë‚´ì¥ëœ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤:  ./test.sh   ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”:  í”„ë¡ íŠ¸ì—”ë“œ ì„œë¹„ìŠ¤ë¡œì˜ í¬íŠ¸ í¬ì›Œë”© ì‹œì‘í—¬ìŠ¤ ì²´í¬, ë©”íŠ¸ë¦­ ë° /v1/models ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ê¸°ëŠ¥ í™•ì¸ì„ ìœ„í•œ ìƒ˜í”Œ ì¶”ë¡  ìš”ì²­ ì‹¤í–‰  ","version":"Next","tagName":"h3"},{"title":"ìˆ˜ë™ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ìˆ˜ë™-í…ŒìŠ¤íŠ¸","content":" ë°°í¬ì— ì§ì ‘ ì•¡ì„¸ìŠ¤:  kubectl port-forward svc/&lt;frontend-service&gt; 8000:8000 -n dynamo-cloud &amp; curl -X POST http://localhost:8000/v1/chat/completions \\ -H &quot;Content-Type: application/json&quot; \\ -d '{ &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;, &quot;messages&quot;: [ {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Explain what a Q-Bit is in quantum computing.&quot;} ], &quot;max_tokens&quot;: 2000, &quot;temperature&quot;: 0.7, &quot;stream&quot;: false }'   ì˜ˆìƒ ì¶œë ¥:  { &quot;id&quot;: &quot;1918b11a-6d98-4891-bc84-08f99de70fd0&quot;, &quot;choices&quot;: [ { &quot;index&quot;: 0, &quot;message&quot;: { &quot;content&quot;: &quot;A Q-bit, or qubit, is the basic unit of quantum information...&quot;, &quot;role&quot;: &quot;assistant&quot; }, &quot;finish_reason&quot;: &quot;stop&quot; } ], &quot;created&quot;: 1752018267, &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;, &quot;object&quot;: &quot;chat.completion&quot; }   ","version":"Next","tagName":"h3"},{"title":"ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ëª¨ë‹ˆí„°ë§-ë°-ê´€ì¸¡","content":" ","version":"Next","tagName":"h2"},{"title":"Grafana ëŒ€ì‹œë³´ë“œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#grafana-ëŒ€ì‹œë³´ë“œ","content":" ì‹œê°í™”ë¥¼ ìœ„í•´ Grafanaì— ì•¡ì„¸ìŠ¤ (ê¸°ë³¸ í¬íŠ¸ 3000):  kubectl port-forward -n kube-prometheus-stack svc/kube-prometheus-stack-grafana 3000:80   ","version":"Next","tagName":"h3"},{"title":"Prometheus ë©”íŠ¸ë¦­â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#prometheus-ë©”íŠ¸ë¦­","content":" ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì„ ìœ„í•´ Prometheusì— ì•¡ì„¸ìŠ¤ (í¬íŠ¸ 9090):  kubectl port-forward -n kube-prometheus-stack svc/prometheus 9090:80   ","version":"Next","tagName":"h3"},{"title":"ìë™ ëª¨ë‹ˆí„°ë§â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ìë™-ëª¨ë‹ˆí„°ë§","content":" ë°°í¬ëŠ” ìë™ìœ¼ë¡œ ë‹¤ìŒì„ ìƒì„±í•©ë‹ˆë‹¤:  Service: API í˜¸ì¶œ ë° ë©”íŠ¸ë¦­ì„ ìœ„í•œ ì¶”ë¡  ê·¸ë˜í”„ ë…¸ì¶œServiceMonitor: ë©”íŠ¸ë¦­ ìŠ¤í¬ë˜í•‘ì„ ìœ„í•œ Prometheus êµ¬ì„±ëŒ€ì‹œë³´ë“œ: ì¶”ë¡  ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ì‚¬ì „ êµ¬ì„±ëœ Grafana ëŒ€ì‹œë³´ë“œ  ","version":"Next","tagName":"h3"},{"title":"ê³ ê¸‰ êµ¬ì„±â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ê³ ê¸‰-êµ¬ì„±","content":" ","version":"Next","tagName":"h2"},{"title":"ë²„ì „ ê´€ë¦¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ë²„ì „-ê´€ë¦¬","content":" ë°°í¬ëŠ” ìœ ì—°í•œ ì¬ì •ì˜ ì˜µì…˜ìœ¼ë¡œ Dynamo ë²„ì „ì„ ìë™ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤:  ê¸°ë³¸ ë™ì‘:  terraform/blueprint.tfvarsì—ì„œ ë²„ì „ ì½ê¸° (dynamo_stack_version = &quot;v0.4.1&quot;)YAML ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì—ì„œ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ íƒœê·¸ ìë™ ì—…ë°ì´íŠ¸ì†ŒìŠ¤ íŒŒì¼ì„ ìˆ˜ì •í•˜ì§€ ì•Šê³  ì„ì‹œ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±  ì¬ì •ì˜ ì˜µì…˜:  # í™˜ê²½ ë³€ìˆ˜ (ìµœìš°ì„  ìˆœìœ„) export DYNAMO_VERSION=v0.4.1 ./deploy.sh vllm # ì¸ë¼ì¸ ì¬ì •ì˜ DYNAMO_VERSION=v0.4.1 ./deploy.sh sglang # terraform/blueprint.tfvars ì—…ë°ì´íŠ¸ (ì˜êµ¬) dynamo_stack_version = &quot;v0.4.1&quot;   ì§€ì›ë˜ëŠ” ë²„ì „:  v0.4.1: í˜„ì¬ ì•ˆì • ë¦´ë¦¬ìŠ¤ (ê¸°ë³¸)ë¹„ê³µê°œ ë¹Œë“œì˜ ì‚¬ìš©ì ì •ì˜ ë²„ì „  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì‚¬ìš©ì-ì •ì˜-ëª¨ë¸-ë°°í¬","content":" ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ì„ ë°°í¬í•˜ë ¤ë©´ dynamo/examples/llm/configs/ì˜ êµ¬ì„± íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:  ì•„í‚¤í…ì²˜ ì„ íƒ: ëª¨ë¸ í¬ê¸° ë° ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ì„ íƒêµ¬ì„± ì—…ë°ì´íŠ¸: ì ì ˆí•œ YAML íŒŒì¼ í¸ì§‘ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •: model ë° served_model_name í•„ë“œ ì—…ë°ì´íŠ¸ë¦¬ì†ŒìŠ¤ êµ¬ì„±: GPU í• ë‹¹ ë° ë©”ëª¨ë¦¬ ì„¤ì • ì¡°ì •  DeepSeek-R1 70B ëª¨ë¸ ì˜ˆ:  Common: model: deepseek-ai/DeepSeek-R1-Distill-Llama-70B max-model-len: 32768 tensor-parallel-size: 4 Frontend: served_model_name: deepseek-ai/DeepSeek-R1-Distill-Llama-70B VllmWorker: ServiceArgs: resources: gpu: '4'   ","version":"Next","tagName":"h3"},{"title":"êµ¬ì„± ì˜µì…˜â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#êµ¬ì„±-ì˜µì…˜","content":" ì£¼ìš” êµ¬ì„±ì€ terraform/blueprint.tfvarsì— ìˆìŠµë‹ˆë‹¤:  # Dynamo ë°°í¬ì— í•„ìš” enable_dynamo_stack = true enable_argocd = true # Dynamo í”Œë«í¼ ë²„ì „ dynamo_stack_version = &quot;v0.4.1&quot; # í•„ìˆ˜ ì¸í”„ë¼ êµ¬ì„± ìš”ì†Œ enable_aws_efs_csi_driver = true enable_aws_efa_k8s_device_plugin = true enable_ai_ml_observability_stack = true   ","version":"Next","tagName":"h3"},{"title":"ë¬¸ì œ í•´ê²°â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ë¬¸ì œ-í•´ê²°","content":" ","version":"Next","tagName":"h2"},{"title":"ì¼ë°˜ì ì¸ ë¬¸ì œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì¼ë°˜ì ì¸-ë¬¸ì œ","content":" GPU ë…¸ë“œ ì‚¬ìš© ë¶ˆê°€: Karpenter ë¡œê·¸ ë° ì¸ìŠ¤í„´ìŠ¤ ê°€ìš©ì„± í™•ì¸Pod ì‹¤íŒ¨: ë¦¬ì†ŒìŠ¤ ì œí•œ ë° í´ëŸ¬ìŠ¤í„° ìš©ëŸ‰ í™•ì¸ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HuggingFace í† í° ë° ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸API 503 ì˜¤ë¥˜: ëª¨ë¸ ë¡œë”© ëŒ€ê¸° ë˜ëŠ” ì›Œì»¤ ìƒíƒœ í™•ì¸  ","version":"Next","tagName":"h3"},{"title":"ë””ë²„ê·¸ ëª…ë ¹â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ë””ë²„ê·¸-ëª…ë ¹","content":" # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸ kubectl get nodes kubectl get pods -n dynamo-cloud # ë¡œê·¸ ë³´ê¸° kubectl logs -n argocd -l app.kubernetes.io/name=argocd-server kubectl logs -n dynamo-cloud -l app=vllm-worker # ë°°í¬ í™•ì¸ kubectl get dynamographdeployment -n dynamo-cloud kubectl describe dynamographdeployment &lt;name&gt; -n dynamo-cloud   ","version":"Next","tagName":"h3"},{"title":"ë…¸ë“œ ì„ íƒ ë° ì‚¬ìš©ì ì •ì˜â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ë…¸ë“œ-ì„ íƒ-ë°-ì‚¬ìš©ì-ì •ì˜","content":" ","version":"Next","tagName":"h2"},{"title":"ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì„ íƒâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì¸ìŠ¤í„´ìŠ¤-ìœ í˜•-ì„ íƒ","content":" DynamoGraphDeploymentì—ì„œ nodeSelectorë¥¼ ìˆ˜ì •í•˜ì—¬ Dynamo êµ¬ì„± ìš”ì†Œê°€ ë°°í¬ë˜ëŠ” Karpenter ë…¸ë“œ í’€ì„ ì‚¬ìš©ì ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  # ì˜ˆ: G5 ì¸ìŠ¤í„´ìŠ¤ì— GPU ì›Œì»¤ ë°°í¬ VllmWorker: extraPodSpec: nodeSelector: karpenter.sh/nodepool: g5-gpu-karpenter resources: requests: gpu: &quot;1&quot; # ì˜ˆ: CPU ì¸ìŠ¤í„´ìŠ¤ì— í”„ë¡ íŠ¸ì—”ë“œ ë°°í¬ Frontend: extraPodSpec: nodeSelector: karpenter.sh/nodepool: cpu-karpenter   ì‚¬ìš© ê°€ëŠ¥í•œ ë…¸ë“œ í’€ (ê¸°ë³¸ ì¸í”„ë¼ì— êµ¬ì„±ë¨):  g5-gpu-karpenter: NVIDIA A10G GPUê°€ ìˆëŠ” G5 ì¸ìŠ¤í„´ìŠ¤g6-gpu-karpenter: NVIDIA L4 GPUê°€ ìˆëŠ” G6 ì¸ìŠ¤í„´ìŠ¤ (êµ¬ì„±ëœ ê²½ìš°)cpu-karpenter: í”„ë¡ íŠ¸ì—”ë“œìš© CPU ì „ìš© ì¸ìŠ¤í„´ìŠ¤  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ìš©ì ì •ì˜ ê°œë°œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì‚¬ìš©ì-ì •ì˜-ê°œë°œ","content":" ê³ ê¸‰ ì‚¬ìš©ì ì •ì˜ ë° ê°œë°œì˜ ê²½ìš°:  ì†ŒìŠ¤ ì½”ë“œ: ì „ì²´ Dynamo ì†ŒìŠ¤ ì½”ë“œëŠ” í¬ê´„ì ì¸ ë¬¸ì„œ ë° ì˜ˆì œì™€ í•¨ê»˜ ~/dynamoì—ì„œ ì‚¬ìš© ê°€ëŠ¥ë¸”ë£¨í”„ë¦°íŠ¸ ì˜ˆì œ: blueprints/inference/nvidia-dynamo/ í´ë”ì˜ ê° ì˜ˆì œì—ëŠ” ìì„¸í•œ README íŒŒì¼ í¬í•¨ì»¨í…Œì´ë„ˆ ì†ŒìŠ¤: ëª¨ë“  ì†ŒìŠ¤ ì½”ë“œëŠ” ì»¨í…Œì´ë„ˆ ë‚´ ì‚¬ìš©ì ì •ì˜ë¥¼ ìœ„í•´ NGC ì»¨í…Œì´ë„ˆì˜ /workspace/ì— í¬í•¨ë¨  íŠ¹ì • ì‚¬ìš©ì ì •ì˜ ì§€ì¹¨ì€ ê° ë¸”ë£¨í”„ë¦°íŠ¸ ì˜ˆì œì˜ ê°œë³„ README íŒŒì¼ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h3"},{"title":"ë‹¤ì¤‘ ë…¸ë“œ Tensor Parallelism ì œí•œ ì‚¬í•­â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ë‹¤ì¤‘-ë…¸ë“œ-tensor-parallelism-ì œí•œ-ì‚¬í•­","content":" ","version":"Next","tagName":"h2"},{"title":"ë‹¤ì¤‘ ë ˆí”Œë¦¬ì¹´ vs ë‹¤ì¤‘ ë…¸ë“œ ì´í•´â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ë‹¤ì¤‘-ë ˆí”Œë¦¬ì¹´-vs-ë‹¤ì¤‘-ë…¸ë“œ-ì´í•´","content":" ë‹¤ì¤‘ ë ˆí”Œë¦¬ì¹´ ë°°í¬ (ì˜ˆì œì—ì„œ ì œê³µí•˜ëŠ” ê²ƒ)ì™€ ì§„ì •í•œ ë‹¤ì¤‘ ë…¸ë“œ tensor parallelism (íŠ¹ìˆ˜ ì¸í”„ë¼ê°€ í•„ìš”)ì„ êµ¬ë¶„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤:  ì˜ˆì œì—ì„œ ì œê³µí•˜ëŠ” ê²ƒ (ë‹¤ì¤‘ ë ˆí”Œë¦¬ì¹´)â€‹  ì—¬ëŸ¬ ë…ë¦½ ì›Œì»¤: ê° ì›Œì»¤ ë ˆí”Œë¦¬ì¹´ëŠ” ì™„ì „í•œ ëª¨ë¸ì„ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ (TP=1)ê³ ê°€ìš©ì„±: ê°œë³„ ì›Œì»¤ê°€ ì‹¤íŒ¨í•´ë„ ì„œë¹„ìŠ¤ ê³„ì† ìš´ì˜ë¡œë“œ ë°¸ëŸ°ì‹±: ì²˜ë¦¬ëŸ‰ ì¦ê°€ë¥¼ ìœ„í•´ ì›Œì»¤ ê°„ ìš”ì²­ ë¶„ì‚°KV ì¸ì‹ ë¼ìš°íŒ…: ì„±ëŠ¥ ê·¹ëŒ€í™”ë¥¼ ìœ„í•œ ìºì‹œ ì¤‘ë³µ ê¸°ë°˜ ì§€ëŠ¥í˜• ìš”ì²­ ë¼ìš°íŒ…Kubernetes ë„¤ì´í‹°ë¸Œ: í‘œì¤€ Kubernetes ë°°í¬ì™€ ì›í™œí•˜ê²Œ ì‘ë™  ì˜ˆì œì—ì„œ ì œê³µí•˜ì§€ ì•ŠëŠ” ê²ƒ (ì§„ì •í•œ ë‹¤ì¤‘ ë…¸ë“œ TP)â€‹  êµì°¨ ë…¸ë“œ ëª¨ë¸ ìƒ¤ë”©: ëª¨ë¸ì´ ì—¬ëŸ¬ ë…¸ë“œì— ê±¸ì³ ë¶„í• ë˜ì§€ ì•ŠìŒëŒ€í˜• ëª¨ë¸ì„ ìœ„í•œ ë©”ëª¨ë¦¬ í™•ì¥: ê° ì›Œì»¤ê°€ ì™„ì „í•œ ëª¨ë¸ì„ ë§ì¶°ì•¼ í•¨ (êµì°¨ ë…¸ë“œ ë©”ëª¨ë¦¬ ê³µìœ  ì—†ìŒ)ë…¸ë“œ ê°„ Tensor Parallelism: êµì°¨ ë…¸ë“œ í…ì„œ ì—°ì‚° ì—†ìŒ  ","version":"Next","tagName":"h3"},{"title":"í˜„ì¬ Kubernetes ì œí•œ ì‚¬í•­â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#í˜„ì¬-kubernetes-ì œí•œ-ì‚¬í•­","content":" KubernetesëŠ” í˜„ì¬ ì§„ì •í•œ ë‹¤ì¤‘ ë…¸ë“œ tensor parallelismì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ê¸°ìˆ ì  ì œì•½ì´ ìˆìŠµë‹ˆë‹¤:  ì¸í”„ë¼ ìš”êµ¬ ì‚¬í•­â€‹  ì§„ì •í•œ ë‹¤ì¤‘ ë…¸ë“œ tensor parallelismì—ëŠ” ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:  MPI/Slurm í™˜ê²½: ì¡°ì •ëœ ë¶„ì‚° ëª¨ë¸ ë¡œë”©ì„ ìœ„í•œ mpirun ë˜ëŠ” srun ì‚¬ìš©ë™ê¸°í™”ëœ ì´ˆê¸°í™”: ëª¨ë“  ì°¸ì—¬ ë…¸ë“œê°€ ë™ì‹œì— ì‹œì‘í•˜ê³  ì¡°ì • ìœ ì§€í•´ì•¼ í•¨ì €ì§€ì—° ì¸í„°ì»¤ë„¥íŠ¸: InfiniBand, NVLink ë˜ëŠ” ìœ ì‚¬í•œ ê³ ì„±ëŠ¥ ë„¤íŠ¸ì›Œí‚¹ í•„ìš”ê³µìœ  í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹: K8sì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” í”„ë¡œì„¸ìŠ¤ ê·¸ë£¹ ê´€ë¦¬ê°€ í•„ìš”í•œ ë¶„ì‚° í›ˆë ¨/ì¶”ë¡  í”„ë ˆì„ì›Œí¬  Kubernetesê°€ ì´ë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ìœ  (í˜„ì¬)â€‹  Pod ê²©ë¦¬: Kubernetes PodëŠ” ê²©ë¦¬ëœ ë‹¨ìœ„ë¡œ ì„¤ê³„ë˜ì–´ êµì°¨ Pod í…ì„œ ì—°ì‚°ì´ ì–´ë ¤ì›€ë™ì  ìŠ¤ì¼€ì¤„ë§: K8s ë™ì  Pod ë°°ì¹˜ê°€ ë‹¤ì¤‘ ë…¸ë“œ TPì— í•„ìš”í•œ ì •ì , ì¡°ì •ëœ ì‹œì‘ê³¼ ì¶©ëŒë„¤íŠ¸ì›Œí¬ ì¶”ìƒí™”: K8s ë„¤íŠ¸ì›Œí‚¹ ì¶”ìƒí™”ê°€ íš¨ìœ¨ì ì¸ í…ì„œ í†µì‹ ì— í•„ìš”í•œ ì €ìˆ˜ì¤€ ë„¤íŠ¸ì›Œí¬ í”„ë¦¬ë¯¸í‹°ë¸Œë¥¼ ë…¸ì¶œí•˜ì§€ ì•ŠìŒMPI í†µí•© ëˆ„ë½: Kubernetesì— ë„¤ì´í‹°ë¸Œ MPI ì‘ì—… ê´€ë¦¬ ì—†ìŒ (MPI-Operatorì™€ ê°™ì€ í”„ë¡œì íŠ¸ê°€ ì¡´ì¬í•˜ì§€ë§Œ ì¶”ë¡ ì— ë„ë¦¬ ì±„íƒë˜ì§€ ì•ŠìŒ)  ","version":"Next","tagName":"h3"},{"title":"Dynamo ë°±ì—”ë“œì˜ í˜„ì¬ ì§€ì›â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#dynamo-ë°±ì—”ë“œì˜-í˜„ì¬-ì§€ì›","content":" ê³µì‹ Dynamo ë¬¸ì„œ ë° ì˜ˆì œì— ë”°ë¥´ë©´ ê° ë°±ì—”ë“œê°€ ì§€ì›í•˜ëŠ” ê²ƒ:  SGLang ë‹¤ì¤‘ ë…¸ë“œ ì§€ì›â€‹  ìƒíƒœ: ë‹¤ì¤‘ ë…¸ë“œ tensor parallelism ì™„ì „ ì§€ì›ìš”êµ¬ ì‚¬í•­: MPI ì¡°ì •ì´ ìˆëŠ” Slurm í™˜ê²½êµ¬ì„±: --nnodes, --node-rank ë° --dist-init-addr íŒŒë¼ë¯¸í„° ì‚¬ìš©ì˜ˆ: TP16 (ì´ 16 GPU)ìœ¼ë¡œ 4ê°œ ë…¸ë“œì— ê±¸ì¹œ DeepSeek-R1Kubernetes: ì§€ì›ë˜ì§€ ì•ŠìŒ - Slurm/MPI í™˜ê²½ í•„ìš”  # SGLang ë‹¤ì¤‘ ë…¸ë“œ ì˜ˆ (Slurmë§Œ) python3 -m dynamo.sglang.worker \\ --model-path /model/ \\ --tp 16 \\ --nnodes 2 \\ --node-rank 0 \\ --dist-init-addr ${HEAD_NODE_IP}:29500   TensorRT-LLM ë‹¤ì¤‘ ë…¸ë“œ ì§€ì›â€‹  ìƒíƒœ: WideEP (Wide Expert Parallelism)ë¡œ ì™„ì „ ì§€ì›ìš”êµ¬ ì‚¬í•­: MPI ëŸ°ì²˜(srun ë˜ëŠ” mpirun)ê°€ ìˆëŠ” Slurm í™˜ê²½êµ¬ì„±: ë‹¤ì¤‘ ë…¸ë“œ TP16/EP16 êµ¬ì„± ì‚¬ìš© ê°€ëŠ¥ì˜ˆ: 4x GB200 ë…¸ë“œì— ê±¸ì¹œ DeepSeek-R1Kubernetes: ì§€ì›ë˜ì§€ ì•ŠìŒ - MPI ì¡°ì • í•„ìš”  # TRT-LLM ë‹¤ì¤‘ ë…¸ë“œ ì˜ˆ (Slurmë§Œ) srun --nodes=4 --ntasks-per-node=4 \\ python3 -m dynamo.trtllm \\ --model-path /model/ \\ --engine-config wide_ep_config.yaml   vLLM ë‹¤ì¤‘ ë…¸ë“œ ì§€ì›â€‹  ìƒíƒœ: í˜„ì¬ ì§„ì •í•œ ë‹¤ì¤‘ ë…¸ë“œ tensor parallelism ì§€ì›ë˜ì§€ ì•ŠìŒí˜„ì¬ ê¸°ëŠ¥: ë‹¨ì¼ ë…¸ë“œ tensor parallelismë§Œ (ê°™ì€ ë…¸ë“œì˜ ì—¬ëŸ¬ GPU)êµ¬í˜„: ê³ ê°€ìš©ì„±ì„ ìœ„í•œ ë‹¤ì¤‘ ë ˆí”Œë¦¬ì¹´ (ê° ë ˆí”Œë¦¬ì¹´ê°€ ì „ì²´ ëª¨ë¸ ì‹¤í–‰)í–¥í›„: í–¥í›„ vLLM ë¦´ë¦¬ìŠ¤ì—ì„œ ì¶”ê°€ë  ìˆ˜ ìˆìŒ  ","version":"Next","tagName":"h3"},{"title":"ëŒ€í˜• ëª¨ë¸ì„ ìœ„í•œ í•´ê²° ë°©ë²•â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ëŒ€í˜•-ëª¨ë¸ì„-ìœ„í•œ-í•´ê²°-ë°©ë²•","content":" ë‹¨ì¼ ë…¸ë“œì— ë§ì§€ ì•ŠëŠ” ëª¨ë¸ì„ ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ê²½ìš° ë‹¤ìŒ ëŒ€ì•ˆì„ ê³ ë ¤í•˜ì‹­ì‹œì˜¤:  1. ê³ ë©”ëª¨ë¦¬ ë‹¨ì¼ ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤â€‹  ëŒ€ìš©ëŸ‰ GPU ë©”ëª¨ë¦¬ê°€ ìˆëŠ” AWS ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©:  # ì˜ˆ: 8x H100 (ê° 80GB = ì´ 640GB)ì´ ìˆëŠ” P5.48xlarge extraPodSpec: nodeSelector: karpenter.sh/nodepool: p5-gpu-karpenter node.kubernetes.io/instance-type: p5.48xlarge resources: requests: gpu: &quot;8&quot;   2. ëª¨ë¸ ìµœì í™” ê¸°ìˆ â€‹  ì–‘ìí™”: FP16, FP8 ë˜ëŠ” INT8 ì–‘ìí™”ëœ ëª¨ë¸ ì‚¬ìš©ëª¨ë¸ í”„ë£¨ë‹: ëœ ì¤‘ìš”í•œ íŒŒë¼ë¯¸í„° ì œê±°LoRA/QLoRA: íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ ì‚¬ìš©  3. Slurm ê¸°ë°˜ ë°°í¬â€‹  ì§„ì •í•œ ë‹¤ì¤‘ ë…¸ë“œ TPê°€ í•„ìš”í•œ ëª¨ë¸ì˜ ê²½ìš° Kubernetes ì™¸ë¶€ì— ë°°í¬:  # Slurmê³¼ í•¨ê»˜ ê³µì‹ Dynamo ì˜ˆì œ ì‚¬ìš© cd ~/dynamo/docs/components/backends/trtllm/ ./srun_disaggregated.sh # 8ë…¸ë“œ ë¶„ë¦¬ ë°°í¬   4. ë¶„ë¦¬ëœ ì•„í‚¤í…ì²˜â€‹  ë” ë‚˜ì€ ë¦¬ì†ŒìŠ¤ í™œìš©ì„ ìœ„í•´ ë¶„ë¦¬ëœ ì˜ˆì œ ì‚¬ìš©:  Prefill ì›Œì»¤: ì…ë ¥ ì²˜ë¦¬ ë‹´ë‹¹ (ë” ì‘ì€ ì¸ìŠ¤í„´ìŠ¤ ê°€ëŠ¥)Decode ì›Œì»¤: í† í° ìƒì„± ë‹´ë‹¹ (ì²˜ë¦¬ëŸ‰ ìµœì í™”)ë…ë¦½ì  í™•ì¥: ì›Œí¬ë¡œë“œì— ë”°ë¼ ê° êµ¬ì„± ìš”ì†Œ í™•ì¥  ","version":"Next","tagName":"h3"},{"title":"í–¥í›„ ê°œë°œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#í–¥í›„-ê°œë°œ","content":" Kubernetesì—ì„œì˜ ë‹¤ì¤‘ ë…¸ë“œ Tensor Parallelismì€ ë‹¤ìŒì„ í†µí•´ í–¥í›„ ë²„ì „ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤:  í–¥ìƒëœ MPI í†µí•©: ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ Kubeflowì˜ MPI-Operatorì™€ ê°™ì€ í”„ë¡œì íŠ¸ë„¤ì´í‹°ë¸Œ K8s ì§€ì›: Kubernetes SIG-Schedulingì´ gang scheduling ë° ì¡°ì •ëœ Pod ì‹œì‘ ì‘ì—… ì¤‘ë²¤ë” ì†”ë£¨ì…˜: í´ë¼ìš°ë“œ ì œê³µìê°€ ê´€ë¦¬í˜• ì¶”ë¡ ì„ ìœ„í•œ ì‚¬ìš©ì ì •ì˜ ì†”ë£¨ì…˜ ê°œë°œ ê°€ëŠ¥í”„ë ˆì„ì›Œí¬ ì§„í™”: ì¶”ë¡  í”„ë ˆì„ì›Œí¬ê°€ Kubernetes ë„¤ì´í‹°ë¸Œ ë¶„ì‚° ì‹¤í–‰ ì¶”ê°€  ","version":"Next","tagName":"h3"},{"title":"ê¶Œì¥ ì‚¬í•­â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ê¶Œì¥-ì‚¬í•­","content":" í˜„ì¬ ë°°í¬ì˜ ê²½ìš°:  ì†Œí˜• ~ ì¤‘í˜• ëª¨ë¸ (70B ì´í•˜): ë‹¤ì¤‘ GPU ì¸ìŠ¤í„´ìŠ¤ë¡œ ë‹¨ì¼ ë…¸ë“œ ë°°í¬ ì‚¬ìš©ê³ ê°€ìš©ì„± í•„ìš”: KV ë¼ìš°íŒ…ì´ ìˆëŠ” ë‹¤ì¤‘ ë ˆí”Œë¦¬ì¹´ ì˜ˆì œ ì‚¬ìš©ëŒ€í˜• ëª¨ë¸ (70B ì´ìƒ): Kubernetes ì™¸ë¶€ Slurm ê¸°ë°˜ ë°°í¬ ê³ ë ¤ìµœëŒ€ ì„±ëŠ¥: ìµœì í™”ëœ ì›Œì»¤ ë¹„ìœ¨ë¡œ ë¶„ë¦¬ëœ ì•„í‚¤í…ì²˜ ì‚¬ìš©  í–¥í›„ ê°œë°œ ëª¨ë‹ˆí„°ë§:  Kubernetes ë‹¤ì¤‘ ë…¸ë“œ TP ì—…ë°ì´íŠ¸ëŠ” Dynamo ë¦´ë¦¬ìŠ¤ íŒ”ë¡œìš°TensorRT-LLM ë° vLLM ë¡œë“œë§µ í™•ì¸gang scheduling ê°œì„ ì„ ìœ„í•œ Kubernetes SIG-Scheduling ëª¨ë‹ˆí„°ë§  ","version":"Next","tagName":"h3"},{"title":"ëŒ€ì²´ ë°°í¬ ì˜µì…˜â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ëŒ€ì²´-ë°°í¬-ì˜µì…˜","content":" ","version":"Next","tagName":"h2"},{"title":"ê¸°ì¡´ EKS í´ëŸ¬ìŠ¤í„°ì˜ ê²½ìš°â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ê¸°ì¡´-eks-í´ëŸ¬ìŠ¤í„°ì˜-ê²½ìš°","content":" GPU ë…¸ë“œê°€ ìˆëŠ” EKS í´ëŸ¬ìŠ¤í„°ê°€ ì´ë¯¸ ìˆê³  ë” ê°„ë‹¨í•œ ì ‘ê·¼ ë°©ì‹ì„ ì„ í˜¸í•˜ëŠ” ê²½ìš°:  ì§ì ‘ Helm ì„¤ì¹˜: dynamo ì†ŒìŠ¤ ì €ì¥ì†Œì—ì„œ ì§ì ‘ ê³µì‹ NVIDIA Dynamo Helm ì°¨íŠ¸ ì‚¬ìš©ìˆ˜ë™ ì„¤ì •: Kubernetes ë°°í¬ì— ëŒ€í•œ ì—…ìŠ¤íŠ¸ë¦¼ NVIDIA Dynamo ë¬¸ì„œ íŒ”ë¡œìš°ì‚¬ìš©ì ì •ì˜ í†µí•©: ê¸°ì¡´ ì¸í”„ë¼ì— Dynamo êµ¬ì„± ìš”ì†Œ í†µí•©  ","version":"Next","tagName":"h3"},{"title":"ì´ ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ”?â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì´-ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼-ì‚¬ìš©í•˜ëŠ”-ì´ìœ ëŠ”","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” ë‹¤ìŒì„ ì›í•˜ëŠ” ì‚¬ìš©ìë¥¼ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤:  ì™„ì „í•œ ì¸í”„ë¼: VPCì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ì¶”ë¡ ê¹Œì§€ ì—”ë“œíˆ¬ì—”ë“œ ì„¤ì •í”„ë¡œë•ì…˜ ì¤€ë¹„: ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ëª¨ë‹ˆí„°ë§, ë³´ì•ˆ ë° í™•ì¥ì„±AWS í†µí•©: EKS, ECR, EFA ë° ê¸°íƒ€ AWS ì„œë¹„ìŠ¤ì— ìµœì í™”ëª¨ë²” ì‚¬ë¡€: ai-on-eks íŒ¨í„´ ë° AWS ê¶Œì¥ ì‚¬í•­ ì¤€ìˆ˜  ","version":"Next","tagName":"h3"},{"title":"ì°¸ì¡°â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì°¸ì¡°","content":" ","version":"Next","tagName":"h2"},{"title":"ê³µì‹ NVIDIA ë¦¬ì†ŒìŠ¤â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ê³µì‹-nvidia-ë¦¬ì†ŒìŠ¤","content":" ë¬¸ì„œ:  NVIDIA Dynamo ê³µì‹ ë¬¸ì„œ: ì „ì²´ í”Œë«í¼ ë¬¸ì„œNVIDIA Developer Blog: ì†Œê°œ ë° ì•„í‚¤í…ì²˜ ê°œìš”NVIDIA Dynamo ì œí’ˆ í˜ì´ì§€: ê³µì‹ ì œí’ˆ ì •ë³´  ì†ŒìŠ¤ ì½”ë“œ:  NVIDIA Dynamo GitHub: ì†ŒìŠ¤ ì½”ë“œê°€ ìˆëŠ” ë©”ì¸ ì €ì¥ì†ŒNVIDIA NIXL Library: ì €ì§€ì—° í†µì‹ ì„ ìœ„í•œ NVIDIA Inference Xfer Library  ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë° Helm ì°¨íŠ¸:  Dynamo Collection (NGC): Dynamo ë¦¬ì†ŒìŠ¤ì˜ ì „ì²´ ì»¬ë ‰ì…˜Dynamo Platform Helm Chart: ê³µì‹ Kubernetes ë°°í¬vLLM Runtime Container: vLLM ë°±ì—”ë“œ (v0.4.1)SGLang Runtime Container: SGLang ë°±ì—”ë“œ (v0.4.1)TensorRT-LLM Runtime Container: TRT-LLM ë°±ì—”ë“œ (v0.4.1)  ","version":"Next","tagName":"h3"},{"title":"AI-on-EKS ë¸”ë£¨í”„ë¦°íŠ¸ ë¦¬ì†ŒìŠ¤â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ai-on-eks-ë¸”ë£¨í”„ë¦°íŠ¸-ë¦¬ì†ŒìŠ¤","content":" ì¸í”„ë¼ ë° ì˜ˆì œ:  AI-on-EKS Repository: ë©”ì¸ ë¸”ë£¨í”„ë¦°íŠ¸ ì €ì¥ì†ŒDynamo Blueprint: ì˜ˆì œê°€ í¬í•¨ëœ ì „ì²´ ë¸”ë£¨í”„ë¦°íŠ¸Infrastructure Code: Terraform ë° ë°°í¬ ìŠ¤í¬ë¦½íŠ¸  ì˜ˆì œ ë¬¸ì„œ:  Hello World: CPU ì „ìš© í…ŒìŠ¤íŠ¸ ì˜ˆì œvLLM Example: vLLM ì§‘ê³„ ì„œë¹™SGLang Example: RadixAttention ìºì‹±TensorRT-LLM Example: ìµœì í™” ì¶”ë¡ Multi-Replica vLLM: ê³ ê°€ìš©ì„± ë°°í¬  ","version":"Next","tagName":"h3"},{"title":"ê´€ë ¨ ê¸°ìˆ â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ê´€ë ¨-ê¸°ìˆ ","content":" ì¶”ë¡  í”„ë ˆì„ì›Œí¬:  vLLM: ê³ ì²˜ë¦¬ëŸ‰ LLM ì¶”ë¡  ì—”ì§„SGLang: RadixAttentionì´ ìˆëŠ” êµ¬ì¡°í™”ëœ ìƒì„±TensorRT-LLM: NVIDIAì˜ ìµœì í™”ëœ ì¶”ë¡  ë¼ì´ë¸ŒëŸ¬ë¦¬  Kubernetes ë° AWS:  Amazon EKS: ê´€ë¦¬í˜• Kubernetes ì„œë¹„ìŠ¤Karpenter: Kubernetes ë…¸ë“œ ì˜¤í† ìŠ¤ì¼€ì¼ë§ArgoCD: GitOps ì§€ì†ì  ë°°í¬  ","version":"Next","tagName":"h3"},{"title":"ë‹¤ìŒ ë‹¨ê³„â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ë‹¤ìŒ-ë‹¨ê³„","content":" ì˜ˆì œ íƒìƒ‰: GitHub ì €ì¥ì†Œì˜ ì˜ˆì œ í´ë” í™•ì¸ë°°í¬ í™•ì¥: ëŒ€í˜• ëª¨ë¸ì„ ìœ„í•œ ë‹¤ì¤‘ ë…¸ë“œ ì„¤ì • êµ¬ì„±ì• í”Œë¦¬ì¼€ì´ì…˜ í†µí•©: ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ì— ì—°ê²°ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§: ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•´ Grafana ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ë¹„ìš© ìµœì í™”: ì˜¤í† ìŠ¤ì¼€ì¼ë§ ë° ë¦¬ì†ŒìŠ¤ ìµœì í™” êµ¬í˜„  ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA Dynamo","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-dynamo#ì •ë¦¬","content":" NVIDIA Dynamo ë°°í¬ê°€ ì™„ë£Œë˜ë©´ í†µí•© ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¦¬ì†ŒìŠ¤ë¥¼ ì œê±°í•©ë‹ˆë‹¤:  cd infra/nvidia-dynamo ./cleanup.sh   ì •ë¦¬ë˜ëŠ” ê²ƒ (ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ):  Dynamo ì˜ˆì œ: ë°°í¬ëœ ëª¨ë“  ì¶”ë¡  ê·¸ë˜í”„ ë° ì›Œí¬ë¡œë“œDynamo Platform: Operator, API Store ë° ì§€ì› ì„œë¹„ìŠ¤ArgoCD ì• í”Œë¦¬ì¼€ì´ì…˜: GitOps ê´€ë¦¬ ë¦¬ì†ŒìŠ¤Kubernetes ë¦¬ì†ŒìŠ¤: ë„¤ì„ìŠ¤í˜ì´ìŠ¤, ì‹œí¬ë¦¿ ë° êµ¬ì„±ì¸í”„ë¼: EKS í´ëŸ¬ìŠ¤í„°, VPC, ë³´ì•ˆ ê·¸ë£¹ ë° ëª¨ë“  AWS ë¦¬ì†ŒìŠ¤ë¹„ìš© ìµœì í™”: ì”ë¥˜ ë¦¬ì†ŒìŠ¤ê°€ ê³„ì† ì²­êµ¬ë˜ì§€ ì•Šë„ë¡ ë³´ì¥  ê¸°ëŠ¥:  ì§€ëŠ¥í˜• ìˆœì„œ: ì¢…ì†ì„±ì„ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì •ë¦¬ì•ˆì „ ê²€ì‚¬: ì‚­ì œ ì‹œë„ ì „ ë¦¬ì†ŒìŠ¤ ì¡´ì¬ í™•ì¸ì§„í–‰ ìƒí™© í”¼ë“œë°±: ì •ë¦¬ ì§„í–‰ ìƒí™© ë° ë°œìƒí•œ ë¬¸ì œ í‘œì‹œì™„ì „ ì œê±°: ìˆ˜ë™ ì •ë¦¬ ë‹¨ê³„ ë¶ˆí•„ìš”  ì†Œìš” ì‹œê°„: ì „ì²´ ì¸í”„ë¼ í•´ì œì— ~10-15ë¶„  ì´ ë°°í¬ëŠ” Karpenter ìë™ í™•ì¥, EFA ë„¤íŠ¸ì›Œí‚¹ ë° ì›í™œí•œ AWS ì„œë¹„ìŠ¤ í†µí•©ì„ í¬í•¨í•œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ê¸°ëŠ¥ê³¼ í•¨ê»˜ Amazon EKSì—ì„œ í”„ë¡œë•ì…˜ ì¤€ë¹„ëœ NVIDIA Dynamo í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤. ","version":"Next","tagName":"h2"},{"title":"Amazon EKSì˜ NVIDIA NIM Operator","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator","content":"","keywords":"","version":"Next"},{"title":"NVIDIA NIMì´ë€?â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#nvidia-nimì´ë€","content":" NVIDIA NIM (NVIDIA Inference Microservices)ì€ ìì²´ í™˜ê²½ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ë° ê¸°íƒ€ AI ëª¨ë¸ì„ ë” ì‰½ê²Œ ë°°í¬í•˜ê³  í˜¸ìŠ¤íŒ…í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì»¨í…Œì´ë„ˆí™”ëœ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì§‘í•©ì…ë‹ˆë‹¤. NIMì€ ì±—ë´‡ ë° AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ ê°™ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ í‘œì¤€ API(OpenAI ë˜ëŠ” ê¸°íƒ€ AI ì„œë¹„ìŠ¤ì™€ ìœ ì‚¬)ë¥¼ ê°œë°œìì—ê²Œ ì œê³µí•˜ë©´ì„œ, ê³ ì„±ëŠ¥ ì¶”ë¡ (Inference)ì„ ìœ„í•´ NVIDIAì˜ GPU ê°€ì†ì„ í™œìš©í•©ë‹ˆë‹¤. ë³¸ì§ˆì ìœ¼ë¡œ NIMì€ ëª¨ë¸ ëŸ°íƒ€ì„ ë° ìµœì í™”ì˜ ë³µì¡ì„±ì„ ì¶”ìƒí™”í•˜ì—¬, ë‚´ë¶€ì ìœ¼ë¡œ ìµœì í™”ëœ ë°±ì—”ë“œ(ì˜ˆ: TensorRT-LLM, FasterTransformer ë“±)ë¥¼ í†µí•´ ë¹ ë¥¸ ì¶”ë¡  ê²½ë¡œë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Kubernetesìš© NVIDIA NIM Operatorâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#kubernetesìš©-nvidia-nim-operator","content":" NVIDIA NIM OperatorëŠ” Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ NVIDIA NIM ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ì˜ ë°°í¬, í™•ì¥ ë° ê´€ë¦¬ë¥¼ ìë™í™”í•˜ëŠ” Kubernetes ì˜¤í¼ë ˆì´í„°ì…ë‹ˆë‹¤.    ì»¨í…Œì´ë„ˆë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ê±°ë‚˜, GPU ë…¸ë“œë¥¼ í”„ë¡œë¹„ì €ë‹í•˜ê±°ë‚˜, ëª¨ë“  ëª¨ë¸ì— ëŒ€í•´ YAMLì„ ì‘ì„±í•˜ëŠ” ëŒ€ì‹ , NIM OperatorëŠ” ì„¸ ê°€ì§€ ì£¼ìš” Custom Resource Definition(CRD)ì„ ë„ì…í•©ë‹ˆë‹¤:  NIMCacheNIMServiceNIMPipeline  ì´ëŸ¬í•œ CRDë¥¼ í†µí•´ ë„¤ì´í‹°ë¸Œ Kubernetes êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë°°í¬ë¥¼ ì„ ì–¸ì ìœ¼ë¡œ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Operatorê°€ ì²˜ë¦¬í•˜ëŠ” ì‘ì—…:  NVIDIA GPU Cloud (NGC)ì—ì„œ ëª¨ë¸ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°ëª¨ë¸ ê°€ì¤‘ì¹˜ ë° ìµœì í™”ëœ ëŸ°íƒ€ì„ í”„ë¡œíŒŒì¼ ìºì‹±GPU í• ë‹¹ì„ í¬í•¨í•œ ëª¨ë¸ ì„œë¹™ Pod ì‹¤í–‰Kubernetes Servicesë¥¼ í†µí•œ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ ë…¸ì¶œì˜¤í† ìŠ¤ì¼€ì¼ë§ í†µí•© (ì˜ˆ: HPA + Karpenter)NIMPipelineì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ëª¨ë¸ì„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²´ì´ë‹  ","version":"Next","tagName":"h2"},{"title":"NIMCache - ë” ë¹ ë¥¸ ë¡œë“œ ì‹œê°„ì„ ìœ„í•œ ëª¨ë¸ ìºì‹±â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#nimcache---ë”-ë¹ ë¥¸-ë¡œë“œ-ì‹œê°„ì„-ìœ„í•œ-ëª¨ë¸-ìºì‹±","content":" NIMCache (nimcaches.apps.nvidia.com)ëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜, í† í¬ë‚˜ì´ì € ë° ëŸ°íƒ€ì„ ìµœì í™” ì—”ì§„ íŒŒì¼(ì˜ˆ: TensorRT-LLM í”„ë¡œíŒŒì¼)ì„ ê³µìœ  ì˜êµ¬ ë³¼ë¥¨ì— ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•˜ê³  ì €ì¥í•˜ëŠ” ì»¤ìŠ¤í…€ ë¦¬ì†ŒìŠ¤ì…ë‹ˆë‹¤.  ì´ë¥¼ í†µí•´ ë³´ì¥ë˜ëŠ” ì‚¬í•­:  ë” ë¹ ë¥¸ ì½œë“œ ìŠ¤íƒ€íŠ¸ ì‹œê°„: NGCì—ì„œ ë°˜ë³µ ë‹¤ìš´ë¡œë“œ ì—†ìŒë…¸ë“œì™€ ë ˆí”Œë¦¬ì¹´ ê°„ ìŠ¤í† ë¦¬ì§€ ì¬ì‚¬ìš©ì¤‘ì•™ ì§‘ì¤‘ì‹ ê³µìœ  ëª¨ë¸ ì €ì¥ì†Œ (ì¼ë°˜ì ìœ¼ë¡œ EKSì—ì„œ EFS ë˜ëŠ” FSx for Lustre ì‚¬ìš©)  ëª¨ë¸ í”„ë¡œíŒŒì¼ì€ íŠ¹ì • GPU(ì˜ˆ: A10G, L4) ë° ì •ë°€ë„(ì˜ˆ: FP16)ì— ìµœì í™”ë©ë‹ˆë‹¤. NIMCacheê°€ ìƒì„±ë˜ë©´ Operatorê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í”„ë¡œíŒŒì¼ì„ ê²€ìƒ‰í•˜ê³  í´ëŸ¬ìŠ¤í„°ì— ê°€ì¥ ì í•©í•œ í”„ë¡œíŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.  íŒ: í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” NIMCache ì‚¬ìš©ì„ ì ê·¹ ê¶Œì¥í•©ë‹ˆë‹¤. íŠ¹íˆ ì—¬ëŸ¬ ë ˆí”Œë¦¬ì¹´ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ ëª¨ë¸ì„ ìì£¼ ì¬ì‹œì‘í•˜ëŠ” ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"NIMService - ëª¨ë¸ ì„œë²„ ë°°í¬ ë° ê´€ë¦¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#nimservice---ëª¨ë¸-ì„œë²„-ë°°í¬-ë°-ê´€ë¦¬","content":" NIMService (nimservices.apps.nvidia.com)ëŠ” í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ NIM ëª¨ë¸ ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€, GPU ë¦¬ì†ŒìŠ¤, ë ˆí”Œë¦¬ì¹´ ìˆ˜ ë° ì„ íƒì ìœ¼ë¡œ NIMCache ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤.  ì£¼ìš” ì´ì :  Kubernetes YAMLì„ ì‚¬ìš©í•œ ì„ ì–¸ì  ëª¨ë¸ ë°°í¬GPU ë…¸ë“œì— ëŒ€í•œ ìë™ ë…¸ë“œ ìŠ¤ì¼€ì¤„ë§NIMCacheë¥¼ ì‚¬ìš©í•œ ê³µìœ  ìºì‹œ ì§€ì›HPA ë˜ëŠ” ì™¸ë¶€ íŠ¸ë¦¬ê±°ë¥¼ í†µí•œ ì˜¤í† ìŠ¤ì¼€ì¼ë§API ë…¸ì¶œì„ ìœ„í•œ ClusterIP ë˜ëŠ” Ingress ì§€ì›  ì˜ˆë¥¼ ë“¤ì–´, Meta Llama 3.1 8B Instruct ëª¨ë¸ì„ ë°°í¬í•˜ë ¤ë©´ ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:  ëª¨ë¸ì„ ì €ì¥í•  NIMCache (ì„ íƒ ì‚¬í•­ì´ì§€ë§Œ ê¶Œì¥)ìºì‹œëœ ëª¨ë¸ì„ ê°€ë¦¬í‚¤ê³  GPUë¥¼ í• ë‹¹í•˜ëŠ” NIMService  NIMCacheë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ Podê°€ ì‹œì‘ë  ë•Œë§ˆë‹¤ ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì–´ ì‹œì‘ ì§€ì—° ì‹œê°„ì´ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"NIMPipelineâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#nimpipeline","content":" NIMPipelineì€ ì—¬ëŸ¬ NIMService ë¦¬ì†ŒìŠ¤ë¥¼ ìˆœì„œê°€ ìˆëŠ” ì¶”ë¡  íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ê·¸ë£¹í™”í•  ìˆ˜ ìˆëŠ” ë˜ ë‹¤ë¥¸ CRDì…ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ì¤‘ ëª¨ë¸ ì›Œí¬í”Œë¡œìš°ì— ìœ ìš©í•©ë‹ˆë‹¤:  Retrieval-Augmented Generation (RAG)ì„ë² ë”© + LLM ì²´ì´ë‹ì „ì²˜ë¦¬ + ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸  ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” NIMCacheì™€ NIMServiceë¥¼ ì‚¬ìš©í•œ ë‹¨ì¼ ëª¨ë¸ ë°°í¬ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Amazon EKSì—ì„œì˜ ë°°í¬ íŒ¨í„´ ê°œìš”â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#amazon-eksì—ì„œì˜-ë°°í¬-íŒ¨í„´-ê°œìš”","content":" ì´ ë°°í¬ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” NVIDIA NIM Operatorë¥¼ ì‚¬ìš©í•˜ì—¬ Amazon EKSì—ì„œ ë‹¤ì¤‘ GPU ì§€ì›ê³¼ ë¹ ë¥¸ ì‹œì‘ ì‹œê°„ì„ ìœ„í•œ ìµœì í™”ëœ ëª¨ë¸ ìºì‹±ì„ í†µí•´ Meta Llama 3.1 8B Instruct ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.    ëª¨ë¸ì€ ë‹¤ìŒì„ ì‚¬ìš©í•˜ì—¬ ì„œë¹™ë©ë‹ˆë‹¤:  G5 ì¸ìŠ¤í„´ìŠ¤ (g5.12xlarge): 4ê°œì˜ NVIDIA A10G GPUê°€ ì¥ì°©ëœ ì¸ìŠ¤í„´ìŠ¤Tensor Parallelism (TP): 2ë¡œ ì„¤ì •ë˜ì–´ ëª¨ë¸ì´ 2ê°œì˜ GPUì—ì„œ ë³‘ë ¬ë¡œ ì‹¤í–‰ë¨ì˜êµ¬ ê³µìœ  ìºì‹œ: ì´ì „ì— ìƒì„±ëœ ì—”ì§„ íŒŒì¼ì„ ì¬ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì‹œì‘ ì†ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ Amazon EFSë¡œ ì§€ì›  ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†Œë¥¼ ê²°í•©í•˜ì—¬ ëª¨ë¸ì€ ë‹¤ìŒì„ ì§€ì›í•˜ëŠ” í™•ì¥ ê°€ëŠ¥í•œ Kubernetes ì›Œí¬ë¡œë“œë¡œ ë°°í¬ë©ë‹ˆë‹¤:  Karpenterë¥¼ í†µí•œ íš¨ìœ¨ì ì¸ GPU ìŠ¤ì¼€ì¤„ë§NIMCacheë¥¼ ì‚¬ìš©í•œ ë¹ ë¥¸ ëª¨ë¸ ë¡œë“œNIMServiceë¥¼ í†µí•œ í™•ì¥ ê°€ëŠ¥í•œ ì„œë¹™ ì—”ë“œí¬ì¸íŠ¸  ì°¸ê³ : ì„±ëŠ¥ ë° ë¹„ìš© ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ tensorParallelism ì„¤ì •ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•(ì˜ˆ: L4 GPUê°€ ìˆëŠ” G6)ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ê²½ê³  ì°¸ê³ : NVIDIA NIMì„ êµ¬í˜„í•˜ê¸° ì „ì— NVIDIA AI Enterpriseì˜ ì¼ë¶€ì´ë¯€ë¡œ í”„ë¡œë•ì…˜ ì‚¬ìš© ì‹œ ì ì¬ì ì¸ ë¹„ìš© ë° ë¼ì´ì„ ìŠ¤ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒì„ ì¸ì§€í•˜ì‹­ì‹œì˜¤. í‰ê°€ë¥¼ ìœ„í•´ NVIDIAëŠ” 90ì¼ê°„ NVIDIA AI Enterpriseë¥¼ ì‚¬ìš©í•´ ë³¼ ìˆ˜ ìˆëŠ” ë¬´ë£Œ í‰ê°€ ë¼ì´ì„ ìŠ¤ë¥¼ ì œê³µí•˜ë©°, íšŒì‚¬ ì´ë©”ì¼ë¡œ ë“±ë¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#ì†”ë£¨ì…˜-ë°°í¬","content":" ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Terraformì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒì„ í¬í•¨í•œ ì „ì²´ AWS ì¸í”„ë¼ë¥¼ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤:  í¼ë¸”ë¦­ ë° í”„ë¼ì´ë¹— ì„œë¸Œë„·ì´ ìˆëŠ” Amazon VPCAmazon EKS í´ëŸ¬ìŠ¤í„°Karpenterë¥¼ ì‚¬ìš©í•œ GPU ë…¸ë“œí’€ë‹¤ìŒê³¼ ê°™ì€ ì• ë“œì˜¨: NVIDIA device pluginEFS CSI driverNVIDIA NIM Operator  ë°ëª¨ë¡œì„œ Meta Llama-3.1 8B Instruct ëª¨ë¸ì´ NIMServiceë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ë˜ë©°, ì„ íƒì ìœ¼ë¡œ ì½œë“œ ìŠ¤íƒ€íŠ¸ ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ NIMCacheë¡œ ì§€ì›ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#ì‚¬ì „-ìš”êµ¬-ì‚¬í•­","content":" NVIDIA NIMì„ ì‹œì‘í•˜ê¸° ì „ì— ë‹¤ìŒì„ í™•ì¸í•˜ì‹­ì‹œì˜¤:  NVIDIA NIM ê³„ì • ì„¤ì • ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ë ¤ë©´ í´ë¦­í•˜ì‹­ì‹œì˜¤ NVIDIA AI Enterprise ê³„ì • NVIDIA AI Enterprise ê³„ì •ì— ë“±ë¡í•˜ì‹­ì‹œì˜¤. ê³„ì •ì´ ì—†ìœ¼ë©´ ì´ ë§í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€íŒ ê³„ì •ì— ê°€ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. NGC API í‚¤ NVIDIA AI Enterprise ê³„ì •ì— ë¡œê·¸ì¸í•©ë‹ˆë‹¤ NGC (NVIDIA GPU Cloud) í¬í„¸ë¡œ ì´ë™í•©ë‹ˆë‹¤ ê°œì¸ API í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤: ê³„ì • ì„¤ì •ìœ¼ë¡œ ì´ë™í•˜ê±°ë‚˜ ì§ì ‘ https://org.ngc.nvidia.com/setup/personal-keysë¡œ ì´ë™í•©ë‹ˆë‹¤&quot;Generate Personal Key&quot;ë¥¼ í´ë¦­í•©ë‹ˆë‹¤&quot;Services Included&quot; ë“œë¡­ë‹¤ìš´ì—ì„œ ìµœì†Œí•œ &quot;NGC Catalog&quot;ê°€ ì„ íƒë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤API í‚¤ë¥¼ ë³µì‚¬í•˜ê³  ì•ˆì „í•˜ê²Œ ì €ì¥í•©ë‹ˆë‹¤. í‚¤ëŠ” nvapi- ì ‘ë‘ì‚¬ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤ NGC API í‚¤ ê²€ì¦ ë° ì´ë¯¸ì§€ í’€ í…ŒìŠ¤íŠ¸ API í‚¤ê°€ ìœ íš¨í•˜ê³  ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´: NGC API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤: export NGC_API_KEY=&lt;your_api_key_here&gt; NVIDIA Container Registryì— Docker ì¸ì¦: echo &quot;$NGC_API_KEY&quot; | docker login nvcr.io --username '$oauthtoken' --password-stdin NGCì—ì„œ ì´ë¯¸ì§€ í’€ í…ŒìŠ¤íŠ¸: docker pull nvcr.io/nim/meta/llama3-8b-instruct:latest ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦´ í•„ìš” ì—†ì´, API í‚¤ê°€ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ìœ íš¨í•œì§€ë§Œ í™•ì¸í•˜ë©´ ë©ë‹ˆë‹¤.  ì´ íŠœí† ë¦¬ì–¼ì„ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤  ê´€ë¦¬ì ê¶Œí•œê³¼ ë™ë“±í•œ í™œì„± AWS ê³„ì •aws clikubectlTerraform  ","version":"Next","tagName":"h3"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#ë°°í¬","content":" ai-on-eks ì €ì¥ì†Œë¥¼ í´ë¡ í•©ë‹ˆë‹¤. ì´ ì €ì¥ì†Œì—ëŠ” ì´ ë°°í¬ íŒ¨í„´ì„ ìœ„í•œ Terraform ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:  git clone https://github.com/awslabs/ai-on-eks.git   NVIDIA NIM ë°°í¬ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ê³  ì¸í”„ë¼ë¥¼ ë°°í¬í•˜ëŠ” ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:  cd ai-on-eks/infra/nvidia-nim ./install.sh   ì´ ë°°í¬ëŠ” ì•½ ~20ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤.  ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´ ì¶œë ¥ì—ì„œ configure_kubectl ëª…ë ¹ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. EKS í´ëŸ¬ìŠ¤í„° ì•¡ì„¸ìŠ¤ë¥¼ êµ¬ì„±í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•©ë‹ˆë‹¤  # EKS ì¸ì¦ì„ ìœ„í•œ k8s êµ¬ì„± íŒŒì¼ ìƒì„± aws eks --region us-west-2 update-kubeconfig --name nvidia-nim-eks   ë°°í¬ í™•ì¸ - ë°°í¬ ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ë ¤ë©´ í´ë¦­í•˜ì‹­ì‹œì˜¤ $ kubectl get all -n nim-operator kubectl get all -n nim-operator NAME READY STATUS RESTARTS AGE pod/nim-operator-k8s-nim-operator-6fdffdf97f-56fxc 1/1 Running 0 26h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/k8s-nim-operator-metrics-service ClusterIP 172.20.148.6 &lt;none&gt; 8080/TCP 26h NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/nim-operator-k8s-nim-operator 1/1 1 1 26h NAME DESIRED CURRENT READY AGE replicaset.apps/nim-operator-k8s-nim-operator-6fdffdf97f 1 1 1 26h $ kubectl get crds | grep nim nimcaches.apps.nvidia.com 2025-03-27T17:39:00Z nimpipelines.apps.nvidia.com 2025-03-27T17:39:00Z nimservices.apps.nvidia.com 2025-03-27T17:39:01Z $ kubectl get crds | grep nemo nemocustomizers.apps.nvidia.com 2025-03-27T17:38:59Z nemodatastores.apps.nvidia.com 2025-03-27T17:38:59Z nemoentitystores.apps.nvidia.com 2025-03-27T17:38:59Z nemoevaluators.apps.nvidia.com 2025-03-27T17:39:00Z nemoguardrails.apps.nvidia.com 2025-03-27T17:39:00Z Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§ Nodepool ëª©ë¡ ë³´ê¸° $ kubectl get nodepools NAME NODECLASS NODES READY AGE g5-gpu-karpenter g5-gpu-karpenter 1 True 47h g6-gpu-karpenter g6-gpu-karpenter 0 True 7h56m inferentia-inf2 inferentia-inf2 0 False 47h trainium-trn1 trainium-trn1 0 False 47h x86-cpu-karpenter x86-cpu-karpenter 0 True 47h   ","version":"Next","tagName":"h3"},{"title":"NIM Operatorë¡œ llama-3.1-8b-instruct ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#nim-operatorë¡œ-llama-31-8b-instruct-ë°°í¬","content":" 1ë‹¨ê³„: ì¸ì¦ì„ ìœ„í•œ Secret ìƒì„±â€‹  NVIDIA ì»¨í…Œì´ë„ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì™€ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ì— ì•¡ì„¸ìŠ¤í•˜ë ¤ë©´ NGC API í‚¤ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‘ ê°œì˜ Kubernetes Secretì„ ìƒì„±í•©ë‹ˆë‹¤: Docker ì´ë¯¸ì§€ í’€ì„ ìœ„í•œ ngc-secretê³¼ ëª¨ë¸ ì¸ì¦ì„ ìœ„í•œ ngc-api-secret.  cd blueprints/inference/gpu/nvidia-nim-operator-llama3-8b NGC_API_KEY=&quot;your-real-ngc-key&quot; ./deploy-nim-auth.sh   2ë‹¨ê³„: NIMCache CRDë¥¼ ì‚¬ìš©í•˜ì—¬ EFSì— ëª¨ë¸ ìºì‹œâ€‹  NIMCache ì»¤ìŠ¤í…€ ë¦¬ì†ŒìŠ¤ëŠ” ëª¨ë¸ì„ ê°€ì ¸ì˜¤ê³  ìµœì í™”ëœ ì—”ì§„ í”„ë¡œíŒŒì¼ì„ EFSì— ìºì‹œí•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ë‚˜ì¤‘ì— NIMServiceë¥¼ í†µí•´ ëª¨ë¸ì„ ì‹¤í–‰í•  ë•Œ ì‹œì‘ ì‹œê°„ì´ í¬ê²Œ ë‹¨ì¶•ë©ë‹ˆë‹¤.  cd blueprints/inference/gpu/nvidia-nim-operator-llama3-8b kubectl apply -f nim-cache-llama3-8b-instruct.yaml   ìƒíƒœ í™•ì¸:  kubectl get nimcaches.apps.nvidia.com -n nim-service   ì˜ˆìƒ ì¶œë ¥:  NAME STATUS PVC AGE meta-llama3-8b-instruct Ready meta-llama3-8b-instruct-pvc 21h   ìºì‹œëœ ëª¨ë¸ í”„ë¡œíŒŒì¼ í‘œì‹œ:  kubectl get nimcaches.apps.nvidia.com -n nim-service \\ meta-llama3-8b-instruct -o=jsonpath=&quot;{.status.profiles}&quot; | jq .   ìƒ˜í”Œ ì¶œë ¥:  [ { &quot;config&quot;: { &quot;feat_lora&quot;: &quot;false&quot;, &quot;gpu&quot;: &quot;A10G&quot;, &quot;llm_engine&quot;: &quot;tensorrt_llm&quot;, &quot;precision&quot;: &quot;fp16&quot;, &quot;profile&quot;: &quot;throughput&quot;, &quot;tp&quot;: &quot;2&quot; } } ]   3ë‹¨ê³„: NIMService CRDë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë°°í¬â€‹  ì´ì œ ìºì‹œëœ ì—”ì§„ í”„ë¡œíŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì„œë¹„ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.  cd blueprints/inference/gpu/nvidia-nim-operator-llama3-8b kubectl apply -f nim-service-llama3-8b-instruct.yaml   ë°°í¬ëœ ë¦¬ì†ŒìŠ¤ í™•ì¸:  kubectl get all -n nim-service   ì˜ˆìƒ ì¶œë ¥:  NAME READY STATUS RESTARTS AGE pod/meta-llama3-8b-instruct-6cdf47d6f6-hlbnf 1/1 Running 0 6h35m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/meta-llama3-8b-instruct ClusterIP 172.20.85.8 &lt;none&gt; 8000/TCP 6h35m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/meta-llama3-8b-instruct 1/1 1 1 6h35m NAME DESIRED CURRENT READY AGE replicaset.apps/meta-llama3-8b-instruct-6cdf47d6f6 1 1 1 6h35m   ","version":"Next","tagName":"h3"},{"title":"ëª¨ë¸ ì‹œì‘ íƒ€ì„ë¼ì¸â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#ëª¨ë¸-ì‹œì‘-íƒ€ì„ë¼ì¸","content":" ë‹¤ìŒ ìƒ˜í”Œì€ pod/meta-llama3-8b-instruct-6cdf47d6f6-hlbnf ë¡œê·¸ì—ì„œ ìº¡ì²˜ë˜ì—ˆìŠµë‹ˆë‹¤  ë‹¨ê³„\tíƒ€ì„ìŠ¤íƒ¬í”„\tì„¤ëª…ì‹œì‘\t~20:00:50\tPod ì‹œì‘, NIM ì»¨í…Œì´ë„ˆ ë¡œê·¸ ì‹œì‘ í”„ë¡œíŒŒì¼ ë§¤ì¹­\t20:00:50.100\tìºì‹œëœ í”„ë¡œíŒŒì¼ ê°ì§€ ë° ì„ íƒ (tp=2) ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì¤€ë¹„\t20:00:50.132\t0.126ì´ˆ ë§Œì— EFSë¥¼ í†µí•´ ëª¨ë¸ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì´ˆê¸°í™” TensorRT ì´ˆê¸°í™”\t20:00:51.168\tTensorRT-LLM ì—”ì§„ ì„¤ì • ì‹œì‘ ì—”ì§„ ì¤€ë¹„\t20:01:06\tì—”ì§„ ë¡œë“œ ë° í”„ë¡œíŒŒì¼ í™œì„±í™” (~2ê°œ GPUì— ê±¸ì³ 16.6 GiB) API ì„œë²„ ì¤€ë¹„\t20:02:11.036\tFastAPI + Uvicorn ì‹œì‘ í—¬ìŠ¤ ì²´í¬ OK\t20:02:18.781\t/v1/health/ready ì—”ë“œí¬ì¸íŠ¸ê°€ 200 OK ë°˜í™˜  ì‹œì‘ ì‹œê°„ (ì½œë“œ ë¶€íŒ…ì—ì„œ ì¤€ë¹„ê¹Œì§€): EFSì˜ ìºì‹œëœ ì—”ì§„ ë•ë¶„ì— ~81ì´ˆ.  ","version":"Next","tagName":"h3"},{"title":"í”„ë¡¬í”„íŠ¸ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#í”„ë¡¬í”„íŠ¸ë¡œ-ëª¨ë¸-í…ŒìŠ¤íŠ¸","content":" 1ë‹¨ê³„: ëª¨ë¸ ì„œë¹„ìŠ¤ í¬íŠ¸ í¬ì›Œë”©â€‹  í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¡œì»¬ë¡œ ë…¸ì¶œí•©ë‹ˆë‹¤:  kubectl port-forward -n nim-service service/meta-llama3-8b-instruct 8001:8000   2ë‹¨ê³„: curlì„ ì‚¬ìš©í•˜ì—¬ ìƒ˜í”Œ í”„ë¡¬í”„íŠ¸ ì „ì†¡â€‹  ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ì±„íŒ… í”„ë¡¬í”„íŠ¸ë¡œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:  curl -X POST \\ http://localhost:8001/v1/chat/completions \\ -H 'Accept: application/json' \\ -H 'Content-Type: application/json' \\ -d '{ &quot;model&quot;: &quot;meta/llama-3.1-8b-instruct&quot;, &quot;messages&quot;: [ { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What should I do for a 4 day vacation at Cape Hatteras National Seashore?&quot; } ], &quot;top_p&quot;: 1, &quot;n&quot;: 1, &quot;max_tokens&quot;: 1024, &quot;stream&quot;: false, &quot;frequency_penalty&quot;: 0.0, &quot;stop&quot;: [&quot;STOP&quot;] }'   ìƒ˜í”Œ ì‘ë‹µ (ìš”ì•½):  {&quot;id&quot;:&quot;chat-061a9dba9179437fa24cab7f7c767f19&quot;,&quot;object&quot;:&quot;chat.completion&quot;,&quot;created&quot;:1743215809,&quot;model&quot;:&quot;meta/llama-3.1-8b-instruct&quot;,&quot;choices&quot;:[{&quot;index&quot;:0,&quot;message&quot;:{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;Cape Hatteras National Seashore is a beautiful coastal destination with a rich history, pristine beaches, ... exploration of the area's natural beauty and history. Feel free to modify it to suit your interests and preferences. Safe travels!&quot;},&quot;logprobs&quot;:null,&quot;finish_reason&quot;:&quot;stop&quot;,&quot;stop_reason&quot;:null}],&quot;usage&quot;:{&quot;prompt_tokens&quot;:30,&quot;total_tokens&quot;:773,&quot;completion_tokens&quot;:743},&quot;prompt_logprobs&quot;:null}%   ëª¨ë¸ì€ ì´ì œ ë‘ ê°œì˜ A10G GPUì—ì„œ Tensor Parallelism = 2ë¡œ ì‹¤í–‰ë˜ë©°, ê°ê° ì•½ 21.4 GiBì˜ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. EFSë¡œ ì§€ì›ë˜ëŠ” NIMCache ë•ë¶„ì— ëª¨ë¸ì´ ë¹ ë¥´ê²Œ ë¡œë“œë˜ì–´ ì €ì§€ì—° ì¶”ë¡ ì„ ìˆ˜í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Open WebUI ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#open-webui-ë°°í¬","content":" ì •ë³´ Open WebUIëŠ” OpenAI API ì„œë²„ ë° Ollamaì™€ í˜¸í™˜ë˜ëŠ” ëª¨ë¸ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.  1. WebUI ë°°í¬  ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ Open WebUIë¥¼ ë°°í¬í•©ë‹ˆë‹¤:  kubectl apply -f ai-on-eks/blueprints/inference/gpu/nvidia-nim-operator-llama3-8b/openai-webui-deployment.yaml   2. WebUI ì ‘ê·¼ì„ ìœ„í•œ í¬íŠ¸ í¬ì›Œë”©  kubectl í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ WebUIì— ì ‘ê·¼í•©ë‹ˆë‹¤:  kubectl port-forward svc/open-webui 8081:80 -n openai-webui   3. WebUI ì ‘ê·¼  ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  http://localhost:8081 ë¡œ ì´ë™í•©ë‹ˆë‹¤  4. ê°€ì…  ì´ë¦„, ì´ë©”ì¼ ë° ì„ì˜ì˜ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì…í•©ë‹ˆë‹¤.  5. ìƒˆ ì±„íŒ… ì‹œì‘  ì•„ë˜ ìŠ¤í¬ë¦°ìƒ·ê³¼ ê°™ì´ ë“œë¡­ë‹¤ìš´ ë©”ë‰´ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•˜ê³  New Chatì„ í´ë¦­í•©ë‹ˆë‹¤:    6. í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì…ë ¥  í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:    ","version":"Next","tagName":"h2"},{"title":"NVIDIA GenAI-Perf ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#nvidia-genai-perf-ë„êµ¬ë¥¼-ì‚¬ìš©í•œ-ì„±ëŠ¥-í…ŒìŠ¤íŠ¸","content":" GenAI-PerfëŠ” ì¶”ë¡  ì„œë²„ë¥¼ í†µí•´ ì œê³µë˜ëŠ” ìƒì„±í˜• AI ëª¨ë¸ì˜ ì²˜ë¦¬ëŸ‰ê³¼ ì§€ì—° ì‹œê°„ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ëª…ë ¹ì¤„ ë„êµ¬ì…ë‹ˆë‹¤.  GenAI-PerfëŠ” ì¶”ë¡  ì„œë²„ì— ë°°í¬ëœ ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë²¤ì¹˜ë§ˆí¬í•˜ëŠ” í‘œì¤€ ë„êµ¬ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ë„êµ¬ì—ëŠ” GPUê°€ í•„ìš”í•©ë‹ˆë‹¤. ë” ì‰½ê²Œ í•˜ê¸° ìœ„í•´ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë¯¸ë¦¬ êµ¬ì„±ëœ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ genaiperf-deploy.yamlì„ ì œê³µí•©ë‹ˆë‹¤.  cd ai-on-eks/blueprints/inference/gpu/nvidia-nim-operator-llama3-8b kubectl apply -f genaiperf-deploy.yaml   Podê°€ 1/1 Running ìƒíƒœê°€ ë˜ë©´ Podì— ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  export POD_NAME=$(kubectl get po -l app=genai-perf -ojsonpath='{.items[0].metadata.name}') kubectl exec -it $POD_NAME -- bash   ë°°í¬ëœ NIM Llama3 ëª¨ë¸ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰  genai-perf profile -m meta/llama-3.1-8b-instruct \\ --url meta-llama3-8b-instruct.nim-service:8000 \\ --service-kind openai \\ --endpoint-type chat \\ --num-prompts 100 \\ --synthetic-input-tokens-mean 200 \\ --synthetic-input-tokens-stddev 0 \\ --output-tokens-mean 100 \\ --output-tokens-stddev 0 \\ --concurrency 20 \\ --streaming \\ --tokenizer hf-internal-testing/llama-tokenizer   ë‹¤ìŒê³¼ ìœ ì‚¬í•œ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤    genai-perfê°€ ìˆ˜ì§‘í•˜ëŠ” ë©”íŠ¸ë¦­(Request latency, Output token throughput, Request throughput í¬í•¨)ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ëª…ë ¹ì¤„ ì˜µì…˜ì„ ì´í•´í•˜ë ¤ë©´ ì´ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h2"},{"title":"Grafana ëŒ€ì‹œë³´ë“œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#grafana-ëŒ€ì‹œë³´ë“œ","content":" NVIDIAëŠ” NIM ìƒíƒœë¥¼ ë” ì˜ ì‹œê°í™”í•˜ê¸° ìœ„í•œ Grafana ëŒ€ì‹œë³´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. Grafana ëŒ€ì‹œë³´ë“œì—ëŠ” ëª‡ ê°€ì§€ ì¤‘ìš”í•œ ë©”íŠ¸ë¦­ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:  Time to First Token (TTFT): ëª¨ë¸ì— ëŒ€í•œ ì´ˆê¸° ì¶”ë¡  ìš”ì²­ê³¼ ì²« ë²ˆì§¸ í† í° ë°˜í™˜ ì‚¬ì´ì˜ ì§€ì—° ì‹œê°„ì…ë‹ˆë‹¤.Inter-Token Latency (ITL): ì²« ë²ˆì§¸ í† í° ì´í›„ ê° í† í° ì‚¬ì´ì˜ ì§€ì—° ì‹œê°„ì…ë‹ˆë‹¤.Total Throughput: NIMì´ ì´ˆë‹¹ ìƒì„±í•˜ëŠ” ì´ í† í° ìˆ˜ì…ë‹ˆë‹¤.  ë” ë§ì€ ë©”íŠ¸ë¦­ ì„¤ëª…ì€ ì´ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.    Time-to-First-Token, Inter-Token-Latency, KV Cache Utilization ë©”íŠ¸ë¦­ê³¼ ê°™ì€ ì§€í‘œë¥¼ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•œ Grafana ëŒ€ì‹œë³´ë“œë¥¼ ë³´ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¥´ì‹­ì‹œì˜¤:  ì„¸ë¶€ ì •ë³´ë¥¼ ë³´ë ¤ë©´ í´ë¦­í•˜ì‹­ì‹œì˜¤ 1. Grafana ë¹„ë°€ë²ˆí˜¸ ê²€ìƒ‰. ë¹„ë°€ë²ˆí˜¸ëŠ” AWS Secret Managerì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ Terraform ëª…ë ¹ì€ ì‹œí¬ë¦¿ ì´ë¦„ì„ í‘œì‹œí•©ë‹ˆë‹¤. terraform output grafana_secret_name ê·¸ëŸ° ë‹¤ìŒ ì¶œë ¥ëœ ì‹œí¬ë¦¿ ì´ë¦„ì„ ì‚¬ìš©í•˜ì—¬ ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤, aws secretsmanager get-secret-value --secret-id &lt;grafana_secret_name_output&gt; --region $AWS_REGION --query &quot;SecretString&quot; --output text 2. Grafana ì„œë¹„ìŠ¤ ë…¸ì¶œ í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ì—¬ Grafana ì„œë¹„ìŠ¤ë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤. kubectl port-forward svc/kube-prometheus-stack-grafana 3000:80 -n monitoring 3. Grafana ë¡œê·¸ì¸: ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  http://localhost:3000ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.ì‚¬ìš©ì ì´ë¦„ adminê³¼ AWS Secrets Managerì—ì„œ ê²€ìƒ‰í•œ ë¹„ë°€ë²ˆí˜¸ë¡œ ë¡œê·¸ì¸í•©ë‹ˆë‹¤. 4. NIM ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì—´ê¸°: ë¡œê·¸ì¸ í›„ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ &quot;Dashboards&quot;ë¥¼ í´ë¦­í•˜ê³  &quot;nim&quot;ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤ëª©ë¡ì—ì„œ NVIDIA NIM Monitoring ëŒ€ì‹œë³´ë“œë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤í´ë¦­í•˜ì—¬ ëŒ€ì‹œë³´ë“œë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. ì´ì œ Grafana ëŒ€ì‹œë³´ë“œì— í‘œì‹œëœ ë©”íŠ¸ë¦­ì„ ë³¼ ìˆ˜ ìˆìœ¼ë©°, NVIDIA NIM ì„œë¹„ìŠ¤ ë°°í¬ì˜ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì •ë³´ ì´ ê°€ì´ë“œ ì‘ì„± ì‹œì ì— NVIDIAë„ ì˜ˆì œ Grafana ëŒ€ì‹œë³´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ê²°ë¡ â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#ê²°ë¡ ","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” NVIDIA NIM Operatorë¥¼ ì‚¬ìš©í•˜ì—¬ Amazon EKSì—ì„œ Metaì˜ Llama 3.1 8B Instructì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë°°í¬í•˜ê³  í™•ì¥í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.  OpenAI í˜¸í™˜ APIì™€ GPU ê°€ì† ì¶”ë¡ , ì„ ì–¸ì  Kubernetes CRD (NIMCache, NIMService) ë° EFS ê¸°ë°˜ ìºì‹±ì„ í†µí•œ ë¹ ë¥¸ ëª¨ë¸ ì‹œì‘ì„ ê²°í•©í•˜ì—¬ ê°„ì†Œí™”ëœ í”„ë¡œë•ì…˜ê¸‰ ëª¨ë¸ ë°°í¬ ê²½í—˜ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì£¼ìš” ì´ì :â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#ì£¼ìš”-ì´ì ","content":" ê³µìœ  ì˜êµ¬ ëª¨ë¸ ìºì‹œë¥¼ í†µí•œ ë” ë¹ ë¥¸ ì½œë“œ ìŠ¤íƒ€íŠ¸CRDë¥¼ í†µí•œ ì„ ì–¸ì ì´ê³  ë°˜ë³µ ê°€ëŠ¥í•œ ë°°í¬Karpenterê°€ ì§€ì›í•˜ëŠ” ë™ì  GPU ì˜¤í† ìŠ¤ì¼€ì¼ë§Terraformì„ ì‚¬ìš©í•œ ì›í´ë¦­ ì¸í”„ë¼ í”„ë¡œë¹„ì €ë‹  ~20ë¶„ ë§Œì— ì œë¡œì—ì„œ Kubernetesì˜ í™•ì¥ ê°€ëŠ¥í•œ LLM ì„œë¹„ìŠ¤ê¹Œì§€ - ì €ì§€ì—°ê³¼ ë†’ì€ íš¨ìœ¨ì„±ìœ¼ë¡œ ì‹¤ì œ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•  ì¤€ë¹„ê°€ ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#ì •ë¦¬","content":" ë°°í¬ëœ ëª¨ë¸ ë° ê´€ë ¨ ì¸í”„ë¼ë¥¼ í•´ì œí•˜ë ¤ë©´:  ","version":"Next","tagName":"h2"},{"title":"1ë‹¨ê³„: ëª¨ë¸ ë¦¬ì†ŒìŠ¤ ì‚­ì œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#1ë‹¨ê³„-ëª¨ë¸-ë¦¬ì†ŒìŠ¤-ì‚­ì œ","content":" í´ëŸ¬ìŠ¤í„°ì—ì„œ ë°°í¬ëœ NIMService ë° NIMCache ê°ì²´ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤:  cd blueprints/inference/gpu/nvidia-nim-operator-llama3-8b kubectl delete -f nim-service-llama3-8b-instruct.yaml kubectl delete -f nim-cache-llama3-8b-instruct.yaml   ì‚­ì œ í™•ì¸:  kubectl get nimservices.apps.nvidia.com -n nim-service kubectl get nimcaches.apps.nvidia.com -n nim-service   ","version":"Next","tagName":"h3"},{"title":"2ë‹¨ê³„: AWS ì¸í”„ë¼ ì‚­ì œâ€‹","type":1,"pageTitle":"Amazon EKSì˜ NVIDIA NIM Operator","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/nvidia-nim-operator#2ë‹¨ê³„-aws-ì¸í”„ë¼-ì‚­ì œ","content":" ë£¨íŠ¸ Terraform ëª¨ë“ˆë¡œ ëŒì•„ê°€ì„œ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ VPC, EKS í´ëŸ¬ìŠ¤í„°, EFS ë° ë…¸ë“œ ê·¸ë£¹ì„ í¬í•¨í•˜ì—¬ ì´ ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ìœ„í•´ ìƒì„±ëœ ëª¨ë“  AWS ë¦¬ì†ŒìŠ¤ê°€ ì‚­ì œë©ë‹ˆë‹¤:  cd ai-on-eks/infra/nvidia-nim ./cleanup.sh  ","version":"Next","tagName":"h3"},{"title":"Rayì™€ vLLMì„ ì‚¬ìš©í•œ EKSì—ì„œì˜ DeepSeek-R1","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/ray-vllm-deepseek","content":"","keywords":"","version":"Next"},{"title":"GPU ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ ì´í•´â€‹","type":1,"pageTitle":"Rayì™€ vLLMì„ ì‚¬ìš©í•œ EKSì—ì„œì˜ DeepSeek-R1","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/ray-vllm-deepseek#gpu-ë©”ëª¨ë¦¬-ìš”êµ¬-ì‚¬í•­-ì´í•´","content":" DeepSeek-R1-Distill-Llamaì™€ ê°™ì€ 8B íŒŒë¼ë¯¸í„° ëª¨ë¸ì„ ë°°í¬í•˜ë ¤ë©´ ì‹ ì¤‘í•œ ë©”ëª¨ë¦¬ ê³„íšì´ í•„ìš”í•©ë‹ˆë‹¤. ê° ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 2ë°”ì´íŠ¸(BF16 ì •ë°€ë„)ë¥¼ ì†Œë¹„í•˜ë©°, ì´ëŠ” ì „ì²´ ëª¨ë¸ ê°€ì¤‘ì¹˜ì— ì•½ 14.99 GiBì˜ GPU ë©”ëª¨ë¦¬ê°€ í•„ìš”í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ë°°í¬ ì¤‘ ê´€ì°°ëœ ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì…ë‹ˆë‹¤:  Ray ë°°í¬ì˜ ë¡œê·¸ ìƒ˜í”Œ  INFO model_runner.py:1115] Loading model weights took 14.99 GiB INFO worker.py:266] vLLM instance can use total GPU memory (22.30 GiB) x utilization (0.90) = 20.07 GiB INFO worker.py:266] Model weights: 14.99 GiB | Activation memory: 0.85 GiB | KV Cache: 4.17 GiB   G5 ì¸ìŠ¤í„´ìŠ¤ëŠ” 24 GiB ë©”ëª¨ë¦¬ì˜ ë‹¨ì¼ A10G GPUë¥¼ ì œê³µí•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ë‹¹ í•˜ë‚˜ì˜ ëŒ€ê·œëª¨ LLM ì¶”ë¡  í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° ì´ìƒì ì…ë‹ˆë‹¤. ì´ ë°°í¬ì—ì„œëŠ” 1x NVIDIA A10G GPU (24 GiB), 16 vCPU ë° 64 GiB RAMì´ ìˆëŠ” G5.4xlargeë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  vLLMì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ í™œìš©ì„ ìµœì í™”í•˜ì—¬ OOM(ë©”ëª¨ë¦¬ ë¶€ì¡±) ì¶©ëŒì„ ë°©ì§€í•˜ë©´ì„œ ì¶”ë¡  ì†ë„ë¥¼ ìµœëŒ€í™”í•©ë‹ˆë‹¤.  EKS í´ëŸ¬ìŠ¤í„° ë° ì• ë“œì˜¨ ë°°í¬ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ DeepSeek-R1-Distill-Llama-8B ë°°í¬â€‹","type":1,"pageTitle":"Rayì™€ vLLMì„ ì‚¬ìš©í•œ EKSì—ì„œì˜ DeepSeek-R1","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/ray-vllm-deepseek#rayserveì™€-vllmì„-ì‚¬ìš©í•œ-deepseek-r1-distill-llama-8b-ë°°í¬","content":" EKS í´ëŸ¬ìŠ¤í„°ê°€ ë°°í¬ë˜ê³  í•„ìš”í•œ ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ì¤€ë¹„ë˜ë©´ RayServeì™€ vLLMì„ ì‚¬ìš©í•˜ì—¬ DeepSeek-R1-Distill-Llama-8Bë¥¼ ë°°í¬í•˜ëŠ” ë‹¨ê³„ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” Hugging Face Hub í† í°ì„ ë‚´ë³´ë‚´ê³ , Docker ì´ë¯¸ì§€ë¥¼ ìƒì„±(í•„ìš”í•œ ê²½ìš°)í•˜ê³ , RayServe í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•˜ëŠ” ë‹¨ê³„ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.  1ë‹¨ê³„: Hugging Face Hub í† í° ë‚´ë³´ë‚´ê¸°  ëª¨ë¸ì„ ë°°í¬í•˜ê¸° ì „ì— í•„ìš”í•œ ëª¨ë¸ íŒŒì¼ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ Hugging Faceë¡œ ì¸ì¦í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:  Hugging Face ê³„ì •ì„ ë§Œë“­ë‹ˆë‹¤ (ì—†ëŠ” ê²½ìš°).ì•¡ì„¸ìŠ¤ í† í°ì„ ìƒì„±í•©ë‹ˆë‹¤:  Hugging Face Settings -&gt; Access Tokensë¡œ ì´ë™í•©ë‹ˆë‹¤.ì½ê¸° ê¶Œí•œì´ ìˆëŠ” ìƒˆ í† í°ì„ ë§Œë“­ë‹ˆë‹¤.ìƒì„±ëœ í† í°ì„ ë³µì‚¬í•©ë‹ˆë‹¤.  í„°ë¯¸ë„ì—ì„œ í† í°ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤:  export HUGGING_FACE_HUB_TOKEN=$(echo -n &quot;Your-Hugging-Face-Hub-Token-Value&quot; | base64)   ì°¸ê³ : í† í°ì€ Kubernetes ì‹œí¬ë¦¿ì—ì„œ ì‚¬ìš©í•˜ê¸° ì „ì— base64ë¡œ ì¸ì½”ë”©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.  2ë‹¨ê³„: Docker ì´ë¯¸ì§€ ìƒì„±  ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë°°í¬í•˜ë ¤ë©´ Ray, vLLM ë° Hugging Face ì˜ì¡´ì„±ì„ í¬í•¨í•˜ëŠ” Docker ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:  ì œê³µëœ Dockerfileì„ ì‚¬ìš©í•©ë‹ˆë‹¤:  gen-ai/inference/vllm-ray-gpu-deepseek/Dockerfile   ì´ Dockerfileì€ Ray ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©° vLLMê³¼ Hugging Face ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì´ ë°°í¬ì—ëŠ” ì¶”ê°€ íŒ¨í‚¤ì§€ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ê³  Amazon ECRì— í‘¸ì‹œí•©ë‹ˆë‹¤  ë˜ëŠ”  ë¯¸ë¦¬ ë¹Œë“œëœ ì´ë¯¸ì§€ ì‚¬ìš© (PoC ë°°í¬ìš©):  ì‚¬ìš©ì ì •ì˜ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ê³  í‘¸ì‹œí•˜ëŠ” ê²ƒì„ ê±´ë„ˆë›°ë ¤ë©´ ê³µê°œ ECR ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  public.ecr.aws/data-on-eks/ray-2.41.0-py310-cu118-vllm0.7.0  ì°¸ê³ : ì‚¬ìš©ì ì •ì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° RayServe YAML íŒŒì¼ì˜ ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ ECR ì´ë¯¸ì§€ URIë¡œ êµì²´í•˜ì„¸ìš”.  3ë‹¨ê³„: RayServe í´ëŸ¬ìŠ¤í„° ë°°í¬  RayServe í´ëŸ¬ìŠ¤í„°ëŠ” ì—¬ëŸ¬ ë¦¬ì†ŒìŠ¤ë¥¼ í¬í•¨í•˜ëŠ” YAML êµ¬ì„± íŒŒì¼ì— ì •ì˜ë©ë‹ˆë‹¤:  ë°°í¬ë¥¼ ê²©ë¦¬í•˜ê¸° ìœ„í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤.Hugging Face Hub í† í°ì„ ì•ˆì „í•˜ê²Œ ì €ì¥í•˜ê¸° ìœ„í•œ ì‹œí¬ë¦¿.ì„œë¹™ ìŠ¤í¬ë¦½íŠ¸(OpenAI í˜¸í™˜ API ì¸í„°í˜ì´ìŠ¤)ë¥¼ í¬í•¨í•˜ëŠ” ConfigMap.ë‹¤ìŒì„ í¬í•¨í•˜ëŠ” RayServe ì •ì˜: x86 ë…¸ë“œì— ë°°í¬ëœ Ray head íŒŒë“œ.GPU ì¸ìŠ¤í„´ìŠ¤(g5.4xlarge)ì— ë°°í¬ëœ Ray ì›Œì»¤ íŒŒë“œ.  ë°°í¬ ë‹¨ê³„  ì°¸ê³ : ray-vllm-deepseek.ymlì˜ image: í•„ë“œê°€ ì‚¬ìš©ì ì •ì˜ ECR ì´ë¯¸ì§€ URI ë˜ëŠ” ê¸°ë³¸ ê³µê°œ ECR ì´ë¯¸ì§€ë¡œ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.  RayServe êµ¬ì„±ì´ í¬í•¨ëœ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ê³  kubectlì„ ì‚¬ìš©í•˜ì—¬ êµ¬ì„±ì„ ì ìš©í•©ë‹ˆë‹¤  cd cd ai-on-eks/blueprints/inference/vllm-ray-gpu-deepseek/ envsubst &lt; ray-vllm-deepseek.yml | kubectl apply -f -   ì¶œë ¥  namespace/rayserve-vllm created secret/hf-token created configmap/vllm-serve-script created rayservice.ray.io/vllm created   4ë‹¨ê³„: ë°°í¬ ëª¨ë‹ˆí„°ë§  ë°°í¬ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  íŒŒë“œ ìƒíƒœë¥¼ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl get pod -n rayserve-vllm   ì •ë³´ ì°¸ê³ : ì²« ë°°í¬ ì‹œ ì´ë¯¸ì§€ í’€ í”„ë¡œì„¸ìŠ¤ì— ìµœëŒ€ 8ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´í›„ ì—…ë°ì´íŠ¸ëŠ” ë¡œì»¬ ìºì‹œë¥¼ í™œìš©í•©ë‹ˆë‹¤. í•„ìš”í•œ ì˜ì¡´ì„±ë§Œ í¬í•¨í•˜ëŠ” ë” ê°€ë²¼ìš´ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ì—¬ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  NAME READY STATUS RESTARTS AGE vllm-raycluster-7qwlm-head-vkqsc 2/2 Running 0 8m47s vllm-raycluster-7qwlm-worker-gpu-group-vh2ng 0/1 PodInitializing 0 8m47s   ì´ ë°°í¬ëŠ” ë˜í•œ ì—¬ëŸ¬ í¬íŠ¸ê°€ ìˆëŠ” DeepSeek-R1 ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:  8265 - Ray Dashboard8000 - DeepSeek-R1 ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸  ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl get svc -n rayserve-vllm NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE vllm ClusterIP 172.20.208.16 &lt;none&gt; 6379/TCP,8265/TCP,10001/TCP,8000/TCP,8080/TCP 48m vllm-head-svc ClusterIP 172.20.239.237 &lt;none&gt; 6379/TCP,8265/TCP,10001/TCP,8000/TCP,8080/TCP 37m vllm-serve-svc ClusterIP 172.20.196.195 &lt;none&gt; 8000/TCP 37m   Ray ëŒ€ì‹œë³´ë“œì— ì ‘ê·¼í•˜ë ¤ë©´ ê´€ë ¨ í¬íŠ¸ë¥¼ ë¡œì»¬ ë¨¸ì‹ ìœ¼ë¡œ í¬íŠ¸ í¬ì›Œë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl -n rayserve-vllm port-forward svc/vllm 8265:8265   ê·¸ëŸ° ë‹¤ìŒ http://localhost:8265ì—ì„œ ì›¹ UIì— ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë©°, Ray ì—ì½”ì‹œìŠ¤í…œ ë‚´ì˜ ì‘ì—… ë° ì•¡í„° ë°°í¬ê°€ í‘œì‹œë©ë‹ˆë‹¤.  ì •ë³´ ëª¨ë¸ ë°°í¬ì—ëŠ” ì•½ 4ë¶„ì´ ê±¸ë¦½ë‹ˆë‹¤        ","version":"Next","tagName":"h2"},{"title":"DeepSeek-R1 ëª¨ë¸ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Rayì™€ vLLMì„ ì‚¬ìš©í•œ EKSì—ì„œì˜ DeepSeek-R1","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/ray-vllm-deepseek#deepseek-r1-ëª¨ë¸-í…ŒìŠ¤íŠ¸","content":" ì´ì œ DeepSeek-R1-Distill-Llama-8B ì±„íŒ… ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ì°¨ë¡€ì…ë‹ˆë‹¤.  ë¨¼ì € kubectlì„ ì‚¬ìš©í•˜ì—¬ vllm-serve-svc ì„œë¹„ìŠ¤ë¡œ í¬íŠ¸ í¬ì›Œë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl -n rayserve-vllm port-forward svc/vllm-serve-svc 8000:8000   í…ŒìŠ¤íŠ¸ ì¶”ë¡  ìš”ì²­ ì‹¤í–‰:  curl -X POST http://localhost:8000/v1/chat/completions -H &quot;Content-Type: application/json&quot; -d '{ &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;, &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Explain about DeepSeek model?&quot;}], &quot;stream&quot;: false }'   ì‘ë‹µ:  {&quot;id&quot;:&quot;chatcmpl-b86feed9-1482-4d1c-981d-085651d12813&quot;,&quot;object&quot;:&quot;chat.completion&quot;,&quot;created&quot;:1739001265,&quot;model&quot;:&quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,&quot;choices&quot;:[{&quot;index&quot;:0,&quot;message&quot;:{&quot;role&quot;:&quot;assistant&quot;,&quot;content&quot;:&quot;&lt;think&gt;\\n\\n&lt;/think&gt;\\n\\nDeepSeekëŠ” ì¤‘êµ­ íšŒì‚¬ DeepSeek Inc.ì—ì„œ ê°œë°œí•œ ê°•ë ¥í•œ AI ê²€ìƒ‰ ì—”ì§„ì…ë‹ˆë‹¤. ì •ë°€í•œ ì¶”ë¡ ê³¼ íš¨ìœ¨ì ì¸ ê³„ì‚°ì„ í†µí•´ ë³µì¡í•œ STEM(ê³¼í•™, ê¸°ìˆ , ê³µí•™, ìˆ˜í•™) ë¬¸ì œë¥¼ í•´ê²°í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤...&quot;},&quot;logprobs&quot;:null,&quot;finish_reason&quot;:&quot;stop&quot;,&quot;stop_reason&quot;:null}],&quot;usage&quot;:{&quot;prompt_tokens&quot;:10,&quot;total_tokens&quot;:359,&quot;completion_tokens&quot;:349,&quot;prompt_tokens_details&quot;:null},&quot;prompt_logprobs&quot;:null}%   ","version":"Next","tagName":"h2"},{"title":"Open Web UI ë°°í¬â€‹","type":1,"pageTitle":"Rayì™€ vLLMì„ ì‚¬ìš©í•œ EKSì—ì„œì˜ DeepSeek-R1","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/ray-vllm-deepseek#open-web-ui-ë°°í¬","content":" ì´ì œ EKSì— ë°°í¬ëœ DeepSeek ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©í•˜ê¸° ìœ„í•œ ChatGPT ìŠ¤íƒ€ì¼ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ Open WebUIë¥¼ ë°°í¬í•´ ë³´ê² ìŠµë‹ˆë‹¤. Open WebUIëŠ” ëª¨ë¸ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.  Open WebUI ë°°í¬  Open WebUIìš© YAML íŒŒì¼ gen-ai/inference/vllm-ray-gpu-deepseek/open-webui.yamlì„ í™•ì¸í•©ë‹ˆë‹¤. ì´ê²ƒì€ EKSì—ì„œ ì»¨í…Œì´ë„ˆë¡œ ë°°í¬ë˜ë©° ëª¨ë¸ ì„œë¹„ìŠ¤ì™€ í†µì‹ í•©ë‹ˆë‹¤.Open WebUI ë°°í¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤:  cd gen-ai/inference/vllm-ray-gpu-deepseek/ kubectl apply -f open-webui.yaml   ì¶œë ¥:  namespace/openai-webui created deployment.apps/open-webui created service/open-webui created   Open WebUI ì ‘ê·¼  ì›¹ UIë¥¼ ì—´ë ¤ë©´ Open WebUI ì„œë¹„ìŠ¤ë¥¼ í¬íŠ¸ í¬ì›Œë”©í•©ë‹ˆë‹¤:  kubectl -n open-webui port-forward svc/open-webui 8080:80   ê·¸ëŸ° ë‹¤ìŒ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  ë‹¤ìŒìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤: http://localhost:8080  ë“±ë¡ í˜ì´ì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤. ì´ë¦„, ì´ë©”ì¼, ë¹„ë°€ë²ˆí˜¸ë¡œ ë“±ë¡í•©ë‹ˆë‹¤.            ìš”ì²­ì„ ì œì¶œí•œ í›„ GPU ë° CPU ì‚¬ìš©ëŸ‰ì´ ì •ìƒìœ¼ë¡œ ëŒì•„ì˜¤ëŠ” ê²ƒì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:    ","version":"Next","tagName":"h2"},{"title":"ì£¼ìš” ì‚¬í•­â€‹","type":1,"pageTitle":"Rayì™€ vLLMì„ ì‚¬ìš©í•œ EKSì—ì„œì˜ DeepSeek-R1","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/ray-vllm-deepseek#ì£¼ìš”-ì‚¬í•­","content":" 1. ëª¨ë¸ ì´ˆê¸°í™” ë° ë©”ëª¨ë¦¬ í• ë‹¹  ë°°í¬ë˜ë©´ ëª¨ë¸ì€ CUDAë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ì‹¤í–‰ í™˜ê²½ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.GPU ë©”ëª¨ë¦¬ëŠ” ë™ì ìœ¼ë¡œ í• ë‹¹ë˜ë©°, ëª¨ë¸ ê°€ì¤‘ì¹˜(14.99 GiB), í™œì„±í™” ë©”ëª¨ë¦¬(0.85 GiB), KV ìºì‹œ(4.17 GiB)ì— 90% í™œìš©ë¥ ì´ ì˜ˆì•½ë©ë‹ˆë‹¤.ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì˜¤ê³  ì¶”ë¡ ì— ìµœì í™”í•˜ëŠ” ë™ì•ˆ ì²« ë²ˆì§¸ ëª¨ë¸ ë¡œë“œ ì‹œ ì•½ê°„ì˜ ì´ˆê¸° ì§€ì—°ì´ ì˜ˆìƒë©ë‹ˆë‹¤.  2. ì¶”ë¡  ì‹¤í–‰ ë° ìµœì í™”  ëª¨ë¸ì€ ì—¬ëŸ¬ ì‘ì—…ì„ ì§€ì›í•˜ì§€ë§Œ ê¸°ë³¸ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ ìƒì„±(generate)ì…ë‹ˆë‹¤.Flash Attentionì´ í™œì„±í™”ë˜ì–´ ë©”ëª¨ë¦¬ ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì´ê³  ì¶”ë¡  ì†ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.CUDA Graph Captureê°€ ì ìš©ë˜ì–´ ë°˜ë³µ ì¶”ë¡ ì„ ë” ë¹ ë¥´ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆì§€ë§Œ, OOM ë¬¸ì œê°€ ë°œìƒí•˜ë©´ gpu_memory_utilizationì„ ì¤„ì´ê±°ë‚˜ eager ì‹¤í–‰ì„ í™œì„±í™”í•˜ë©´ ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  3. í† í° ìƒì„± ë° ì„±ëŠ¥ ë©”íŠ¸ë¦­  ëª¨ë¸ì€ ì…ë ¥ì„ ê¸°ë‹¤ë¦¬ëŠ” ë™ì•ˆ ì²˜ìŒì— í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ëŸ‰ì´ 0 tokens/secë¡œ í‘œì‹œë©ë‹ˆë‹¤.ì¶”ë¡ ì´ ì‹œì‘ë˜ë©´ í† í° ìƒì„± ì²˜ë¦¬ëŸ‰ì´ ~29 tokens/secë¡œ ì•ˆì •í™”ë©ë‹ˆë‹¤.GPU KV ìºì‹œ í™œìš©ë¥ ì€ ~12.5%ì—ì„œ ì‹œì‘í•˜ì—¬ ë” ë§ì€ í† í°ì´ ì²˜ë¦¬ë¨ì— ë”°ë¼ ì¦ê°€í•˜ì—¬ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë” ë¶€ë“œëŸ¬ìš´ í…ìŠ¤íŠ¸ ìƒì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.  4. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™œìš©  ë³‘ë ¬ ì‹¤í–‰ì„ ì²˜ë¦¬í•˜ëŠ” 8ê°œì˜ CPU ë° 8ê°œì˜ CUDA ë¸”ë¡ì´ ì˜ˆìƒë©ë‹ˆë‹¤.ì¶”ë¡  ë™ì‹œì„±ì€ ìš”ì²­ë‹¹ 8192 í† í°ì— ëŒ€í•´ 4ê°œì˜ ìš”ì²­ìœ¼ë¡œ ì œí•œë˜ë¯€ë¡œ ëª¨ë¸ì´ ì™„ì „íˆ í™œìš©ë˜ë©´ ë™ì‹œ ìš”ì²­ì´ ëŒ€ê¸°ì—´ì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.ë©”ëª¨ë¦¬ ìŠ¤íŒŒì´í¬ê°€ ë°œìƒí•˜ë©´ max_num_seqsë¥¼ ë‚®ì¶”ë©´ GPU ë¶€ë‹´ì„ ì¤„ì´ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  5. ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡ì„±  ë¡œê·¸ì—ì„œ í‰ê·  í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ëŸ‰, ìƒì„± ì†ë„, GPU KV ìºì‹œ ì‚¬ìš©ëŸ‰ì„ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.ì¶”ë¡ ì´ ëŠë ¤ì§€ë©´ ë¡œê·¸ì—ì„œ ë©”ëª¨ë¦¬ ì••ë ¥ì´ë‚˜ ìŠ¤ì¼€ì¤„ë§ ì§€ì—°ì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ” ë³´ë¥˜ ì¤‘ì´ê±°ë‚˜ ìŠ¤ì™‘ëœ ìš”ì²­ì„ í™•ì¸í•˜ì„¸ìš”.ì‹¤ì‹œê°„ ê´€ì¸¡ì„±(ì˜ˆ: ìš”ì²­ ì§€ì—° ì¶”ì )ì€ ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”ë˜ì–´ ìˆì§€ë§Œ ë” ê¹Šì€ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•´ í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë°°í¬ í›„ ì˜ˆìƒ ì‚¬í•­  ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ë° CUDA ê·¸ë˜í”„ ìµœì í™”ë¡œ ì¸í•´ ëª¨ë¸ ì´ˆê¸°í™”ì— ëª‡ ë¶„ì´ ê±¸ë¦½ë‹ˆë‹¤.ì‹¤í–‰ë˜ë©´ íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ê³¼ í•¨ê»˜ ~29 tokens/secì˜ ì•ˆì •ì ì¸ ì²˜ë¦¬ëŸ‰ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.ì„±ëŠ¥ì´ ì €í•˜ë˜ë©´ KV ìºì‹œ í¬ê¸°ë¥¼ ì¡°ì •í•˜ê±°ë‚˜ ë©”ëª¨ë¦¬ í™œìš©ë¥ ì„ ë‚®ì¶”ê±°ë‚˜ ì•ˆì •ì„± í–¥ìƒì„ ìœ„í•´ eager ì‹¤í–‰ì„ í™œì„±í™”í•˜ì„¸ìš”.  ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Rayì™€ vLLMì„ ì‚¬ìš©í•œ EKSì—ì„œì˜ DeepSeek-R1","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/ray-vllm-deepseek#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ê°€ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì„ ë•Œ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ì„ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  RayCluster ì‚­ì œ  cd ai-on-eks/blueprints/inference/vllm-rayserve-gpu kubectl delete -f open-webui.yaml kubectl delete -f ray-vllm-deepseek.yml   cd ai-on-eks/infra/jark-stack/terraform/monitoring kubectl delete -f serviceMonitor.yaml kubectl delete -f podMonitor.yaml   EKS í´ëŸ¬ìŠ¤í„° ë° ë¦¬ì†ŒìŠ¤ ì‚­ì œ  export AWS_DEAFULT_REGION=&quot;DEPLOYED_EKS_CLUSTER_REGION&gt;&quot; cd ai-on-eks/infra/jark-stack/terraform/ &amp;&amp; chmod +x cleanup.sh ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus","content":"","keywords":"","version":"Next"},{"title":"Stable Diffusionì´ë€?â€‹","type":1,"pageTitle":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus#stable-diffusionì´ë€","content":" Stable Diffusionì€ í…ìŠ¤íŠ¸ ì„¤ëª…ì—ì„œ ë©‹ì§€ê³  ìƒì„¸í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ìµœì²¨ë‹¨ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ ìƒì„±ì„ í†µí•´ ìƒìƒë ¥ì„ ë°œíœ˜í•˜ê³ ì í•˜ëŠ” ì•„í‹°ìŠ¤íŠ¸, ë””ìì´ë„ˆ ë° ëª¨ë“  ì‚¬ëŒì„ ìœ„í•œ ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì´ë¯¸ì§€ ìƒì„± í”„ë¡œì„¸ìŠ¤ì—ì„œ ë†’ì€ ìˆ˜ì¤€ì˜ ì°½ì˜ì  ì œì–´ì™€ ìœ ì—°ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus#ì†”ë£¨ì…˜-ë°°í¬","content":" Amazon EKSì—ì„œ Stable Diffusion v2-1ì„ ì‹œì‘í•´ ë³´ê² ìŠµë‹ˆë‹¤! ì´ ì„¹ì…˜ì—ì„œ ë‹¤ë£° ë‚´ìš©ì€:  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­: ëª¨ë“  ê²ƒì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸.ì¸í”„ë¼ ì„¤ì •: EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•˜ê³  ë°°í¬ ì¤€ë¹„.Ray í´ëŸ¬ìŠ¤í„° ë°°í¬: í™•ì¥ì„±ê³¼ íš¨ìœ¨ì„±ì„ ì œê³µí•˜ëŠ” ì´ë¯¸ì§€ ìƒì„± íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬.Gradio Web UI êµ¬ì¶•: Stable Diffusionê³¼ ìƒí˜¸ ì‘ìš©í•˜ê¸° ìœ„í•œ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¸í„°í˜ì´ìŠ¤.  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"Stable Diffusion ëª¨ë¸ì„ í¬í•¨í•œ Ray í´ëŸ¬ìŠ¤í„° ë°°í¬â€‹","type":1,"pageTitle":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus#stable-diffusion-ëª¨ë¸ì„-í¬í•¨í•œ-ray-í´ëŸ¬ìŠ¤í„°-ë°°í¬","content":" jark-stack í´ëŸ¬ìŠ¤í„°ê°€ ë°°í¬ë˜ë©´ kubectlì„ ì‚¬ìš©í•˜ì—¬ /ai-on-eks/blueprints/inference/stable-diffusion-rayserve-gpu/ ê²½ë¡œì—ì„œ ray-service-stablediffusion.yamlì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ë‹¨ê³„ì—ì„œëŠ” Karpenter ìë™ ìŠ¤ì¼€ì¼ë§ì„ ì‚¬ìš©í•˜ì—¬ x86 CPU ì¸ìŠ¤í„´ìŠ¤ì—ì„œ í•˜ë‚˜ì˜ Head Podì™€ Karpenterì— ì˜í•´ ìë™ ìŠ¤ì¼€ì¼ë§ë˜ëŠ” g5.2xlarge ì¸ìŠ¤í„´ìŠ¤ì—ì„œ Ray workersë¡œ êµ¬ì„±ëœ Ray Serve í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•©ë‹ˆë‹¤.  ì´ ë°°í¬ì— ì‚¬ìš©ë˜ëŠ” ì£¼ìš” íŒŒì¼ì„ ìì„¸íˆ ì‚´í´ë³´ê³  ë°°í¬ë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ê¸°ëŠ¥ì„ ì´í•´í•˜ê² ìŠµë‹ˆë‹¤:  ray_serve_sd.py:ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” GPU ì¥ì°© ì¸í”„ë¼ì—ì„œ í™•ì¥ ê°€ëŠ¥í•œ ëª¨ë¸ ì„œë¹™ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” Ray Serveë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ëœ ë‘ ê°€ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œê°€ ìˆëŠ” FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì„¤ì •í•©ë‹ˆë‹¤: StableDiffusionV2 Deployment: ì´ í´ë˜ìŠ¤ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ Stable Diffusion V2 ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  ì²˜ë¦¬ë¥¼ ìœ„í•´ GPUë¡œ ì´ë™í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ì´ë¯¸ì§€ í¬ê¸°ëŠ” ì…ë ¥ íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ì‚¬ìš©ì ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.APIIngress: ì´ FastAPI ì—”ë“œí¬ì¸íŠ¸ëŠ” Stable Diffusion ëª¨ë¸ì— ëŒ€í•œ ì¸í„°í˜ì´ìŠ¤ ì—­í• ì„ í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì™€ ì„ íƒì  ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ë°›ëŠ” /imagine ê²½ë¡œì—ì„œ GET ë©”ì„œë“œë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤. Stable Diffusion ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  PNG íŒŒì¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. ray-service-stablediffusion.yaml:ì´ RayServe ë°°í¬ íŒ¨í„´ì€ GPU ì§€ì›ì´ í¬í•¨ëœ Amazon EKSì—ì„œ Stable Diffusion ëª¨ë¸ì„ í˜¸ìŠ¤íŒ…í•˜ê¸° ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ì „ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ê³  ìˆ˜ì‹  íŠ¸ë˜í”½ì— ë”°ë¼ ë¦¬ì†ŒìŠ¤ í™œìš©ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ìë™ ìŠ¤ì¼€ì¼ë§ ê¸°ëŠ¥ì´ ìˆëŠ” RayServiceë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤. ë°°í¬ëŠ” RayService ìš°ì‚° ì•„ë˜ì—ì„œ ì„œë¹™ë˜ëŠ” ëª¨ë¸ì´ ìˆ˜ìš”ì— ë”°ë¼ 1ê°œì—ì„œ 4ê°œì˜ ë ˆí”Œë¦¬ì¹´ ì‚¬ì´ì—ì„œ ìë™ìœ¼ë¡œ ì¡°ì •í•  ìˆ˜ ìˆë„ë¡ ë³´ì¥í•˜ë©°, ê° ë ˆí”Œë¦¬ì¹´ì—ëŠ” GPUê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ íŒ¨í„´ì€ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ê³  ë¬´ê±°ìš´ ì˜ì¡´ì„±ì´ ë¯¸ë¦¬ ë¡œë“œë˜ë„ë¡ í•˜ì—¬ ì‹œì‘ ì§€ì—°ì„ ìµœì†Œí™”í•˜ë„ë¡ ì„¤ê³„ëœ ì‚¬ìš©ì ì •ì˜ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Stable Diffusion V2 ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus#stable-diffusion-v2-ëª¨ë¸-ë°°í¬","content":" í´ëŸ¬ìŠ¤í„°ê°€ ë¡œì»¬ì—ì„œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸  aws eks --region us-west-2 update-kubeconfig --name jark-stack   RayServe í´ëŸ¬ìŠ¤í„° ë°°í¬  cd ai-on-eks/blueprints/inference/stable-diffusion-rayserve-gpu kubectl apply -f ray-service-stablediffusion.yaml   ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°°í¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤  ì •ë³´ ë°ì´í„° ë³¼ë¥¨ì— ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë¯¸ë¦¬ ë¡œë“œí•˜ì§€ ì•Šì€ ê²½ìš° ë°°í¬ í”„ë¡œì„¸ìŠ¤ì— ìµœëŒ€ 1012ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Head PodëŠ” 23ë¶„ ë‚´ì— ì¤€ë¹„ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, Ray Serve ì›Œì»¤ íŒŒë“œëŠ” Huggingfaceì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ëª¨ë¸ ë°°í¬ì— ìµœëŒ€ 10ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ë°°í¬ëŠ” ì•„ë˜ì™€ ê°™ì´ x86 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” Ray head íŒŒë“œì™€ GPU G5 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” ì›Œì»¤ íŒŒë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.  kubectl get pods -n stablediffusion NAME READY STATUS rservice-raycluster-hb4l4-worker-gpu-worker-group-z8gdw 1/1 Running stablediffusion-service-raycluster-hb4l4-head-4kfzz 2/2 Running   ë°ì´í„° ë³¼ë¥¨ì— ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë¯¸ë¦¬ ë¡œë“œí•œ ê²½ìš° kubectl describe pod -n stablediffusion ì¶œë ¥ì—ì„œ Container image &quot;public.ecr.aws/data-on-eks/ray2.11.0-py310-gpu-stablediffusion:latest&quot; already present on machine ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  kubectl describe pod -n stablediffusion ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 41m default-scheduler 0/8 nodes are available: 1 Insufficient cpu, 3 Insufficient memory, 8 Insufficient nvidia.com/gpu. preemption: 0/8 nodes are available: 8 No preemption victims found for incoming pod. Normal Nominated 41m karpenter Pod should schedule on: nodeclaim/gpu-ljvhl Normal Scheduled 40m default-scheduler Successfully assigned stablediffusion/stablediffusion-raycluster-ms6pl-worker-gpu-85d22 to ip-100-64-136-72.us-west-2.compute.internal Normal Pulled 40m kubelet Container image &quot;public.ecr.aws/data-on-eks/ray2.11.0-py310-gpu-stablediffusion:latest&quot; already present on machine Normal Created 40m kubelet Created container wait-gcs-ready Normal Started 40m kubelet Started container wait-gcs-ready Normal Pulled 39m kubelet Container image &quot;public.ecr.aws/data-on-eks/ray2.11.0-py310-gpu-stablediffusion:latest&quot; already present on machine Normal Created 39m kubelet Created container worker Normal Started 38m kubelet Started container worker   ì´ ë°°í¬ëŠ” ë˜í•œ ì—¬ëŸ¬ í¬íŠ¸ê°€ êµ¬ì„±ëœ stablediffusion ì„œë¹„ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. í¬íŠ¸ 8265ëŠ” Ray ëŒ€ì‹œë³´ë“œìš©ì´ê³  í¬íŠ¸ 8000ì€ Stable Diffusion ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸ìš©ì…ë‹ˆë‹¤.  kubectl get svc -n stablediffusion NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) stablediffusion-service NodePort 172.20.223.142 &lt;none&gt; 8080:30213/TCP,6379:30386/TCP,8265:30857/TCP,10001:30666/TCP,8000:31194/TCP stablediffusion-service-head-svc NodePort 172.20.215.100 &lt;none&gt; 8265:30170/TCP,10001:31246/TCP,8000:30376/TCP,8080:32646/TCP,6379:31846/TCP stablediffusion-service-serve-svc NodePort 172.20.153.125 &lt;none&gt; 8000:31459/TCP   Ray ëŒ€ì‹œë³´ë“œì˜ ê²½ìš° ì´ëŸ¬í•œ í¬íŠ¸ë¥¼ ê°œë³„ì ìœ¼ë¡œ í¬íŠ¸ í¬ì›Œë”©í•˜ì—¬ localhostë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ UIì— ë¡œì»¬ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  kubectl port-forward svc/stablediffusion-service 8266:8265 -n stablediffusion   http://localhost:8265ì—ì„œ ì›¹ UIì— ì ‘ê·¼í•˜ì„¸ìš”. ì´ ì¸í„°í˜ì´ìŠ¤ëŠ” Ray ì—ì½”ì‹œìŠ¤í…œ ë‚´ì˜ ì‘ì—… ë° ì•¡í„° ë°°í¬ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.    ì œê³µëœ ìŠ¤í¬ë¦°ìƒ·ì€ Serve ë°°í¬ì™€ Ray í´ëŸ¬ìŠ¤í„° ë°°í¬ë¥¼ ë³´ì—¬ì£¼ë©°, ì„¤ì • ë° ìš´ì˜ ìƒíƒœì— ëŒ€í•œ ì‹œê°ì  ê°œìš”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"Gradio WebUI ì•± ë°°í¬â€‹","type":1,"pageTitle":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus#gradio-webui-ì•±-ë°°í¬","content":" ë°°í¬ëœ ëª¨ë¸ê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ëŠ” Gradioë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì„¸ìš”.  localhostì—ì„œ Docker ì»¨í…Œì´ë„ˆë¡œ Gradio ì•±ì„ ì„¤ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ ì„¤ì •ì„ í†µí•´ RayServeë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ëœ Stable Diffusion XL ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Gradio ì•± Docker ì»¨í…Œì´ë„ˆ ë¹Œë“œâ€‹","type":1,"pageTitle":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus#gradio-ì•±-docker-ì»¨í…Œì´ë„ˆ-ë¹Œë“œ","content":" ë¨¼ì € í´ë¼ì´ì–¸íŠ¸ ì•±ìš© Docker ì»¨í…Œì´ë„ˆë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤.  cd ai-on-eks/blueprints/inference/gradio-ui docker build --platform=linux/amd64 \\ -t gradio-app:sd \\ --build-arg GRADIO_APP=&quot;gradio-app-stable-diffusion.py&quot; \\ .   ","version":"Next","tagName":"h3"},{"title":"Gradio ì»¨í…Œì´ë„ˆ ë°°í¬â€‹","type":1,"pageTitle":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus#gradio-ì»¨í…Œì´ë„ˆ-ë°°í¬","content":" Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ localhostì—ì„œ ì»¨í…Œì´ë„ˆë¡œ Gradio ì•±ì„ ë°°í¬í•©ë‹ˆë‹¤:  docker run --rm -it -p 7860:7860 -p 8000:8000 gradio-app:sd   ì •ë³´ Docker Desktopì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  finchì™€ ê°™ì€ ê²ƒì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ ì‚¬ìš©ì ì •ì˜ í˜¸ìŠ¤íŠ¸-IP ë§¤í•‘ì„ ìœ„í•œ ì¶”ê°€ í”Œë˜ê·¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. docker run --rm -it \\ --add-host ray-service:&lt;workstation-ip&gt; \\ -e &quot;SERVICE_NAME=http://ray-service:8000&quot; \\ -p 7860:7860 gradio-app:sd   WebUI í˜¸ì¶œâ€‹  ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  ë‹¤ìŒ URLë¡œ ì´ë™í•˜ì—¬ Gradio WebUIì— ì ‘ê·¼í•©ë‹ˆë‹¤:  ë¡œì»¬ URLì—ì„œ ì‹¤í–‰ ì¤‘: http://localhost:7860  ì´ì œ ë¡œì»¬ ë¨¸ì‹ ì—ì„œ Gradio ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"Ray ìë™ ìŠ¤ì¼€ì¼ë§â€‹","type":1,"pageTitle":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus#ray-ìë™-ìŠ¤ì¼€ì¼ë§","content":" ray-serve-stablediffusion.yaml íŒŒì¼ì— ìì„¸íˆ ì„¤ëª…ëœ Ray ìë™ ìŠ¤ì¼€ì¼ë§ êµ¬ì„±ì€ Kubernetesì—ì„œ Rayì˜ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ê³„ì‚° ìš”êµ¬ì— ë”°ë¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë™ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤.  ìˆ˜ì‹  íŠ¸ë˜í”½: stable-diffusion ë°°í¬ì— ëŒ€í•œ ìˆ˜ì‹  ìš”ì²­ì€ Ray Serveê°€ ê¸°ì¡´ ë ˆí”Œë¦¬ì¹´ì˜ ë¶€í•˜ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ë„ë¡ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.ë©”íŠ¸ë¦­ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§: Ray ServeëŠ” ë ˆí”Œë¦¬ì¹´ë‹¹ í‰ê·  ì§„í–‰ ì¤‘ì¸ ìš”ì²­ ìˆ˜ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. ì´ êµ¬ì„±ì—ì„œëŠ” target_num_ongoing_requests_per_replicaê°€ 1ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ë©”íŠ¸ë¦­ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ ë” ë§ì€ ë ˆí”Œë¦¬ì¹´ê°€ í•„ìš”í•˜ë‹¤ëŠ” ì‹ í˜¸ë¥¼ ë³´ëƒ…ë‹ˆë‹¤.ë ˆí”Œë¦¬ì¹´ ìƒì„± (ë…¸ë“œ ë‚´): ë…¸ë“œì— ì¶©ë¶„í•œ GPU ìš©ëŸ‰ì´ ìˆìœ¼ë©´ Ray ServeëŠ” ê¸°ì¡´ ë…¸ë“œ ë‚´ì— ìƒˆ ë ˆí”Œë¦¬ì¹´ë¥¼ ì¶”ê°€í•˜ë ¤ê³  ì‹œë„í•©ë‹ˆë‹¤. ë°°í¬ëŠ” ë ˆí”Œë¦¬ì¹´ë‹¹ 1ê°œì˜ GPUë¥¼ ìš”ì²­í•©ë‹ˆë‹¤ (ray_actor_options: num_gpus: 1).ë…¸ë“œ ìŠ¤ì¼€ì¼ë§ (Karpenter): ë…¸ë“œê°€ ì¶”ê°€ ë ˆí”Œë¦¬ì¹´ë¥¼ ìˆ˜ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° (ì˜ˆ: ë…¸ë“œë‹¹ í•˜ë‚˜ì˜ GPUë§Œ ìˆëŠ” ê²½ìš°), RayëŠ” Kubernetesì— ë” ë§ì€ ë¦¬ì†ŒìŠ¤ê°€ í•„ìš”í•˜ë‹¤ê³  ì‹ í˜¸ë¥¼ ë³´ëƒ…ë‹ˆë‹¤. KarpenterëŠ” Kubernetesì˜ ë³´ë¥˜ ì¤‘ì¸ íŒŒë“œ ìš”ì²­ì„ ê´€ì°°í•˜ê³  ë¦¬ì†ŒìŠ¤ ìš”êµ¬ë¥¼ ì¶©ì¡±í•˜ê¸° ìœ„í•´ ìƒˆ g5 GPU ë…¸ë“œë¥¼ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤.ë ˆí”Œë¦¬ì¹´ ìƒì„± (ë…¸ë“œ ê°„): ìƒˆ ë…¸ë“œê°€ ì¤€ë¹„ë˜ë©´ Ray ServeëŠ” ìƒˆë¡œ í”„ë¡œë¹„ì €ë‹ëœ ë…¸ë“œì— ì¶”ê°€ ë ˆí”Œë¦¬ì¹´ë¥¼ ìŠ¤ì¼€ì¤„ë§í•©ë‹ˆë‹¤.  ìë™ ìŠ¤ì¼€ì¼ë§ ì‹œë®¬ë ˆì´ì…˜:  ë¶€í•˜ ìƒì„±: ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë§Œë“¤ê±°ë‚˜ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ stable diffusion ì„œë¹„ìŠ¤ì— ë²„ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.ê´€ì°° (Ray Dashboard): í¬íŠ¸ í¬ì›Œë”© ë˜ëŠ” í¼ë¸”ë¦­ NLB(êµ¬ì„±ëœ ê²½ìš°)ë¥¼ í†µí•´ http://your-cluster/dashboardì—ì„œ Ray Dashboardì— ì ‘ê·¼í•©ë‹ˆë‹¤. ë‹¤ìŒ ë©”íŠ¸ë¦­ì´ ì–´ë–»ê²Œ ë³€ê²½ë˜ëŠ”ì§€ ê´€ì°°í•©ë‹ˆë‹¤: ë°°í¬ì˜ ë ˆí”Œë¦¬ì¹´ ìˆ˜. Ray í´ëŸ¬ìŠ¤í„°ì˜ ë…¸ë“œ ìˆ˜.ê´€ì°° (Kubernetes): kubectl get pods -n stablediffusionì„ ì‚¬ìš©í•˜ì—¬ ìƒˆ íŒŒë“œ ìƒì„±ì„ í™•ì¸í•©ë‹ˆë‹¤. kubectl get nodesë¥¼ ì‚¬ìš©í•˜ì—¬ Karpenterê°€ í”„ë¡œë¹„ì €ë‹í•œ ìƒˆ ë…¸ë“œë¥¼ ê´€ì°°í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"GPU, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion v2 ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/stablediffusion-gpus#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ê°€ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì„ ë•Œ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ì„ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  1ë‹¨ê³„: Gradio ì»¨í…Œì´ë„ˆ ì‚­ì œ  docker runì´ ì‹¤í–‰ ì¤‘ì¸ localhost í„°ë¯¸ë„ ì°½ì—ì„œ Ctrl-cë¥¼ ëˆŒëŸ¬ Gradio ì•±ì„ ì‹¤í–‰í•˜ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì„ íƒì ìœ¼ë¡œ Docker ì´ë¯¸ì§€ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤  docker rmi gradio-app:sd   2ë‹¨ê³„: Ray í´ëŸ¬ìŠ¤í„° ì‚­ì œ  cd ai-on-eks/blueprints/inference/stable-diffusion-rayserve-gpu kubectl delete -f ray-service-stablediffusion.yaml   3ë‹¨ê³„: EKS í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” -target ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¦¬ì†ŒìŠ¤ê°€ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì‚­ì œë˜ë„ë¡ í™˜ê²½ì„ ì •ë¦¬í•©ë‹ˆë‹¤.  cd ai-on-eks/infra/jark-stack/ ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer","content":"","keywords":"","version":"Next"},{"title":"ì˜ˆìƒ ê²°ê³¼â€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#ì˜ˆìƒ-ê²°ê³¼","content":" ì„¤ëª…ëœ ëŒ€ë¡œ ëª¨ë“  ê²ƒì„ ë°°í¬í•˜ë©´ ì¶”ë¡  ìš”ì²­ì— ëŒ€í•œ ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” Llama-2-7b-chat-hfì™€ Mistral-7B-Instruct-v0.2 ëª¨ë¸ë¡œ triton-client.py ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•œ ì˜ˆì œ ì¶œë ¥ì…ë‹ˆë‹¤.  í´ë¦­í•˜ì—¬ ë¹„êµ ê²°ê³¼ í™•ì¥ ì‹¤í–‰ 1: Llama2\tì‹¤í–‰ 2: Mistral7bpython3 triton-client.py --model-name llama2 --input-prompts prompts.txt --results-file llama2_results.txt\tpython3 triton-client.py --model-name mistral7b --input-prompts prompts.txt --results-file mistral_results.txt prompts.txtì—ì„œ ì…ë ¥ ë¡œë”© ì¤‘...\tprompts.txtì—ì„œ ì…ë ¥ ë¡œë”© ì¤‘... Model llama2 - Request 11: 0.00 ms\tModel mistral7b - Request 3: 0.00 ms Model llama2 - Request 15: 0.02 ms\tModel mistral7b - Request 14: 0.00 ms Model llama2 - Request 3: 0.00 ms\tModel mistral7b - Request 11: 0.00 ms Model llama2 - Request 8: 0.01 ms\tModel mistral7b - Request 15: 0.00 ms Model llama2 - Request 0: 0.01 ms\tModel mistral7b - Request 5: 0.00 ms Model llama2 - Request 9: 0.01 ms\tModel mistral7b - Request 0: 0.01 ms Model llama2 - Request 14: 0.01 ms\tModel mistral7b - Request 7: 0.01 ms Model llama2 - Request 16: 0.00 ms\tModel mistral7b - Request 13: 0.00 ms Model llama2 - Request 19: 0.02 ms\tModel mistral7b - Request 9: 0.00 ms Model llama2 - Request 4: 0.02 ms\tModel mistral7b - Request 16: 0.01 ms Model llama2 - Request 10: 0.02 ms\tModel mistral7b - Request 18: 0.01 ms Model llama2 - Request 6: 0.01 ms\tModel mistral7b - Request 4: 0.01 ms Model llama2 - Request 1: 0.02 ms\tModel mistral7b - Request 8: 0.01 ms Model llama2 - Request 7: 0.02 ms\tModel mistral7b - Request 1: 0.01 ms Model llama2 - Request 18: 0.01 ms\tModel mistral7b - Request 6: 0.00 ms Model llama2 - Request 12: 0.01 ms\tModel mistral7b - Request 12: 0.00 ms Model llama2 - Request 2: 0.01 ms\tModel mistral7b - Request 17: 0.00 ms Model llama2 - Request 17: 0.02 ms\tModel mistral7b - Request 2: 0.01 ms Model llama2 - Request 13: 0.01 ms\tModel mistral7b - Request 19: 0.01 ms Model llama2 - Request 5: 0.02 ms\tModel mistral7b - Request 10: 0.02 ms ê²°ê³¼ë¥¼ llama2_results.txtì— ì €ì¥ ì¤‘...\tê²°ê³¼ë¥¼ mistral_results.txtì— ì €ì¥ ì¤‘... ëª¨ë“  ìš”ì²­ ì´ ì‹œê°„: 0.00ì´ˆ (0.18 ë°€ë¦¬ì´ˆ)\tëª¨ë“  ìš”ì²­ ì´ ì‹œê°„: 0.00ì´ˆ (0.11 ë°€ë¦¬ì´ˆ) PASS: vLLM ì˜ˆì œ\tPASS: vLLM ì˜ˆì œ  Triton Server ë‚´ë¶€ êµ¬ì¡° ë° ë°±ì—”ë“œ í†µí•©  NVIDIA Triton Inference ServerëŠ” ë‹¤ì–‘í•œ ëª¨ë¸ ìœ í˜•ê³¼ ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ê³ ì„±ëŠ¥ ì¶”ë¡ ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Tritonì˜ í•µì‹¬ ê°•ì ì€ ë‹¤ì–‘í•œ ë°±ì—”ë“œ ì§€ì›ì— ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ëª¨ë¸ê³¼ ì›Œí¬ë¡œë“œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìœ ì—°ì„±ê³¼ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.  ìš”ì²­ì´ Triton K8s Serviceì— ë„ë‹¬í•˜ë©´ Triton Serverì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ì„œë²„ëŠ” ë™ì  ë°°ì¹­ì„ ì§€ì›í•˜ì—¬ ì—¬ëŸ¬ ì¶”ë¡  ìš”ì²­ì„ ê·¸ë£¹í™”í•˜ì—¬ ì²˜ë¦¬ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤. ì´ëŠ” ë†’ì€ ì²˜ë¦¬ëŸ‰ ìš”êµ¬ ì‚¬í•­ì´ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ íŠ¹íˆ ìœ ìš©í•˜ë©°, ì§€ì—° ì‹œê°„ì„ ì¤„ì´ê³  ì „ì²´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  ê·¸ëŸ° ë‹¤ìŒ ìš”ì²­ì€ ì˜ˆì•½ëœ íì— ì˜í•´ ê´€ë¦¬ë˜ì–´ ê° ëª¨ë¸ì˜ ì¶”ë¡  ìš”ì²­ì´ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤. Triton ServerëŠ” ì„ íƒì  ë° ê³„ì‚° ëª¨ë¸ ë¡œë”©ì„ ì§€ì›í•˜ë¯€ë¡œ í˜„ì¬ ì›Œí¬ë¡œë“œì™€ ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„±ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ë‹¤ì¤‘ ëª¨ë¸ ë°°í¬ì—ì„œ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.  Tritonì˜ ì¶”ë¡  ê¸°ëŠ¥ì˜ í•µì‹¬ì€ TensorRT-LLM ë° vLLMì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë°±ì—”ë“œì…ë‹ˆë‹¤:  TensorRT-LLM: TensorRT-LLM ë°±ì—”ë“œëŠ” NVIDIA GPUì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ì¶”ë¡ ì„ ìµœì í™”í•©ë‹ˆë‹¤. TensorRTì˜ ê³ ì„±ëŠ¥ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ì¶”ë¡ ì„ ê°€ì†í™”í•˜ê³  ë‚®ì€ ì§€ì—° ì‹œê°„ê³¼ ë†’ì€ ì²˜ë¦¬ëŸ‰ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. TensorRTëŠ” ì§‘ì¤‘ì ì¸ ê³„ì‚° ë¦¬ì†ŒìŠ¤ê°€ í•„ìš”í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì— íŠ¹íˆ ì í•©í•˜ì—¬ ì‹¤ì‹œê°„ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì´ìƒì ì…ë‹ˆë‹¤.  vLLM: vLLM ë°±ì—”ë“œëŠ” ë‹¤ì–‘í•œ LLM ì›Œí¬ë¡œë“œë¥¼ ì²˜ë¦¬í•˜ë„ë¡ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€ê·œëª¨ ëª¨ë¸ì— ë§ì¶¤í™”ëœ íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ì™€ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ë°±ì—”ë“œëŠ” ë©”ëª¨ë¦¬ ë¦¬ì†ŒìŠ¤ê°€ ìµœì ìœ¼ë¡œ ì‚¬ìš©ë˜ë„ë¡ ë³´ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ë³‘ëª© í˜„ìƒ ì—†ì´ ë§¤ìš° í° ëª¨ë¸ì„ ë°°í¬í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. vLLMì€ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ëª¨ë¸ì„ ë™ì‹œì— ì„œë¹™í•´ì•¼ í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì¤‘ìš”í•˜ë©°, ê°•ë ¥í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"Mistralai/Mistral-7B-Instruct-v0.2â€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#mistralaimistral-7b-instruct-v02","content":" Mistralai/Mistral-7B-Instruct-v0.2ëŠ” ê³ í’ˆì§ˆì˜ êµìœ¡ì  ì‘ë‹µì„ ì œê³µí•˜ë„ë¡ ì„¤ê³„ëœ ìµœì²¨ë‹¨ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ë˜ì–´ ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ì¸ê°„ê³¼ ê°™ì€ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” ë° ë›°ì–´ë‚©ë‹ˆë‹¤. ì´ ëª¨ë¸ì˜ ê¸°ëŠ¥ì€ ìì„¸í•œ ì„¤ëª…, ë³µì¡í•œ ì¿¼ë¦¬, ìì—°ì–´ ì´í•´ê°€ í•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Meta-llama/Llama-2-7b-chat-hfâ€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#meta-llamallama-2-7b-chat-hf","content":" Meta-llama/Llama-2-7b-chat-hfëŠ” Metaì—ì„œ ê°œë°œí•œ ê³ ê¸‰ ëŒ€í™”í˜• AI ëª¨ë¸ì…ë‹ˆë‹¤. ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ì— ìµœì í™”ë˜ì–´ ì¼ê´€ë˜ê³  ë¬¸ë§¥ì ìœ¼ë¡œ ê´€ë ¨ì„± ìˆëŠ” ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ëŒ€í™” ë°ì´í„°ì…‹ìœ¼ë¡œ ê°•ë ¥í•˜ê²Œ í›ˆë ¨ë˜ì–´ ì´ ëª¨ë¸ì€ ì°¸ì—¬ì ì´ê³  ë™ì ì¸ ëŒ€í™”ë¥¼ ìœ ì§€í•˜ëŠ” ë° ë›°ì–´ë‚˜ë©°, ê³ ê° ì„œë¹„ìŠ¤ ë´‡, ëŒ€í™”í˜• ì—ì´ì „íŠ¸ ë° ê¸°íƒ€ ì±„íŒ… ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì´ìƒì ì…ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#ì†”ë£¨ì…˜-ë°°í¬","content":" Amazon EKSì—ì„œ mistralai/Mistral-7B-Instruct-v0.2ì™€ meta-llama/Llama-2-7b-chat-hfë¥¼ ë°°í¬í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ì„ ë‹¤ë£¨ê³  ë‹¨ê³„ë³„ë¡œ ë°°í¬ ê³¼ì •ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ëŠ” ì¸í”„ë¼ ì„¤ì •, NVIDIA Triton Inference Server ë°°í¬, ì¶”ë¡ ì„ ìœ„í•´ Triton ì„œë²„ì— gRPC ìš”ì²­ì„ ë³´ë‚´ëŠ” Triton í´ë¼ì´ì–¸íŠ¸ Python ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±ì´ í¬í•¨ë©ë‹ˆë‹¤.  ìœ„í—˜ ì¤‘ìš”: ì—¬ëŸ¬ GPUê°€ ì¥ì°©ëœ g5.24xlarge ì¸ìŠ¤í„´ìŠ¤ì— ë°°í¬í•˜ë©´ ë¹„ìš©ì´ ë§ì´ ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆìƒì¹˜ ëª»í•œ ë¹„ìš©ì„ í”¼í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëŸ‰ì„ ì‹ ì¤‘í•˜ê²Œ ëª¨ë‹ˆí„°ë§í•˜ê³  ê´€ë¦¬í•˜ì„¸ìš”. ì§€ì¶œì„ ì¶”ì í•˜ê¸° ìœ„í•´ ì˜ˆì‚° ì•Œë¦¼ê³¼ ì‚¬ìš© ì œí•œì„ ì„¤ì •í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"vLLM ë°±ì—”ë“œê°€ í¬í•¨ëœ NVIDIA Triton Serverâ€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#vllm-ë°±ì—”ë“œê°€-í¬í•¨ëœ-nvidia-triton-server","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” Triton helm chartë¥¼ ì‚¬ìš©í•˜ì—¬ Amazon EKSì— Triton ì„œë²„ë¥¼ ì„¤ì¹˜í•˜ê³  êµ¬ì„±í•©ë‹ˆë‹¤. ë°°í¬ëŠ” ë¸”ë£¨í”„ë¦°íŠ¸ì˜ ë‹¤ìŒ Terraform ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì„±ë©ë‹ˆë‹¤.  í´ë¦­í•˜ì—¬ ë°°í¬ ì½”ë“œ í™•ì¥ module &quot;triton_server_vllm&quot; { depends_on = [module.eks_blueprints_addons.kube_prometheus_stack] source = &quot;aws-ia/eks-data-addons/aws&quot; version = &quot;~&gt; 1.32.0&quot; # ìµœì‹ /ì›í•˜ëŠ” ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš” oidc_provider_arn = module.eks.oidc_provider_arn enable_nvidia_triton_server = false nvidia_triton_server_helm_config = { version = &quot;1.0.0&quot; timeout = 120 wait = false namespace = kubernetes_namespace_v1.triton.metadata[0].name values = [ &lt;&lt;-EOT replicaCount: 1 image: repository: nvcr.io/nvidia/tritonserver tag: &quot;24.06-vllm-python-py3&quot; serviceAccount: create: false name: ${kubernetes_service_account_v1.triton.metadata[0].name} modelRepositoryPath: s3://${module.s3_bucket.s3_bucket_id}/model_repository environment: - name: model_name value: ${local.default_model_name} - name: &quot;LD_PRELOAD&quot; value: &quot;&quot; - name: &quot;TRANSFORMERS_CACHE&quot; value: &quot;/home/triton-server/.cache&quot; - name: &quot;shm-size&quot; value: &quot;5g&quot; - name: &quot;NCCL_IGNORE_DISABLED_P2P&quot; value: &quot;1&quot; - name: tensor_parallel_size value: &quot;1&quot; - name: gpu_memory_utilization value: &quot;0.9&quot; - name: dtype value: &quot;auto&quot; secretEnvironment: - name: &quot;HUGGING_FACE_TOKEN&quot; secretName: ${kubernetes_secret_v1.huggingface_token.metadata[0].name} key: &quot;HF_TOKEN&quot; resources: limits: cpu: 6 memory: 25Gi nvidia.com/gpu: 4 requests: cpu: 6 memory: 25Gi nvidia.com/gpu: 4 nodeSelector: NodeGroupType: g5-gpu-karpenter type: karpenter tolerations: - key: &quot;nvidia.com/gpu&quot; operator: &quot;Exists&quot; effect: &quot;NoSchedule&quot; EOT ] } }   ì°¸ê³ : Triton ì„œë²„ì— ì‚¬ìš©ë˜ëŠ” ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ëŠ” nvcr.io/nvidia/tritonserver:24.02-vllm-python-py3ì´ë©° vLLM ë°±ì—”ë“œê°€ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. NGC Catalogì—ì„œ ì ì ˆí•œ íƒœê·¸ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ëª¨ë¸ ì €ì¥ì†Œ: Triton Inference ServerëŠ” ì„œë²„ ì‹œì‘ ì‹œ ì§€ì •ëœ í•˜ë‚˜ ì´ìƒì˜ ëª¨ë¸ ì €ì¥ì†Œì—ì„œ ëª¨ë¸ì„ ì„œë¹™í•©ë‹ˆë‹¤. Tritonì€ ë¡œì»¬ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ íŒŒì¼ ê²½ë¡œì™€ Amazon S3ì™€ ê°™ì€ í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ìœ„ì¹˜ì—ì„œ ëª¨ë¸ì— ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ëª¨ë¸ ì €ì¥ì†Œë¥¼ êµ¬ì„±í•˜ëŠ” ë””ë ‰í† ë¦¬ì™€ íŒŒì¼ì€ í•„ìˆ˜ ë ˆì´ì•„ì›ƒì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ì €ì¥ì†Œ ë ˆì´ì•„ì›ƒì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:  í´ë¦­í•˜ì—¬ ëª¨ë¸ ë””ë ‰í† ë¦¬ ê³„ì¸µ êµ¬ì¡° í™•ì¥ &lt;model-repository-path&gt;/ &lt;model-name&gt;/ [config.pbtxt] [&lt;output-labels-file&gt; ...] &lt;version&gt;/ &lt;model-definition-file&gt; &lt;version&gt;/ &lt;model-definition-file&gt; &lt;model-name&gt;/ [config.pbtxt] [&lt;output-labels-file&gt; ...] &lt;version&gt;/ &lt;model-definition-file&gt; &lt;version&gt;/ &lt;model-definition-file&gt; ... ------------- ì˜ˆ: ------------- model-repository/ mistral-7b/ config.pbtxt 1/ model.py llama-2/ config.pbtxt 1/ model.py   vLLM í™œì„±í™”ëœ Triton ëª¨ë¸ì˜ ê²½ìš° model_repositoryëŠ” ai/inference/vllm-nvidia-triton-server-gpu/model_repository ìœ„ì¹˜ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°°í¬ ì¤‘ì— ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” S3 ë²„í‚·ì„ ìƒì„±í•˜ê³  ë¡œì»¬ model_repository ë‚´ìš©ì„ S3 ë²„í‚·ì— ë™ê¸°í™”í•©ë‹ˆë‹¤.  model.py: ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” vLLM ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ Triton ë°±ì—”ë“œ í”„ë ˆì„ì›Œí¬ë¡œ ì‚¬ìš©í•˜ê³  ëª¨ë¸ êµ¬ì„±ì„ ë¡œë“œí•˜ê³  vLLM ì—”ì§„ì„ êµ¬ì„±í•˜ì—¬ TritonPythonModel í´ë˜ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. huggingface_hub ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë¡œê·¸ì¸ í•¨ìˆ˜ëŠ” ëª¨ë¸ ì ‘ê·¼ì„ ìœ„í•´ hugging face ì €ì¥ì†Œì— ëŒ€í•œ ì ‘ê·¼ì„ ì„¤ì •í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ìˆ˜ì‹ ëœ ìš”ì²­ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ asyncio ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ì—ëŠ” ì¶”ë¡  ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³  vLLM ë°±ì—”ë“œì— ìš”ì²­ì„ ë°œí–‰í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” ì—¬ëŸ¬ í•¨ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤.  config.pbtxt: ë‹¤ìŒê³¼ ê°™ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì •í•˜ëŠ” ëª¨ë¸ êµ¬ì„± íŒŒì¼ì…ë‹ˆë‹¤  Name - ëª¨ë¸ì˜ ì´ë¦„ì€ ëª¨ë¸ì„ í¬í•¨í•˜ëŠ” ëª¨ë¸ ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ì˜ nameê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.max_batch_size - max_batch_size ê°’ì€ Tritonì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ë°°ì¹­ ìœ í˜•ì— ëŒ€í•´ ëª¨ë¸ì´ ì§€ì›í•˜ëŠ” ìµœëŒ€ ë°°ì¹˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤Inputs and Outputs - ê° ëª¨ë¸ ì…ë ¥ ë° ì¶œë ¥ì€ ì´ë¦„, ë°ì´í„° ìœ í˜•, ëª¨ì–‘ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì…ë ¥ ëª¨ì–‘ì€ ëª¨ë¸ê³¼ ì¶”ë¡  ìš”ì²­ì—ì„œ Tritonì´ ì˜ˆìƒí•˜ëŠ” ì…ë ¥ í…ì„œì˜ ëª¨ì–‘ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì¶œë ¥ ëª¨ì–‘ì€ ëª¨ë¸ì´ ìƒì„±í•˜ê³  ì¶”ë¡  ìš”ì²­ì— ëŒ€í•œ ì‘ë‹µìœ¼ë¡œ Tritonì´ ë°˜í™˜í•˜ëŠ” ì¶œë ¥ í…ì„œì˜ ëª¨ì–‘ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì…ë ¥ ë° ì¶œë ¥ ëª¨ì–‘ì€ max_batch_sizeì™€ input dims ë˜ëŠ” output dimsë¡œ ì§€ì •ëœ ì°¨ì›ì˜ ì¡°í•©ìœ¼ë¡œ ì§€ì •ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ë°°í¬ í™•ì¸â€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#ë°°í¬-í™•ï¿½ï¿½ì¸","content":" Triton Inference Serverê°€ ì„±ê³µì ìœ¼ë¡œ ë°°í¬ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:  kubectl get all -n triton-vllm   ì•„ë˜ ì¶œë ¥ì€ ë‘ ëª¨ë¸ì„ í˜¸ìŠ¤íŒ…í•˜ëŠ” Triton ì„œë²„ë¥¼ ì‹¤í–‰í•˜ëŠ” í•˜ë‚˜ì˜ íŒŒë“œê°€ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©í•˜ê¸° ìœ„í•œ í•˜ë‚˜ì˜ ì„œë¹„ìŠ¤ì™€ Triton ì„œë²„ë¥¼ ìœ„í•œ í•˜ë‚˜ì˜ ReplicaSetì´ ìˆìŠµë‹ˆë‹¤. ë°°í¬ëŠ” ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­ê³¼ HPA ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§ë©ë‹ˆë‹¤.  NAME READY STATUS RESTARTS AGE pod/nvidia-triton-server-triton-inference-server-c49bd559d-szlpf 1/1 Running 0 13m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/nvidia-triton-server-triton-inference-server ClusterIP 172.20.193.97 &lt;none&gt; 8000/TCP,8001/TCP,8002/TCP 13m service/nvidia-triton-server-triton-inference-server-metrics ClusterIP 172.20.5.247 &lt;none&gt; 8080/TCP 13m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/nvidia-triton-server-triton-inference-server 1/1 1 1 13m NAME DESIRED CURRENT READY AGE replicaset.apps/nvidia-triton-server-triton-inference-server-c49bd559d 1 1 1 13m NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE horizontalpodautoscaler.autoscaling/nvidia-triton-server-triton-inference-server Deployment/nvidia-triton-server-triton-inference-server &lt;unknown&gt;/80%, &lt;unknown&gt;/80% 1 5 1 13m   ì´ ì¶œë ¥ì€ Triton ì„œë²„ íŒŒë“œê°€ ì‹¤í–‰ ì¤‘ì´ê³  ì„œë¹„ìŠ¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆìœ¼ë©° ë°°í¬ê°€ ì˜ˆìƒëŒ€ë¡œ ì‘ë™í•˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. Horizontal Pod Autoscalerë„ í™œì„±í™”ë˜ì–´ ì§€ì •ëœ ë©”íŠ¸ë¦­ì— ë”°ë¼ íŒŒë“œ ìˆ˜ê°€ ìŠ¤ì¼€ì¼ë§ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Llama-2-7b Chat ë° Mistral-7b Chat ëª¨ë¸ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#llama-2-7b-chat-ë°-mistral-7b-chat-ëª¨ë¸-í…ŒìŠ¤íŠ¸","content":" ì´ì œ Llama-2-7b chatê³¼ Mistral-7b chat ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë‘ ëª¨ë¸ì´ ìƒì„±í•œ ì¶œë ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.  ë¨¼ì € kubectlì„ ì‚¬ìš©í•˜ì—¬ Triton-inference-server ì„œë¹„ìŠ¤ë¡œ í¬íŠ¸ í¬ì›Œë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl -n triton-vllm port-forward svc/nvidia-triton-server-triton-inference-server 8001:8001   ë‹¤ìŒìœ¼ë¡œ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ëª¨ë¸ì— ëŒ€í•´ Triton í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:  cd ai-on-eks/blueprints/inference/vllm-nvidia-triton-server-gpu/triton-client python3 -m venv .venv source .venv/bin/activate pip install tritonclient[all] python3 triton-client.py --model-name mistral7b --input-prompts prompts.txt --results-file mistral_results.txt   ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:  python3 triton-client.py --model-name mistral7b --input-prompts prompts.txt --results-file mistral_results.txt `prompts.txt`ì—ì„œ ì…ë ¥ ë¡œë”© ì¤‘... Model mistral7b - Request 3: 0.00 ms Model mistral7b - Request 14: 0.00 ms Model mistral7b - Request 11: 0.00 ms Model mistral7b - Request 15: 0.00 ms Model mistral7b - Request 5: 0.00 ms Model mistral7b - Request 0: 0.01 ms Model mistral7b - Request 7: 0.01 ms Model mistral7b - Request 13: 0.00 ms Model mistral7b - Request 9: 0.00 ms Model mistral7b - Request 16: 0.01 ms Model mistral7b - Request 18: 0.01 ms Model mistral7b - Request 4: 0.01 ms Model mistral7b - Request 8: 0.01 ms Model mistral7b - Request 1: 0.01 ms Model mistral7b - Request 6: 0.00 ms Model mistral7b - Request 12: 0.00 ms Model mistral7b - Request 17: 0.00 ms Model mistral7b - Request 2: 0.01 ms Model mistral7b - Request 19: 0.01 ms Model mistral7b - Request 10: 0.02 ms ê²°ê³¼ë¥¼ `mistral_results.txt`ì— ì €ì¥ ì¤‘... ëª¨ë“  ìš”ì²­ ì´ ì‹œê°„: 0.00ì´ˆ (0.11 ë°€ë¦¬ì´ˆ) PASS: vLLM ì˜ˆì œ   mistral_results.txtì˜ ì¶œë ¥ì€ ì•„ë˜ì™€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:  í´ë¦­í•˜ì—¬ Mistral ê²°ê³¼ ë¶€ë¶„ ì¶œë ¥ í™•ì¥ &lt;s&gt;[INST]&lt;&lt;SYS&gt;&gt; 100ë¬¸ì¥ ì´í•˜ì˜ ì§§ì€ ë‹µë³€ì„ ìœ ì§€í•˜ì„¸ìš”. &lt;&lt;/SYS&gt;&gt; ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ê³¼ ì´ˆëŒ€í˜• ì–¸ì–´ ëª¨ë¸(vLLM)ì˜ ì£¼ìš” ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”? [/INST] ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸(MLM)ì€ íŠ¹ì • ë°ì´í„°ì…‹ê³¼ íŠ¹ì„±ìœ¼ë¡œ í›ˆë ¨ë˜ì–´ í•´ë‹¹ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒ¨í„´ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•©ë‹ˆë‹¤. í›ˆë ¨ì„ ìœ„í•´ ë ˆì´ë¸”ì´ ì§€ì •ëœ ë°ì´í„°ê°€ í•„ìš”í•˜ë©° í›ˆë ¨ ë°ì´í„°ì˜ í¬ê¸°ì™€ ë‹¤ì–‘ì„±ì— ì˜í•´ ì œí•œë©ë‹ˆë‹¤. MLMì€ ì´ë¯¸ì§€ ì¸ì‹ì´ë‚˜ ìŒì„± ì¸ì‹ê³¼ ê°™ì€ êµ¬ì¡°í™”ëœ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë©´ ì´ˆëŒ€í˜• ì–¸ì–´ ëª¨ë¸(vLLM)ì€ ë”¥ëŸ¬ë‹ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ í›ˆë ¨ë©ë‹ˆë‹¤. ìˆ˜ì‹ í•˜ëŠ” ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ì¸ê°„ê³¼ ê°™ì€ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤. vLLMì€ MLMë³´ë‹¤ ë” ë¬¸ë§¥ì„ ì¸ì‹í•˜ê³  ë¯¸ë¬˜í•œ ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ìš”ì•½, ë²ˆì—­, ì§ˆë¬¸ ì‘ë‹µê³¼ ê°™ì€ ë” ë„“ì€ ë²”ìœ„ì˜ ì‘ì—…ë„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ vLLMì€ ê³„ì‚° ë¹„ìš©ì´ ë” ë§ì´ ë“¤ê³  í›ˆë ¨ì— ëŒ€ëŸ‰ì˜ ë°ì´í„°ì™€ ì „ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤. ì ì ˆí•˜ê²Œ ê´€ë¦¬ë˜ì§€ ì•Šìœ¼ë©´ ë¶€ì •í™•í•˜ê±°ë‚˜ í¸í–¥ëœ ì‘ë‹µì„ ìƒì„±í•  ê°€ëŠ¥ì„±ë„ ìˆìŠµë‹ˆë‹¤. =========   ì´ì œ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ë¡œ Llama-2-7b-chat ëª¨ë¸ì—ì„œ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ê³  llama2_results.txtë¼ëŠ” ìƒˆ íŒŒì¼ì—ì„œ ì¶œë ¥ì„ í™•ì¸í•´ ë³´ì„¸ìš”.  python3 triton-client.py --model-name llama2 --input-prompts prompts.txt --results-file llama2_results.txt   ì¶œë ¥ì€ ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:  python3 triton-client.py --model-name llama2 --input-prompts prompts.txt --results-file llama2_results.txt `prompts.txt`ì—ì„œ ì…ë ¥ ë¡œë”© ì¤‘... Model llama2 - Request 11: 0.00 ms Model llama2 - Request 15: 0.02 ms Model llama2 - Request 3: 0.00 ms Model llama2 - Request 8: 0.03 ms Model llama2 - Request 5: 0.02 ms Model llama2 - Request 0: 0.00 ms Model llama2 - Request 14: 0.00 ms Model llama2 - Request 16: 0.01 ms Model llama2 - Request 19: 0.02 ms Model llama2 - Request 4: 0.01 ms Model llama2 - Request 1: 0.01 ms Model llama2 - Request 10: 0.01 ms Model llama2 - Request 9: 0.01 ms Model llama2 - Request 7: 0.01 ms Model llama2 - Request 18: 0.01 ms Model llama2 - Request 12: 0.00 ms Model llama2 - Request 2: 0.00 ms Model llama2 - Request 6: 0.00 ms Model llama2 - Request 17: 0.01 ms Model llama2 - Request 13: 0.01 ms ê²°ê³¼ë¥¼ `llama2_results.txt`ì— ì €ì¥ ì¤‘... ëª¨ë“  ìš”ì²­ ì´ ì‹œê°„: 0.00ì´ˆ (0.18 ë°€ë¦¬ì´ˆ) PASS: vLLM ì˜ˆì œ   ","version":"Next","tagName":"h3"},{"title":"ê´€ì¸¡ì„±â€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#ê´€ì¸¡ì„±","content":" ","version":"Next","tagName":"h2"},{"title":"AWS CloudWatchì™€ Neuron Monitorë¥¼ ì‚¬ìš©í•œ ê´€ì¸¡ì„±â€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#aws-cloudwatchì™€-neuron-monitorë¥¼-ì‚¬ìš©í•œ-ê´€ì¸¡ì„±","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” ê´€ë¦¬í˜• ì• ë“œì˜¨ìœ¼ë¡œ CloudWatch Observability Agentë¥¼ ë°°í¬í•˜ì—¬ ì»¨í…Œì´ë„ˆí™”ëœ ì›Œí¬ë¡œë“œì— ëŒ€í•œ í¬ê´„ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ì œê³µí•©ë‹ˆë‹¤. CPU ë° ë©”ëª¨ë¦¬ í™œìš©ë¥ ê³¼ ê°™ì€ ì£¼ìš” ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ì»¨í…Œì´ë„ˆ ì¸ì‚¬ì´íŠ¸ê°€ í¬í•¨ë©ë‹ˆë‹¤. ë˜í•œ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” NVIDIAì˜ DCGM í”ŒëŸ¬ê·¸ì¸ì„ ì‚¬ìš©í•œ GPU ë©”íŠ¸ë¦­ì„ í†µí•©í•˜ë©°, ì´ëŠ” ê³ ì„±ëŠ¥ GPU ì›Œí¬ë¡œë“œë¥¼ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤. AWS Inferentia ë˜ëŠ” Trainiumì—ì„œ ì‹¤í–‰ë˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ê²½ìš° Neuron Monitor í”ŒëŸ¬ê·¸ì¸ì´ ì¶”ê°€ë˜ì–´ Neuron íŠ¹ì • ë©”íŠ¸ë¦­ì„ ìº¡ì²˜í•˜ê³  ë³´ê³ í•©ë‹ˆë‹¤.  ì»¨í…Œì´ë„ˆ ì¸ì‚¬ì´íŠ¸, GPU ì„±ëŠ¥, Neuron ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ ëª¨ë“  ë©”íŠ¸ë¦­ì€ Amazon CloudWatchë¡œ ì „ì†¡ë˜ë©°, ì—¬ê¸°ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°°í¬ê°€ ì™„ë£Œë˜ë©´ CloudWatch ì½˜ì†”ì—ì„œ ì§ì ‘ ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì— ì ‘ê·¼í•  ìˆ˜ ìˆì–´ ì›Œí¬ë¡œë“œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  CloudWatch EKS ì• ë“œì˜¨ ë°°í¬ ì™¸ì—ë„ ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡ì„±ì„ ìœ„í•œ Prometheus ì„œë²„ì™€ Grafana ë°°í¬ë¥¼ ì œê³µí•˜ëŠ” Kube Prometheus ìŠ¤íƒë„ ë°°í¬í–ˆìŠµë‹ˆë‹¤.  ë¨¼ì € Kube Prometheus ìŠ¤íƒì—ì„œ ë°°í¬í•œ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤:  kubectl get svc -n kube-prometheus-stack   ë‹¤ìŒê³¼ ìœ ì‚¬í•œ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:  kubectl get svc -n kube-prometheus-stack NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-prometheus-stack-grafana ClusterIP 172.20.252.10 &lt;none&gt; 80/TCP 11d kube-prometheus-stack-kube-state-metrics ClusterIP 172.20.34.181 &lt;none&gt; 8080/TCP 11d kube-prometheus-stack-operator ClusterIP 172.20.186.93 &lt;none&gt; 443/TCP 11d kube-prometheus-stack-prometheus ClusterIP 172.20.147.64 &lt;none&gt; 9090/TCP,8080/TCP 11d kube-prometheus-stack-prometheus-node-exporter ClusterIP 172.20.171.165 &lt;none&gt; 9100/TCP 11d prometheus-operated ClusterIP None &lt;none&gt; 9090/TCP 11d   NVIDIA Triton ì„œë²„ ë©”íŠ¸ë¦­ì„ ë…¸ì¶œí•˜ê¸° ìœ„í•´ í¬íŠ¸ 8080ì—ì„œ ë©”íŠ¸ë¦­ ì„œë¹„ìŠ¤(nvidia-triton-server-triton-inference-server-metrics)ë¥¼ ë°°í¬í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”  kubectl get svc -n triton-vllm   ì¶œë ¥ì€ ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:  kubectl get svc -n triton-vllm NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nvidia-triton-server-triton-inference-server ClusterIP 172.20.193.97 &lt;none&gt; 8000/TCP,8001/TCP,8002/TCP 34m nvidia-triton-server-triton-inference-server-metrics ClusterIP 172.20.5.247 &lt;none&gt; 8080/TCP 34m   ì´ëŠ” NVIDIA Triton ì„œë²„ ë©”íŠ¸ë¦­ì´ Prometheus ì„œë²„ì— ì˜í•´ ìŠ¤í¬ë©ë˜ê³  ìˆìŒì„ í™•ì¸í•©ë‹ˆë‹¤. Grafana ëŒ€ì‹œë³´ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì•„ë˜ Grafana ëŒ€ì‹œë³´ë“œì—ì„œ ì—¬ëŸ¬ ì¤‘ìš”í•œ ë©”íŠ¸ë¦­ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:  Average GPU Power Usage: ì´ ê²Œì´ì§€ëŠ” GPUì˜ í˜„ì¬ ì „ë ¥ ì‚¬ìš©ëŸ‰ì„ ë³´ì—¬ì£¼ë©°, ì¶”ë¡  ì‘ì—…ì˜ íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.Compute Time (ë°€ë¦¬ì´ˆ): ì´ ë§‰ëŒ€ ê·¸ë˜í”„ëŠ” ì¶”ë¡  ìš”ì²­ì„ ê³„ì‚°í•˜ëŠ” ë° ê±¸ë¦¬ëŠ” ì‹œê°„ì„ í‘œì‹œí•˜ì—¬ ì§€ì—° ë¬¸ì œë¥¼ ì‹ë³„í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.Cumulative Inference Requests: ì´ ê·¸ë˜í”„ëŠ” ì‹œê°„ ê²½ê³¼ì— ë”°ë¼ ì²˜ë¦¬ëœ ì´ ì¶”ë¡  ìš”ì²­ ìˆ˜ë¥¼ ë³´ì—¬ì£¼ì–´ ì›Œí¬ë¡œë“œì™€ ì„±ëŠ¥ ì¶”ì„¸ì— ëŒ€í•œ í†µì°°ë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.Queue Time (ë°€ë¦¬ì´ˆ): ì´ ë¼ì¸ ê·¸ë˜í”„ëŠ” ìš”ì²­ì´ ì²˜ë¦¬ë˜ê¸° ì „ì— íì—ì„œ ë³´ë‚´ëŠ” ì‹œê°„ì„ ë‚˜íƒ€ë‚´ë©°, ì‹œìŠ¤í…œì˜ ì ì¬ì  ë³‘ëª© í˜„ìƒì„ ê°•ì¡°í•©ë‹ˆë‹¤.    ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•œ ìƒˆ Grafana ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“¤ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:  - Grafana ì„œë¹„ìŠ¤ í¬íŠ¸ í¬ì›Œë”©: kubectl port-forward svc/kube-prometheus-stack-grafana 8080:80 -n kube-prometheus-stack - Grafana ê´€ë¦¬ì ì‚¬ìš©ì admin - Terraform ì¶œë ¥ì—ì„œ ì‹œí¬ë¦¿ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° terraform output grafana_secret_name - ê´€ë¦¬ì ì‚¬ìš©ì ë¹„ë°€ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸° aws secretsmanager get-secret-value --secret-id &lt;grafana_secret_name_output&gt; --region $AWS_REGION --query &quot;SecretString&quot; --output text   Grafanaì— ë¡œê·¸ì¸:  ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  http://localhost:8080ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.ì‚¬ìš©ì ì´ë¦„ adminê³¼ AWS Secrets Managerì—ì„œ ê²€ìƒ‰í•œ ë¹„ë°€ë²ˆí˜¸ë¡œ ë¡œê·¸ì¸í•©ë‹ˆë‹¤.  ì˜¤í”ˆì†ŒìŠ¤ Grafana ëŒ€ì‹œë³´ë“œ ê°€ì ¸ì˜¤ê¸°:  ë¡œê·¸ì¸ í›„ ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ &quot;+&quot; ì•„ì´ì½˜ì„ í´ë¦­í•˜ê³  &quot;Import&quot;ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.ë‹¤ìŒ URLì„ ì…ë ¥í•˜ì—¬ ëŒ€ì‹œë³´ë“œ JSONì„ ê°€ì ¸ì˜µë‹ˆë‹¤: Triton Server Grafana Dashboardì•ˆë‚´ì— ë”°ë¼ ê°€ì ¸ì˜¤ê¸° í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ë£Œí•©ë‹ˆë‹¤.  ì´ì œ ìƒˆ Grafana ëŒ€ì‹œë³´ë“œì— í‘œì‹œëœ ë©”íŠ¸ë¦­ì„ ë³¼ ìˆ˜ ìˆì–´ NVIDIA Triton Inference Server ë°°í¬ì˜ ì„±ëŠ¥ê³¼ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"ê²°ë¡ â€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#ê²°ë¡ ","content":" Amazon EKSì—ì„œ NVIDIA Triton Inference Serverì™€ vLLM ë°±ì—”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ë°°í¬í•˜ê³  ê´€ë¦¬í•˜ë©´ í˜„ëŒ€ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ê°•ë ¥í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ë”°ë¥´ë©´ í•„ìš”í•œ ì¸í”„ë¼ë¥¼ ì„¤ì •í•˜ê³ , Triton ì„œë²„ë¥¼ ë°°í¬í•˜ê³ , Kube Prometheus ìŠ¤íƒê³¼ Grafanaë¥¼ ì‚¬ìš©í•˜ì—¬ ê°•ë ¥í•œ ê´€ì¸¡ì„±ì„ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"NVIDIA Triton Serverì™€ vLLMì„ ì‚¬ìš©í•œ ì—¬ëŸ¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-NVIDIATritonServer#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ê°€ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì„ ë•Œ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ì„ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  EKS í´ëŸ¬ìŠ¤í„° ì •ë¦¬:ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” -target ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¦¬ì†ŒìŠ¤ê°€ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì‚­ì œë˜ë„ë¡ í™˜ê²½ì„ ì •ë¦¬í•©ë‹ˆë‹¤.  export AWS_DEAFULT_REGION=&quot;DEPLOYED_EKS_CLUSTER_REGION&gt;&quot; cd ai-on-eks/infra/nvidia-triton-server/ &amp;&amp; chmod +x cleanup.sh ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ë°°í¬","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve","content":"","keywords":"","version":"Next"},{"title":"RayServeì™€ vLLM ë°±ì—”ë“œ í†µí•©â€‹","type":1,"pageTitle":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve#rayserveì™€-vllm-ë°±ì—”ë“œ-í†µí•©","content":" vLLM: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ìœ„í•´ íŠ¹ë³„íˆ ì„¤ê³„ëœ ê³ ì²˜ë¦¬ëŸ‰ ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì¶”ë¡  ë° ì„œë¹™ ì—”ì§„ì…ë‹ˆë‹¤. ë°°í¬ ë° ì¶”ë¡  ì„±ëŠ¥ì„ ìµœì í™”í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ëª©í•  ë§Œí•œ ê¸°ëŠ¥ì€ ìš´ì˜ ì²´ì œì˜ ê°€ìƒ ë©”ëª¨ë¦¬ í˜ì´ì§•ì—ì„œ ì˜ê°ì„ ë°›ì€ í˜ì‹ ì ì¸ ì–´í…ì…˜ ì•Œê³ ë¦¬ì¦˜ì¸ PagedAttentionì…ë‹ˆë‹¤. PagedAttentionì€ ì–´í…ì…˜ í‚¤ì™€ ê°’ í…ì„œ(KV ìºì‹œ)ë¥¼ ë¹„ì—°ì†ì ì¸ ë©”ëª¨ë¦¬ ê³µê°„ì— ì €ì¥í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ë©°, ì´ë¥¼ í†µí•´ ë©”ëª¨ë¦¬ ë‹¨í¸í™”ì™€ ë‚­ë¹„ë¥¼ í¬ê²Œ ì¤„ì…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ vLLMì„ HuggingFace Transformers(HF) ë° HuggingFace Text Generation Inference(TGI)ì™€ ë¹„êµí•œ ë¸”ë¡œê·¸ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.  vLLMì€ ìˆ˜ì‹  ìš”ì²­ì˜ ì—°ì† ë°°ì¹­ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚° ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ì„ ìµœì í™”í•˜ê³  ì—¬ëŸ¬ ìš”ì²­ì„ ê·¸ë£¹í™”í•˜ì—¬ ì¶”ë¡  ì†ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì´ ë™ì  ë°°ì¹­ì€ ì²˜ë¦¬ëŸ‰ì„ ê·¹ëŒ€í™”í•˜ê³  ì§€ì—° ì‹œê°„ì„ ì¤„ì…ë‹ˆë‹¤. ë˜í•œ GPUì—ì„œ ê°€ì†í™”ëœ ëª¨ë¸ ì‹¤í–‰ì„ ìœ„í•´ ìµœì í™”ëœ CUDA ì»¤ë„ì„ ì œê³µí•©ë‹ˆë‹¤. ë˜ ë‹¤ë¥¸ ì£¼ìš” ì¥ì ì€ ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ì—ì„œ ì—¬ëŸ¬ ì¶œë ¥ ì‹œí€€ìŠ¤ê°€ ìƒì„±ë˜ëŠ” ë³‘ë ¬ ìƒ˜í”Œë§ ì¤‘ vLLMì˜ íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ê³µìœ ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ìµœëŒ€ 55% ê°ì†Œí•˜ê³  ì²˜ë¦¬ëŸ‰ì´ ìµœëŒ€ 2.2ë°° í–¥ìƒë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Mistralai/Mistral-7B-Instruct-v0.2â€‹","type":1,"pageTitle":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve#mistralaimistral-7b-instruct-v02","content":" ì´ ê°€ì´ë“œì—ì„œëŠ” RayServeì™€ vLLMì„ ì‚¬ìš©í•˜ì—¬ Mistral-7B-Instruct-v0.2 ëª¨ë¸ì„ ë°°í¬í•©ë‹ˆë‹¤. ì´ ì§€ì¹¨ì„ Llama2ì™€ ê°™ì€ ë‹¤ë¥¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ë°°í¬í•˜ëŠ” ë° ì‰½ê²Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Mistral-7B-Instruct-v0.2ëŠ” ê³ í’ˆì§ˆì˜ êµìœ¡ì  ì‘ë‹µì„ ì œê³µí•˜ë„ë¡ ì„¤ê³„ëœ ìµœì²¨ë‹¨ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ë˜ì–´ ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ì¸ê°„ê³¼ ê°™ì€ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” ë° ë›°ì–´ë‚˜ë©°, ìì„¸í•œ ì„¤ëª…, ë³µì¡í•œ ì¿¼ë¦¬, ìì—°ì–´ ì´í•´ê°€ í•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•©ë‹ˆë‹¤.  ì†”ë£¨ì…˜ ë°°í¬ ğŸ‘ˆ  ","version":"Next","tagName":"h3"},{"title":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ Mistral-7B-Instruct-v0.2 ë°°í¬â€‹","type":1,"pageTitle":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve#rayserveì™€-vllmì„-ì‚¬ìš©í•œ-mistral-7b-instruct-v02-ë°°í¬","content":" í•„ìš”í•œ ëª¨ë“  êµ¬ì„± ìš”ì†Œì™€ í•¨ê»˜ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•œ í›„, RayServeì™€ vLLMì„ ì‚¬ìš©í•˜ì—¬ Mistral-7B-Instruct-v0.2ë¥¼ ë°°í¬í•˜ëŠ” ë‹¨ê³„ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  1ë‹¨ê³„: ì´ ë°°í¬ì˜ ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ìœ¼ë¡œ Hugging Face ê³„ì •ì„ í†µí•´ ëª¨ë¸ì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤:    2ë‹¨ê³„: Hugginface Hub í† í° ë‚´ë³´ë‚´ê¸°  RayServeì™€ vLLM ë°±ì—”ë“œë¡œ Mistral-7B-Instruct-v0.2 ëª¨ë¸ì„ ë°°í¬í•˜ë ¤ë©´ Hugging Face Hub í† í°ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ í† í°ì€ ì¸ì¦ ë° ëª¨ë¸ ì ‘ê·¼ì— í•„ìš”í•©ë‹ˆë‹¤. Hugging Face í† í°ì„ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì•ˆë‚´ëŠ” Hugging Face í† í° ê´€ë¦¬ë¥¼ ë°©ë¬¸í•˜ì„¸ìš”.  Your-Hugging-Face-Hub-Token-Valueë¥¼ ì‹¤ì œ Hugging Face Hub í† í°ìœ¼ë¡œ êµì²´í•˜ì„¸ìš”. ì´ ë‹¨ê³„ëŠ” ë°°í¬ê°€ Mistral-7B-Instruct-v0.2 ëª¨ë¸ì— ì ‘ê·¼í•˜ëŠ” ë° í•„ìš”í•œ ì¸ì¦ì„ ê°–ì¶”ë„ë¡ í•©ë‹ˆë‹¤.  export HUGGING_FACE_HUB_TOKEN=$(echo -n &quot;Your-Hugging-Face-Hub-Token-Value&quot; | base64)   3ë‹¨ê³„: RayService í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•˜ë ¤ë©´ ray-service-vllm.yaml íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ì—¬ ë°°í¬ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. RayService YAML êµ¬ì„±ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ëŠ” ai-on-eks/blueprints/inference/vllm-rayserve-gpu/ray-service-vllm.yaml ìœ„ì¹˜ì˜ íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.  í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”. ì´ë ‡ê²Œ í•˜ë©´ RayService êµ¬ì„±ì´ ì ìš©ë˜ê³  EKS ì„¤ì •ì— í´ëŸ¬ìŠ¤í„°ê°€ ë°°í¬ë©ë‹ˆë‹¤.  cd ai-on-eks/blueprints/inference/vllm-rayserve-gpu envsubst &lt; ray-service-vllm.yaml| kubectl apply -f -   4ë‹¨ê³„: ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°°í¬ë¥¼ í™•ì¸í•©ë‹ˆë‹¤  ë°°í¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:  ì •ë³´ ë°°í¬ ê³¼ì •ì€ ìµœëŒ€ 10ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Head PodëŠ” 5~6ë¶„ ë‚´ì— ì¤€ë¹„ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, Ray Serve ì›Œì»¤ íŒŒë“œëŠ” Huggingfaceì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ëª¨ë¸ ë°°í¬ì— ìµœëŒ€ 10ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  RayServe êµ¬ì„±ì— ë”°ë¥´ë©´ í•˜ë‚˜ì˜ Ray head íŒŒë“œê°€ x86 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ê³  í•˜ë‚˜ì˜ ì›Œì»¤ íŒŒë“œê°€ g5 GPU ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤. ì—¬ëŸ¬ ë ˆí”Œë¦¬ì¹´ë¥¼ ì‹¤í–‰í•˜ë„ë¡ RayServe YAML íŒŒì¼ì„ ìˆ˜ì •í•  ìˆ˜ ìˆì§€ë§Œ, ê° ì¶”ê°€ ë ˆí”Œë¦¬ì¹´ì—ëŠ” ë³„ë„ì˜ GPUê°€ í•„ìš”í•˜ì—¬ ìƒˆ ì¸ìŠ¤í„´ìŠ¤ê°€ ìƒì„±ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  kubectl get pod -n rayserve-vllm   NAME READY STATUS RESTARTS AGE vllm-raycluster-nvtxg-head-g2cg8 1/1 Running 0 47m vllm-raycluster-nvtxg-worker-gpu-group-msl5p 1/1 Running 0 47m   ì´ ë°°í¬ëŠ” ì—¬ëŸ¬ í¬íŠ¸ê°€ ìˆëŠ” Mistral ì„œë¹„ìŠ¤ë„ êµ¬ì„±í•©ë‹ˆë‹¤. í¬íŠ¸ 8265ëŠ” Ray ëŒ€ì‹œë³´ë“œìš©ì´ê³  í¬íŠ¸ 8000ì€ Mistral ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸ìš©ì…ë‹ˆë‹¤.  ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:  kubectl get svc -n rayserve-vllm NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE vllm ClusterIP 172.20.208.16 &lt;none&gt; 6379/TCP,8265/TCP,10001/TCP,8000/TCP,8080/TCP 48m vllm-head-svc ClusterIP 172.20.239.237 &lt;none&gt; 6379/TCP,8265/TCP,10001/TCP,8000/TCP,8080/TCP 37m vllm-serve-svc ClusterIP 172.20.196.195 &lt;none&gt; 8000/TCP 37m   Ray ëŒ€ì‹œë³´ë“œì— ì ‘ê·¼í•˜ë ¤ë©´ ê´€ë ¨ í¬íŠ¸ë¥¼ ë¡œì»¬ ë¨¸ì‹ ìœ¼ë¡œ í¬íŠ¸ í¬ì›Œë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl -n rayserve-vllm port-forward svc/vllm 8265:8265   ê·¸ëŸ° ë‹¤ìŒ http://localhost:8265ì—ì„œ ì›¹ UIì— ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë©°, Ray ì—ì½”ì‹œìŠ¤í…œ ë‚´ì˜ ì‘ì—… ë° ì•¡í„° ë°°í¬ê°€ í‘œì‹œë©ë‹ˆë‹¤.    ë°°í¬ê°€ ì™„ë£Œë˜ë©´ Controller ë° Proxy ìƒíƒœê°€ HEALTHYì´ê³  Application ìƒíƒœê°€ RUNNINGì´ì–´ì•¼ í•©ë‹ˆë‹¤    ","version":"Next","tagName":"h2"},{"title":"Mistral-7b ì±„íŒ… ëª¨ë¸ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve#mistral-7b-ì±„íŒ…-ëª¨ë¸-í…ŒìŠ¤íŠ¸","content":" ì´ì œ Mistral-7B ì±„íŒ… ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ì°¨ë¡€ì…ë‹ˆë‹¤. Python í´ë¼ì´ì–¸íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ RayServe ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ì— í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ë‚´ê³  ëª¨ë¸ì´ ìƒì„±í•œ ì¶œë ¥ì„ í™•ì¸í•©ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ëŠ” prompts.txt íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì½ê³  ì‘ë‹µì„ ê°™ì€ ìœ„ì¹˜ì˜ results.txt íŒŒì¼ì— ì”ë‹ˆë‹¤. ë˜í•œ ê° ì‘ë‹µì— ëŒ€í•œ ì‘ë‹µ ì‹œê°„ê³¼ í† í° ê¸¸ì´ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.  ë¨¼ì € kubectlì„ ì‚¬ìš©í•˜ì—¬ vllm-serve-svc ì„œë¹„ìŠ¤ë¡œ í¬íŠ¸ í¬ì›Œë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl -n rayserve-vllm port-forward svc/vllm-serve-svc 8000:8000   client.pyëŠ” HTTP POST ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ /vllm ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ëŒ€ìƒìœ¼ë¡œ í…ìŠ¤íŠ¸ ì™„ì„± ë° Q&amp;Aë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ëª©ë¡ì„ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ì— ë³´ëƒ…ë‹ˆë‹¤.  prompts.txt íŒŒì¼ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ê°€ìƒ í™˜ê²½ì—ì„œ Python í´ë¼ì´ì–¸íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:  cd ai-on-eks/blueprints/inference/vllm-rayserve-gpu python3 -m venv .venv source .venv/bin/activate pip install requests python3 client.py   í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:  í´ë¦­í•˜ì—¬ Python í´ë¼ì´ì–¸íŠ¸ í„°ë¯¸ë„ ì¶œë ¥ í™•ì¥ python3 client.py INFO:__main__:Warm-up successful INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 INFO:__main__:Response status: 200 Prompt: [INST] Explain the concept of generative adversarial networks (GANs). [/INST] Response Time: 20.72 seconds Token Length: 440 ================================================================================ Prompt: [INST] How does a variational autoencoder (VAE) work? [/INST] Response Time: 18.88 seconds Token Length: 397 ================================================================================ Prompt: [INST] What are the applications of generative AI in healthcare? [/INST] Response Time: 15.22 seconds Token Length: 323 ================================================================================ Prompt: [INST] Describe the process of training a GAN. [/INST] Response Time: 20.82 seconds Token Length: 437 ================================================================================ Prompt: [INST] How can generative AI be used in creative arts? [/INST] Response Time: 21.64 seconds Token Length: 454 ================================================================================ Prompt: [INST] What is the difference between supervised and unsupervised learning in the context of generative AI? [/INST] Response Time: 13.76 seconds Token Length: 310 ================================================================================ Prompt: [INST] Explain the role of a discriminator in a GAN. [/INST] Response Time: 11.96 seconds Token Length: 259 ================================================================================ Prompt: [INST] How can generative AI improve natural language processing (NLP)? [/INST] Response Time: 19.92 seconds Token Length: 393 ================================================================================ Prompt: [INST] What are the ethical considerations of using generative AI? [/INST] Response Time: 17.59 seconds Token Length: 361 ================================================================================ Prompt: [INST] How is generative AI used in drug discovery? [/INST] Response Time: 14.31 seconds Token Length: 311 ================================================================================ Prompt: [INST] Describe the architecture of a Transformer model. [/INST] Response Time: 26.96 seconds Token Length: 521 ================================================================================ Prompt: [INST] How can generative AI be applied in the gaming industry? [/INST] Response Time: 16.43 seconds Token Length: 348 ================================================================================ Prompt: [INST] What is the purpose of latent space in generative models? [/INST] Response Time: 11.55 seconds Token Length: 253 ================================================================================ Prompt: [INST] How does text generation with GPT-3 work? [/INST] Response Time: 12.64 seconds Token Length: 265 ================================================================================ Prompt: [INST] What are the challenges of using generative AI in finance? [/INST] Response Time: 18.21 seconds Token Length: 331 ================================================================================ Prompt: [INST] Explain the concept of zero-shot learning in generative AI. [/INST] Response Time: 14.92 seconds Token Length: 340 ================================================================================ Prompt: [INST] How can generative AI be used for image synthesis? [/INST] Response Time: 17.81 seconds Token Length: 352 ================================================================================ Prompt: [INST] What are some real-world applications of deepfakes? [/INST] Response Time: 14.39 seconds Token Length: 284 ================================================================================ Prompt: [INST] How can generative AI contribute to personalized medicine? [/INST] Response Time: 16.90 seconds Token Length: 338 ================================================================================ Prompt: [INST] Describe the use of generative AI in autonomous vehicles. [/INST] Response Time: 13.99 seconds Token Length: 299 ================================================================================   ê° í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‹¤ì œ ì‘ë‹µì€ results.txt íŒŒì¼ì—ì„œ í™•ì¸í•˜ì„¸ìš”.  í´ë¦­í•˜ì—¬ Mistral ê²°ê³¼ ë¶€ë¶„ ì¶œë ¥ í™•ì¥ Prompt: [INST] Explain the theory of relativity. Response: [INST] Explain the theory of relativity. [/INST] The theory of relativity, developed by Albert Einstein, is a fundamental theory in physics that describes the relationship between space and time, and how matter and energy interact within that framework. It is actually composed of two parts: the Special Theory of Relativity, published in 1905, and the General Theory of Relativity, published in 1915. The Special Theory of Relativity is based on two postulates: the first one states that the laws of physics are the same in all inertial frames of reference (frames that are not accelerating); the second one asserts that the speed of light in a vacuum is the same for all observers, regardless of their motion or the source of the light. From these two postulates, several counter-intuitive consequences follow. For example, the length of an object contracts when it is in motion relative to an observer, and time dilation occurs, meaning that a moving clock appears to tick slower than a stationary one. These phenomena have been confirmed by numerous experiments. The General Theory of Relativity is a theory of gravitation, which extended the Special Theory of Relativity by incorporating gravity into the fabric of spacetime. In this theory, mass causes a distortion or curvature in spacetime, which is felt as a gravitational force. This is in contrast to the Newtonian view of gravity as a force acting at a distance between two masses. One of the most famous predictions of General Relativity is the bending of light by gravity, which was first observed during a solar eclipse in 1919. The theory has been extremely successful in explaining various phenomena, such as the precession of Mercury's orbit, the gravitational redshift of light, and the existence of black holes and gravitational waves. In summary, the theory of relativity is a groundbreaking theory in physics that fundamentally changed our understanding of space, time, and matter. It has been incredibly successful in making accurate predictions about the natural world and has stood the test of time through numerous experiments and observations. --------------------------------------------------------------------------------   ","version":"Next","tagName":"h2"},{"title":"ê´€ì¸¡ì„±â€‹","type":1,"pageTitle":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve#ê´€ì¸¡ì„±","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ì˜ ì¼ë¶€ë¡œ ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡ì„±ì„ ìœ„í•œ Prometheus ì„œë²„ì™€ Grafana ë°°í¬ë¥¼ ì œê³µí•˜ëŠ” Kube Prometheus ìŠ¤íƒë„ ë°°í¬í–ˆìŠµë‹ˆë‹¤.  ë¨¼ì € Kube Prometheus ìŠ¤íƒì—ì„œ ë°°í¬í•œ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤:  kubectl get svc -n kube-prometheus-stack   ë‹¤ìŒê³¼ ìœ ì‚¬í•œ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:  kubectl get svc -n kube-prometheus-stack NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-prometheus-stack-grafana ClusterIP 172.20.252.10 &lt;none&gt; 80/TCP 11d kube-prometheus-stack-kube-state-metrics ClusterIP 172.20.34.181 &lt;none&gt; 8080/TCP 11d kube-prometheus-stack-operator ClusterIP 172.20.186.93 &lt;none&gt; 443/TCP 11d kube-prometheus-stack-prometheus ClusterIP 172.20.147.64 &lt;none&gt; 9090/TCP,8080/TCP 11d kube-prometheus-stack-prometheus-node-exporter ClusterIP 172.20.171.165 &lt;none&gt; 9100/TCP 11d prometheus-operated ClusterIP None &lt;none&gt; 9090/TCP 11d   Kube Prometheus ìŠ¤íƒ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•œ í›„ Ray í´ëŸ¬ìŠ¤í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ë„ë¡ Prometheusë¥¼ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ServiceMonitorì™€ PodMonitor ë¦¬ì†ŒìŠ¤ë¥¼ ëª¨ë‘ ë°°í¬í•´ì•¼ í•©ë‹ˆë‹¤:  ServiceMonitorëŠ” ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë…¸ì¶œí•˜ëŠ” Kubernetes ì„œë¹„ìŠ¤ê°€ ìˆëŠ” Ray head ë…¸ë“œì—ì„œ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.PodMonitorëŠ” KubeRay ì˜¤í¼ë ˆì´í„°ê°€ Ray ì›Œì»¤ íŒŒë“œì— ëŒ€í•œ Kubernetes ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— í•„ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ServiceMonitorë¥¼ ì‚¬ìš©í•˜ì—¬ ì›Œì»¤ íŒŒë“œì—ì„œ ë©”íŠ¸ë¦­ì„ ìŠ¤í¬ë©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ëŒ€ì‹  PodMonitors CRDë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.  cd ai-on-eks/infra/jark-stack/terraform/monitoring   kubectl apply -f serviceMonitor.yaml kubectl apply -f podMonitor.yaml   Grafanaì™€ Prometheus í†µí•©  Grafanaì™€ Prometheusë¥¼ Ray ëŒ€ì‹œë³´ë“œì™€ í†µí•©í•˜ê¸° ìœ„í•´ Ray í´ëŸ¬ìŠ¤í„° êµ¬ì„±ì—ì„œ íŠ¹ì • í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤:  env: - name: RAY_GRAFANA_HOST value: http://kube-prometheus-stack-grafana.kube-prometheus-stack.svc:80 - name: RAY_PROMETHEUS_HOST value: http://kube-prometheus-stack-prometheus.kube-prometheus-stack.svc:9090   ì´ëŸ¬í•œ í™˜ê²½ ë³€ìˆ˜ëŠ” Ray ëŒ€ì‹œë³´ë“œ ë‚´ì— Grafana íŒ¨ë„ì„ ì„ë² ë”©í•˜ê³  Ray, Grafana, Prometheus ê°„ì˜ ì˜¬ë°”ë¥¸ í†µì‹ ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤:  RAY_GRAFANA_HOSTëŠ” Grafanaì— ëŒ€í•œ ë‚´ë¶€ Kubernetes ì„œë¹„ìŠ¤ URLì„ ì •ì˜í•©ë‹ˆë‹¤. Ray head íŒŒë“œëŠ” í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ë°±ì—”ë“œ í—¬ìŠ¤ ì²´í¬ ë° í†µì‹ ì— ì´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.RAY_PROMETHEUS_HOSTëŠ” Prometheusì— ëŒ€í•œ ë‚´ë¶€ Kubernetes ì„œë¹„ìŠ¤ URLì„ ì§€ì •í•˜ì—¬ Rayê°€ í•„ìš”í•  ë•Œ ë©”íŠ¸ë¦­ì„ ì¿¼ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.  Prometheus ì›¹ UI ì ‘ê·¼  # Prometheus ì„œë²„ íŒŒë“œì—ì„œ Prometheus ì›¹ UI í¬íŠ¸ë¥¼ í¬ì›Œë”©í•©ë‹ˆë‹¤. kubectl port-forward prometheus-kube-prometheus-stack-prometheus-0 -n kube-prometheus-stack 9090:9090   (YOUR_IP):9090/targets(ì˜ˆ: 127.0.0.1:9090/targets)ë¡œ ì´ë™í•©ë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: podMonitor/kube-prometheus-stack/ray-workers-monitor/0 (1/1 up)serviceMonitor/kube-prometheus-stack/ray-head-monitor/0 (2/2 up)    Grafana ì ‘ê·¼  - Grafana ì„œë¹„ìŠ¤ í¬íŠ¸ í¬ì›Œë”©: kubectl port-forward deployment/kube-prometheus-stack-grafana -n kube-prometheus-stack 3000:3000 # Grafana ë¡œê·¸ì¸ í˜ì´ì§€ëŠ” (YOUR_IP):3000/login(ì˜ˆ: 127.0.0.1:3000/login)ì—ì„œ í™•ì¸í•©ë‹ˆë‹¤. - Grafana ê´€ë¦¬ì ì‚¬ìš©ì admin - Terraform ì¶œë ¥ì—ì„œ ì‹œí¬ë¦¿ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° terraform output grafana_secret_name - ê´€ë¦¬ì ì‚¬ìš©ì ë¹„ë°€ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸° aws secretsmanager get-secret-value --secret-id &lt;grafana_secret_name_output&gt; --region $AWS_REGION --query &quot;SecretString&quot; --output text   ì°¸ê³ : kubectl port-forwardëŠ” í”„ë¡œë•ì…˜ ì‚¬ìš©ì— ê¶Œì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ë’¤ì— Grafanaë¥¼ ë…¸ì¶œí•˜ëŠ” ë°©ë²•ì€ ì´ Grafana ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.  ì˜¤í”ˆì†ŒìŠ¤ Grafana ëŒ€ì‹œë³´ë“œ ê°€ì ¸ì˜¤ê¸°  Dashboards ë©”ë‰´ë¥¼ í†µí•´ JSON íŒŒì¼ì„ ê°€ì ¸ì™€ ìƒˆ ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“­ë‹ˆë‹¤.ì™¼ìª½ íŒ¨ë„ì—ì„œ 'Dashboards' ì•„ì´ì½˜ì„ í´ë¦­í•˜ê³  'New', 'Import'ë¥¼ ì„ íƒí•œ ë‹¤ìŒ 'Upload JSON file'ì„ í´ë¦­í•©ë‹ˆë‹¤.JSON íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤. ì‚¬ë¡€ 1: Ray 2.24.0ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° GitHub ì €ì¥ì†Œì˜ ìƒ˜í”Œ êµ¬ì„± íŒŒì¼ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ì´ë¦„ì€ xxx_grafana_dashboard.json íŒ¨í„´ì„ ë”°ë¦…ë‹ˆë‹¤.ì‚¬ë¡€ 2: ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ head íŒŒë“œì˜ /tmp/ray/session_latest/metrics/grafana/dashboards/ì—ì„œ JSON íŒŒì¼ì„ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤. kubectl cpë¥¼ ì‚¬ìš©í•˜ì—¬ head íŒŒë“œì—ì„œ ë¡œì»¬ ë¨¸ì‹ ìœ¼ë¡œ íŒŒì¼ì„ ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. &quot;Import&quot;ë¥¼ í´ë¦­í•©ë‹ˆë‹¤.  TODO: ëŒ€ì‹œë³´ë“œë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì€ ì´ìƒì ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹œë³´ë“œë¥¼ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.   ì•„ë˜ Grafana ëŒ€ì‹œë³´ë“œì—ì„œ ì—¬ëŸ¬ ë©”íŠ¸ë¦­ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:  Scheduler Task StateëŠ” íŠ¹ì • ìƒíƒœì— ìˆëŠ” í˜„ì¬ ì‘ì—… ìˆ˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.Active Tasks by Nameì€ íŠ¹ì • ì´ë¦„ì„ ê°€ì§„ í˜„ì¬(í™œì„±) ì‘ì—… ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.Scheduler Actor StateëŠ” íŠ¹ì • ìƒíƒœì— ìˆëŠ” í˜„ì¬ ì•¡í„° ìˆ˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.Active Actors by Nameì€ íŠ¹ì • ì´ë¦„ì„ ê°€ì§„ í˜„ì¬(í™œì„±) ì•¡í„° ìˆ˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"ê²°ë¡ â€‹","type":1,"pageTitle":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve#ê²°ë¡ ","content":" Ray Serveë¥¼ vLLM ë°±ì—”ë“œì™€ í†µí•©í•˜ë©´ íš¨ìœ¨ì„±, í™•ì¥ì„±, ë¹„ìš© íš¨ìœ¨ì„± ì¸¡ë©´ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ì¶”ë¡ ì— ë§ì€ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤. Ray Serveì˜ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ë° ë™ì  ë°°ì¹­ ê¸°ëŠ¥ì€ ê³ ì²˜ë¦¬ëŸ‰ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì¤‘ìš”í•œ ìµœì ì˜ GPU í™œìš©ì„ ë³´ì¥í•©ë‹ˆë‹¤. vLLMê³¼ì˜ í†µí•©ì€ ì •ì  ë°°ì¹­ì— ë¹„í•´ ì²˜ë¦¬ëŸ‰ì„ í¬ê²Œ í–¥ìƒì‹œí‚¤ê³  ì§€ì—° ì‹œê°„ì„ ì¤„ì´ëŠ” ì—°ì† ë°°ì¹­ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì´ë¥¼ ë”ìš± í–¥ìƒì‹œí‚µë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ Ray Serveì™€ vLLMì˜ ì¡°í•©ì€ í”„ë¡œë•ì…˜ì—ì„œ LLMì„ ë°°í¬í•˜ê¸° ìœ„í•œ ê°•ë ¥í•˜ê³  í™•ì¥ ê°€ëŠ¥í•˜ë©° ë¹„ìš© íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ë°°í¬","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/GPUs/vLLM-rayserve#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ê°€ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì„ ë•Œ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ì„ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  RayCluster ì‚­ì œ  cd ai-on-eks/blueprints/inference/vllm-rayserve-gpu kubectl delete -f ray-service-vllm.yaml   cd ai-on-eks/infra/jark-stack/terraform/monitoring kubectl delete -f serviceMonitor.yaml kubectl delete -f podMonitor.yaml   EKS í´ëŸ¬ìŠ¤í„° ë° ë¦¬ì†ŒìŠ¤ ì‚­ì œ  export AWS_DEAFULT_REGION=&quot;DEPLOYED_EKS_CLUSTER_REGION&gt;&quot; cd ai-on-eks/infra/jark-stack/terraform/ &amp;&amp; chmod +x cleanup.sh ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2","content":"","keywords":"","version":"Next"},{"title":"Llama-2ë€?â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#llama-2ë€","content":" Llama-2ëŠ” 2ì¡° ê°œì˜ í…ìŠ¤íŠ¸ ë° ì½”ë“œ í† í°ìœ¼ë¡œ í›ˆë ¨ëœ ì‚¬ì „ í›ˆë ¨ëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì…ë‹ˆë‹¤. í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ê°€ì¥ í¬ê³  ê°•ë ¥í•œ LLM ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. Llama-2ëŠ” ìì—°ì–´ ì²˜ë¦¬, í…ìŠ¤íŠ¸ ìƒì„± ë° ë²ˆì—­ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Llama-2-chatâ€‹  Llama-2ëŠ” ì—„ê²©í•œ í›ˆë ¨ ê³¼ì •ì„ ê±°ì¹œ ë›°ì–´ë‚œ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ê³µê°œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¨ë¼ì¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ì‚¬ì „ í›ˆë ¨ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì§€ë„ ë¯¸ì„¸ ì¡°ì •ì„ í†µí•´ ì´ˆê¸° ë²„ì „ì˜ Llama-2-chatì´ ìƒì„±ë©ë‹ˆë‹¤. ì´í›„ Llama-2-chatì€ ê±°ë¶€ ìƒ˜í”Œë§ ë° ê·¼ì ‘ ì •ì±… ìµœì í™”(PPO)ì™€ ê°™ì€ ê¸°ìˆ ì„ í¬í•¨í•˜ëŠ” ì¸ê°„ í”¼ë“œë°±ì„ í†µí•œ ê°•í™” í•™ìŠµ(RLHF)ì„ ì‚¬ìš©í•˜ì—¬ ë°˜ë³µì ìœ¼ë¡œ ì •ì œë©ë‹ˆë‹¤. ì´ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ Amazon EKSì™€ Ray Serveì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ë°°í¬í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´í•˜ëŠ” ê³ ë„ë¡œ ìœ ëŠ¥í•˜ê³  ë¯¸ì„¸ ì¡°ì •ëœ ì–¸ì–´ ëª¨ë¸ì´ ìƒì„±ë©ë‹ˆë‹¤.  Llama-2ëŠ” ì„¸ ê°€ì§€ ëª¨ë¸ í¬ê¸°ë¡œ ì œê³µë©ë‹ˆë‹¤:  Llama-2-70b: 700ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ê°€ì¥ í° Llama-2 ëª¨ë¸ì…ë‹ˆë‹¤. ê°€ì¥ ê°•ë ¥í•œ Llama-2 ëª¨ë¸ì´ë©° ê°€ì¥ ê¹Œë‹¤ë¡œìš´ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Llama-2-13b: 130ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ì¤‘ê°„ í¬ê¸°ì˜ Llama-2 ëª¨ë¸ì…ë‹ˆë‹¤. ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„± ì‚¬ì´ì˜ ì¢‹ì€ ê· í˜•ì„ ì œê³µí•˜ë©° ë‹¤ì–‘í•œ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Llama-2-7b: 70ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ê°€ì¥ ì‘ì€ Llama-2 ëª¨ë¸ì…ë‹ˆë‹¤. ê°€ì¥ íš¨ìœ¨ì ì¸ Llama-2 ëª¨ë¸ì´ë©° ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì´ í•„ìš”í•˜ì§€ ì•Šì€ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì–´ë–¤ Llama-2 ëª¨ë¸ í¬ê¸°ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ë‚˜ìš”?â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#ì–´ë–¤-llama-2-ëª¨ë¸-í¬ê¸°ë¥¼-ì‚¬ìš©í•´ì•¼-í•˜ë‚˜ìš”","content":" ê°€ì¥ ì í•©í•œ Llama-2 ëª¨ë¸ í¬ê¸°ëŠ” íŠ¹ì • ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ë‹¬ë¼ì§€ë©°, ìµœê³ ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ í•­ìƒ ê°€ì¥ í° ëª¨ë¸ì´ í•„ìš”í•œ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. ì ì ˆí•œ Llama-2 ëª¨ë¸ í¬ê¸°ë¥¼ ì„ íƒí•  ë•Œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤, ì‘ë‹µ ì‹œê°„ ë° ë¹„ìš© íš¨ìœ¨ì„±ê³¼ ê°™ì€ ìš”ì†Œë¥¼ ê³ ë ¤í•˜ì—¬ ìš”êµ¬ ì‚¬í•­ì„ í‰ê°€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ê²°ì •ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª©í‘œì™€ ì œì•½ ì¡°ê±´ì— ëŒ€í•œ í¬ê´„ì ì¸ í‰ê°€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œì˜ ì¶”ë¡ : Llama-2ì˜ ì ì¬ë ¥ ê·¹ëŒ€í™”â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#trn1inf2-ì¸ìŠ¤í„´ìŠ¤ì—ì„œì˜-ì¶”ë¡ -llama-2ì˜-ì ì¬ë ¥-ê·¹ëŒ€í™”","content":" Llama-2ëŠ” ë‹¤ì–‘í•œ í•˜ë“œì›¨ì–´ í”Œë«í¼ì— ë°°í¬í•  ìˆ˜ ìˆìœ¼ë©°, ê°ê° ê³ ìœ í•œ ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Llama-2ì˜ íš¨ìœ¨ì„±, í™•ì¥ì„± ë° ë¹„ìš© íš¨ìœ¨ì„±ì„ ìµœëŒ€í™”í•˜ëŠ” ë° ìˆì–´ AWS Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ê°€ ìµœì ì˜ ì„ íƒì…ë‹ˆë‹¤.  í™•ì¥ì„± ë° ê°€ìš©ì„±Llama-2ì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ë°°í¬í•  ë•Œ ì£¼ìš” ê³¼ì œ ì¤‘ í•˜ë‚˜ëŠ” ì ì ˆí•œ í•˜ë“œì›¨ì–´ì˜ í™•ì¥ì„±ê³¼ ê°€ìš©ì„±ì…ë‹ˆë‹¤. ê¸°ì¡´ GPU ì¸ìŠ¤í„´ìŠ¤ëŠ” ë†’ì€ ìˆ˜ìš”ë¡œ ì¸í•´ ë¶€ì¡±í•œ ê²½ìš°ê°€ ë§ì•„ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í•˜ê³  í™•ì¥í•˜ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤. ë°˜ë©´ trn1.32xlarge, trn1n.32xlarge, inf2.24xlarge ë° inf2.48xlargeì™€ ê°™ì€ Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” LLMì„ í¬í•¨í•œ ìƒì„±í˜• AI ëª¨ë¸ì˜ ê³ ì„±ëŠ¥ ë”¥ëŸ¬ë‹(DL) í›ˆë ¨ ë° ì¶”ë¡ ì„ ìœ„í•´ íŠ¹ë³„íˆ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤. í™•ì¥ì„±ê³¼ ê°€ìš©ì„±ì„ ëª¨ë‘ ì œê³µí•˜ì—¬ ë¦¬ì†ŒìŠ¤ ë³‘ëª© í˜„ìƒì´ë‚˜ ì§€ì—° ì—†ì´ í•„ìš”ì— ë”°ë¼ Llama-2 ëª¨ë¸ì„ ë°°í¬í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë¹„ìš© ìµœì í™”:ê¸°ì¡´ GPU ì¸ìŠ¤í„´ìŠ¤ì—ì„œ LLMì„ ì‹¤í–‰í•˜ë©´ GPUì˜ ë¶€ì¡±ê³¼ ê²½ìŸì ì¸ ê°€ê²©ìœ¼ë¡œ ì¸í•´ ë¹„ìš©ì´ ë§ì´ ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ë¹„ìš© íš¨ìœ¨ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. AI ë° ê¸°ê³„ í•™ìŠµ ì‘ì—…ì— ìµœì í™”ëœ ì „ìš© í•˜ë“œì›¨ì–´ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ ë¹„ìš©ì˜ ì¼ë¶€ë¡œ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¹„ìš© ìµœì í™”ë¥¼ í†µí•´ ì˜ˆì‚°ì„ íš¨ìœ¨ì ìœ¼ë¡œ í• ë‹¹í•˜ì—¬ LLM ë°°í¬ë¥¼ ì ‘ê·¼ ê°€ëŠ¥í•˜ê³  ì§€ì† ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì„±ëŠ¥ í–¥ìƒLlama-2ëŠ” GPUì—ì„œ ê³ ì„±ëŠ¥ ì¶”ë¡ ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì§€ë§Œ, Neuron ê°€ì†ê¸°ëŠ” ì„±ëŠ¥ì„ í•œ ë‹¨ê³„ ë” ëŒì–´ì˜¬ë¦½ë‹ˆë‹¤. Neuron ê°€ì†ê¸°ëŠ” ê¸°ê³„ í•™ìŠµ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•´ íŠ¹ë³„íˆ êµ¬ì¶•ë˜ì–´ Llama-2ì˜ ì¶”ë¡  ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” í•˜ë“œì›¨ì–´ ê°€ì†ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ì— Llama-2ë¥¼ ë°°í¬í•  ë•Œ ë” ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ê³¼ ê°œì„ ëœ ì‚¬ìš©ì ê²½í—˜ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ëª¨ë¸ ì‚¬ì–‘â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#ëª¨ë¸-ì‚¬ì–‘","content":" ì•„ë˜ í‘œëŠ” ë‹¤ì–‘í•œ í¬ê¸°ì˜ Llama-2 ëª¨ë¸, ê°€ì¤‘ì¹˜ ë° ë°°í¬ë¥¼ ìœ„í•œ í•˜ë“œì›¨ì–´ ìš”êµ¬ ì‚¬í•­ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  í¬ê¸°ì˜ Llama-2 ëª¨ë¸ì„ ë°°í¬í•˜ëŠ” ë° í•„ìš”í•œ ì¸í”„ë¼ë¥¼ ì„¤ê³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ Llama-2-13b-chat ëª¨ë¸ì„ ë°°í¬í•˜ë ¤ë©´ ì´ ê°€ì†ê¸° ë©”ëª¨ë¦¬ê°€ ìµœì†Œ 26 GBì¸ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.  ëª¨ë¸\tê°€ì¤‘ì¹˜\të°”ì´íŠ¸\tíŒŒë¼ë¯¸í„° í¬ê¸° (10ì–µ)\tì´ ê°€ì†ê¸° ë©”ëª¨ë¦¬ (GB)\tNeuronCoreë‹¹ ê°€ì†ê¸° ë©”ëª¨ë¦¬ í¬ê¸° (GB)\tí•„ìš”í•œ Neuron ì½”ì–´\tí•„ìš”í•œ Neuron ê°€ì†ê¸°\tì¸ìŠ¤í„´ìŠ¤ ìœ í˜•\ttp_degreeMeta/Llama-2-70b\tfloat16\t2\t70\t140\t16\t9\t5\tinf2.48x\t24 Meta/Llama-2-13b\tfloat16\t2\t13\t26\t16\t2\t1\tinf2.24x\t12 Meta/Llama-2-7b\tfloat16\t2\t7\t14\t16\t1\t1\tinf2.24x\t12  ","version":"Next","tagName":"h3"},{"title":"ì˜ˆì œ ì‚¬ìš© ì‚¬ë¡€â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#ì˜ˆì œ-ì‚¬ìš©-ì‚¬ë¡€","content":" íšŒì‚¬ê°€ ê³ ê° ì§€ì›ì„ ì œê³µí•˜ê¸° ìœ„í•´ Llama-2 ì±—ë´‡ì„ ë°°í¬í•˜ë ¤ê³  í•©ë‹ˆë‹¤. íšŒì‚¬ëŠ” ëŒ€ê·œëª¨ ê³ ê° ê¸°ë°˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©° í”¼í¬ ì‹œê°„ì— ë§ì€ ì–‘ì˜ ì±„íŒ… ìš”ì²­ì„ ë°›ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•©ë‹ˆë‹¤. íšŒì‚¬ëŠ” ë†’ì€ ìš”ì²­ëŸ‰ì„ ì²˜ë¦¬í•˜ê³  ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” ì¸í”„ë¼ë¥¼ ì„¤ê³„í•´ì•¼ í•©ë‹ˆë‹¤.  íšŒì‚¬ëŠ” Inferentia2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Llama-2 ì±—ë´‡ì„ íš¨ìœ¨ì ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Inferentia2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ê¸°ê³„ í•™ìŠµ ì‘ì—…ì„ ìœ„í•œ íŠ¹ìˆ˜ í•˜ë“œì›¨ì–´ ê°€ì†ê¸°ì…ë‹ˆë‹¤. ê¸°ê³„ í•™ìŠµ ì›Œí¬ë¡œë“œì— ëŒ€í•´ GPUë³´ë‹¤ ìµœëŒ€ 20ë°° ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ìµœëŒ€ 7ë°° ë” ë‚®ì€ ë¹„ìš©ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  íšŒì‚¬ëŠ” ë˜í•œ Ray Serveë¥¼ ì‚¬ìš©í•˜ì—¬ Llama-2 ì±—ë´‡ì„ ìˆ˜í‰ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Ray ServeëŠ” ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì„ ì„œë¹™í•˜ê¸° ìœ„í•œ ë¶„ì‚° í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ìˆ˜ìš”ì— ë”°ë¼ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ í™•ì¥í•˜ê±°ë‚˜ ì¶•ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Llama-2 ì±—ë´‡ì„ í™•ì¥í•˜ê¸° ìœ„í•´ íšŒì‚¬ëŠ” ì—¬ëŸ¬ Inferentia2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°°í¬í•˜ê³  Ray Serveë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ ê°„ì— íŠ¸ë˜í”½ì„ ë¶„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ íšŒì‚¬ëŠ” ë†’ì€ ìš”ì²­ëŸ‰ì„ ì²˜ë¦¬í•˜ê³  ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜ ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#ì†”ë£¨ì…˜-ì•„í‚¤í…ì²˜","content":" ì´ ì„¹ì…˜ì—ì„œëŠ” Amazon EKSì—ì„œ Llama-2 ëª¨ë¸, Ray Serve ë° Inferentia2ë¥¼ ê²°í•©í•œ ì†”ë£¨ì…˜ì˜ ì•„í‚¤í…ì²˜ë¥¼ ìì„¸íˆ ì‚´í´ë´…ë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#ì†”ë£¨ì…˜-ë°°í¬","content":" Amazon EKSì— Llama-2-13b chatì„ ë°°í¬í•˜ë ¤ë©´ í•„ìš”í•œ ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ì„ ë‹¤ë£¨ê³  ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì¸í”„ë¼ ì„¤ì •, Ray í´ëŸ¬ìŠ¤í„° ë°°í¬ ë° Gradio WebUI ì•± ìƒì„±ì´ í¬í•¨ë©ë‹ˆë‹¤.  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"Llama-2-Chat ëª¨ë¸ì´ ìˆëŠ” Ray í´ëŸ¬ìŠ¤í„° ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#llama-2-chat-ëª¨ë¸ì´-ìˆëŠ”-ray-í´ëŸ¬ìŠ¤í„°-ë°°í¬","content":" Trainium on EKS í´ëŸ¬ìŠ¤í„°ê°€ ë°°í¬ë˜ë©´ kubectlì„ ì‚¬ìš©í•˜ì—¬ ray-service-Llama-2.yamlì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ë‹¨ê³„ì—ì„œëŠ” Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§ì„ ì‚¬ìš©í•˜ëŠ” x86 CPU ì¸ìŠ¤í„´ìŠ¤ì˜ Head Pod í•˜ë‚˜ì™€ Karpenterì— ì˜í•´ ì˜¤í† ìŠ¤ì¼€ì¼ë§ë˜ëŠ” Inf2.48xlarge ì¸ìŠ¤í„´ìŠ¤ì˜ Ray ì›Œì»¤ë¡œ êµ¬ì„±ëœ Ray Serve í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•©ë‹ˆë‹¤.  ë°°í¬ë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ì´ ë°°í¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì£¼ìš” íŒŒì¼ì„ ìì„¸íˆ ì‚´í´ë³´ê³  ê¸°ëŠ¥ì„ ì´í•´í•´ ë´…ì‹œë‹¤:  ray_serve_Llama-2.py:ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” FastAPI, Ray Serve ë° PyTorch ê¸°ë°˜ Hugging Face Transformersë¥¼ ì‚¬ìš©í•˜ì—¬ NousResearch/Llama-2-13b-chat-hf ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ í…ìŠ¤íŠ¸ ìƒì„± APIë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë˜ëŠ” ì‚¬ìš©ìëŠ” meta-llama/Llama-2-13b-chat-hf ëª¨ë¸ë¡œ ìœ ì—°í•˜ê²Œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ëŠ” ì…ë ¥ ë¬¸ì¥ì„ ìˆ˜ë½í•˜ê³  í–¥ìƒëœ ì„±ëŠ¥ì„ ìœ„í•œ Neuron ê°€ì†ì˜ ì´ì ì„ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ë†’ì€ êµ¬ì„± ê°€ëŠ¥ì„±ìœ¼ë¡œ ì‚¬ìš©ìëŠ” ì±—ë´‡ ë° í…ìŠ¤íŠ¸ ìƒì„± ì‘ì—…ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë§ê²Œ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ray-service-Llama-2.yaml:ì´ Ray Serve YAML íŒŒì¼ì€ Llama-2-13b-chat ëª¨ë¸ì„ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìš©ì´í•˜ê²Œ í•˜ëŠ” Ray Serve ì„œë¹„ìŠ¤ë¥¼ ë°°í¬í•˜ê¸° ìœ„í•œ Kubernetes êµ¬ì„± ì—­í• ì„ í•©ë‹ˆë‹¤. ë¦¬ì†ŒìŠ¤ë¥¼ ë¶„ë¦¬í•˜ê¸° ìœ„í•´ Llama-2ë¼ëŠ” Kubernetes ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. êµ¬ì„± ë‚´ì—ì„œ Llama-2-serviceë¼ëŠ” RayService ì‚¬ì–‘ì´ ìƒì„±ë˜ê³  Llama-2 ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë‚´ì— í˜¸ìŠ¤íŒ…ë©ë‹ˆë‹¤. RayService ì‚¬ì–‘ì€ Ray Serve ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ Python ìŠ¤í¬ë¦½íŠ¸ ray_serve_Llama-2.py (ê°™ì€ í´ë” ë‚´ì˜ Dockerfileì— ë³µì‚¬ë¨)ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œ ì‚¬ìš©ëœ Docker ì´ë¯¸ì§€ëŠ” ë°°í¬ ìš©ì´ì„±ì„ ìœ„í•´ Amazon Elastic Container Registry (ECR)ì— ê³µê°œì ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” íŠ¹ì • ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ Dockerfileì„ ìˆ˜ì •í•˜ê³  ìì²´ ECR ë¦¬í¬ì§€í† ë¦¬ì— í‘¸ì‹œí•˜ì—¬ YAML íŒŒì¼ì—ì„œ ì°¸ì¡°í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"1ë‹¨ê³„: Llama-2-Chat ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#1ë‹¨ê³„-llama-2-chat-ëª¨ë¸-ë°°í¬","content":" í´ëŸ¬ìŠ¤í„°ê°€ ë¡œì»¬ì—ì„œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸  aws eks --region us-west-2 update-kubeconfig --name trainium-inferentia   RayServe í´ëŸ¬ìŠ¤í„° ë°°í¬  cd ai-on-eks/blueprints/inference/llama2-13b-chat-rayserve-inf2 kubectl apply -f ray-service-llama2.yaml   ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°°í¬ í™•ì¸  ì •ë³´ ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Head PodëŠ” 2~3ë¶„ ë‚´ì— ì¤€ë¹„ë˜ê³ , Ray Serve ì›Œì»¤ PodëŠ” Huggingfaceì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ëª¨ë¸ ë°°í¬ì— ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  kubectl get all -n llama2   ì¶œë ¥:  NAME READY STATUS RESTARTS AGE pod/llama2-raycluster-fcmtr-head-bf58d 1/1 Running 0 67m pod/llama2-raycluster-fcmtr-worker-inf2-lgnb2 1/1 Running 0 5m30s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/llama2 ClusterIP 172.20.118.243 &lt;none&gt; 10001/TCP,8000/TCP,8080/TCP,6379/TCP,8265/TCP 67m service/llama2-head-svc ClusterIP 172.20.168.94 &lt;none&gt; 8080/TCP,6379/TCP,8265/TCP,10001/TCP,8000/TCP 57m service/llama2-serve-svc ClusterIP 172.20.61.167 &lt;none&gt; 8000/TCP 57m NAME DESIRED WORKERS AVAILABLE WORKERS CPUS MEMORY GPUS STATUS AGE raycluster.ray.io/llama2-raycluster-fcmtr 1 1 184 704565270Ki 0 ready 67m NAME SERVICE STATUS NUM SERVE ENDPOINTS rayservice.ray.io/llama2 Running 2   kubectl get ingress -n llama2   ì¶œë ¥:  NAME CLASS HOSTS ADDRESS PORTS AGE llama2 nginx * k8s-ingressn-ingressn-aca7f16a80-1223456666.elb.us-west-2.amazonaws.com 80 69m   ì£¼ì˜ ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” ë³´ì•ˆìƒì˜ ì´ìœ ë¡œ ë‚´ë¶€ ë¡œë“œ ë°¸ëŸ°ì„œë¥¼ ë°°í¬í•˜ë¯€ë¡œ ë™ì¼í•œ VPCì— ìˆì§€ ì•Šìœ¼ë©´ ë¸Œë¼ìš°ì €ì—ì„œ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.ì—¬ê¸°ì˜ ì§€ì¹¨ì— ë”°ë¼ NLBë¥¼ ê³µê°œë¡œ ì„¤ì •í•˜ë„ë¡ ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜ëŠ” ë¡œë“œ ë°¸ëŸ°ì„œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì„œë¹„ìŠ¤ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ì œ ì•„ë˜ì˜ ë¡œë“œ ë°¸ëŸ°ì„œ URLì„ ì‚¬ìš©í•˜ì—¬ Ray ëŒ€ì‹œë³´ë“œì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. &lt;NLB_DNS_NAME&gt;ì„ NLB ì—”ë“œí¬ì¸íŠ¸ë¡œ ë°”ê¾¸ì‹­ì‹œì˜¤:  http://\\&lt;NLB_DNS_NAME\\&gt;/dashboard/#/serve   ê³µê°œ ë¡œë“œ ë°¸ëŸ°ì„œì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ì—†ëŠ” ê²½ìš° í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ê³  ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ localhostë¥¼ ì‚¬ìš©í•˜ì—¬ Ray ëŒ€ì‹œë³´ë“œë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl port-forward service/llama2 8265:8265 -n llama2   ë¸Œë¼ìš°ì €ì—ì„œ ë§í¬ ì—´ê¸°: http://localhost:8265/  ì´ ì›¹í˜ì´ì§€ì—ì„œ ì•„ë˜ ì´ë¯¸ì§€ì™€ ê°™ì´ ëª¨ë¸ ë°°í¬ ì§„í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:    ","version":"Next","tagName":"h3"},{"title":"2ë‹¨ê³„: Llama-2-Chat ëª¨ë¸ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#2ë‹¨ê³„-llama-2-chat-ëª¨ë¸-í…ŒìŠ¤íŠ¸","content":" ëª¨ë¸ ë°°í¬ ìƒíƒœê°€ running ìƒíƒœê°€ ë˜ë©´ Llama-2-chat ì‚¬ìš©ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  í¬íŠ¸ í¬ì›Œë”© ì‚¬ìš©  ë¨¼ì € í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ì—¬ ì„œë¹„ìŠ¤ì— ë¡œì»¬ë¡œ ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤:  kubectl port-forward service/llama2-serve-svc 8000:8000 -n llama2   ê·¸ëŸ° ë‹¤ìŒ URL ëì— ì¿¼ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ ë‹¤ìŒ URLë¡œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  http://localhost:8000/infer?sentence=what is data parallelism and tensor parallelism and the differences   ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.    NLB ì‚¬ìš©:  Network Load Balancer (NLB)ë¥¼ ì‚¬ìš©í•˜ë ¤ëŠ” ê²½ìš° ì—¬ê¸°ì˜ ì§€ì¹¨ì— ë”°ë¼ NLBë¥¼ ê³µê°œë¡œ ì„¤ì •í•˜ë„ë¡ ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ê·¸ëŸ° ë‹¤ìŒ URL ëì— ì¿¼ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ ë‹¤ìŒ URLì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  http://\\&lt;NLB_DNS_NAME\\&gt;/serve/infer?sentence=what is data parallelism and tensor parallelisma and the differences   ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:    ","version":"Next","tagName":"h3"},{"title":"3ë‹¨ê³„: Gradio WebUI ì•± ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#3ë‹¨ê³„-gradio-webui-ì•±-ë°°í¬","content":" Gradio Web UIëŠ” inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ EKS í´ëŸ¬ìŠ¤í„°ì— ë°°í¬ëœ Llama2 ì¶”ë¡  ì„œë¹„ìŠ¤ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. Gradio UIëŠ” ì„œë¹„ìŠ¤ ì´ë¦„ê³¼ í¬íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í¬íŠ¸ 8000ì—ì„œ ë…¸ì¶œë˜ëŠ” Llama2 ì„œë¹„ìŠ¤(llama2-serve-svc.llama2.svc.cluster.local:8000)ì™€ ë‚´ë¶€ì ìœ¼ë¡œ í†µì‹ í•©ë‹ˆë‹¤.  Gradio ì•±ì„ ìœ„í•œ ê¸°ë³¸ Docker(ai/inference/gradio-ui/Dockerfile-gradio-base) ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìœ¼ë©°, ì´ëŠ” ëª¨ë“  ëª¨ë¸ ì¶”ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì´ë¯¸ì§€ëŠ” Public ECRì— ê²Œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  Gradio ì•± ë°°í¬ ë‹¨ê³„:â€‹  ë‹¤ìŒ YAML ìŠ¤í¬ë¦½íŠ¸(ai/inference/llama2-13b-chat-rayserve-inf2/gradio-ui.yaml)ëŠ” ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸ ìŠ¤í¬ë¦½íŠ¸ê°€ í¬í•¨ëœ ì „ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤, ë°°í¬, ì„œë¹„ìŠ¤ ë° ConfigMapì„ ìƒì„±í•©ë‹ˆë‹¤.  ì´ë¥¼ ë°°í¬í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  cd ai-on-eks/blueprints/inference/llama2-13b-chat-rayserve-inf2/ kubectl apply -f gradio-ui.yaml   í™•ì¸ ë‹¨ê³„:ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°°í¬, ì„œë¹„ìŠ¤ ë° ConfigMapì„ í™•ì¸í•©ë‹ˆë‹¤:  kubectl get deployments -n gradio-llama2-inf2 kubectl get services -n gradio-llama2-inf2 kubectl get configmaps -n gradio-llama2-inf2   ì„œë¹„ìŠ¤ í¬íŠ¸ í¬ì›Œë”©:  ë¡œì»¬ì—ì„œ Web UIì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆë„ë¡ í¬íŠ¸ í¬ì›Œë”© ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl port-forward service/gradio-service 7860:7860 -n gradio-llama2-inf2   WebUI í˜¸ì¶œâ€‹  ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  ë‹¤ìŒ URLë¡œ ì´ë™í•˜ì—¬ Gradio WebUIì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤:  ë¡œì»¬ URLì—ì„œ ì‹¤í–‰ ì¤‘: http://localhost:7860  ì´ì œ ë¡œì»¬ ë¨¸ì‹ ì—ì„œ Gradio ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"ê²°ë¡ â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#ê²°ë¡ ","content":" ê²°ë¡ ì ìœ¼ë¡œ, Llama-2-13b chat ëª¨ë¸ì„ Ray Serveì™€ í•¨ê»˜ EKSì— ì„±ê³µì ìœ¼ë¡œ ë°°í¬í•˜ê³  Gradioë¥¼ ì‚¬ìš©í•˜ì—¬ chatGPT ìŠ¤íƒ€ì¼ì˜ ì±„íŒ… ì›¹ UIë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ìì—°ì–´ ì²˜ë¦¬ ë° ì±—ë´‡ ê°œë°œì— í¥ë¯¸ë¡œìš´ ê°€ëŠ¥ì„±ì„ ì—´ì–´ì¤ë‹ˆë‹¤.  ìš”ì•½í•˜ë©´, Llama-2ë¥¼ ë°°í¬í•˜ê³  í™•ì¥í•  ë•Œ AWS Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ë§¤ë ¥ì ì¸ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤. GPU ë¶€ì¡±ê³¼ ê´€ë ¨ëœ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ë©´ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ì´ê³  ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ ì‹¤í–‰í•˜ëŠ” ë° í•„ìš”í•œ í™•ì¥ì„±, ë¹„ìš© ìµœì í™” ë° ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí•©ë‹ˆë‹¤. ì±—ë´‡, ìì—°ì–´ ì²˜ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ë˜ëŠ” ê¸°íƒ€ LLM ê¸°ë°˜ ì†”ë£¨ì…˜ì„ êµ¬ì¶•í•˜ë“  Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ AWS í´ë¼ìš°ë“œì—ì„œ Llama-2ì˜ ì ì¬ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-2-13b Chat ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama2-inf2#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  1ë‹¨ê³„: Gradio ì•± ë° Llama2 ì¶”ë¡  ë°°í¬ ì‚­ì œ  cd ai-on-eks/blueprints/inference/llama2-13b-chat-rayserve-inf2 kubectl delete -f gradio-ui.yaml kubectl delete -f ray-service-llama2.yaml   2ë‹¨ê³„: EKS í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” -target ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¦¬ì†ŒìŠ¤ê°€ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì‚­ì œë˜ë„ë¡ í™˜ê²½ì„ ì •ë¦¬í•©ë‹ˆë‹¤.  cd ai-on-eks/infra/trainium-inferentia ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2","content":"","keywords":"","version":"Next"},{"title":"Llama-3-8B Instructë€?â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#llama-3-8b-instructë€","content":" MetaëŠ” 8B ë° 70B í¬ê¸°ì˜ ì‚¬ì „ í›ˆë ¨ ë° ëª…ë ¹ì–´ ì¡°ì • ìƒì„± í…ìŠ¤íŠ¸ ëª¨ë¸ ì»¬ë ‰ì…˜ì¸ Meta Llama 3 ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ì œí’ˆêµ°ì„ ê°œë°œí•˜ê³  ì¶œì‹œí–ˆìŠµë‹ˆë‹¤. Llama 3 ëª…ë ¹ì–´ ì¡°ì • ëª¨ë¸ì€ ëŒ€í™” ì‚¬ìš© ì‚¬ë¡€ì— ìµœì í™”ë˜ì–´ ìˆìœ¼ë©° ì¼ë°˜ì ì¸ ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë§ì€ ì˜¤í”ˆ ì†ŒìŠ¤ ì±„íŒ… ëª¨ë¸ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤. ë˜í•œ ì´ëŸ¬í•œ ëª¨ë¸ì„ ê°œë°œí•  ë•Œ ìœ ìš©ì„±ê³¼ ì•ˆì „ì„±ì„ ìµœì í™”í•˜ëŠ” ë° ì„¸ì‹¬í•œ ì£¼ì˜ë¥¼ ê¸°ìš¸ì˜€ìŠµë‹ˆë‹¤.  Llama3 í¬ê¸° ë° ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ëŠ” ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  í™•ì¥ì„± ë° ê°€ìš©ì„±  Llama-3ì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ë°°í¬í•  ë•Œ ì£¼ìš” ê³¼ì œ ì¤‘ í•˜ë‚˜ëŠ” ì ì ˆí•œ í•˜ë“œì›¨ì–´ì˜ í™•ì¥ì„±ê³¼ ê°€ìš©ì„±ì…ë‹ˆë‹¤. ê¸°ì¡´ GPU ì¸ìŠ¤í„´ìŠ¤ëŠ” ë†’ì€ ìˆ˜ìš”ë¡œ ì¸í•´ ë¶€ì¡±í•œ ê²½ìš°ê°€ ë§ì•„ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í•˜ê³  í™•ì¥í•˜ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤.  ë°˜ë©´ trn1.32xlarge, trn1n.32xlarge, inf2.24xlarge ë° inf2.48xlargeì™€ ê°™ì€ Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” LLMì„ í¬í•¨í•œ ìƒì„±í˜• AI ëª¨ë¸ì˜ ê³ ì„±ëŠ¥ ë”¥ëŸ¬ë‹(DL) í›ˆë ¨ ë° ì¶”ë¡ ì„ ìœ„í•´ íŠ¹ë³„íˆ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤. í™•ì¥ì„±ê³¼ ê°€ìš©ì„±ì„ ëª¨ë‘ ì œê³µí•˜ì—¬ ë¦¬ì†ŒìŠ¤ ë³‘ëª© í˜„ìƒì´ë‚˜ ì§€ì—° ì—†ì´ í•„ìš”ì— ë”°ë¼ Llama-3 ëª¨ë¸ì„ ë°°í¬í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë¹„ìš© ìµœì í™”  ê¸°ì¡´ GPU ì¸ìŠ¤í„´ìŠ¤ì—ì„œ LLMì„ ì‹¤í–‰í•˜ë©´ GPUì˜ ë¶€ì¡±ê³¼ ê²½ìŸì ì¸ ê°€ê²©ìœ¼ë¡œ ì¸í•´ ë¹„ìš©ì´ ë§ì´ ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ë¹„ìš© íš¨ìœ¨ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. AI ë° ê¸°ê³„ í•™ìŠµ ì‘ì—…ì— ìµœì í™”ëœ ì „ìš© í•˜ë“œì›¨ì–´ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ ë¹„ìš©ì˜ ì¼ë¶€ë¡œ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¹„ìš© ìµœì í™”ë¥¼ í†µí•´ ì˜ˆì‚°ì„ íš¨ìœ¨ì ìœ¼ë¡œ í• ë‹¹í•˜ì—¬ LLM ë°°í¬ë¥¼ ì ‘ê·¼ ê°€ëŠ¥í•˜ê³  ì§€ì† ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì„±ëŠ¥ í–¥ìƒ  Llama-3ëŠ” GPUì—ì„œ ê³ ì„±ëŠ¥ ì¶”ë¡ ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì§€ë§Œ, Neuron ê°€ì†ê¸°ëŠ” ì„±ëŠ¥ì„ í•œ ë‹¨ê³„ ë” ëŒì–´ì˜¬ë¦½ë‹ˆë‹¤. Neuron ê°€ì†ê¸°ëŠ” ê¸°ê³„ í•™ìŠµ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•´ íŠ¹ë³„íˆ êµ¬ì¶•ë˜ì–´ Llama-3ì˜ ì¶”ë¡  ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” í•˜ë“œì›¨ì–´ ê°€ì†ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ì— Llama-3ë¥¼ ë°°í¬í•  ë•Œ ë” ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ê³¼ ê°œì„ ëœ ì‚¬ìš©ì ê²½í—˜ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì˜ˆì œ ì‚¬ìš© ì‚¬ë¡€â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#ì˜ˆì œ-ì‚¬ìš©-ì‚¬ë¡€","content":" íšŒì‚¬ê°€ ê³ ê° ì§€ì›ì„ ì œê³µí•˜ê¸° ìœ„í•´ Llama-3 ì±—ë´‡ì„ ë°°í¬í•˜ë ¤ê³  í•©ë‹ˆë‹¤. íšŒì‚¬ëŠ” ëŒ€ê·œëª¨ ê³ ê° ê¸°ë°˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©° í”¼í¬ ì‹œê°„ì— ë§ì€ ì–‘ì˜ ì±„íŒ… ìš”ì²­ì„ ë°›ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•©ë‹ˆë‹¤. íšŒì‚¬ëŠ” ë†’ì€ ìš”ì²­ëŸ‰ì„ ì²˜ë¦¬í•˜ê³  ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” ì¸í”„ë¼ë¥¼ ì„¤ê³„í•´ì•¼ í•©ë‹ˆë‹¤.  íšŒì‚¬ëŠ” Inferentia2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Llama-3 ì±—ë´‡ì„ íš¨ìœ¨ì ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Inferentia2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ê¸°ê³„ í•™ìŠµ ì‘ì—…ì„ ìœ„í•œ íŠ¹ìˆ˜ í•˜ë“œì›¨ì–´ ê°€ì†ê¸°ì…ë‹ˆë‹¤. ê¸°ê³„ í•™ìŠµ ì›Œí¬ë¡œë“œì— ëŒ€í•´ GPUë³´ë‹¤ ìµœëŒ€ 20ë°° ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ìµœëŒ€ 7ë°° ë” ë‚®ì€ ë¹„ìš©ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  íšŒì‚¬ëŠ” ë˜í•œ Ray Serveë¥¼ ì‚¬ìš©í•˜ì—¬ Llama-3 ì±—ë´‡ì„ ìˆ˜í‰ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Ray ServeëŠ” ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì„ ì„œë¹™í•˜ê¸° ìœ„í•œ ë¶„ì‚° í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ìˆ˜ìš”ì— ë”°ë¼ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ í™•ì¥í•˜ê±°ë‚˜ ì¶•ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Llama-3 ì±—ë´‡ì„ í™•ì¥í•˜ê¸° ìœ„í•´ íšŒì‚¬ëŠ” ì—¬ëŸ¬ Inferentia2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°°í¬í•˜ê³  Ray Serveë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ ê°„ì— íŠ¸ë˜í”½ì„ ë¶„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ íšŒì‚¬ëŠ” ë†’ì€ ìš”ì²­ëŸ‰ì„ ì²˜ë¦¬í•˜ê³  ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜ ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#ì†”ë£¨ì…˜-ì•„í‚¤í…ì²˜","content":" ì´ ì„¹ì…˜ì—ì„œëŠ” Amazon EKSì—ì„œ Llama-3 ëª¨ë¸, Ray Serve ë° Inferentia2ë¥¼ ê²°í•©í•œ ì†”ë£¨ì…˜ì˜ ì•„í‚¤í…ì²˜ë¥¼ ìì„¸íˆ ì‚´í´ë´…ë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#ì†”ë£¨ì…˜-ë°°í¬","content":" Amazon EKSì— Llama-3-8b-instructë¥¼ ë°°í¬í•˜ë ¤ë©´ í•„ìš”í•œ ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ì„ ë‹¤ë£¨ê³  ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.  ì—¬ê¸°ì—ëŠ” ì¸í”„ë¼ ì„¤ì •, Ray í´ëŸ¬ìŠ¤í„° ë°°í¬ ë° Gradio WebUI ì•± ìƒì„±ì´ í¬í•¨ë©ë‹ˆë‹¤.  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"Llama3 ëª¨ë¸ì´ ìˆëŠ” Ray í´ëŸ¬ìŠ¤í„° ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#llama3-ëª¨ë¸ì´-ìˆëŠ”-ray-í´ëŸ¬ìŠ¤í„°-ë°°í¬","content":" Trainium on EKS í´ëŸ¬ìŠ¤í„°ê°€ ë°°í¬ë˜ë©´ kubectlì„ ì‚¬ìš©í•˜ì—¬ ray-service-Llama-3.yamlì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ë‹¨ê³„ì—ì„œëŠ” Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§ì„ ì‚¬ìš©í•˜ëŠ” x86 CPU ì¸ìŠ¤í„´ìŠ¤ì˜ Head Pod í•˜ë‚˜ì™€ Karpenterì— ì˜í•´ ì˜¤í† ìŠ¤ì¼€ì¼ë§ë˜ëŠ” Inf2.48xlarge ì¸ìŠ¤í„´ìŠ¤ì˜ Ray ì›Œì»¤ë¡œ êµ¬ì„±ëœ Ray Serve í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•©ë‹ˆë‹¤.  ë°°í¬ë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ì´ ë°°í¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì£¼ìš” íŒŒì¼ì„ ìì„¸íˆ ì‚´í´ë³´ê³  ê¸°ëŠ¥ì„ ì´í•´í•´ ë´…ì‹œë‹¤:  ray_serve_Llama-3.py:  ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” FastAPI, Ray Serve ë° PyTorch ê¸°ë°˜ Hugging Face Transformersë¥¼ ì‚¬ìš©í•˜ì—¬ meta-llama/Meta-Llama-3-8B-Instruct ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ í…ìŠ¤íŠ¸ ìƒì„± APIë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  ìŠ¤í¬ë¦½íŠ¸ëŠ” ì…ë ¥ ë¬¸ì¥ì„ ìˆ˜ë½í•˜ê³  í–¥ìƒëœ ì„±ëŠ¥ì„ ìœ„í•œ Neuron ê°€ì†ì˜ ì´ì ì„ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ë†’ì€ êµ¬ì„± ê°€ëŠ¥ì„±ìœ¼ë¡œ ì‚¬ìš©ìëŠ” ì±—ë´‡ ë° í…ìŠ¤íŠ¸ ìƒì„± ì‘ì—…ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë§ê²Œ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ray-service-Llama-3.yaml:  ì´ Ray Serve YAML íŒŒì¼ì€ llama-3-8B-Instruct ëª¨ë¸ì„ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìš©ì´í•˜ê²Œ í•˜ëŠ” Ray Serve ì„œë¹„ìŠ¤ë¥¼ ë°°í¬í•˜ê¸° ìœ„í•œ Kubernetes êµ¬ì„± ì—­í• ì„ í•©ë‹ˆë‹¤.  ë¦¬ì†ŒìŠ¤ë¥¼ ë¶„ë¦¬í•˜ê¸° ìœ„í•´ llama3ë¼ëŠ” Kubernetes ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. êµ¬ì„± ë‚´ì—ì„œ llama-3ë¼ëŠ” RayService ì‚¬ì–‘ì´ ìƒì„±ë˜ê³  llama3 ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë‚´ì— í˜¸ìŠ¤íŒ…ë©ë‹ˆë‹¤. RayService ì‚¬ì–‘ì€ Ray Serve ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ Python ìŠ¤í¬ë¦½íŠ¸ ray_serve_llama3.py (ê°™ì€ í´ë” ë‚´ì˜ Dockerfileì— ë³µì‚¬ë¨)ë¥¼ í™œìš©í•©ë‹ˆë‹¤.  ì´ ì˜ˆì œì—ì„œ ì‚¬ìš©ëœ Docker ì´ë¯¸ì§€ëŠ” ë°°í¬ ìš©ì´ì„±ì„ ìœ„í•´ Amazon Elastic Container Registry (ECR)ì— ê³µê°œì ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” íŠ¹ì • ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ Dockerfileì„ ìˆ˜ì •í•˜ê³  ìì²´ ECR ë¦¬í¬ì§€í† ë¦¬ì— í‘¸ì‹œí•˜ì—¬ YAML íŒŒì¼ì—ì„œ ì°¸ì¡°í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Llama-3-Instruct ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#llama-3-instruct-ëª¨ë¸-ë°°í¬","content":" í´ëŸ¬ìŠ¤í„°ê°€ ë¡œì»¬ì—ì„œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸  aws eks --region us-west-2 update-kubeconfig --name trainium-inferentia   RayServe í´ëŸ¬ìŠ¤í„° ë°°í¬  ì •ë³´ llama3-8B-Instruct ëª¨ë¸ì„ ë°°í¬í•˜ë ¤ë©´ Hugging Face Hub í† í°ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ êµ¬ì„±í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì´ í† í°ì€ ì¸ì¦ ë° ëª¨ë¸ ì•¡ì„¸ìŠ¤ì— í•„ìš”í•©ë‹ˆë‹¤. Hugging Face í† í° ìƒì„± ë° ê´€ë¦¬ ë°©ë²•ì— ëŒ€í•œ ì§€ì¹¨ì€ Hugging Face Token Managementë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  # Hugging Face Hub í† í°ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ì´ ë³€ìˆ˜ëŠ” ray-service-llama3.yaml íŒŒì¼ì„ ì ìš©í•  ë•Œ ëŒ€ì²´ë©ë‹ˆë‹¤ export HUGGING_FACE_HUB_TOKEN=&lt;Your-Hugging-Face-Hub-Token-Value&gt; cd ai-on-eks/blueprints/inference/llama3-8b-rayserve-inf2 envsubst &lt; ray-service-llama3.yaml| kubectl apply -f -   ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°°í¬ í™•ì¸  ì •ë³´ ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Head PodëŠ” 2~3ë¶„ ë‚´ì— ì¤€ë¹„ë˜ê³ , Ray Serve ì›Œì»¤ PodëŠ” Huggingfaceì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ëª¨ë¸ ë°°í¬ì— ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  $ kubectl get all -n llama3 NAME READY STATUS RESTARTS AGE pod/llama3-raycluster-smqrl-head-4wlbb 0/1 Running 0 77s pod/service-raycluster-smqrl-worker-inf2-wjxqq 0/1 Running 0 77s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/llama3 ClusterIP 172.20.246.48 &lt;none&gt; 8000:32138/TCP,52365:32653/TCP,8080:32604/TCP,6379:32739/TCP,8265:32288/TCP,10001:32419/TCP 78s $ kubectl get ingress -n llama3 NAME CLASS HOSTS ADDRESS PORTS AGE llama3 nginx * k8s-ingressn-ingressn-randomid-randomid.elb.us-west-2.amazonaws.com 80 2m4s   ì´ì œ ì•„ë˜ì˜ ë¡œë“œ ë°¸ëŸ°ì„œ URLì„ ì‚¬ìš©í•˜ì—¬ Ray ëŒ€ì‹œë³´ë“œì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  http://&lt;NLB_DNS_NAME&gt;/dashboard/#/serve  ê³µê°œ ë¡œë“œ ë°¸ëŸ°ì„œì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ì—†ëŠ” ê²½ìš° í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ê³  ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ localhostë¥¼ ì‚¬ìš©í•˜ì—¬ Ray ëŒ€ì‹œë³´ë“œë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl port-forward svc/llama3 8265:8265 -n llama3 # ë¸Œë¼ìš°ì €ì—ì„œ ë§í¬ ì—´ê¸° http://localhost:8265/   ì´ ì›¹í˜ì´ì§€ì—ì„œ ì•„ë˜ ì´ë¯¸ì§€ì™€ ê°™ì´ ëª¨ë¸ ë°°í¬ ì§„í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:    ","version":"Next","tagName":"h3"},{"title":"Llama3 ëª¨ë¸ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#llama3-ëª¨ë¸-í…ŒìŠ¤íŠ¸","content":" ëª¨ë¸ ë°°í¬ ìƒíƒœê°€ running ìƒíƒœê°€ ë˜ë©´ Llama-3-instruct ì‚¬ìš©ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  URL ëì— ì¿¼ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ ë‹¤ìŒ URLì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  http://&lt;NLB_DNS_NAME&gt;/serve/infer?sentence=what is data parallelism and tensor parallelisma and the differences  ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:    ","version":"Next","tagName":"h3"},{"title":"Gradio WebUI ì•± ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#gradio-webui-ì•±-ë°°í¬","content":" ë°°í¬ëœ ëª¨ë¸ê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ëŠ” ì‚¬ìš©ì ì¹œí™”ì ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ Gradioë¥¼ ì‚¬ìš©í•˜ì—¬ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.  RayServeë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ëœ LLama-3-Instruct ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©í•˜ê¸° ìœ„í•´ ë¡œì»¬ ë¨¸ì‹ ì— Gradio ì•±ì„ ë°°í¬í•´ ë´…ì‹œë‹¤.  ì •ë³´ Gradio ì•±ì€ ë°ëª¨ ëª©ì ìœ¼ë¡œë§Œ ìƒì„±ëœ ë¡œì»¬ë¡œ ë…¸ì¶œëœ ì„œë¹„ìŠ¤ì™€ ìƒí˜¸ ì‘ìš©í•©ë‹ˆë‹¤. ë˜ëŠ” ë” ë„“ì€ ì ‘ê·¼ì„±ì„ ìœ„í•´ Ingress ë° Load Balancerê°€ ìˆëŠ” Podë¡œ EKSì— Gradio ì•±ì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"llama3 Ray ì„œë¹„ìŠ¤ë¡œ í¬íŠ¸ í¬ì›Œë”© ì‹¤í–‰â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#llama3-ray-ì„œë¹„ìŠ¤ë¡œ-í¬íŠ¸-í¬ì›Œë”©-ì‹¤í–‰","content":" ë¨¼ì € kubectlì„ ì‚¬ìš©í•˜ì—¬ Llama-3 Ray ì„œë¹„ìŠ¤ë¡œ í¬íŠ¸ í¬ì›Œë”©ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl port-forward svc/llama3-service 8000:8000 -n llama3   ","version":"Next","tagName":"h3"},{"title":"Gradio WebUI ì•± ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#gradio-webui-ì•±-ë°°í¬-1","content":" ë°°í¬ëœ ëª¨ë¸ê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ëŠ” ì‚¬ìš©ì ì¹œí™”ì ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ Gradioë¥¼ ì‚¬ìš©í•˜ì—¬ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.  localhostì—ì„œ Docker ì»¨í…Œì´ë„ˆë¡œ ì‹¤í–‰ë˜ëŠ” Gradio ì•±ì„ ì„¤ì •í•˜ëŠ” ê²ƒìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤. ì´ ì„¤ì •ì„ í†µí•´ RayServeë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ëœ Llama-3-Instruct ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Gradio ì•± Docker ì»¨í…Œì´ë„ˆ ë¹Œë“œâ€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#gradio-ì•±-docker-ì»¨í…Œì´ë„ˆ-ë¹Œë“œ","content":" ë¨¼ì € í´ë¼ì´ì–¸íŠ¸ ì•±ìš© Docker ì»¨í…Œì´ë„ˆë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤.  cd ai-on-eks/blueprints/inference/gradio-ui docker build --platform=linux/amd64 \\ -t gradio-app:llama \\ --build-arg GRADIO_APP=&quot;gradio-app-llama.py&quot; \\ .   ","version":"Next","tagName":"h3"},{"title":"Gradio ì»¨í…Œì´ë„ˆ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#gradio-ì»¨í…Œì´ë„ˆ-ë°°í¬","content":" dockerë¥¼ ì‚¬ìš©í•˜ì—¬ localhostì—ì„œ ì»¨í…Œì´ë„ˆë¡œ Gradio ì•±ì„ ë°°í¬í•©ë‹ˆë‹¤:  docker run --rm -it -p 7860:7860 -p 8000:8000 gradio-app:llama   ì •ë³´ ë¨¸ì‹ ì—ì„œ Docker Desktopì„ ì‹¤í–‰í•˜ì§€ ì•Šê³  finchì™€ ê°™ì€ ê²ƒì„ ëŒ€ì‹  ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ ì‚¬ìš©ì ì •ì˜ í˜¸ìŠ¤íŠ¸-IP ë§¤í•‘ì„ ìœ„í•œ ì¶”ê°€ í”Œë˜ê·¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. docker run --rm -it \\ --add-host ray-service:&lt;workstation-ip&gt; \\ -e &quot;SERVICE_NAME=http://ray-service:8000&quot; \\ -p 7860:7860 gradio-app:llama   WebUI í˜¸ì¶œâ€‹  ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  ë‹¤ìŒ URLë¡œ ì´ë™í•˜ì—¬ Gradio WebUIì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤:  ë¡œì»¬ URLì—ì„œ ì‹¤í–‰ ì¤‘: http://localhost:7860  ì´ì œ ë¡œì»¬ ë¨¸ì‹ ì—ì„œ Gradio ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"ê²°ë¡ â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#ê²°ë¡ ","content":" ìš”ì•½í•˜ë©´, Llama-3ë¥¼ ë°°í¬í•˜ê³  í™•ì¥í•  ë•Œ AWS Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ë§¤ë ¥ì ì¸ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤. GPU ë¶€ì¡±ê³¼ ê´€ë ¨ëœ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ë©´ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ì´ê³  ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ ì‹¤í–‰í•˜ëŠ” ë° í•„ìš”í•œ í™•ì¥ì„±, ë¹„ìš© ìµœì í™” ë° ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí•©ë‹ˆë‹¤. ì±—ë´‡, ìì—°ì–´ ì²˜ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ë˜ëŠ” ê¸°íƒ€ LLM ê¸°ë°˜ ì†”ë£¨ì…˜ì„ êµ¬ì¶•í•˜ë“  Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ AWS í´ë¼ìš°ë“œì—ì„œ Llama-3ì˜ ì ì¬ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Llama-3-8B Instruct ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama3-inf2#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  1ë‹¨ê³„: Gradio ì»¨í…Œì´ë„ˆ ì‚­ì œ  Gradio ì•±ì„ ì‹¤í–‰í•˜ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ docker runì´ ì‹¤í–‰ ì¤‘ì¸ localhost í„°ë¯¸ë„ ì°½ì—ì„œ Ctrl-cë¥¼ ëˆ„ë¦…ë‹ˆë‹¤. ì„ íƒì ìœ¼ë¡œ Docker ì´ë¯¸ì§€ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤  docker rmi gradio-app:llama   2ë‹¨ê³„: Ray í´ëŸ¬ìŠ¤í„° ì‚­ì œ  cd ai-on-eks/blueprints/inference/llama3-8b-instruct-rayserve-inf2 kubectl delete -f ray-service-llama3.yaml   3ë‹¨ê³„: EKS í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” -target ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¦¬ì†ŒìŠ¤ê°€ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì‚­ì œë˜ë„ë¡ í™˜ê²½ì„ ì •ë¦¬í•©ë‹ˆë‹¤.  cd ai-on-eks/infra/trainium-inferentia/ ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Inferentia2, Ray Serve, Gradioë¥¼ ì‚¬ìš©í•œ Mistral-7B-Instruct-v0.2 ì„œë¹™","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/Mistral-7b-inf2","content":"","keywords":"","version":"Next"},{"title":"Mistral-7B-Instruct-v0.2 ëª¨ë¸ì´ë€?â€‹","type":1,"pageTitle":"Inferentia2, Ray Serve, Gradioë¥¼ ì‚¬ìš©í•œ Mistral-7B-Instruct-v0.2 ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/Mistral-7b-inf2#mistral-7b-instruct-v02-ëª¨ë¸ì´ë€","content":" mistralai/Mistral-7B-Instruct-v0.2ëŠ” ê³µê°œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëŒ€í™” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ë¯¸ì„¸ ì¡°ì •ëœ Mistral-7B-v0.2 ê¸°ë³¸ ëª¨ë¸ì˜ ëª…ë ¹ì–´ ì¡°ì • ë²„ì „ì…ë‹ˆë‹¤. ëª…ë ¹ì–´ë¥¼ ë”°ë¥´ê³  ì‘ì—…ì„ ì™„ë£Œí•˜ë„ë¡ ì„¤ê³„ë˜ì–´ ì±—ë´‡, ê°€ìƒ ì–´ì‹œìŠ¤í„´íŠ¸ ë° ì‘ì—… ì§€í–¥ ëŒ€í™” ì‹œìŠ¤í…œê³¼ ê°™ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì í•©í•©ë‹ˆë‹¤. 73ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ Mistral-7B-v0.2 ê¸°ë³¸ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, ë” ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•œ Grouped-Query Attention (GQA)ê³¼ ê°œì„ ëœ ê²¬ê³ ì„±ì„ ìœ„í•œ Byte-fallback BPE í† í¬ë‚˜ì´ì €ë¥¼ í¬í•¨í•œ ìµœì‹  ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  ìì„¸í•œ ë‚´ìš©ì€ Model Cardë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia2, Ray Serve, Gradioë¥¼ ì‚¬ìš©í•œ Mistral-7B-Instruct-v0.2 ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/Mistral-7b-inf2#ì†”ë£¨ì…˜-ë°°í¬","content":" Amazon EKSì—ì„œ Mistral-7B-Instruct-v0.2 ëª¨ë¸ì„ ì‹œì‘í•˜ê³  ì‹¤í–‰í•´ ë´…ì‹œë‹¤! ì´ ì„¹ì…˜ì—ì„œëŠ” ë‹¤ìŒì„ ë‹¤ë£¹ë‹ˆë‹¤:  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­: ì‹œì‘í•˜ê¸° ì „ì— í•„ìš”í•œ ëª¨ë“  ë„êµ¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸.ì¸í”„ë¼ ì„¤ì •: EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•˜ê³  ë°°í¬ ì¤€ë¹„.Ray í´ëŸ¬ìŠ¤í„° ë°°í¬: í™•ì¥ì„±ê³¼ íš¨ìœ¨ì„±ì„ ì œê³µí•˜ëŠ” ì´ë¯¸ì§€ ìƒì„± íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬.Gradio Web UI ë¹Œë“œ: Mistral 7B ëª¨ë¸ê³¼ì˜ ì›í™œí•œ ìƒí˜¸ ì‘ìš©ì„ ìœ„í•œ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¸í„°í˜ì´ìŠ¤ ìƒì„±.  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"Mistral 7B ëª¨ë¸ì´ ìˆëŠ” Ray í´ëŸ¬ìŠ¤í„° ë°°í¬â€‹","type":1,"pageTitle":"Inferentia2, Ray Serve, Gradioë¥¼ ì‚¬ìš©í•œ Mistral-7B-Instruct-v0.2 ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/Mistral-7b-inf2#mistral-7b-ëª¨ë¸ì´-ìˆëŠ”-ray-í´ëŸ¬ìŠ¤í„°-ë°°í¬","content":" trainium-inferentia EKS í´ëŸ¬ìŠ¤í„°ê°€ ë°°í¬ë˜ë©´ kubectlì„ ì‚¬ìš©í•˜ì—¬ /ai-on-eks/blueprints/inference/mistral-7b-rayserve-inf2/ ê²½ë¡œì—ì„œ ray-service-mistral.yamlì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ë‹¨ê³„ì—ì„œëŠ” Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§ì„ ì‚¬ìš©í•˜ëŠ” x86 CPU ì¸ìŠ¤í„´ìŠ¤ì˜ Head Pod í•˜ë‚˜ì™€ Karpenterì— ì˜í•´ ì˜¤í† ìŠ¤ì¼€ì¼ë§ë˜ëŠ” inf2.24xlarge ì¸ìŠ¤í„´ìŠ¤ì˜ Ray ì›Œì»¤ë¡œ êµ¬ì„±ëœ Ray Serve í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•©ë‹ˆë‹¤.  ë°°í¬ë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ì´ ë°°í¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì£¼ìš” íŒŒì¼ì„ ìì„¸íˆ ì‚´í´ë³´ê³  ê¸°ëŠ¥ì„ ì´í•´í•´ ë´…ì‹œë‹¤:  ray_serve_mistral.py:ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” AWS Neuron ì¸í”„ë¼(Inf2)ì—ì„œ í™•ì¥ ê°€ëŠ¥í•œ ëª¨ë¸ ì„œë¹™ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” Ray Serveë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ëœ ë‘ ê°€ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œê°€ ìˆëŠ” FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì„¤ì •í•©ë‹ˆë‹¤: mistral-7b Deployment: ì´ í´ë˜ìŠ¤ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ Mistral 7B ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  ì²˜ë¦¬ë¥¼ ìœ„í•´ Inf2 ë…¸ë“œë¡œ ì´ë™í•©ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ëŠ” ì´ Mistral ëª¨ë¸ì— ëŒ€í•´ grouped-query attention (GQA) ëª¨ë¸ì— ëŒ€í•œ Transformers Neuron ì§€ì›ì„ í™œìš©í•©ë‹ˆë‹¤. mistral-7b-instruct-v0.2ëŠ” ì±„íŒ… ê¸°ë°˜ ëª¨ë¸ì…ë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ì£¼ìœ„ì— [INST] ë° [/INST] í† í°ì„ ì¶”ê°€í•˜ì—¬ ëª…ë ¹ì–´ì— í•„ìš”í•œ ì ‘ë‘ì‚¬ë„ ì¶”ê°€í•©ë‹ˆë‹¤.APIIngress: ì´ FastAPI ì—”ë“œí¬ì¸íŠ¸ëŠ” Mistral 7B ëª¨ë¸ì— ëŒ€í•œ ì¸í„°í˜ì´ìŠ¤ ì—­í• ì„ í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ëŠ” /infer ê²½ë¡œì— GET ë©”ì„œë“œë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ì— í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤. ray-service-mistral.yaml:ì´ RayServe ë°°í¬ íŒ¨í„´ì€ AWS Inferentia2 ì§€ì›ê³¼ í•¨ê»˜ Amazon EKSì—ì„œ Mistral-7B-Instruct-v0.2 ëª¨ë¸ì„ í˜¸ìŠ¤íŒ…í•˜ê¸° ìœ„í•œ í™•ì¥ ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ì „ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë“¤ì–´ì˜¤ëŠ” íŠ¸ë˜í”½ì— ë”°ë¼ ë¦¬ì†ŒìŠ¤ í™œìš©ë„ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì˜¤í† ìŠ¤ì¼€ì¼ë§ ê¸°ëŠ¥ì´ ìˆëŠ” RayServiceë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤. ë°°í¬ëŠ” RayService ìš°ì‚° ì•„ë˜ì—ì„œ ì œê³µë˜ëŠ” ëª¨ë¸ì´ ìˆ˜ìš”ì— ë”°ë¼ ë ˆí”Œë¦¬ì¹´ë¥¼ ìë™ìœ¼ë¡œ ì¡°ì •í•  ìˆ˜ ìˆë„ë¡ ë³´ì¥í•˜ë©°, ê° ë ˆí”Œë¦¬ì¹´ì—ëŠ” 2ê°œì˜ neuron ì½”ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ íŒ¨í„´ì€ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ê³  ë¬´ê±°ìš´ ì¢…ì†ì„±ì´ ë¯¸ë¦¬ ë¡œë“œë˜ì–´ ì‹œì‘ ì§€ì—°ì„ ìµœì†Œí™”í•˜ë„ë¡ ì„¤ê³„ëœ ì‚¬ìš©ì ì •ì˜ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Mistral-7B-Instruct-v0.2 ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia2, Ray Serve, Gradioë¥¼ ì‚¬ìš©í•œ Mistral-7B-Instruct-v0.2 ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/Mistral-7b-inf2#mistral-7b-instruct-v02-ëª¨ë¸-ë°°í¬","content":" í´ëŸ¬ìŠ¤í„°ê°€ ë¡œì»¬ì—ì„œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸  aws eks --region us-west-2 update-kubeconfig --name trainium-inferentia   RayServe í´ëŸ¬ìŠ¤í„° ë°°í¬  ì •ë³´ Mistral-7B-Instruct-v0.2 ëª¨ë¸ì„ ë°°í¬í•˜ë ¤ë©´ Hugging Face Hub í† í°ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ êµ¬ì„±í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì´ í† í°ì€ ì¸ì¦ ë° ëª¨ë¸ ì•¡ì„¸ìŠ¤ì— í•„ìš”í•©ë‹ˆë‹¤. Hugging Face í† í° ìƒì„± ë° ê´€ë¦¬ ë°©ë²•ì— ëŒ€í•œ ì§€ì¹¨ì€ Hugging Face Token Managementë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  # Hugging Face Hub í† í°ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ì´ ë³€ìˆ˜ëŠ” ray-service-mistral.yaml íŒŒì¼ì„ ì ìš©í•  ë•Œ ëŒ€ì²´ë©ë‹ˆë‹¤ export HUGGING_FACE_HUB_TOKEN=$(echo -n &quot;Your-Hugging-Face-Hub-Token-Value&quot; | base64) cd ai-on-eks/blueprints/inference/mistral-7b-rayserve-inf2 envsubst &lt; ray-service-mistral.yaml| kubectl apply -f -   ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°°í¬ í™•ì¸  ì •ë³´ ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Head PodëŠ” 2~3ë¶„ ë‚´ì— ì¤€ë¹„ë˜ê³ , Ray Serve ì›Œì»¤ PodëŠ” Huggingfaceì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ëª¨ë¸ ë°°í¬ì— ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ë°°í¬ëŠ” ì•„ë˜ì™€ ê°™ì´ x86 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” Ray head podì™€ inf2.24xl ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” ì›Œì»¤ podë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.  kubectl get pods -n mistral NAME READY STATUS service-raycluster-68tvp-worker-inf2-worker-group-2kckv 1/1 Running mistral-service-raycluster-68tvp-head-dmfz5 2/2 Running   ì´ ë°°í¬ëŠ” ë˜í•œ ì—¬ëŸ¬ í¬íŠ¸ê°€ êµ¬ì„±ëœ mistral ì„œë¹„ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. í¬íŠ¸ 8265ëŠ” Ray ëŒ€ì‹œë³´ë“œìš©ì´ê³  í¬íŠ¸ 8000ì€ Mistral ëª¨ë¸ ì—”ë“œí¬ì¸íŠ¸ìš©ì…ë‹ˆë‹¤.  kubectl get svc -n mistral NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) mistral-service NodePort 172.20.118.238 &lt;none&gt; 10001:30998/TCP,8000:32437/TCP,52365:31487/TCP,8080:30351/TCP,6379:30392/TCP,8265:30904/TCP mistral-service-head-svc NodePort 172.20.245.131 &lt;none&gt; 6379:31478/TCP,8265:31393/TCP,10001:32627/TCP,8000:31251/TCP,52365:31492/TCP,8080:31471/TCP mistral-service-serve-svc NodePort 172.20.109.223 &lt;none&gt; 8000:31679/TCP   Ray ëŒ€ì‹œë³´ë“œì˜ ê²½ìš° ì´ëŸ¬í•œ í¬íŠ¸ë¥¼ ê°œë³„ì ìœ¼ë¡œ í¬íŠ¸ í¬ì›Œë”©í•˜ì—¬ localhostë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ ì›¹ UIì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  kubectl -n mistral port-forward svc/mistral-service 8265:8265   http://localhost:8265ë¥¼ í†µí•´ ì›¹ UIì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤. ì´ ì¸í„°í˜ì´ìŠ¤ëŠ” Ray ì—ì½”ì‹œìŠ¤í…œ ë‚´ì˜ ì‘ì—… ë° ì•¡í„° ë°°í¬ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.    ë°°í¬ê°€ ì™„ë£Œë˜ë©´ Controller ë° Proxy ìƒíƒœê°€ HEALTHYì´ê³  Application ìƒíƒœê°€ RUNNINGì´ì–´ì•¼ í•©ë‹ˆë‹¤    Ray ëŒ€ì‹œë³´ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ Serve ë°°í¬ ë° ë¦¬ì†ŒìŠ¤ í™œìš©ë„ë¥¼ í¬í•¨í•œ Ray í´ëŸ¬ìŠ¤í„° ë°°í¬ë¥¼ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"Gradio WebUI ì•± ë°°í¬â€‹","type":1,"pageTitle":"Inferentia2, Ray Serve, Gradioë¥¼ ì‚¬ìš©í•œ Mistral-7B-Instruct-v0.2 ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/Mistral-7b-inf2#gradio-webui-ì•±-ë°°í¬","content":" Gradio Web UIëŠ” inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ EKS í´ëŸ¬ìŠ¤í„°ì— ë°°í¬ëœ Mistral7b ì¶”ë¡  ì„œë¹„ìŠ¤ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. Gradio UIëŠ” ì„œë¹„ìŠ¤ ì´ë¦„ê³¼ í¬íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í¬íŠ¸ 8000ì—ì„œ ë…¸ì¶œë˜ëŠ” mistral ì„œë¹„ìŠ¤(mistral-serve-svc.mistral.svc.cluster.local:8000)ì™€ ë‚´ë¶€ì ìœ¼ë¡œ í†µì‹ í•©ë‹ˆë‹¤.  Gradio ì•±ì„ ìœ„í•œ ê¸°ë³¸ Docker(ai/inference/gradio-ui/Dockerfile-gradio-base) ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìœ¼ë©°, ì´ëŠ” ëª¨ë“  ëª¨ë¸ ì¶”ë¡ ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì´ë¯¸ì§€ëŠ” Public ECRì— ê²Œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  Gradio ì•± ë°°í¬ ë‹¨ê³„:â€‹  ë‹¤ìŒ YAML ìŠ¤í¬ë¦½íŠ¸(ai/inference/mistral-7b-rayserve-inf2/gradio-ui.yaml)ëŠ” ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸ ìŠ¤í¬ë¦½íŠ¸ê°€ í¬í•¨ëœ ì „ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤, ë°°í¬, ì„œë¹„ìŠ¤ ë° ConfigMapì„ ìƒì„±í•©ë‹ˆë‹¤.  ì´ë¥¼ ë°°í¬í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  cd ai-on-eks/blueprints/inference/mistral-7b-rayserve-inf2/ kubectl apply -f gradio-ui.yaml   í™•ì¸ ë‹¨ê³„:ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°°í¬, ì„œë¹„ìŠ¤ ë° ConfigMapì„ í™•ì¸í•©ë‹ˆë‹¤:  kubectl get deployments -n gradio-mistral7b-inf2 kubectl get services -n gradio-mistral7b-inf2 kubectl get configmaps -n gradio-mistral7b-inf2   ì„œë¹„ìŠ¤ í¬íŠ¸ í¬ì›Œë”©:  ë¡œì»¬ì—ì„œ Web UIì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆë„ë¡ í¬íŠ¸ í¬ì›Œë”© ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl port-forward service/gradio-service 7860:7860 -n gradio-mistral7b-inf2   WebUI í˜¸ì¶œâ€‹  ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  ë‹¤ìŒ URLë¡œ ì´ë™í•˜ì—¬ Gradio WebUIì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤:  ë¡œì»¬ URLì—ì„œ ì‹¤í–‰ ì¤‘: http://localhost:7860  ì´ì œ ë¡œì»¬ ë¨¸ì‹ ì—ì„œ Gradio ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    Mistral ëª¨ë¸ê³¼ì˜ ìƒí˜¸ ì‘ìš©â€‹  Mistral-7B-Instruct-v0.2 ëª¨ë¸ì€ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜(Q&amp;A, ëŒ€í™”), í…ìŠ¤íŠ¸ ìƒì„±, ì§€ì‹ ê²€ìƒ‰ ë“±ì˜ ìš©ë„ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì•„ë˜ ìŠ¤í¬ë¦°ìƒ·ì€ ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ëª¨ë¸ ì‘ë‹µì˜ ëª‡ ê°€ì§€ ì˜ˆë¥¼ ì œê³µí•©ë‹ˆë‹¤.        ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Inferentia2, Ray Serve, Gradioë¥¼ ì‚¬ìš©í•œ Mistral-7B-Instruct-v0.2 ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/Mistral-7b-inf2#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  1ë‹¨ê³„: Gradio ì•± ë° mistral ì¶”ë¡  ë°°í¬ ì‚­ì œ  cd ai-on-eks/blueprints/inference/mistral-7b-rayserve-inf2 kubectl delete -f gradio-ui.yaml kubectl delete -f ray-service-mistral.yaml   2ë‹¨ê³„: EKS í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” -target ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¦¬ì†ŒìŠ¤ê°€ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì‚­ì œë˜ë„ë¡ í™˜ê²½ì„ ì •ë¦¬í•©ë‹ˆë‹¤.  cd ai-on-eks/infra/trainium-inferentia/ ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Llama 4 Inference with vLLM on AWS Trainium","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2","content":"","keywords":"","version":"Next"},{"title":"Why Trainium for Llama 4?â€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#why-trainium-for-llama-4","content":" AWS Trainium provides large HBM memory capacity, making it an excellent choice for large MoE models like Llama 4:  Instance\tChips\tNeuronCores\tHBM Memory\tKarpenter\tEKS Auto Modetrn1.32xlarge\t16 Trainium v1\t32\t512 GiB\tSupported\tSupported trn2.48xlarge\t16 Trainium v2\t64\t1.5 TiB\tSupported\tNot yet supported  Advantage\tDetailNo quantization needed\tBoth trn1 (512 GiB) and trn2 (1.5 TiB) support Scout (~220 GiB) in native BF16 Karpenter auto-provisioning\tNeuron NodePool provisions Trainium nodes on-demand when workloads are scheduled trn2 for Maverick\ttrn2.48xlarge (1.5 TiB) supports Maverick (~800 GiB) in BF16 without quantization  ","version":"Next","tagName":"h2"},{"title":"Memory Comparison: GPU vs Trainiumâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#memory-comparison-gpu-vs-trainium","content":" Model\tBF16 Memory\tGPU (FP8 required?)\ttrn1.32xlarge (512 GiB)\ttrn2.48xlarge (1.5 TiB)Scout 17B-16E\t~220 GiB\tp4d.24xlarge (320 GiB) - No\tFits in BF16\tFits in BF16 Maverick 17B-128E\t~800 GiB\tp5.48xlarge (640 GiB) - Yes, FP8\tDoes not fit\tFits in BF16  ì •ë³´ For Maverick, only trn2.48xlarge has sufficient memory (1.5 TiB) for BF16. GPU deployment requires FP8 quantization, and trn1.32xlarge (512 GiB) is insufficient.  ê²½ê³  Trainium instance availability varies by region: aws ec2 describe-instance-type-offerings --region &lt;REGION&gt; \\ --location-type availability-zone \\ --filters &quot;Name=instance-type,Values=trn*&quot; \\ --query 'InstanceTypeOfferings[].{Type:InstanceType,Zone:Location}' --output table trn2.48xlarge: Limited availability (us-east-2). Not supported by EKS Auto Mode â€” use Karpenter with the inference-ready cluster.trn1.32xlarge: Available in more regions (us-west-2, us-east-1, us-east-2, etc.).  ","version":"Next","tagName":"h3"},{"title":"Model Compilationâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#model-compilation","content":" The AWS Neuron DLC uses optimum-neuron to run vLLM on Trainium. Models must be pre-compiled for Neuron before serving. The DLC checks the optimum-neuron-cache on Hugging Face for pre-compiled model artifacts matching your configuration (model, batch size, sequence length, tensor parallelism, dtype).  ì •ë³´ The optimum-cli export neuron command does not support llama4 as a model type. However, vllm serve uses a separate inference code path (optimum.neuron.models.inference.llama4) that includes full MoE support via Llama4NeuronModelForCausalLM. Compilation is triggered automatically on first serve.  ","version":"Next","tagName":"h2"},{"title":"Software Versionsâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#software-versions","content":" Component\tVersion\tNotesNeuron SDK\t2.26.1\tRequired optimum-neuron\t&gt;= 0.4.0\tLlama 4 inference support added in v0.4.0 vLLM\t0.11.0\tWith optimum-neuron Neuron platform plugin neuronx-distributed\t0.15\tMoE module used by Llama 4 inference DLC Image\t763104351884.dkr.ecr.&lt;region&gt;.amazonaws.com/huggingface-vllm-inference-neuronx:0.11.0-optimum0.4.5-neuronx-py310-sdk2.26.1-ubuntu22.04\tLatest available  Deploying the Inference-Ready EKS Cluster ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"Deploy Llama 4 Scout on Trainiumâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#deploy-llama-4-scout-on-trainium","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1: Create Hugging Face Token Secretâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#step-1-create-hugging-face-token-secret","content":" kubectl create secret generic hf-token --from-literal=token=&lt;your-huggingface-token&gt;   ","version":"Next","tagName":"h3"},{"title":"Step 2: Deploy with Helmâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#step-2-deploy-with-helm","content":" For trn2.48xlarge (Scout):  helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update helm install llama4-scout-neuron ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-4-scout-17b-vllm-neuron.yaml   ì •ë³´ Key deployment parameters: tensor_parallel_size: 16 (one per Trainium chip, not per NeuronCore)Docker image: AWS Neuron DLC from private ECR (763104351884.dkr.ecr.&lt;region&gt;.amazonaws.com/huggingface-vllm-inference-neuronx)Neuron device requests: aws.amazon.com/neuron: 16 for all 16 chipsCPU memory: 384Gi minimum (weight sharding requires loading the full model into CPU memory)Instance type: trn2.48xlarge (default for both Scout and Maverick)Environment variable: VLLM_NEURON_FRAMEWORK=optimum is required for on-the-fly Neuron compilation  ","version":"Next","tagName":"h3"},{"title":"Step 3: Monitor Deploymentâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#step-3-monitor-deployment","content":" After deploying, Karpenter will automatically provision a Trainium node:  # Watch node provisioning kubectl get nodeclaims -w # Check pod status kubectl get pods -w   During deployment, the pod will go through these stages:  Pending - waiting for Trainium node provisioning (~5 minutes)ContainerCreating - pulling the Neuron DLC image (~2.9 GiB)Running - Neuron model compilation (30-60+ minutes on first run)Ready - vLLM server is serving requests  CPU Memory Requirements The pod requires at least 384 GiB of CPU memory for model weight sharding across 16 Neuron devices. With insufficient memory (e.g., 64 GiB), the pod will be OOMKilled during weight loading. The trn2.48xlarge instance provides ~2 TiB of system memory, so this is well within capacity.  ê²½ê³  The first deployment takes significantly longer due to Neuron model compilation. Subsequent deployments with the same configuration will use cached artifacts. Monitor the compilation progress in the logs: kubectl logs -f -l app.kubernetes.io/instance=llama4-scout-neuron   Tested deployment timeline on trn2.48xlarge (Scout):  Phase\tDuration\tDescriptionNode provisioning\t~5 min\tKarpenter provisions trn2.48xlarge Image pull\t~30 sec\tDLC image (~2.9 GiB, cached after first pull) HLO generation\t~60 sec\tGenerates HLOs for context_encoding and token_generation Neuron compilation\t~200 sec\tneuronx-cc compiles HLOs to NEFFs (target=trn2) Model build\t~650 sec\tWeight layout transformation Weight loading\t~5 min\tDownload, shard, and load weights to 16 Neuron devices Total (first deploy)\t~20 min\tSubsequent deploys reuse cached compilation artifacts  Once complete, the vLLM server will start:  INFO: Application startup complete. INFO: Uvicorn running on http://0.0.0.0:8000   ","version":"Next","tagName":"h3"},{"title":"Deploy Llama 4 Maverick on Trainium2â€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#deploy-llama-4-maverick-on-trainium2","content":" Maverick requires trn2.48xlarge (1.5 TiB HBM) and runs in native BF16 without quantization. Ensure your cluster has the trn2-neuron Karpenter NodePool configured (see cluster setup above).  helm install llama4-maverick-neuron ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-4-maverick-17b-vllm-neuron.yaml   ê²½ê³  trn2.48xlarge is available in limited regions (us-east-2). Verify availability before deploying.Ensure your AWS account has sufficient service quota for Trainium instances (Maverick requires 192 vCPUs).  ","version":"Next","tagName":"h2"},{"title":"Test the Modelâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#test-the-model","content":" ","version":"Next","tagName":"h2"},{"title":"Port Forwardâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#port-forward","content":" kubectl port-forward svc/llama4-scout-neuron 8000:8000   ","version":"Next","tagName":"h3"},{"title":"Chat Completion Requestâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#chat-completion-request","content":" curl -X POST http://localhost:8000/v1/chat/completions \\ -H &quot;Content-Type: application/json&quot; \\ -d '{ &quot;model&quot;: &quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;, &quot;messages&quot;: [ {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Explain the benefits of Mixture of Experts architecture in large language models.&quot;} ], &quot;max_tokens&quot;: 512, &quot;temperature&quot;: 0.7 }'   ","version":"Next","tagName":"h3"},{"title":"List Available Modelsâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#list-available-models","content":" curl http://localhost:8000/v1/models | python3 -m json.tool   ","version":"Next","tagName":"h3"},{"title":"Multimodal Request (Text + Image)â€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#multimodal-request-text--image","content":" Llama 4 supports multimodal inference. Send image URLs alongside text:  curl -X POST http://localhost:8000/v1/chat/completions \\ -H &quot;Content-Type: application/json&quot; \\ -d '{ &quot;model&quot;: &quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;, &quot;messages&quot;: [ { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [ {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Describe what you see in this image.&quot;}, {&quot;type&quot;: &quot;image_url&quot;, &quot;image_url&quot;: {&quot;url&quot;: &quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg&quot;}} ] } ], &quot;max_tokens&quot;: 256 }'   ","version":"Next","tagName":"h3"},{"title":"Deploy Open WebUIâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#deploy-open-webui","content":" Open WebUI provides a ChatGPT-style interface for interacting with the model.  helm repo add open-webui https://helm.openwebui.com/ helm repo update helm install open-webui open-webui/open-webui \\ --namespace open-webui --create-namespace \\ --set ollama.enabled=false \\ --set env.OPENAI_API_BASE_URL=http://llama4-scout-neuron.default.svc.cluster.local:8000/v1 \\ --set env.OPENAI_API_KEY=dummy   Access the UI:  kubectl port-forward svc/open-webui 8080:80 -n open-webui   Open http://localhost:8080 in your browser and register a new account. The model will appear in the model selector.  ","version":"Next","tagName":"h2"},{"title":"Monitoringâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#monitoring","content":" ","version":"Next","tagName":"h2"},{"title":"Check Inference Logsâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#check-inference-logs","content":" # View vLLM Neuron logs kubectl logs -l app.kubernetes.io/instance=llama4-scout-neuron --tail=100 # Monitor token generation throughput kubectl logs -l app.kubernetes.io/instance=llama4-scout-neuron -f | grep &quot;tokens/s&quot;   ","version":"Next","tagName":"h3"},{"title":"Observability Dashboardâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#observability-dashboard","content":" If the observability stack is enabled on your cluster, access Grafana:  kubectl port-forward svc/kube-prometheus-stack-grafana 3000:80 -n monitoring   ","version":"Next","tagName":"h3"},{"title":"Cleanupâ€‹","type":1,"pageTitle":"Llama 4 Inference with vLLM on AWS Trainium","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/llama4-trn2#cleanup","content":" Remove the model deployment:  # Remove Scout helm uninstall llama4-scout-neuron # Remove Maverick (if deployed) helm uninstall llama4-maverick-neuron   To destroy the entire cluster infrastructure:  cd ai-on-eks/infra/solutions/inference-ready-cluster ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Ray Serve ê³ ê°€ìš©ì„±","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/rayserve-ha","content":"","keywords":"","version":"Next"},{"title":"Elastic Cache for Redisë¥¼ ì‚¬ìš©í•œ Ray Head ë…¸ë“œ ê³ ê°€ìš©ì„±(HA)â€‹","type":1,"pageTitle":"Ray Serve ê³ ê°€ìš©ì„±","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/rayserve-ha#elastic-cache-for-redisë¥¼-ì‚¬ìš©í•œ-ray-head-ë…¸ë“œ-ê³ ê°€ìš©ì„±ha","content":" Ray í´ëŸ¬ìŠ¤í„°ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†ŒëŠ” ì‘ì—… ìŠ¤ì¼€ì¤„ë§, ìƒíƒœ ë™ê¸°í™” ë° ë…¸ë“œ ì¡°ì •ì„ ê´€ë¦¬í•˜ì—¬ ì „ì²´ í´ëŸ¬ìŠ¤í„°ë¥¼ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ëŠ” í—¤ë“œ ë…¸ë“œì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ë³¸ì ìœ¼ë¡œ Ray head PodëŠ” ë‹¨ì¼ ì¥ì•  ì§€ì ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì‹¤íŒ¨í•˜ë©´ Ray ì›Œì»¤ Podë¥¼ í¬í•¨í•œ ì „ì²´ í´ëŸ¬ìŠ¤í„°ë¥¼ ë‹¤ì‹œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.  ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Ray head ë…¸ë“œì˜ ê³ ê°€ìš©ì„±(HA)ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. Global Control Service (GCS)ëŠ” RayClusterì—ì„œ í´ëŸ¬ìŠ¤í„° ìˆ˜ì¤€ ë©”íƒ€ë°ì´í„°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ GCSëŠ” ëª¨ë“  ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ë¯€ë¡œ ì¥ì•  í—ˆìš©ì´ ì—†ìœ¼ë©°, ì‹¤íŒ¨ ì‹œ ì „ì²´ Ray í´ëŸ¬ìŠ¤í„°ê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ë°©ì§€í•˜ë ¤ë©´ Rayì˜ Global Control Store (GCS)ì— ì¥ì•  í—ˆìš©ì„ ì¶”ê°€í•´ì•¼ í•˜ë©°, ì´ë¥¼ í†µí•´ head ë…¸ë“œê°€ ì¶©ëŒí•´ë„ Ray Serve ì• í”Œë¦¬ì¼€ì´ì…˜ì´ íŠ¸ë˜í”½ì„ ì„œë¹™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. GCSê°€ ì¬ì‹œì‘ë˜ë©´ Redis ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ëª¨ë“  ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ì •ìƒ ê¸°ëŠ¥ì„ ì¬ê°œí•©ë‹ˆë‹¤.      ë‹¤ìŒ ì„¹ì…˜ì—ì„œëŠ” GCS ì¥ì•  í—ˆìš©ì„ í™œì„±í™”í•˜ê³  Ray head Podì˜ ê³ ê°€ìš©ì„±ì„ ë³´ì¥í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ë‹¨ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Mistral-7B-Instruct-v0.2 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ Ray head ê³ ê°€ìš©ì„±ì„ ì‹œì—°í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì™¸ë¶€ Redis ì„œë²„ ì¶”ê°€â€‹","type":1,"pageTitle":"Ray Serve ê³ ê°€ìš©ì„±","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/rayserve-ha#ì™¸ë¶€-redis-ì„œë²„-ì¶”ê°€","content":" GCS ì¥ì•  í—ˆìš©ì—ëŠ” ì™¸ë¶€ Redis ë°ì´í„°ë² ì´ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ìì²´ Redis ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í˜¸ìŠ¤íŒ…í•˜ê±°ë‚˜ íƒ€ì‚¬ ë²¤ë”ë¥¼ í†µí•´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ê°œë°œ ë° í…ŒìŠ¤íŠ¸ ëª©ì ìœ¼ë¡œ Ray í´ëŸ¬ìŠ¤í„°ì™€ ë™ì¼í•œ EKS í´ëŸ¬ìŠ¤í„°ì— ì»¨í…Œì´ë„ˆí™”ëœ Redis ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í˜¸ìŠ¤íŒ…í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í”„ë¡œë•ì…˜ ì„¤ì •ì˜ ê²½ìš° ê³ ê°€ìš©ì„± ì™¸ë¶€ Redis í´ëŸ¬ìŠ¤í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ íŒ¨í„´ì—ì„œëŠ” Amazon ElasticCache for Redisë¥¼ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ Redis í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. Redis í´ëŸ¬ìŠ¤í„° ì„¤ì •ì— Amazon memoryDBë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  í˜„ì¬ ë¸”ë£¨í”„ë¦°íŠ¸ì˜ ì¼ë¶€ë¡œ AWSì—ì„œ Elastic Cache Redis í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•˜ëŠ” elasticacheë¼ëŠ” terraform ëª¨ë“ˆì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. Redis í´ëŸ¬ìŠ¤í„°ëŠ” í´ëŸ¬ìŠ¤í„° ëª¨ë“œê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©° í•˜ë‚˜ì˜ ë…¸ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì´ í´ëŸ¬ìŠ¤í„° ë…¸ë“œì˜ ì—”ë“œí¬ì¸íŠ¸ëŠ” ì½ê¸°ì™€ ì“°ê¸° ëª¨ë‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ëª¨ë“ˆì—ì„œ ì£¼ëª©í•  ì£¼ìš” ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:  Redis í´ëŸ¬ìŠ¤í„°ëŠ” EKS í´ëŸ¬ìŠ¤í„°ì™€ ë™ì¼í•œ VPCì— ìˆìŠµë‹ˆë‹¤. Redis í´ëŸ¬ìŠ¤í„°ê°€ ë³„ë„ì˜ VPCì— ìƒì„±ëœ ê²½ìš° ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™œì„±í™”í•˜ë ¤ë©´ EKS í´ëŸ¬ìŠ¤í„° VPCì™€ Elastic Cache Redis í´ëŸ¬ìŠ¤í„° VPC ê°„ì— VPC í”¼ì–´ë§ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.Redis í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹œ ìºì‹œ ì„œë¸Œë„· ê·¸ë£¹ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì„œë¸Œë„· ê·¸ë£¹ì€ VPCì˜ ìºì‹œì— ì§€ì •í•  ìˆ˜ ìˆëŠ” ì„œë¸Œë„· ëª¨ìŒì…ë‹ˆë‹¤. ElastiCacheëŠ” í•´ë‹¹ ìºì‹œ ì„œë¸Œë„· ê·¸ë£¹ì„ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ì„œë¸Œë„· ë‚´ì˜ ê° ìºì‹œ ë…¸ë“œì— IP ì£¼ì†Œë¥¼ í• ë‹¹í•©ë‹ˆë‹¤. ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” Elastic cache Redis í´ëŸ¬ìŠ¤í„°ì˜ ì„œë¸Œë„· ê·¸ë£¹ì— EKS í´ëŸ¬ìŠ¤í„°ê°€ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ì„œë¸Œë„·ì„ ìë™ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.ë³´ì•ˆ ê·¸ë£¹ - Redis ìºì‹œì— í• ë‹¹ëœ ë³´ì•ˆ ê·¸ë£¹ì—ëŠ” EKS í´ëŸ¬ìŠ¤í„°ì˜ ì›Œì»¤ ë…¸ë“œ ë³´ì•ˆ ê·¸ë£¹ì—ì„œ í¬íŠ¸ 6379ë¥¼ í†µí•´ Redis í´ëŸ¬ìŠ¤í„° ë³´ì•ˆ ê·¸ë£¹ìœ¼ë¡œì˜ TCP íŠ¸ë˜í”½ì„ í—ˆìš©í•˜ëŠ” ì¸ë°”ìš´ë“œ ê·œì¹™ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. Ray head Podê°€ í¬íŠ¸ 6379ë¥¼ í†µí•´ Elastic cache Redis í´ëŸ¬ìŠ¤í„°ì— ì—°ê²°ì„ ì„¤ì •í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” ì¸ë°”ìš´ë“œ ê·œì¹™ìœ¼ë¡œ ë³´ì•ˆ ê·¸ë£¹ì„ ìë™ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.  Amazon Elastic Cacheë¥¼ ì‚¬ìš©í•˜ì—¬ Redis í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•˜ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¥´ì‹­ì‹œì˜¤.  ì •ë³´ ì´ Mistral7b ë°°í¬ëŠ” ê³ ê°€ìš©ì„±ê³¼ í•¨ê»˜ Ray Serveë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì—ì„œ ì´ë¯¸ mistral7bë¥¼ ë°°í¬í•œ ê²½ìš° ë°°í¬ë¥¼ ì‚­ì œí•˜ê³  ì•„ë˜ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­:  aws clikubectlterraformenvsubstjq  ë¨¼ì € ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ enable_rayserve_ha_elastic_cache_redis ë³€ìˆ˜ë¥¼ trueë¡œ ì„¤ì •í•˜ì—¬ Redis í´ëŸ¬ìŠ¤í„° ìƒì„±ì„ í™œì„±í™”í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ falseì…ë‹ˆë‹¤.  export TF_VAR_enable_rayserve_ha_elastic_cache_redis=true   ê·¸ëŸ° ë‹¤ìŒ install.sh ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ KubeRay operator ë° ê¸°íƒ€ ì• ë“œì˜¨ì´ ìˆëŠ” EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.  cd ai-on-eks/infra/trainium-inferentia ./install.sh   EKS í´ëŸ¬ìŠ¤í„° ì™¸ì—ë„ ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” AWS Elastic Cache Redis í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ìƒ˜í”Œ ì¶œë ¥ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤  Apply complete! Resources: 8 added, 1 changed, 0 destroyed. Outputs: configure_kubectl = &quot;aws eks --region us-west-2 update-kubeconfig --name trainium-inferentia&quot; elastic_cache_redis_cluster_arn = &quot;arn:aws:elasticache:us-west-2:11111111111:cluster:trainium-inferentia&quot;   ","version":"Next","tagName":"h3"},{"title":"RayServiceì— ì™¸ë¶€ Redis ì •ë³´ ì¶”ê°€â€‹","type":1,"pageTitle":"Ray Serve ê³ ê°€ìš©ì„±","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/rayserve-ha#rayserviceì—-ì™¸ë¶€-redis-ì •ë³´-ì¶”ê°€","content":" elastic cache Redis í´ëŸ¬ìŠ¤í„°ê°€ ìƒì„±ë˜ë©´ mistral-7b ëª¨ë¸ ì¶”ë¡ ì„ ìœ„í•œ RayService êµ¬ì„±ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.  ë¨¼ì € AWS CLIì™€ jqë¥¼ ì‚¬ìš©í•˜ì—¬ ì•„ë˜ì™€ ê°™ì´ Elastic Cache Redis í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸ë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.  export EXT_REDIS_ENDPOINT=$(aws elasticache describe-cache-clusters \\ --cache-cluster-id &quot;trainium-inferentia&quot; \\ --show-cache-node-info | jq -r '.CacheClusters[0].CacheNodes[0].Endpoint.Address')   ì´ì œ RayService CRD ì•„ë˜ì— ray.io/ft-enabled: &quot;true&quot; ì–´ë…¸í…Œì´ì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤. ray.io/ft-enabled ì–´ë…¸í…Œì´ì…˜ì€ trueë¡œ ì„¤ì •í•˜ë©´ GCS ì¥ì•  í—ˆìš©ì„ í™œì„±í™”í•©ë‹ˆë‹¤.  apiVersion: ray.io/v1 kind: RayService metadata: name: mistral namespace: mistral annotations: ray.io/ft-enabled: &quot;true&quot;   headGroupSpecì— ì™¸ë¶€ Redis í´ëŸ¬ìŠ¤í„° ì •ë³´ë¥¼ RAY_REDIS_ADDRESS í™˜ê²½ ë³€ìˆ˜ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.  headGroupSpec: headService: metadata: name: mistral namespace: mistral rayStartParams: dashboard-host: '0.0.0.0' num-cpus: &quot;0&quot; template: spec: containers: - name: head .... env: - name: RAY_REDIS_ADDRESS value: $EXT_REDIS_ENDPOINT:6379   RAY_REDIS_ADDRESSì˜ ê°’ì€ Redis ë°ì´í„°ë² ì´ìŠ¤ì˜ ì£¼ì†Œì—¬ì•¼ í•©ë‹ˆë‹¤. Redis í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸ì™€ í¬íŠ¸ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.  ai/inference/mistral-7b-rayserve-inf2/ray-service-mistral-ft.yaml íŒŒì¼ì—ì„œ GCS ì¥ì•  í—ˆìš©ì´ í™œì„±í™”ëœ ì „ì²´ RayService êµ¬ì„±ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ìœ„ì˜ RayService êµ¬ì„±ìœ¼ë¡œ Ray head Podì— ëŒ€í•œ GCS ì¥ì•  í—ˆìš©ì„ í™œì„±í™”í–ˆìœ¼ë©°, Ray í´ëŸ¬ìŠ¤í„°ëŠ” ëª¨ë“  Ray ì›Œì»¤ë¥¼ ì¬ì‹œì‘í•˜ì§€ ì•Šê³  head Pod ì¶©ëŒì—ì„œ ë³µêµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ìœ„ì˜ RayService êµ¬ì„±ì„ ì ìš©í•˜ê³  ë™ì‘ì„ í™•ì¸í•´ ë´…ì‹œë‹¤.  cd ai-on-eks/blueprints/inference/ envsubst &lt; mistral-7b-rayserve-inf2/ray-service-mistral-ft.yaml| kubectl apply -f -   ì¶œë ¥ì€ ì•„ë˜ì™€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤  namespace/mistral created secret/hf-token created rayservice.ray.io/mistral created ingress.networking.k8s.io/mistral created   í´ëŸ¬ìŠ¤í„°ì˜ Ray Pod ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.  kubectl get po -n mistral   Ray head ë° ì›Œì»¤ PodëŠ” ì•„ë˜ì™€ ê°™ì´ Running ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤.  NAME READY STATUS RESTARTS AGE mistral-raycluster-rf6l9-head-hc8ch 2/2 Running 0 31m mistral-raycluster-rf6l9-worker-inf2-tdrs6 1/1 Running 0 31m   ","version":"Next","tagName":"h3"},{"title":"Ray Head Pod ì¶©ëŒ ì‹œë®¬ë ˆì´ì…˜â€‹","type":1,"pageTitle":"Ray Serve ê³ ê°€ìš©ì„±","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/rayserve-ha#ray-head-pod-ì¶©ëŒ-ì‹œë®¬ë ˆì´ì…˜","content":" Podë¥¼ ì‚­ì œí•˜ì—¬ Ray head Pod ì¶©ëŒì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤  kubectl -n mistral delete po mistral-raycluster-rf6l9-head-xxxxx pod &quot;mistral-raycluster-rf6l9-head-xxxxx&quot; deleted   Ray head Podê°€ ì¢…ë£Œë˜ê³  ìë™ ì¬ì‹œì‘ë  ë•Œ Ray ì›Œì»¤ Podê°€ ê³„ì† ì‹¤í–‰ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Lens IDEì˜ ì•„ë˜ ìŠ¤í¬ë¦°ìƒ·ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.      Mistral AI Gradio ì•± í…ŒìŠ¤íŠ¸â€‹  Ray head Podê°€ ì‚­ì œëœ ë™ì•ˆ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ”ì§€ Gradio UI ì•±ë„ í…ŒìŠ¤íŠ¸í•´ ë´…ì‹œë‹¤.  ë¸Œë¼ìš°ì €ë¥¼ localhost:7860ìœ¼ë¡œ ì§€ì •í•˜ì—¬ Gradio Mistral AI Chat ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì—½ë‹ˆë‹¤.  ì´ì œ ìœ„ ë‹¨ê³„ì—ì„œ ë³´ì—¬ì¤€ ê²ƒì²˜ëŸ¼ Ray head Podë¥¼ ì‚­ì œí•˜ì—¬ Ray head Pod ì¶©ëŒ ì‹œë®¬ë ˆì´ì…˜ì„ ë°˜ë³µí•©ë‹ˆë‹¤.  Ray head Podê°€ ì¢…ë£Œë˜ê³  ë³µêµ¬ë˜ëŠ” ë™ì•ˆ Mistral AI Chat ì¸í„°í˜ì´ìŠ¤ì— ì§ˆë¬¸ì„ ì œì¶œí•©ë‹ˆë‹¤. ì•„ë˜ ìŠ¤í¬ë¦°ìƒ·ì—ì„œ Ray head Podê°€ ì‚­ì œë˜ê³  ë³µêµ¬ë˜ëŠ” ë™ì•ˆ ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹¤ì œë¡œ íŠ¸ë˜í”½ì„ ì„œë¹™í•  ìˆ˜ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. GCS ì¥ì•  í—ˆìš©ìœ¼ë¡œ ì¸í•´ RayServe ì„œë¹„ìŠ¤ê°€ ì´ ê²½ìš° ì¬ì‹œì‘ë˜ì§€ ì•ŠëŠ” Ray ì›Œì»¤ Podë¥¼ ê°€ë¦¬í‚¤ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.        RayServe ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì—”ë“œíˆ¬ì—”ë“œ ì¥ì•  í—ˆìš©ì„ í™œì„±í™”í•˜ëŠ” ì „ì²´ ê°€ì´ë“œëŠ” Ray Guideë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h3"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Ray Serve ê³ ê°€ìš©ì„±","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/rayserve-ha#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  1ë‹¨ê³„: Gradio ì•± ë° mistral ì¶”ë¡  ë°°í¬ ì‚­ì œ  cd ai-on-eks/blueprints/inference/mistral-7b-rayserve-inf2 kubectl delete -f gradio-ui.yaml kubectl delete -f ray-service-mistral-ft.yaml   2ë‹¨ê³„: EKS í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” -target ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¦¬ì†ŒìŠ¤ê°€ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì‚­ì œë˜ë„ë¡ í™˜ê²½ì„ ì •ë¦¬í•©ë‹ˆë‹¤.  cd ai-on-eks/infra/trainium-inferentia/ ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2","content":"","keywords":"","version":"Next"},{"title":"Stable Diffusionì´ë€?â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#stable-diffusionì´ë€","content":" Stable Diffusionì€ ëª‡ ì´ˆ ë§Œì— ë©‹ì§„ ì•„íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ëª¨ë¸ì…ë‹ˆë‹¤. í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ê°€ì¥ í¬ê³  ê°•ë ¥í•œ LLM ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì£¼ë¡œ í…ìŠ¤íŠ¸ ì„¤ëª…ì— ì¡°ê±´í™”ëœ ìƒì„¸í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ì§€ë§Œ ì¸í˜ì¸íŒ…, ì•„ì›ƒí˜ì¸íŒ… ë° í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì— ì˜í•´ ì•ˆë‚´ë˜ëŠ” ì´ë¯¸ì§€-ì´ë¯¸ì§€ ë²ˆì—­ ìƒì„±ê³¼ ê°™ì€ ë‹¤ë¥¸ ì‘ì—…ì—ë„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Stable Diffusion XL(SDXL)â€‹  SDXLì€ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ í•©ì„±ì„ ìœ„í•œ ì ì¬ í™•ì‚° ëª¨ë¸ì…ë‹ˆë‹¤. ì´ì „ ë²„ì „ì˜ Stable Diffusionê³¼ ë¹„êµí•˜ì—¬ SDXLì€ ì ì¬ í™•ì‚° ë° ë…¸ì´ì¦ˆ ê°ì†Œë¥¼ ìœ„í•œ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. SDXLì€ ë˜í•œ ë” ë§ì€ ì–´í…ì…˜ ë¸”ë¡ê³¼ SDXLì´ ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ë” í° êµì°¨ ì–´í…ì…˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°–ëŠ” ë” í° UNetì„ ì‚¬ìš©í•˜ì—¬ ì´ì „ Stable Diffusion ëª¨ë¸ì— ë¹„í•´ ìƒì„±ëœ ì´ë¯¸ì§€ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.  SDXLì€ ì—¬ëŸ¬ ìƒˆë¡œìš´ ì»¨ë””ì…”ë‹ ì²´ê³„ë¡œ ì„¤ê³„ë˜ì—ˆìœ¼ë©° ì—¬ëŸ¬ ì¢…íš¡ë¹„ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ ì´ë¯¸ì§€-ì´ë¯¸ì§€ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ SDXLì—ì„œ ìƒì„±ëœ ìƒ˜í”Œì˜ ì‹œê°ì  ì¶©ì‹¤ë„ë¥¼ ê°œì„ í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì •ì œ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.  ì´ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ Amazon EKSì™€ Ray Serveì—ì„œ íš¨ê³¼ì ìœ¼ë¡œ ë°°í¬í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´í•˜ëŠ” ê³ ë„ë¡œ ìœ ëŠ¥í•˜ê³  ë¯¸ì„¸ ì¡°ì •ëœ ì–¸ì–´ ëª¨ë¸ì´ ìƒì„±ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œì˜ ì¶”ë¡ : Stable Diffusion LLMì˜ ì ì¬ë ¥ ê·¹ëŒ€í™”â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#trn1inf2-ì¸ìŠ¤í„´ìŠ¤ì—ì„œì˜-ì¶”ë¡ -stable-diffusion-llmì˜-ì ì¬ë ¥-ê·¹ëŒ€í™”","content":" Stable Diffusion XLì€ ë‹¤ì–‘í•œ í•˜ë“œì›¨ì–´ í”Œë«í¼ì— ë°°í¬í•  ìˆ˜ ìˆìœ¼ë©°, ê°ê° ê³ ìœ í•œ ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Stable Diffusion ëª¨ë¸ì˜ íš¨ìœ¨ì„±, í™•ì¥ì„± ë° ë¹„ìš© íš¨ìœ¨ì„±ì„ ìµœëŒ€í™”í•˜ëŠ” ë° ìˆì–´ AWS Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ê°€ ìµœì ì˜ ì„ íƒì…ë‹ˆë‹¤.  í™•ì¥ì„± ë° ê°€ìš©ì„±StableDiffusion XLê³¼ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ë°°í¬í•  ë•Œ ì£¼ìš” ê³¼ì œ ì¤‘ í•˜ë‚˜ëŠ” ì ì ˆí•œ í•˜ë“œì›¨ì–´ì˜ í™•ì¥ì„±ê³¼ ê°€ìš©ì„±ì…ë‹ˆë‹¤. ê¸°ì¡´ GPU ì¸ìŠ¤í„´ìŠ¤ëŠ” ë†’ì€ ìˆ˜ìš”ë¡œ ì¸í•´ ë¶€ì¡±í•œ ê²½ìš°ê°€ ë§ì•„ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í•˜ê³  í™•ì¥í•˜ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤. ë°˜ë©´ trn1.32xlarge, trn1n.32xlarge, inf2.24xlarge ë° inf2.48xlargeì™€ ê°™ì€ Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” LLMì„ í¬í•¨í•œ ìƒì„±í˜• AI ëª¨ë¸ì˜ ê³ ì„±ëŠ¥ ë”¥ëŸ¬ë‹(DL) í›ˆë ¨ ë° ì¶”ë¡ ì„ ìœ„í•´ íŠ¹ë³„íˆ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤. í™•ì¥ì„±ê³¼ ê°€ìš©ì„±ì„ ëª¨ë‘ ì œê³µí•˜ì—¬ ë¦¬ì†ŒìŠ¤ ë³‘ëª© í˜„ìƒì´ë‚˜ ì§€ì—° ì—†ì´ í•„ìš”ì— ë”°ë¼ Stable-diffusion-xl ëª¨ë¸ì„ ë°°í¬í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë¹„ìš© ìµœì í™”:ê¸°ì¡´ GPU ì¸ìŠ¤í„´ìŠ¤ì—ì„œ LLMì„ ì‹¤í–‰í•˜ë©´ GPUì˜ ë¶€ì¡±ê³¼ ê²½ìŸì ì¸ ê°€ê²©ìœ¼ë¡œ ì¸í•´ ë¹„ìš©ì´ ë§ì´ ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ë¹„ìš© íš¨ìœ¨ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. AI ë° ê¸°ê³„ í•™ìŠµ ì‘ì—…ì— ìµœì í™”ëœ ì „ìš© í•˜ë“œì›¨ì–´ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ ë¹„ìš©ì˜ ì¼ë¶€ë¡œ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¹„ìš© ìµœì í™”ë¥¼ í†µí•´ ì˜ˆì‚°ì„ íš¨ìœ¨ì ìœ¼ë¡œ í• ë‹¹í•˜ì—¬ LLM ë°°í¬ë¥¼ ì ‘ê·¼ ê°€ëŠ¥í•˜ê³  ì§€ì† ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì„±ëŠ¥ í–¥ìƒStable-Diffusion-xlì€ GPUì—ì„œ ê³ ì„±ëŠ¥ ì¶”ë¡ ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì§€ë§Œ, Neuron ê°€ì†ê¸°ëŠ” ì„±ëŠ¥ì„ í•œ ë‹¨ê³„ ë” ëŒì–´ì˜¬ë¦½ë‹ˆë‹¤. Neuron ê°€ì†ê¸°ëŠ” ê¸°ê³„ í•™ìŠµ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•´ íŠ¹ë³„íˆ êµ¬ì¶•ë˜ì–´ Stable-diffusionì˜ ì¶”ë¡  ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” í•˜ë“œì›¨ì–´ ê°€ì†ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ì— Stable-Diffusion-xlì„ ë°°í¬í•  ë•Œ ë” ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ê³¼ ê°œì„ ëœ ì‚¬ìš©ì ê²½í—˜ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì˜ˆì œ ì‚¬ìš© ì‚¬ë¡€â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#ì˜ˆì œ-ì‚¬ìš©-ì‚¬ë¡€","content":" ë””ì§€í„¸ ì•„íŠ¸ íšŒì‚¬ê°€ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ëŠ¥í•œ ì•„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Stable-diffusion-xl ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„±ê¸°ë¥¼ ë°°í¬í•˜ë ¤ê³  í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì„ íƒì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìëŠ” ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ì•„íŠ¸ì›Œí¬, ê·¸ë˜í”½ ë° ë¡œê³ ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ìƒì„±ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•„íŠ¸ë¥¼ ì˜ˆì¸¡í•˜ê±°ë‚˜ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìœ¼ë©° ì œí’ˆ ë°˜ë³µ ì£¼ê¸°ì—ì„œ ìƒë‹¹í•œ ì‹œê°„ ì ˆì•½ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íšŒì‚¬ëŠ” ëŒ€ê·œëª¨ ê³ ê° ê¸°ë°˜ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©° ëª¨ë¸ì´ ë†’ì€ ë¶€í•˜ì—ì„œ í™•ì¥ ê°€ëŠ¥í•˜ê¸°ë¥¼ ì›í•©ë‹ˆë‹¤. íšŒì‚¬ëŠ” ë†’ì€ ìš”ì²­ëŸ‰ì„ ì²˜ë¦¬í•˜ê³  ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ì œê³µí•  ìˆ˜ ìˆëŠ” ì¸í”„ë¼ë¥¼ ì„¤ê³„í•´ì•¼ í•©ë‹ˆë‹¤.  íšŒì‚¬ëŠ” Inferentia2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Stable diffusion ì´ë¯¸ì§€ ìƒì„±ê¸°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Inferentia2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ê¸°ê³„ í•™ìŠµ ì‘ì—…ì„ ìœ„í•œ íŠ¹ìˆ˜ í•˜ë“œì›¨ì–´ ê°€ì†ê¸°ì…ë‹ˆë‹¤. ê¸°ê³„ í•™ìŠµ ì›Œí¬ë¡œë“œì— ëŒ€í•´ GPUë³´ë‹¤ ìµœëŒ€ 20ë°° ë” ë‚˜ì€ ì„±ëŠ¥ê³¼ ìµœëŒ€ 7ë°° ë” ë‚®ì€ ë¹„ìš©ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  íšŒì‚¬ëŠ” ë˜í•œ Ray Serveë¥¼ ì‚¬ìš©í•˜ì—¬ Stable diffusion ì´ë¯¸ì§€ ìƒì„±ê¸°ë¥¼ ìˆ˜í‰ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Ray ServeëŠ” ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì„ ì„œë¹™í•˜ê¸° ìœ„í•œ ë¶„ì‚° í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ìˆ˜ìš”ì— ë”°ë¼ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ í™•ì¥í•˜ê±°ë‚˜ ì¶•ì†Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Stable diffusion ì´ë¯¸ì§€ ìƒì„±ê¸°ë¥¼ í™•ì¥í•˜ê¸° ìœ„í•´ íšŒì‚¬ëŠ” ì—¬ëŸ¬ Inferentia2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°°í¬í•˜ê³  Ray Serveë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ ê°„ì— íŠ¸ë˜í”½ì„ ë¶„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ íšŒì‚¬ëŠ” ë†’ì€ ìš”ì²­ëŸ‰ì„ ì²˜ë¦¬í•˜ê³  ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜ ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#ì†”ë£¨ì…˜-ì•„í‚¤í…ì²˜","content":" ì´ ì„¹ì…˜ì—ì„œëŠ” Amazon EKSì—ì„œ Stable diffusion xl ëª¨ë¸, Ray Serve ë° Inferentia2ë¥¼ ê²°í•©í•œ ì†”ë£¨ì…˜ì˜ ì•„í‚¤í…ì²˜ë¥¼ ìì„¸íˆ ì‚´í´ë´…ë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#ì†”ë£¨ì…˜-ë°°í¬","content":" Amazon EKSì— stable-diffusion-xl-base-1-0ë¥¼ ë°°í¬í•˜ë ¤ë©´ í•„ìš”í•œ ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ì„ ë‹¤ë£¨ê³  ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì¸í”„ë¼ ì„¤ì •, Ray í´ëŸ¬ìŠ¤í„° ë°°í¬ ë° Gradio WebUI ì•± ìƒì„±ì´ í¬í•¨ë©ë‹ˆë‹¤.  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"Stable Diffusion XL ëª¨ë¸ì´ ìˆëŠ” Ray í´ëŸ¬ìŠ¤í„° ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#stable-diffusion-xl-ëª¨ë¸ì´-ìˆëŠ”-ray-í´ëŸ¬ìŠ¤í„°-ë°°í¬","content":" Trainium on EKS í´ëŸ¬ìŠ¤í„°ê°€ ë°°í¬ë˜ë©´ kubectlì„ ì‚¬ìš©í•˜ì—¬ ray-service-stablediffusion.yamlì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ë‹¨ê³„ì—ì„œëŠ” Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§ì„ ì‚¬ìš©í•˜ëŠ” x86 CPU ì¸ìŠ¤í„´ìŠ¤ì˜ Head Pod í•˜ë‚˜ì™€ Karpenterì— ì˜í•´ ì˜¤í† ìŠ¤ì¼€ì¼ë§ë˜ëŠ” Inf2.48xlarge ì¸ìŠ¤í„´ìŠ¤ì˜ Ray ì›Œì»¤ë¡œ êµ¬ì„±ëœ Ray Serve í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•©ë‹ˆë‹¤.  ë°°í¬ë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ì´ ë°°í¬ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì£¼ìš” íŒŒì¼ì„ ìì„¸íˆ ì‚´í´ë³´ê³  ê¸°ëŠ¥ì„ ì´í•´í•´ ë´…ì‹œë‹¤:  ray_serve_stablediffusion.py:ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” FastAPI, Ray Serve ë° Hugging Face Optimum Neuron ë„êµ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ Neuronx model for stable-diffusion-xl-base-1-0-1024x1024 ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  ì´ ì˜ˆì œ ë¸”ë£¨í”„ë¦°íŠ¸ì—ì„œëŠ” AWS Neuronì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì»´íŒŒì¼ëœ ì‚¬ì „ ì»´íŒŒì¼ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì›í•˜ëŠ” stable diffusion ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³  ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê¸° ì „ì— AWS Neuronì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì»´íŒŒì¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ray-service-stablediffusion.yaml:ì´ Ray Serve YAML íŒŒì¼ì€ stable-diffusion-xl-base-1.0 ëª¨ë¸ì„ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìš©ì´í•˜ê²Œ í•˜ëŠ” Ray Serve ì„œë¹„ìŠ¤ë¥¼ ë°°í¬í•˜ê¸° ìœ„í•œ Kubernetes êµ¬ì„± ì—­í• ì„ í•©ë‹ˆë‹¤. ë¦¬ì†ŒìŠ¤ë¥¼ ë¶„ë¦¬í•˜ê¸° ìœ„í•´ stablediffusionì´ë¼ëŠ” Kubernetes ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. êµ¬ì„± ë‚´ì—ì„œ stablediffusion-serviceë¼ëŠ” RayService ì‚¬ì–‘ì´ ìƒì„±ë˜ê³  stablediffusion ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë‚´ì— í˜¸ìŠ¤íŒ…ë©ë‹ˆë‹¤. RayService ì‚¬ì–‘ì€ Ray Serve ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ Python ìŠ¤í¬ë¦½íŠ¸ ray_serve_stablediffusion.py (ê°™ì€ í´ë” ë‚´ì˜ Dockerfileì— ë³µì‚¬ë¨)ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œ ì‚¬ìš©ëœ Docker ì´ë¯¸ì§€ëŠ” ë°°í¬ ìš©ì´ì„±ì„ ìœ„í•´ Amazon Elastic Container Registry (ECR)ì— ê³µê°œì ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” íŠ¹ì • ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ Dockerfileì„ ìˆ˜ì •í•˜ê³  ìì²´ ECR ë¦¬í¬ì§€í† ë¦¬ì— í‘¸ì‹œí•˜ì—¬ YAML íŒŒì¼ì—ì„œ ì°¸ì¡°í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Stable-Diffusion-xl-base-1-0 ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#stable-diffusion-xl-base-1-0-ëª¨ë¸-ë°°í¬","content":" í´ëŸ¬ìŠ¤í„°ê°€ ë¡œì»¬ì—ì„œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸  aws eks --region us-west-2 update-kubeconfig --name trainium-inferentia   RayServe í´ëŸ¬ìŠ¤í„° ë°°í¬  cd ai-on-eks/blueprints/inference/stable-diffusion-xl-base-rayserve-inf2 kubectl apply -f ray-service-stablediffusion.yaml   ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°°í¬ í™•ì¸  ì •ë³´ ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Head PodëŠ” 2~3ë¶„ ë‚´ì— ì¤€ë¹„ë˜ê³ , Ray Serve ì›Œì»¤ PodëŠ” Huggingfaceì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ëª¨ë¸ ë°°í¬ì— ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  $ kubectl get po -n stablediffusion -w NAME READY STATUS RESTARTS AGE service-raycluster-gc7gb-worker-inf2-worker-group-k2kf2 0/1 Init:0/1 0 7s stablediffusion-service-raycluster-gc7gb-head-6fqvv 1/1 Running 0 7s service-raycluster-gc7gb-worker-inf2-worker-group-k2kf2 0/1 PodInitializing 0 9s service-raycluster-gc7gb-worker-inf2-worker-group-k2kf2 1/1 Running 0 10s stablediffusion-service-raycluster-gc7gb-head-6fqvv 1/1 Running 0 53s service-raycluster-gc7gb-worker-inf2-worker-group-k2kf2 1/1 Running 0 53s   ìƒì„±ëœ ì„œë¹„ìŠ¤ ë° ingress ë¦¬ì†ŒìŠ¤ë„ í™•ì¸  kubectl get svc -n stablediffusion NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE stablediffusion-service NodePort 172.20.175.61 &lt;none&gt; 6379:32190/TCP,8265:32375/TCP,10001:32117/TCP,8000:30770/TCP,52365:30334/TCP,8080:30094/TCP 16h stablediffusion-service-head-svc NodePort 172.20.193.225 &lt;none&gt; 6379:32228/TCP,8265:30215/TCP,10001:30767/TCP,8000:31482/TCP,52365:30170/TCP,8080:31584/TCP 16h stablediffusion-service-serve-svc NodePort 172.20.15.224 &lt;none&gt; 8000:30982/TCP 16h $ kubectl get ingress -n stablediffusion NAME CLASS HOSTS ADDRESS PORTS AGE stablediffusion-ingress nginx * k8s-ingressn-ingressn-7f3f4b475b-1b8966c0b8f4d3da.elb.us-west-2.amazonaws.com 80 16h   ì´ì œ ì•„ë˜ì˜ ë¡œë“œ ë°¸ëŸ°ì„œ URLì„ ì‚¬ìš©í•˜ì—¬ Ray ëŒ€ì‹œë³´ë“œì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  http://&lt;NLB_DNS_NAME&gt;/dashboard/#/serve  ê³µê°œ ë¡œë“œ ë°¸ëŸ°ì„œì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ì—†ëŠ” ê²½ìš° í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ê³  ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ localhostë¥¼ ì‚¬ìš©í•˜ì—¬ Ray ëŒ€ì‹œë³´ë“œë¥¼ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl port-forward svc/stablediffusion-service 8265:8265 -n stablediffusion # ë¸Œë¼ìš°ì €ì—ì„œ ë§í¬ ì—´ê¸° http://localhost:8265/   ì´ ì›¹í˜ì´ì§€ì—ì„œ ì•„ë˜ ì´ë¯¸ì§€ì™€ ê°™ì´ ëª¨ë¸ ë°°í¬ ì§„í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:    ","version":"Next","tagName":"h3"},{"title":"Stable Diffusion XL ëª¨ë¸ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#stable-diffusion-xl-ëª¨ë¸-í…ŒìŠ¤íŠ¸","content":" Ray ëŒ€ì‹œë³´ë“œì—ì„œ Stable Diffusion ëª¨ë¸ ë°°í¬ ìƒíƒœê°€ running ìƒíƒœë¡œ ì „í™˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ë©´ ëª¨ë¸ì„ í™œìš©í•  ì¤€ë¹„ê°€ ëœ ê²ƒì…ë‹ˆë‹¤. ì´ ìƒíƒœ ë³€ê²½ì€ Stable Diffusion ëª¨ë¸ì´ ì´ì œ ì™„ì „íˆ ì‘ë™í•˜ë©° í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ì„ ì²˜ë¦¬í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  URL ëì— ì¿¼ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ ë‹¤ìŒ URLì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  http://&lt;NLB_DNS_NAME&gt;/serve/imagine?prompt=an astronaut is dancing on green grass, sunlit  ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:    ","version":"Next","tagName":"h3"},{"title":"Gradio WebUI ì•± ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#gradio-webui-ì•±-ë°°í¬","content":" ë°°í¬ëœ ëª¨ë¸ê³¼ ì›í™œí•˜ê²Œ í†µí•©ë˜ëŠ” ì‚¬ìš©ì ì¹œí™”ì ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ Gradioë¥¼ ì‚¬ìš©í•˜ì—¬ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.  localhostì—ì„œ Docker ì»¨í…Œì´ë„ˆë¡œ ì‹¤í–‰ë˜ëŠ” Gradio ì•±ì„ ì„¤ì •í•˜ëŠ” ê²ƒìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤. ì´ ì„¤ì •ì„ í†µí•´ RayServeë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬ëœ Stable Diffusion XL ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Gradio ì•± Docker ì»¨í…Œì´ë„ˆ ë¹Œë“œâ€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#gradio-ì•±-docker-ì»¨í…Œì´ë„ˆ-ë¹Œë“œ","content":" ë¨¼ì € í´ë¼ì´ì–¸íŠ¸ ì•±ìš© Docker ì»¨í…Œì´ë„ˆë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤.  cd ai-on-eks/blueprints/inference/gradio-ui docker build --platform=linux/amd64 \\ -t gradio-app:sd \\ --build-arg GRADIO_APP=&quot;gradio-app-stable-diffusion.py&quot; \\ .   ","version":"Next","tagName":"h3"},{"title":"Gradio ì»¨í…Œì´ë„ˆ ë°°í¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#gradio-ì»¨í…Œì´ë„ˆ-ë°°í¬","content":" dockerë¥¼ ì‚¬ìš©í•˜ì—¬ localhostì—ì„œ ì»¨í…Œì´ë„ˆë¡œ Gradio ì•±ì„ ë°°í¬í•©ë‹ˆë‹¤:  docker run --rm -it -p 7860:7860 -p 8000:8000 gradio-app:sd   ì •ë³´ ë¨¸ì‹ ì—ì„œ Docker Desktopì„ ì‹¤í–‰í•˜ì§€ ì•Šê³  finchì™€ ê°™ì€ ê²ƒì„ ëŒ€ì‹  ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ ì‚¬ìš©ì ì •ì˜ í˜¸ìŠ¤íŠ¸-IP ë§¤í•‘ì„ ìœ„í•œ ì¶”ê°€ í”Œë˜ê·¸ê°€ í•„ìš”í•©ë‹ˆë‹¤. docker run --rm -it \\ --add-host ray-service:&lt;workstation-ip&gt; \\ -e &quot;SERVICE_NAME=http://ray-service:8000&quot; \\ -p 7860:7860 gradio-app:sd   WebUI í˜¸ì¶œâ€‹  ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  ë‹¤ìŒ URLë¡œ ì´ë™í•˜ì—¬ Gradio WebUIì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤:  ë¡œì»¬ URLì—ì„œ ì‹¤í–‰ ì¤‘: http://localhost:7860  ì´ì œ ë¡œì»¬ ë¨¸ì‹ ì—ì„œ Gradio ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"ê²°ë¡ â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#ê²°ë¡ ","content":" ê²°ë¡ ì ìœ¼ë¡œ, Stable-diffusion-xl-base ëª¨ë¸ì„ Ray Serveì™€ í•¨ê»˜ EKSì— ì„±ê³µì ìœ¼ë¡œ ë°°í¬í•˜ê³  Gradioë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì›¹ UIë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ìì—°ì–´ ì²˜ë¦¬ ë° í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„±ê¸° ë° ì´ë¯¸ì§€ ì˜ˆì¸¡ê¸° ê°œë°œì— í¥ë¯¸ë¡œìš´ ê°€ëŠ¥ì„±ì„ ì—´ì–´ì¤ë‹ˆë‹¤.  ìš”ì•½í•˜ë©´, Stable diffusion ëª¨ë¸ì„ ë°°í¬í•˜ê³  í™•ì¥í•  ë•Œ AWS Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ë§¤ë ¥ì ì¸ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤. GPU ë¶€ì¡±ê³¼ ê´€ë ¨ëœ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ë©´ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ì´ê³  ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ ì‹¤í–‰í•˜ëŠ” ë° í•„ìš”í•œ í™•ì¥ì„±, ë¹„ìš© ìµœì í™” ë° ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ê¸°, ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìƒì„±ê¸° ë˜ëŠ” ê¸°íƒ€ LLM ê¸°ë°˜ ì†”ë£¨ì…˜ì„ êµ¬ì¶•í•˜ë“  Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ AWS í´ë¼ìš°ë“œì—ì„œ Stable Diffusion LLMì˜ ì ì¬ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Inferentia, Ray Serve ë° Gradioë¥¼ ì‚¬ìš©í•œ Stable Diffusion XL Base ëª¨ë¸ ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/stablediffusion-inf2#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  1ë‹¨ê³„: Gradio ì»¨í…Œì´ë„ˆ ì‚­ì œ  Gradio ì•±ì„ ì‹¤í–‰í•˜ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ docker runì´ ì‹¤í–‰ ì¤‘ì¸ localhost í„°ë¯¸ë„ ì°½ì—ì„œ Ctrl-cë¥¼ ëˆ„ë¦…ë‹ˆë‹¤. ì„ íƒì ìœ¼ë¡œ Docker ì´ë¯¸ì§€ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤  docker rmi gradio-app:sd   2ë‹¨ê³„: Ray í´ëŸ¬ìŠ¤í„° ì‚­ì œ  cd ai-on-eks/blueprints/inference/stable-diffusion-xl-base-rayserve-inf2 kubectl delete -f ray-service-stablediffusion.yaml   3ë‹¨ê³„: EKS í´ëŸ¬ìŠ¤í„° ì •ë¦¬ ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” -target ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ë¦¬ì†ŒìŠ¤ê°€ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì‚­ì œë˜ë„ë¡ í™˜ê²½ì„ ì •ë¦¬í•©ë‹ˆë‹¤.  cd ai-on-eks/infra/trainium-inferentia/ ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"EKSì—ì„œì˜ Slurm","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/training/GPUs/slinky-slurm","content":"","keywords":"","version":"Next"},{"title":"Slurmì´ë€?â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ Slurm","url":"/ai-on-eks/ko/docs/blueprints/training/GPUs/slinky-slurm#slurmì´ë€","content":" Slurmì€ ëª¨ë“  ê·œëª¨ì˜ ì»´í“¨íŠ¸ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì˜¤í”ˆì†ŒìŠ¤ì˜ ê³ ë„ë¡œ í™•ì¥ ê°€ëŠ¥í•œ ì›Œí¬ë¡œë“œ ê´€ë¦¬ì ë° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬ì…ë‹ˆë‹¤. ì„¸ ê°€ì§€ í•µì‹¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤: ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì ‘ê·¼ í• ë‹¹, ë³‘ë ¬ ì»´í“¨íŒ… ì‘ì—…ì„ ì‹œì‘í•˜ê³  ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ ì œê³µ, ë¦¬ì†ŒìŠ¤ ê²½í•©ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…ì˜ í ê´€ë¦¬.  Slurmì€ AI í›ˆë ¨ì—ì„œ ê³ ì„±ëŠ¥ ì»´í“¨íŒ… í´ëŸ¬ìŠ¤í„° ì „ì²´ì— ê±¸ì³ ëŒ€ê·œëª¨ GPU ê°€ì† ì›Œí¬ë¡œë“œë¥¼ ê´€ë¦¬í•˜ê³  ìŠ¤ì¼€ì¤„ë§í•˜ëŠ” ë° ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤. ì—°êµ¬ìì™€ ì—”ì§€ë‹ˆì–´ê°€ CPU, GPU, ë©”ëª¨ë¦¬ë¥¼ í¬í•¨í•œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í• ë‹¹í•  ìˆ˜ ìˆê²Œ í•˜ë©°, ë¦¬ì†ŒìŠ¤ ìœ í˜•ê³¼ ì‘ì—… ìš°ì„ ìˆœìœ„ì— ëŒ€í•œ ì„¸ë°€í•œ ì œì–´ë¡œ ì—¬ëŸ¬ ë…¸ë“œì— ê±¸ì³ ë”¥ëŸ¬ë‹ ëª¨ë¸ê³¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ë¶„ì‚° í›ˆë ¨ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. Slurmì˜ ì•ˆì •ì„±, ê³ ê¸‰ ìŠ¤ì¼€ì¤„ë§ ê¸°ëŠ¥, ì˜¨í”„ë ˆë¯¸ìŠ¤ ë° í´ë¼ìš°ë“œ í™˜ê²½ê³¼ì˜ í†µí•©ì€ í˜„ëŒ€ AI ì—°êµ¬ ë° ì‚°ì—…ì´ ìš”êµ¬í•˜ëŠ” ê·œëª¨, ì²˜ë¦¬ëŸ‰, ì¬í˜„ì„±ì„ ì²˜ë¦¬í•˜ëŠ” ë° ì„ í˜¸ë˜ëŠ” ì„ íƒì´ ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Slinky í”„ë¡œì íŠ¸ë€?â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ Slurm","url":"/ai-on-eks/ko/docs/blueprints/training/GPUs/slinky-slurm#slinky-í”„ë¡œì íŠ¸ë€","content":" Slinky í”„ë¡œì íŠ¸ëŠ” Slurmì˜ ì£¼ìš” ê°œë°œì‚¬ì¸ SchedMDê°€ ì„¤ê³„í•œ ì˜¤í”ˆì†ŒìŠ¤ í†µí•© ë„êµ¬ ëª¨ìŒìœ¼ë¡œ, Slurm ê¸°ëŠ¥ì„ Kubernetesì— ë„ì…í•˜ì—¬ íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì™€ ìŠ¤ì¼€ì¤„ë§ì„ ìœ„í•œ ë‘ ì„¸ê³„ì˜ ì¥ì ì„ ê²°í•©í•©ë‹ˆë‹¤. Slinky í”„ë¡œì íŠ¸ì—ëŠ” Slurm í´ëŸ¬ìŠ¤í„°ìš© Kubernetes ì˜¤í¼ë ˆì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, Kubernetes í™˜ê²½ ë‚´ì—ì„œ ë°°í¬ëœ Slurm Cluster ë° NodeSet ë¦¬ì†ŒìŠ¤ì˜ ìˆ˜ëª… ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì»¤ìŠ¤í…€ ì»¨íŠ¸ë¡¤ëŸ¬ì™€ ì»¤ìŠ¤í…€ ë¦¬ì†ŒìŠ¤ ì •ì˜(CRD)ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.  ì´ Slurm í´ëŸ¬ìŠ¤í„°ì—ëŠ” ë‹¤ìŒ êµ¬ì„± ìš”ì†Œê°€ í¬í•¨ë©ë‹ˆë‹¤:  êµ¬ì„± ìš”ì†Œ\tì„¤ëª…Controller (slurmctld)\të¦¬ì†ŒìŠ¤ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³ , ì‘ì—…ì„ ìˆ˜ë½í•˜ë©°, ì»´í“¨íŠ¸ ë…¸ë“œì— ì‘ì—…ì„ í• ë‹¹í•˜ëŠ” ì¤‘ì•™ ê´€ë¦¬ ë°ëª¬ì…ë‹ˆë‹¤. Accounting (slurmdbd)\tMariaDB ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—”ë“œë¥¼ í†µí•´ ì‘ì—… íšŒê³„ ë° ì‚¬ìš©ì/í”„ë¡œì íŠ¸ ê´€ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. Compute (slurmd)\tì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ì›Œì»¤ ë…¸ë“œë¡œ, ë‹¤ë¥¸ íŒŒí‹°ì…˜ìœ¼ë¡œ ê·¸ë£¹í™”í•  ìˆ˜ ìˆëŠ” NodeSetìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. Login\tì‚¬ìš©ìê°€ Slurm í´ëŸ¬ìŠ¤í„°ì™€ ìƒí˜¸ ì‘ìš©í•˜ê³  ì‘ì—…ì„ ì œì¶œí•  ìˆ˜ ìˆë„ë¡ SSH ì ‘ê·¼ ì§€ì ì„ ì œê³µí•©ë‹ˆë‹¤. REST API (slurmrestd)\tí´ëŸ¬ìŠ¤í„°ì™€ì˜ í”„ë¡œê·¸ë˜ë° ë°©ì‹ ìƒí˜¸ ì‘ìš©ì„ ìœ„í•´ Slurm ê¸°ëŠ¥ì— ëŒ€í•œ HTTP ê¸°ë°˜ API ì ‘ê·¼ì„ ì œê³µí•©ë‹ˆë‹¤. Authentication (sackd)\tSlurm ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì•ˆì „í•œ ì ‘ê·¼ì„ ìœ„í•œ ìê²© ì¦ëª… ì¸ì¦ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. MariaDB\tì‘ì—…, ì‚¬ìš©ì ë° í”„ë¡œì íŠ¸ ì •ë³´ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ accounting ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—”ë“œì…ë‹ˆë‹¤. Prometheus Service Monitor\tëª¨ë‹ˆí„°ë§ ëª©ì ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ëŸ¬, íŒŒí‹°ì…˜, ë…¸ë“œ ë° ì‘ì—… ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ë„ë¡ ì»¨íŠ¸ë¡¤ëŸ¬ ë‚´ì— êµ¬ì„±ë©ë‹ˆë‹¤.  Amazon EKSì™€ ê²°í•©í•˜ë©´ Slinky í”„ë¡œì íŠ¸ëŠ” Kubernetesì—ì„œ ì¸í”„ë¼ ê´€ë¦¬ë¥¼ í‘œì¤€í™”í•œ ê¸°ì—…ì´ ML ê³¼í•™ìë“¤ì—ê²Œ Slurm ê¸°ë°˜ ê²½í—˜ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ë˜í•œ ë™ì¼í•œ ê°€ì† ë…¸ë“œ í´ëŸ¬ìŠ¤í„°ì—ì„œ í›ˆë ¨, ì‹¤í—˜ ë° ì¶”ë¡ ì´ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"EKSì—ì„œì˜ Slurm ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ Slurm","url":"/ai-on-eks/ko/docs/blueprints/training/GPUs/slinky-slurm#eksì—ì„œì˜-slurm-ì•„í‚¤í…ì²˜","content":"   ìœ„ ë‹¤ì´ì–´ê·¸ë¨ì€ ì´ ê°€ì´ë“œì— ì„¤ëª…ëœ EKSì—ì„œì˜ Slurm ë°°í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. Amazon EKS í´ëŸ¬ìŠ¤í„°ê°€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´ ì—­í• ì„ í•˜ë©°, í•µì‹¬ Slurm Cluster êµ¬ì„± ìš”ì†ŒëŠ” m6i.xlarge ì¸ìŠ¤í„´ìŠ¤ì˜ ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì—ì„œ í˜¸ìŠ¤íŒ…ë˜ê³ , Karpenter NodePoolì€ slurmd íŒŒë“œê°€ ì‹¤í–‰ë  GPU ê°€ì† ì»´í“¨íŠ¸ ë…¸ë“œì˜ ë°°í¬ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤. Slinky Slurm ì˜¤í¼ë ˆì´í„°ì™€ Slurm í´ëŸ¬ìŠ¤í„°ëŠ” ArgoCD ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ìë™ ë°°í¬ë©ë‹ˆë‹¤.  ë¡œê·¸ì¸ LoadBalancer íƒ€ì… ì„œë¹„ìŠ¤ëŠ” AWS Load Balancer Controllerë¥¼ ì‚¬ìš©í•˜ì—¬ AWS Network Load Balancerë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ë„ë¡ ì–´ë…¸í…Œì´ì…˜ë˜ì–´ ìˆì–´, ML ê³¼í•™ìë“¤ì´ kubectlì„ í†µí•´ Kubernetes API ì„œë²„ì™€ ì¸í„°í˜ì´ìŠ¤í•˜ì§€ ì•Šê³ ë„ ë¡œê·¸ì¸ íŒŒë“œì— SSHë¡œ ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë¡œê·¸ì¸ ë° slurmd íŒŒë“œì—ëŠ” Amazon FSx for Lustre ê³µìœ  íŒŒì¼ ì‹œìŠ¤í…œë„ ë§ˆìš´íŠ¸ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì»¨í…Œì´ë„ˆí™”ëœ slurmd íŒŒë“œë¥¼ ì‚¬ìš©í•˜ë©´ ì „í†µì ìœ¼ë¡œ Condaë‚˜ Python ê°€ìƒ í™˜ê²½ì„ ì‚¬ìš©í•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í–ˆë˜ ë§ì€ ì¢…ì†ì„±ì„ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì— í¬í•¨í•  ìˆ˜ ìˆì§€ë§Œ, ê³µìœ  íŒŒì¼ ì‹œìŠ¤í…œì€ í›ˆë ¨ ì•„í‹°íŒ©íŠ¸, ë°ì´í„°, ë¡œê·¸ ë° ì²´í¬í¬ì¸íŠ¸ ì €ì¥ì— ì—¬ì „íˆ ìœ ìš©í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” ê¸°ëŠ¥ ë° ì´ì â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ Slurm","url":"/ai-on-eks/ko/docs/blueprints/training/GPUs/slinky-slurm#ì£¼ìš”-ê¸°ëŠ¥-ë°-ì´ì ","content":" ë™ì¼í•œ ì¸í”„ë¼ì—ì„œ Slurm ì›Œí¬ë¡œë“œì™€ ì»¨í…Œì´ë„ˆí™”ëœ Kubernetes ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë‚˜ë€íˆ ì‹¤í–‰í•©ë‹ˆë‹¤. Slurmê³¼ Kubernetes ì›Œí¬ë¡œë“œ ëª¨ë‘ ë™ì¼í•œ ë…¸ë“œ í’€ì—ì„œ ìŠ¤ì¼€ì¤„ë§ë˜ì–´ í™œìš©ë„ë¥¼ ë†’ì´ê³  ë¦¬ì†ŒìŠ¤ ë‹¨í¸í™”ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.ì–‘ìª½ ì—ì½”ì‹œìŠ¤í…œì˜ ìµìˆ™í•œ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ Slurm ì‘ì—…ê³¼ Kubernetes íŒŒë“œë¥¼ ì›í™œí•˜ê²Œ ê´€ë¦¬í•˜ë©´ì„œ ì œì–´ë‚˜ ì„±ëŠ¥ì„ í¬ìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.ì›Œí¬ë¡œë“œ ìˆ˜ìš”ì— ë”°ë¼ ì»´í“¨íŠ¸ ë…¸ë“œë¥¼ ë™ì ìœ¼ë¡œ ì¶”ê°€í•˜ê±°ë‚˜ ì œê±°í•˜ì—¬ í• ë‹¹ëœ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìë™ ìŠ¤ì¼€ì¼ë§í•˜ê³ , ìˆ˜ìš”ì˜ ê¸‰ì¦ê³¼ ê°ì†Œë¥¼ ì²˜ë¦¬í•˜ì—¬ ì¸í”„ë¼ ë¹„ìš©ê³¼ ìœ íœ´ ë¦¬ì†ŒìŠ¤ ë‚­ë¹„ë¥¼ ì¤„ì…ë‹ˆë‹¤.Kubernetes ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ í†µí•œ ê³ ê°€ìš©ì„±. ì»¨íŠ¸ë¡¤ëŸ¬ë‚˜ ì›Œì»¤ íŒŒë“œê°€ ì‹¤íŒ¨í•˜ë©´ Kubernetesê°€ ìë™ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì‘í•˜ì—¬ ìˆ˜ë™ ê°œì…ì„ ì¤„ì…ë‹ˆë‹¤.Slurmì˜ ì •êµí•œ ìŠ¤ì¼€ì¤„ë§ ê¸°ëŠ¥(ê³µì • ê³µìœ  í• ë‹¹, ì¢…ì†ì„± ê´€ë¦¬, ìš°ì„ ìˆœìœ„ ìŠ¤ì¼€ì¤„ë§)ì´ Kubernetesì— í†µí•©ë˜ì–´ ì»´í“¨íŠ¸ í™œìš©ë¥ ì„ ê·¹ëŒ€í™”í•˜ê³  ì›Œí¬ë¡œë“œ ìš”êµ¬ì‚¬í•­ì— ë§ì¶° ë¦¬ì†ŒìŠ¤ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.Slurmê³¼ ê·¸ ì¢…ì†ì„±ì´ ì»¨í…Œì´ë„ˆë¡œ ë°°í¬ë˜ì–´ í™˜ê²½ ì „ë°˜ì— ê±¸ì³ ì¼ê´€ëœ ë°°í¬ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. ì´ëŠ” êµ¬ì„± ë“œë¦¬í”„íŠ¸ë¥¼ ì¤„ì´ê³  ê°œë°œì—ì„œ í”„ë¡œë•ì…˜ìœ¼ë¡œì˜ ì „í™˜ì„ ê°„ì†Œí™”í•©ë‹ˆë‹¤.ì‚¬ìš©ìëŠ” íŠ¹ìˆ˜í•œ ìš”êµ¬ì‚¬í•­(ì˜ˆ: ì»¤ìŠ¤í…€ ì¢…ì†ì„±, ë¼ì´ë¸ŒëŸ¬ë¦¬)ì— ë§ì¶¤í™”ëœ Slurm ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ì—¬ ê³¼í•™ì  ë˜ëŠ” ê·œì œ í™˜ê²½ì—ì„œ ì¼ê´€ì„±ê³¼ ì¬í˜„ì„±ì„ ì´‰ì§„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.ê´€ë¦¬ìëŠ” Kubernetes Custom Resourcesë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¤ìŠ¤í…€ Slurm í´ëŸ¬ìŠ¤í„°ì™€ ë…¸ë“œ ì„¸íŠ¸ë¥¼ ì§ì ‘ ì •ì˜í•  ìˆ˜ ìˆìœ¼ë©°, ë‹¤ë¥¸ ìœ í˜•ì˜ ì‘ì—…(ì˜ˆ: ì•ˆì •ì  vs ê¸°íšŒì£¼ì˜ì /ë°±í•„ íŒŒí‹°ì…˜)ì„ ìœ„í•´ ì»´í“¨íŠ¸ ë…¸ë“œë¥¼ íŒŒí‹°ì…”ë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.SlinkyëŠ” Slurmê³¼ Kubernetes ëª¨ë‘ë¥¼ ìœ„í•œ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒê³¼ í†µí•©ë˜ì–´ ê´€ë¦¬ìì™€ ì‚¬ìš©ìì—ê²Œ ê°•ë ¥í•œ ë©”íŠ¸ë¦­ê³¼ ì‹œê°í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ì†”ë£¨ì…˜ ë°°í¬ ğŸ‘ˆ  ë°°í¬ í™•ì¸ ğŸ‘ˆ  FSDP ì˜ˆì œ ì‹¤í–‰ ğŸ‘ˆ  CloudWatch Container Insights ğŸ‘ˆ  ì •ë¦¬ ğŸ‘ˆ ","version":"Next","tagName":"h3"},{"title":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2","content":"","keywords":"","version":"Next"},{"title":"AWS Neuronì´ë€?â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#aws-neuronì´ë€","content":" ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” AWS Inferentia ë° Trainium ê°€ì†ê¸°ì—ì„œ ë”¥ëŸ¬ë‹ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ê°•ë ¥í•œ SDKì¸ AWS Neuronì„ í™œìš©í•©ë‹ˆë‹¤. Neuronì€ PyTorch ë° TensorFlowì™€ ê°™ì€ í”„ë ˆì„ì›Œí¬ì™€ ì›í™œí•˜ê²Œ í†µí•©ë˜ì–´ Inf1, Inf2, Trn1 ë° Trn1nê³¼ ê°™ì€ íŠ¹ìˆ˜ EC2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ê³ ì„±ëŠ¥ ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì„ ê°œë°œ, í”„ë¡œíŒŒì¼ë§ ë° ë°°í¬í•˜ê¸° ìœ„í•œ í¬ê´„ì ì¸ íˆ´í‚·ì„ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"vLLMì´ë€?â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#vllmì´ë€","content":" vLLMì€ ì²˜ë¦¬ëŸ‰ì„ ê·¹ëŒ€í™”í•˜ê³  ì§€ì—° ì‹œê°„ì„ ìµœì†Œí™”í•˜ë„ë¡ ì„¤ê³„ëœ LLM ì¶”ë¡  ë° ì„œë¹™ì„ ìœ„í•œ ê³ ì„±ëŠ¥ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. í•µì‹¬ì ìœ¼ë¡œ vLLMì€ GPU ë¦¬ì†ŒìŠ¤ì˜ ìµœì  í™œìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ í¬ê²Œ ê°œì„ í•˜ëŠ” í˜ì‹ ì ì¸ ì–´í…ì…˜ ì•Œê³ ë¦¬ì¦˜ì¸ PagedAttentionì„ í™œìš©í•©ë‹ˆë‹¤. ì´ ì˜¤í”ˆ ì†ŒìŠ¤ ì†”ë£¨ì…˜ì€ Python API ë° OpenAI í˜¸í™˜ ì„œë²„ë¥¼ í†µí•œ ì›í™œí•œ í†µí•©ì„ ì œê³µí•˜ì—¬ ê°œë°œìê°€ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ Llama 3ì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì „ë¡€ ì—†ëŠ” íš¨ìœ¨ì„±ìœ¼ë¡œ ë°°í¬í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"RayServeë€?â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#rayserveë€","content":" Ray ServeëŠ” Ray ìœ„ì— êµ¬ì¶•ëœ í™•ì¥ ê°€ëŠ¥í•œ ëª¨ë¸ ì„œë¹™ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, í”„ë ˆì„ì›Œí¬ ë¶ˆê°€ì§€ë¡ ì  ë°°í¬, ëª¨ë¸ êµ¬ì„± ë° ë‚´ì¥ í™•ì¥ê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ê°–ì¶˜ ê¸°ê³„ í•™ìŠµ ëª¨ë¸ ë° AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë°°í¬í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. KubeRay í”„ë¡œì íŠ¸ì˜ ì¼ë¶€ì¸ Kubernetes ì‚¬ìš©ì ì •ì˜ ë¦¬ì†ŒìŠ¤ì¸ RayServiceë„ ì ‘í•˜ê²Œ ë˜ë©°, ì´ëŠ” Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ Ray Serve ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë°°í¬í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Llama-3-8B Instructë€?â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#llama-3-8b-instructë€","content":" MetaëŠ” 8B ë° 70B í¬ê¸°ì˜ ì‚¬ì „ í›ˆë ¨ ë° ëª…ë ¹ì–´ ì¡°ì • ìƒì„± í…ìŠ¤íŠ¸ ëª¨ë¸ ì»¬ë ‰ì…˜ì¸ Meta Llama 3 ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ì œí’ˆêµ°ì„ ê°œë°œí•˜ê³  ì¶œì‹œí–ˆìŠµë‹ˆë‹¤. Llama 3 ëª…ë ¹ì–´ ì¡°ì • ëª¨ë¸ì€ ëŒ€í™” ì‚¬ìš© ì‚¬ë¡€ì— ìµœì í™”ë˜ì–´ ìˆìœ¼ë©° ì¼ë°˜ì ì¸ ì—…ê³„ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë§ì€ ì˜¤í”ˆ ì†ŒìŠ¤ ì±„íŒ… ëª¨ë¸ì„ ëŠ¥ê°€í•©ë‹ˆë‹¤. ë˜í•œ ì´ëŸ¬í•œ ëª¨ë¸ì„ ê°œë°œí•  ë•Œ ìœ ìš©ì„±ê³¼ ì•ˆì „ì„±ì„ ìµœì í™”í•˜ëŠ” ë° ì„¸ì‹¬í•œ ì£¼ì˜ë¥¼ ê¸°ìš¸ì˜€ìŠµë‹ˆë‹¤.  Llama3 í¬ê¸° ë° ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ëŠ” ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì™œ AWS ê°€ì†ê¸°ì¸ê°€?â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#ì™œ-aws-ê°€ì†ê¸°ì¸ê°€","content":" í™•ì¥ì„± ë° ê°€ìš©ì„±  Llama-3ì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ë°°í¬í•  ë•Œ ì£¼ìš” ê³¼ì œ ì¤‘ í•˜ë‚˜ëŠ” ì ì ˆí•œ í•˜ë“œì›¨ì–´ì˜ í™•ì¥ì„±ê³¼ ê°€ìš©ì„±ì…ë‹ˆë‹¤. ê¸°ì¡´ GPU ì¸ìŠ¤í„´ìŠ¤ëŠ” ë†’ì€ ìˆ˜ìš”ë¡œ ì¸í•´ ë¶€ì¡±í•œ ê²½ìš°ê°€ ë§ì•„ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í•˜ê³  í™•ì¥í•˜ê¸°ê°€ ì–´ë µìŠµë‹ˆë‹¤.  ë°˜ë©´ trn1.32xlarge, trn1n.32xlarge, inf2.24xlarge ë° inf2.48xlargeì™€ ê°™ì€ Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” LLMì„ í¬í•¨í•œ ìƒì„±í˜• AI ëª¨ë¸ì˜ ê³ ì„±ëŠ¥ ë”¥ëŸ¬ë‹(DL) í›ˆë ¨ ë° ì¶”ë¡ ì„ ìœ„í•´ íŠ¹ë³„íˆ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤. í™•ì¥ì„±ê³¼ ê°€ìš©ì„±ì„ ëª¨ë‘ ì œê³µí•˜ì—¬ ë¦¬ì†ŒìŠ¤ ë³‘ëª© í˜„ìƒì´ë‚˜ ì§€ì—° ì—†ì´ í•„ìš”ì— ë”°ë¼ Llama-3 ëª¨ë¸ì„ ë°°í¬í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë¹„ìš© ìµœì í™”  ê¸°ì¡´ GPU ì¸ìŠ¤í„´ìŠ¤ì—ì„œ LLMì„ ì‹¤í–‰í•˜ë©´ GPUì˜ ë¶€ì¡±ê³¼ ê²½ìŸì ì¸ ê°€ê²©ìœ¼ë¡œ ì¸í•´ ë¹„ìš©ì´ ë§ì´ ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ë¹„ìš© íš¨ìœ¨ì ì¸ ëŒ€ì•ˆì„ ì œê³µí•©ë‹ˆë‹¤. AI ë° ê¸°ê³„ í•™ìŠµ ì‘ì—…ì— ìµœì í™”ëœ ì „ìš© í•˜ë“œì›¨ì–´ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ ë¹„ìš©ì˜ ì¼ë¶€ë¡œ ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¹„ìš© ìµœì í™”ë¥¼ í†µí•´ ì˜ˆì‚°ì„ íš¨ìœ¨ì ìœ¼ë¡œ í• ë‹¹í•˜ì—¬ LLM ë°°í¬ë¥¼ ì ‘ê·¼ ê°€ëŠ¥í•˜ê³  ì§€ì† ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì„±ëŠ¥ í–¥ìƒ  Llama-3ëŠ” GPUì—ì„œ ê³ ì„±ëŠ¥ ì¶”ë¡ ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì§€ë§Œ, Neuron ê°€ì†ê¸°ëŠ” ì„±ëŠ¥ì„ í•œ ë‹¨ê³„ ë” ëŒì–´ì˜¬ë¦½ë‹ˆë‹¤. Neuron ê°€ì†ê¸°ëŠ” ê¸°ê³„ í•™ìŠµ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•´ íŠ¹ë³„íˆ êµ¬ì¶•ë˜ì–´ Llama-3ì˜ ì¶”ë¡  ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” í•˜ë“œì›¨ì–´ ê°€ì†ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ì— Llama-3ë¥¼ ë°°í¬í•  ë•Œ ë” ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ê³¼ ê°œì„ ëœ ì‚¬ìš©ì ê²½í—˜ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜ ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#ì†”ë£¨ì…˜-ì•„í‚¤í…ì²˜","content":" ì´ ì„¹ì…˜ì—ì„œëŠ” Amazon EKSì—ì„œ Llama-3 ëª¨ë¸, Ray Serve ë° Inferentia2ë¥¼ ê²°í•©í•œ ì†”ë£¨ì…˜ì˜ ì•„í‚¤í…ì²˜ë¥¼ ìì„¸íˆ ì‚´í´ë´…ë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#ì†”ë£¨ì…˜-ë°°í¬","content":" Amazon EKSì— Llama-3-8B-instructë¥¼ ë°°í¬í•˜ë ¤ë©´ í•„ìš”í•œ ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ì„ ë‹¤ë£¨ê³  ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.  ì—¬ê¸°ì—ëŠ” AWS Inferentia ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•œ ì¸í”„ë¼ ì„¤ì • ë° Ray í´ëŸ¬ìŠ¤í„° ë°°í¬ê°€ í¬í•¨ë©ë‹ˆë‹¤.  ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"Llama3 ëª¨ë¸ì´ ìˆëŠ” Ray í´ëŸ¬ìŠ¤í„° ë°°í¬â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#llama3-ëª¨ë¸ì´-ìˆëŠ”-ray-í´ëŸ¬ìŠ¤í„°-ë°°í¬","content":" ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” RayCluster, RayJob ë° RayServiceì™€ ê°™ì€ Ray íŠ¹ì • êµ¬ì„±ì— ëŒ€í•œ ì‚¬ìš©ì ì •ì˜ ë¦¬ì†ŒìŠ¤ ì •ì˜ë¡œ Kubernetesë¥¼ í™•ì¥í•˜ëŠ” KubeRay operatorë¥¼ í™œìš©í•©ë‹ˆë‹¤. operatorëŠ” ì´ëŸ¬í•œ ë¦¬ì†ŒìŠ¤ì™€ ê´€ë ¨ëœ ì‚¬ìš©ì ì´ë²¤íŠ¸ë¥¼ ê°ì‹œí•˜ê³ , Ray í´ëŸ¬ìŠ¤í„°ë¥¼ í˜•ì„±í•˜ëŠ” ë° í•„ìš”í•œ Kubernetes ì•„í‹°íŒ©íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ë©°, ì›í•˜ëŠ” êµ¬ì„±ì´ ì‹¤ì œ ìƒíƒœì™€ ì¼ì¹˜í•˜ë„ë¡ í´ëŸ¬ìŠ¤í„° ìƒíƒœë¥¼ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤. ì„¤ì •, ì›Œì»¤ ê·¸ë£¹ì˜ ë™ì  í™•ì¥ ë° í•´ì œë¥¼ í¬í•¨í•œ ìˆ˜ëª… ì£¼ê¸° ê´€ë¦¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ Kubernetesì—ì„œ Ray ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê´€ë¦¬í•˜ëŠ” ë³µì¡ì„±ì„ ì¶”ìƒí™”í•©ë‹ˆë‹¤.  ê° Ray í´ëŸ¬ìŠ¤í„°ëŠ” í—¤ë“œ ë…¸ë“œ podì™€ ì›Œì»¤ ë…¸ë“œ pod ëª¨ìŒìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ì›Œí¬ë¡œë“œ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ í´ëŸ¬ìŠ¤í„° í¬ê¸°ë¥¼ ì¡°ì •í•˜ëŠ” ì„ íƒì  ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì§€ì›ì´ ìˆìŠµë‹ˆë‹¤. KubeRayëŠ” ì´ê¸°ì¢… ì»´í“¨íŒ… ë…¸ë“œ(GPU í¬í•¨) ë° ë™ì¼í•œ Kubernetes í´ëŸ¬ìŠ¤í„°ì—ì„œ ë‹¤ë¥¸ Ray ë²„ì „ìœ¼ë¡œ ì—¬ëŸ¬ Ray í´ëŸ¬ìŠ¤í„° ì‹¤í–‰ì„ ì§€ì›í•©ë‹ˆë‹¤. ë˜í•œ KubeRayëŠ” AWS Inferentia ê°€ì†ê¸°ì™€ í†µí•©ë˜ì–´ íŠ¹ìˆ˜ í•˜ë“œì›¨ì–´ì—ì„œ Llama 3ì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë°°í¬í•˜ì—¬ ê¸°ê³„ í•™ìŠµ ì¶”ë¡  ì‘ì—…ì˜ ì„±ëŠ¥ê³¼ ë¹„ìš© íš¨ìœ¨ì„±ì„ ì ì¬ì ìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  í•„ìš”í•œ ëª¨ë“  êµ¬ì„± ìš”ì†Œì™€ í•¨ê»˜ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í–ˆìœ¼ë¯€ë¡œ ì´ì œ AWS ê°€ì†ê¸°ì—ì„œ RayServe ë° vLLMì„ ì‚¬ìš©í•˜ì—¬ NousResearch/Meta-Llama-3-8B-Instructë¥¼ ë°°í¬í•˜ëŠ” ë‹¨ê³„ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  1ë‹¨ê³„: RayService í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•˜ë ¤ë©´ vllm-rayserve-deployment.yaml íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ê³  í„°ë¯¸ë„ì—ì„œ kubectl apply ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ RayService êµ¬ì„±ì´ ì ìš©ë˜ê³  EKS ì„¤ì •ì— í´ëŸ¬ìŠ¤í„°ê°€ ë°°í¬ë©ë‹ˆë‹¤.  cd ai-on-eks/blueprints/inference/vllm-rayserve-inf2 kubectl apply -f vllm-rayserve-deployment.yaml   ì„ íƒì  êµ¬ì„±  ê¸°ë³¸ì ìœ¼ë¡œ inf2.8xlarge ì¸ìŠ¤í„´ìŠ¤ê°€ í”„ë¡œë¹„ì €ë‹ë©ë‹ˆë‹¤. inf2.48xlargeë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ vllm-rayserve-deployment.yaml íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ worker ì»¨í…Œì´ë„ˆ ì•„ë˜ì˜ resources ì„¹ì…˜ì„ ë³€ê²½í•©ë‹ˆë‹¤.  limits: cpu: &quot;30&quot; memory: &quot;110G&quot; aws.amazon.com/neuron: &quot;1&quot; requests: cpu: &quot;30&quot; memory: &quot;110G&quot; aws.amazon.com/neuron: &quot;1&quot;   ë‹¤ìŒìœ¼ë¡œ ë³€ê²½:  limits: cpu: &quot;90&quot; memory: &quot;360G&quot; aws.amazon.com/neuron: &quot;12&quot; requests: cpu: &quot;90&quot; memory: &quot;360G&quot; aws.amazon.com/neuron: &quot;12&quot;   ì„ íƒ ì‚¬í•­: 70B ëª¨ë¸ ë°°í¬inf2.48xlargeì—ì„œ llama-70B ëª¨ë¸ì„ ë°°í¬í•˜ë ¤ë©´ ai-on-eks/blueprints/inference/vllm-rayserve-inf2/vllm-rayserve-deployment-70B.yamlì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤. ì´ ë°°í¬ëŠ” ëŒ€í˜• ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  Neuron ì½”ì–´ì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ì»´íŒŒì¼í•˜ëŠ” ë° ì•½ 60ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤.  2ë‹¨ê³„: ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°°í¬ í™•ì¸  ë°°í¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  ì •ë³´ ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Head PodëŠ” 5~6ë¶„ ë‚´ì— ì¤€ë¹„ë˜ê³ , Ray Serve ì›Œì»¤ PodëŠ” Huggingfaceì—ì„œ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ëª¨ë¸ ë°°í¬ì— ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  RayServe êµ¬ì„±ì— ë”°ë¼ x86 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” Ray head pod í•˜ë‚˜ì™€ inf2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” ì›Œì»¤ pod í•˜ë‚˜ê°€ ìˆìŠµë‹ˆë‹¤. RayServe YAML íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ ì—¬ëŸ¬ ë ˆí”Œë¦¬ì¹´ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê° ì¶”ê°€ ë ˆí”Œë¦¬ì¹´ëŠ” ì ì¬ì ìœ¼ë¡œ ìƒˆ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŒì— ìœ ì˜í•˜ì‹­ì‹œì˜¤.  kubectl get pods -n vllm   NAME READY STATUS RESTARTS AGE lm-llama3-inf2-raycluster-ksh7w-worker-inf2-group-dcs5n 1/1 Running 0 2d4h vllm-llama3-inf2-raycluster-ksh7w-head-4ck8f 2/2 Running 0 2d4h   ì´ ë°°í¬ëŠ” ë˜í•œ ì—¬ëŸ¬ í¬íŠ¸ê°€ êµ¬ì„±ëœ ì„œë¹„ìŠ¤ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤. í¬íŠ¸ 8265ëŠ” Ray ëŒ€ì‹œë³´ë“œìš©ì´ê³  í¬íŠ¸ 8000ì€ vLLM ì¶”ë¡  ì„œë²„ ì—”ë“œí¬ì¸íŠ¸ìš©ì…ë‹ˆë‹¤.  ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ì„œë¹„ìŠ¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤:  kubectl get svc -n vllm NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE vllm ClusterIP 172.20.23.54 &lt;none&gt; 8080/TCP,6379/TCP,8265/TCP,10001/TCP,8000/TCP 2d4h vllm-llama3-inf2-head-svc ClusterIP 172.20.18.130 &lt;none&gt; 6379/TCP,8265/TCP,10001/TCP,8000/TCP,8080/TCP 2d4h vllm-llama3-inf2-serve-svc ClusterIP 172.20.153.10 &lt;none&gt; 8000/TCP 2d4h   Ray ëŒ€ì‹œë³´ë“œì— ì•¡ì„¸ìŠ¤í•˜ë ¤ë©´ ê´€ë ¨ í¬íŠ¸ë¥¼ ë¡œì»¬ ë¨¸ì‹ ìœ¼ë¡œ í¬íŠ¸ í¬ì›Œë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl -n vllm port-forward svc/vllm 8265:8265   ê·¸ëŸ° ë‹¤ìŒ Ray ì—ì½”ì‹œìŠ¤í…œ ë‚´ì˜ ì‘ì—… ë° ì•¡í„° ë°°í¬ë¥¼ í‘œì‹œí•˜ëŠ” http://localhost:8265ì—ì„œ ì›¹ UIì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ë°°í¬ê°€ ì™„ë£Œë˜ë©´ Controller ë° Proxy ìƒíƒœê°€ HEALTHYì´ê³  Application ìƒíƒœê°€ RUNNINGì´ì–´ì•¼ í•©ë‹ˆë‹¤    ","version":"Next","tagName":"h2"},{"title":"Llama3 ëª¨ë¸ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#llama3-ëª¨ë¸-í…ŒìŠ¤íŠ¸","content":" ì´ì œ Meta-Llama-3-8B-Instruct ì±„íŒ… ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ì‹œê°„ì…ë‹ˆë‹¤. Python í´ë¼ì´ì–¸íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ RayServe ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ì— í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ë‚´ê³  ëª¨ë¸ì´ ìƒì„±í•œ ì¶œë ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.  ë¨¼ì € kubectlì„ ì‚¬ìš©í•˜ì—¬ vllm-llama3-inf2-serve-svc ì„œë¹„ìŠ¤ë¡œ í¬íŠ¸ í¬ì›Œë”©ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl -n vllm port-forward svc/vllm-llama3-inf2-serve-svc 8000:8000   openai-client.pyëŠ” HTTP POST ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ vllm ì„œë²„ë¥¼ ëŒ€ìƒìœ¼ë¡œ í…ìŠ¤íŠ¸ ì™„ì„± ë° Q&amp;Aë¥¼ ìœ„í•´ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ì— í”„ë¡¬í”„íŠ¸ ëª©ë¡ì„ ë³´ëƒ…ë‹ˆë‹¤.  ê°€ìƒ í™˜ê²½ì—ì„œ Python í´ë¼ì´ì–¸íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì‹­ì‹œì˜¤:  cd ai-on-eks/blueprints/inference/vllm-rayserve-inf2 python3 -m venv .venv source .venv/bin/activate pip3 install openai python3 openai-client.py   í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒê³¼ ìœ ì‚¬í•œ ì¶œë ¥ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:  Python í´ë¼ì´ì–¸íŠ¸ í„°ë¯¸ë„ ì¶œë ¥ì„ ë³´ë ¤ë©´ í´ë¦­í•˜ì‹­ì‹œì˜¤ Example 1 - Simple chat completion: Handling connection for 8000 The capital of India is New Delhi. Example 2 - Chat completion with different parameters: The twin suns of Tatooine set slowly in the horizon, casting a warm orange glow over the bustling spaceport of Anchorhead. Amidst the hustle and bustle, a young farm boy named Anakin Skywalker sat atop a dusty speeder, his eyes fixed on the horizon as he dreamed of adventure beyond the desert planet. As the suns dipped below the dunes, Anakin's uncle, Owen Lars, called out to him from the doorway of their humble moisture farm. &quot;Anakin, it's time to head back! Your aunt and I have prepared a special dinner in your honor.&quot; But Anakin was torn. He had received a strange message from an unknown sender, hinting at a great destiny waiting for him. Against his uncle's warnings, Anakin decided to investigate further, sneaking away into the night to follow the mysterious clues. As he rode his speeder through the desert, the darkness seemed to grow thicker, and the silence was broken only by the distant Example 3 - Streaming chat completion: I'd be happy to help you with that. Here we go: 1... (Pause) 2... (Pause) 3... (Pause) 4... (Pause) 5... (Pause) 6... (Pause) 7... (Pause) 8... (Pause) 9... (Pause) 10! Let me know if you have any other requests!   ","version":"Next","tagName":"h3"},{"title":"ê´€ì¸¡ì„±â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#ê´€ì¸¡ì„±","content":" ","version":"Next","tagName":"h2"},{"title":"AWS CloudWatch ë° Neuron Monitorë¥¼ í†µí•œ ê´€ì¸¡ì„±â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#aws-cloudwatch-ë°-neuron-monitorë¥¼-í†µí•œ-ê´€ì¸¡ì„±","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” CloudWatch Observability Agentë¥¼ ê´€ë¦¬í˜• ì• ë“œì˜¨ìœ¼ë¡œ ë°°í¬í•˜ì—¬ ì»¨í…Œì´ë„ˆí™”ëœ ì›Œí¬ë¡œë“œì— ëŒ€í•œ í¬ê´„ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ì œê³µí•©ë‹ˆë‹¤. CPU ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ê³¼ ê°™ì€ ì£¼ìš” ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ì¶”ì í•˜ê¸° ìœ„í•œ container insightsê°€ í¬í•¨ë©ë‹ˆë‹¤. ë˜í•œ ì• ë“œì˜¨ì€ Neuron Monitor í”ŒëŸ¬ê·¸ì¸ì„ í™œìš©í•˜ì—¬ Neuron íŠ¹ì • ë©”íŠ¸ë¦­ì„ ìº¡ì²˜í•˜ê³  ë³´ê³ í•©ë‹ˆë‹¤.  container insights ë° Neuron Core ì‚¬ìš©ë¥ , NeuronCore ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ê°™ì€ Neuron ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ ëª¨ë“  ë©”íŠ¸ë¦­ì€ Amazon CloudWatchë¡œ ì „ì†¡ë˜ì–´ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°°í¬ê°€ ì™„ë£Œë˜ë©´ CloudWatch ì½˜ì†”ì—ì„œ ì§ì ‘ ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì— ì•¡ì„¸ìŠ¤í•˜ì—¬ ì›Œí¬ë¡œë“œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"Open WebUI ë°°í¬â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#open-webui-ë°°í¬","content":" ì •ë³´ Open WebUIëŠ” OpenAI API ì„œë²„ ë° Ollamaì™€ í˜¸í™˜ë˜ëŠ” ëª¨ë¸ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.  1. WebUI ë°°í¬  ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ Open WebUIë¥¼ ë°°í¬í•©ë‹ˆë‹¤:  kubectl apply -f openai-webui-deployment.yaml   2. WebUI ì ‘ê·¼ì„ ìœ„í•œ í¬íŠ¸ í¬ì›Œë”©  ì°¸ê³  Python í´ë¼ì´ì–¸íŠ¸ë¡œ ì¶”ë¡ ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ ì´ë¯¸ í¬íŠ¸ í¬ì›Œë”©ì„ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš° ctrl+cë¥¼ ëˆŒëŸ¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.  kubectl í¬íŠ¸ í¬ì›Œë”©ì„ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ WebUIì— ì ‘ê·¼í•©ë‹ˆë‹¤:  kubectl port-forward svc/open-webui 8081:80 -n openai-webui   3. WebUI ì ‘ê·¼  ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  http://localhost:8081 ë¡œ ì´ë™í•©ë‹ˆë‹¤  4. ê°€ì…  ì´ë¦„, ì´ë©”ì¼ ë° ì„ì˜ì˜ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì…í•©ë‹ˆë‹¤.  5. ìƒˆ ì±„íŒ… ì‹œì‘  ì•„ë˜ ìŠ¤í¬ë¦°ìƒ·ê³¼ ê°™ì´ ë“œë¡­ë‹¤ìš´ ë©”ë‰´ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•˜ê³  New Chatì„ í´ë¦­í•©ë‹ˆë‹¤:    6. í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì…ë ¥  í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:    ","version":"Next","tagName":"h2"},{"title":"LLMPerf ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#llmperf-ë„êµ¬ë¥¼-ì‚¬ìš©í•œ-ì„±ëŠ¥-ë²¤ì¹˜ë§ˆí‚¹","content":" LLMPerfëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ ë²¤ì¹˜ë§ˆí‚¹í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì˜¤í”ˆ ì†ŒìŠ¤ ë„êµ¬ì…ë‹ˆë‹¤.  LLMPerf ë„êµ¬ëŠ” ìœ„ì—ì„œ kubectl -n vllm port-forward svc/vllm-llama3-inf2-serve-svc 8000:8000 ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ì„¤ì •í•œ í¬íŠ¸ í¬ì›Œë”©ì„ í†µí•´ í¬íŠ¸ 8000ì„ í†µí•´ vllm ì„œë¹„ìŠ¤ì— ì—°ê²°í•©ë‹ˆë‹¤.  í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.  LLMPerf ì €ì¥ì†Œ í´ë¡ :  git clone https://github.com/ray-project/llmperf.git cd llmperf pip install -e . pip install pandas pip install ray   ì•„ë˜ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ vllm_benchmark.sh íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:  cat &lt;&lt; 'EOF' &gt; vllm_benchmark.sh #!/bin/bash model=${1:-NousResearch/Meta-Llama-3-8B-Instruct} vu=${2:-1} export OPENAI_API_KEY=EMPTY export OPENAI_API_BASE=&quot;http://localhost:8000/v1&quot; export TOKENIZERS_PARALLELISM=true #if you have more vllm servers, append the below line to the above #;http://localhost:8001/v1;http://localhost:8002/v1&quot; max_requests=$(expr ${vu} \\* 8 ) date_str=$(date '+%Y-%m-%d-%H-%M-%S') python ./token_benchmark_ray.py \\ --model ${model} \\ --mean-input-tokens 512 \\ --stddev-input-tokens 20 \\ --mean-output-tokens 245 \\ --stddev-output-tokens 20 \\ --max-num-completed-requests ${max_requests} \\ --timeout 7200 \\ --num-concurrent-requests ${vu} \\ --results-dir &quot;vllm_bench_results/${date_str}&quot; \\ --llm-api openai \\ --additional-sampling-params '{}' EOF   --mean-input-tokens: ì…ë ¥ í”„ë¡¬í”„íŠ¸ì˜ í‰ê·  í† í° ìˆ˜ ì§€ì •  --stddev-input-tokens: ë” í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ í™˜ê²½ì„ ë§Œë“¤ê¸° ìœ„í•œ ì…ë ¥ í† í° ê¸¸ì´ì˜ ë³€ë™ì„± ì§€ì •  --mean-output-tokens: í˜„ì‹¤ì ì¸ ì‘ë‹µ ê¸¸ì´ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•´ ëª¨ë¸ ì¶œë ¥ì—ì„œ ì˜ˆìƒë˜ëŠ” í‰ê·  í† í° ìˆ˜ ì§€ì •  --stddev-output-tokens: ì‘ë‹µ í¬ê¸°ì˜ ë‹¤ì–‘ì„±ì„ ë„ì…í•˜ëŠ” ì¶œë ¥ í† í° ê¸¸ì´ì˜ ë³€ë™ì„± ì§€ì •  --max-num-completed-requests: ì²˜ë¦¬í•  ìµœëŒ€ ìš”ì²­ ìˆ˜ ì„¤ì •  --num-concurrent-requests: ë³‘ë ¬ ì›Œí¬ë¡œë“œë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ê¸° ìœ„í•œ ë™ì‹œ ìš”ì²­ ìˆ˜ ì§€ì •  ì•„ë˜ ëª…ë ¹ì€ ì§€ì •ëœ ëª¨ë¸ NousResearch/Meta-Llama-3-8B-Instructë¡œ ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ê°€ìƒ ì‚¬ìš©ì ìˆ˜ë¥¼ 2ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ì´ ê²°ê³¼ ë²¤ì¹˜ë§ˆí¬ëŠ” 2ê°œì˜ ë™ì‹œ ìš”ì²­ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ì²˜ë¦¬í•  ìµœëŒ€ 16ê°œì˜ ìš”ì²­ì„ ê³„ì‚°í•©ë‹ˆë‹¤.  ì•„ë˜ ëª…ë ¹ ì‹¤í–‰:  ./vllm_benchmark.sh NousResearch/Meta-Llama-3-8B-Instruct 2   ë‹¤ìŒê³¼ ìœ ì‚¬í•œ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:  ./vllm_benchmark.sh NousResearch/Meta-Llama-3-8B-Instruct 2 None of PyTorch, TensorFlow &gt;= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used. You are using the default legacy behaviour of the &lt;class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'&gt;. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message. 2024-09-03 09:54:45,976\tINFO worker.py:1783 -- Started a local Ray instance. 0%| | 0/16 [00:00&lt;?, ?it/s]Handling connection for 8000 Handling connection for 8000 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2/16 [00:17&lt;02:00, 8.58s/it]Handling connection for 8000 ... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [02:01&lt;00:00, 7.58s/it] \\Results for token benchmark for NousResearch/Meta-Llama-3-8B-Instruct queried with the openai api. inter_token_latency_s p25 = 0.051964785839225695 p50 = 0.053331799814278796 ... mean = 0.053548951905597324 ... ttft_s p25 = 1.5284210312238429 p50 = 1.7579061459982768 ... mean = 1.5821313202395686 ... end_to_end_latency_s p25 = 13.74749460403109 p50 = 14.441407957987394 ... mean = 14.528114874927269 ... request_output_throughput_token_per_s p25 = 18.111220396798153 p50 = 18.703139371912407 ... mean = 18.682678715983627 ... Number Of Errored Requests: 0 Overall Output Throughput: 35.827933968528434 Number Of Completed Requests: 16 Completed Requests Per Minute: 7.914131755588426   ë™ì‹œ ìš”ì²­ ìˆ˜ë¥¼ ëŠ˜ë ¤ê°€ë©° ë²¤ì¹˜ë§ˆí‚¹ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì—¬ ë™ì‹œ ìš”ì²­ ìˆ˜ ì¦ê°€ì— ë”°ë¼ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  ./vllm_benchmark.sh NousResearch/Meta-Llama-3-8B-Instruct 2 ./vllm_benchmark.sh NousResearch/Meta-Llama-3-8B-Instruct 4 ./vllm_benchmark.sh NousResearch/Meta-Llama-3-8B-Instruct 8 ./vllm_benchmark.sh NousResearch/Meta-Llama-3-8B-Instruct 16 . .   ","version":"Next","tagName":"h2"},{"title":"ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë©”íŠ¸ë¦­â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#ì„±ëŠ¥-ë²¤ì¹˜ë§ˆí‚¹-ë©”íŠ¸ë¦­","content":" llmperf ë””ë ‰í† ë¦¬ì˜ vllm_bench_results ë””ë ‰í† ë¦¬ì—ì„œ ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤í¬ë¦½íŠ¸ì˜ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” ë‚ ì§œ-ì‹œê°„ ëª…ëª… ê·œì¹™ì„ ë”°ë¥´ëŠ” í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë  ë•Œë§ˆë‹¤ ìƒˆ í´ë”ê°€ ìƒì„±ë©ë‹ˆë‹¤.  ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤í¬ë¦½íŠ¸ì˜ ëª¨ë“  ì‹¤í–‰ ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ì˜ 2ê°œ íŒŒì¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:  NousResearch-Meta-Llama-3-8B-Instruct_512_245_summary_32.json - ëª¨ë“  ìš”ì²­/ì‘ë‹µ ìŒì— ê±¸ì¹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìš”ì•½ í¬í•¨.  NousResearch-Meta-Llama-3-8B-Instruct_512_245_individual_responses.json - ê° ìš”ì²­/ì‘ë‹µ ìŒì— ëŒ€í•œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ í¬í•¨.  ì´ëŸ¬í•œ ê° íŒŒì¼ì—ëŠ” ë‹¤ìŒ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë©”íŠ¸ë¦­ì´ í¬í•¨ë©ë‹ˆë‹¤:  results_inter_token_latency_s_*: Token generation latency (TPOT)ë¼ê³ ë„ í•©ë‹ˆë‹¤. Inter-Token ì§€ì—° ì‹œê°„ì€ ë””ì½”ë”© ë˜ëŠ” ìƒì„± ë‹¨ê³„ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì—°ì† ì¶œë ¥ í† í°ì„ ìƒì„±í•˜ëŠ” ë° ê±¸ë¦¬ëŠ” í‰ê·  ì‹œê°„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤  results_ttft_s_*: ì²« ë²ˆì§¸ í† í° ìƒì„±ê¹Œì§€ì˜ ì‹œê°„(Time to First Token, TTFT)  results_end_to_end_s_*: ì—”ë“œíˆ¬ì—”ë“œ ì§€ì—° ì‹œê°„ - ì‚¬ìš©ìê°€ ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¥¼ ì œì¶œí•œ ì‹œì ë¶€í„° LLMì´ ì™„ì „í•œ ì¶œë ¥ ì‘ë‹µì„ ìƒì„±í•˜ê¸°ê¹Œì§€ ê±¸ë¦¬ëŠ” ì´ ì‹œê°„  results_request_output_throughput_token_per_s_*: ëª¨ë“  ì‚¬ìš©ì ìš”ì²­ ë˜ëŠ” ì¿¼ë¦¬ì—ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì´ˆë‹¹ ìƒì„±í•˜ëŠ” ì¶œë ¥ í† í° ìˆ˜  results_number_input_tokens_*: ìš”ì²­ì˜ ì…ë ¥ í† í° ìˆ˜(ì…ë ¥ ê¸¸ì´)  results_number_output_tokens_*: ìš”ì²­ì˜ ì¶œë ¥ í† í° ìˆ˜(ì¶œë ¥ ê¸¸ì´)  ","version":"Next","tagName":"h3"},{"title":"ê²°ë¡ â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#ê²°ë¡ ","content":" ìš”ì•½í•˜ë©´, Llama-3ë¥¼ ë°°í¬í•˜ê³  í™•ì¥í•  ë•Œ AWS Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ëŠ” ë§¤ë ¥ì ì¸ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤. GPU ë¶€ì¡±ê³¼ ê´€ë ¨ëœ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ë©´ì„œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ì´ê³  ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ ì‹¤í–‰í•˜ëŠ” ë° í•„ìš”í•œ í™•ì¥ì„±, ë¹„ìš© ìµœì í™” ë° ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí•©ë‹ˆë‹¤. ì±—ë´‡, ìì—°ì–´ ì²˜ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ë˜ëŠ” ê¸°íƒ€ LLM ê¸°ë°˜ ì†”ë£¨ì…˜ì„ êµ¬ì¶•í•˜ë“  Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ AWS í´ë¼ìš°ë“œì—ì„œ Llama-3ì˜ ì ì¬ë ¥ì„ ìµœëŒ€í•œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"AWS Neuronì—ì„œ RayServeì™€ vLLMì„ ì‚¬ìš©í•œ LLM ì„œë¹™","url":"/ai-on-eks/ko/docs/blueprints/inference/framework-guides/Neuron/vllm-ray-inf2#ì •ë¦¬","content":" ë§ˆì§€ë§‰ìœ¼ë¡œ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•˜ê³  í”„ë¡œë¹„ì €ë‹ í•´ì œí•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.  RayCluster ì‚­ì œ  cd ai-on-eks/blueprints/inference/vllm-rayserve-inf2 kubectl delete -f vllm-rayserve-deployment.yaml   EKS í´ëŸ¬ìŠ¤í„° ë° ë¦¬ì†ŒìŠ¤ ì‚­ì œ  cd ai-on-eks/infra/trainium-inferentia/terraform/_LOCAL ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"EKSì—ì„œì˜ BioNeMo","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/training/GPUs/bionemo","content":"","keywords":"","version":"Next"},{"title":"ì†Œê°œâ€‹","type":1,"pageTitle":"EKSì—ì„œì˜ BioNeMo","url":"/ai-on-eks/ko/docs/blueprints/training/GPUs/bionemo#ì†Œê°œ","content":" NVIDIA BioNeMoëŠ” ì‹ ì•½ ê°œë°œì„ ìœ„í•œ ìƒì„±í˜• AI í”Œë«í¼ìœ¼ë¡œ, ìì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ í›ˆë ¨ì„ ë‹¨ìˆœí™”í•˜ê³  ê°€ì†í™”í•˜ë©° ì‹ ì•½ ê°œë°œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ëª¨ë¸ ë°°í¬ë¥¼ í™•ì¥í•©ë‹ˆë‹¤. BioNeMoëŠ” AI ëª¨ë¸ ê°œë°œê³¼ ë°°í¬ ëª¨ë‘ì— ê°€ì¥ ë¹ ë¥¸ ê²½ë¡œë¥¼ ì œê³µí•˜ì—¬ AI ê¸°ë°˜ ì‹ ì•½ ê°œë°œë¡œì˜ ì—¬ì •ì„ ê°€ì†í™”í•©ë‹ˆë‹¤. ì‚¬ìš©ìì™€ ê¸°ì—¬ì ì»¤ë®¤ë‹ˆí‹°ê°€ ì„±ì¥í•˜ê³  ìˆìœ¼ë©° NVIDIAì—ì„œ ì ê·¹ì ìœ¼ë¡œ ìœ ì§€ ê´€ë¦¬í•˜ê³  ê°œë°œí•˜ê³  ìˆìŠµë‹ˆë‹¤.  ì»¨í…Œì´ë„ˆí™”ëœ íŠ¹ì„±ì„ ê³ ë ¤í•  ë•Œ BioNeMoëŠ” Amazon Sagemaker, AWS ParallelCluster, Amazon ECS, Amazon EKSì™€ ê°™ì€ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ë°°í¬ì˜ ë‹¤ì–‘ì„±ì„ ì°¾ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ì†”ë£¨ì…˜ì€ Amazon EKSì—ì„œì˜ BioNeMo ë°°í¬ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.  ì¶œì²˜: https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/  ","version":"Next","tagName":"h2"},{"title":"Kubernetesì—ì„œ BioNeMo ë°°í¬â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ BioNeMo","url":"/ai-on-eks/ko/docs/blueprints/training/GPUs/bionemo#kubernetesì—ì„œ-bionemo-ë°°í¬","content":" ì´ ë¸”ë£¨í”„ë¦°íŠ¸ëŠ” ê¸°ëŠ¥ì„ ìœ„í•´ ì„¸ ê°€ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œë¥¼ í™œìš©í•©ë‹ˆë‹¤. NVIDIA Device Pluginì€ GPU ì‚¬ìš©ì„ ìš©ì´í•˜ê²Œ í•˜ê³ , FSxëŠ” í›ˆë ¨ ë°ì´í„°ë¥¼ ì €ì¥í•˜ë©°, Kubeflow Training OperatorëŠ” ì‹¤ì œ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.  Kubeflow Training OperatorNVIDIA Device PluginFSx for Lustre CSI Driver  ì´ ë¸”ë£¨í”„ë¦°íŠ¸ì—ì„œëŠ” Amazon EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•˜ê³  ë°ì´í„° ì¤€ë¹„ ì‘ì—…ê³¼ ë¶„ì‚° ëª¨ë¸ í›ˆë ¨ ì‘ì—…ì„ ëª¨ë‘ ì‹¤í–‰í•©ë‹ˆë‹¤.  ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ğŸ‘ˆ  ë¸”ë£¨í”„ë¦°íŠ¸ ë°°í¬ ğŸ‘ˆ  ë°°í¬ í™•ì¸ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"BioNeMo í›ˆë ¨ ì‘ì—… ì‹¤í–‰â€‹","type":1,"pageTitle":"EKSì—ì„œì˜ BioNeMo","url":"/ai-on-eks/ko/docs/blueprints/training/GPUs/bionemo#bionemo-í›ˆë ¨-ì‘ì—…-ì‹¤í–‰","content":" ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•œ í›„ í´ëŸ¬ìŠ¤í„°ì— ì‘ì—…ì„ ì œì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  1ë‹¨ê³„: Uniref50 ë°ì´í„° ì¤€ë¹„ ì‘ì—… ì‹œì‘â€‹  uniref50-job.yamlì´ë¼ëŠ” ì²« ë²ˆì§¸ ì‘ì—…ì€ ì²˜ë¦¬ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  íŒŒí‹°ì…”ë‹í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ì‘ì—…ì€ íŠ¹ë³„íˆ uniref50 ë°ì´í„°ì…‹ì„ ê²€ìƒ‰í•˜ê³  FSx for Lustre íŒŒì¼ ì‹œìŠ¤í…œ ë‚´ì— êµ¬ì„±í•©ë‹ˆë‹¤. ì´ êµ¬ì¡°í™”ëœ ë ˆì´ì•„ì›ƒì€ í›ˆë ¨, í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ëª©ì ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. uniref ë°ì´í„°ì…‹ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ì‘ì—…ì„ ì‹¤í–‰í•˜ë ¤ë©´ examples/esm1nv ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ê³  ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ uniref50-job.yaml ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ ë°°í¬í•©ë‹ˆë‹¤:  cd examples/esm1nv kubectl apply -f uniref50-job.yaml   ì •ë³´ ì´ ì‘ì—…ì€ ì¼ë°˜ì ìœ¼ë¡œ 50~60ì‹œê°„ ì •ë„ì˜ ìƒë‹¹í•œ ì‹œê°„ì´ í•„ìš”í•©ë‹ˆë‹¤.  ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ uniref50-download-* íŒŒë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤  kubectl get pods   ì§„í–‰ ìƒí™©ì„ í™•ì¸í•˜ë ¤ë©´ í•´ë‹¹ íŒŒë“œì—ì„œ ìƒì„±ëœ ë¡œê·¸ë¥¼ ê²€í† í•©ë‹ˆë‹¤:  kubectl logs uniref50-download-xnz42 [NeMo I 2024-02-26 23:02:20 preprocess:289] Download and preprocess of UniRef50 data does not currently use GPU. Workstation or CPU-only instance recommended. [NeMo I 2024-02-26 23:02:20 preprocess:115] Data processing can take an hour or more depending on system resources. [NeMo I 2024-02-26 23:02:20 preprocess:117] Downloading file from https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref50/uniref50.fasta.gz... [NeMo I 2024-02-26 23:02:20 preprocess:75] Downloading file to /fsx/raw/uniref50.fasta.gz... [NeMo I 2024-02-26 23:08:33 preprocess:89] Extracting file to /fsx/raw/uniref50.fasta... [NeMo I 2024-02-26 23:12:46 preprocess:311] UniRef50 data processing complete. [NeMo I 2024-02-26 23:12:46 preprocess:313] Indexing UniRef50 dataset. [NeMo I 2024-02-26 23:16:21 preprocess:319] Writing processed dataset files to /fsx/processed... [NeMo I 2024-02-26 23:16:21 preprocess:255] Creating train split...   ì´ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ì´ /fsx/processed ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤. ì´ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  ë‹¤ìŒìœ¼ë¡œ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  ì´ PyTorchJob YAMLì—ì„œ python3 -m torch.distributed.run ëª…ë ¹ì€ Kubernetes í´ëŸ¬ìŠ¤í„°ì˜ ì—¬ëŸ¬ ì›Œì»¤ íŒŒë“œì—ì„œ ë¶„ì‚° í›ˆë ¨ì„ ì¡°ìœ¨í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.  ë‹¤ìŒ ì‘ì—…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤:  ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹ ì„ ìœ„í•œ ë¶„ì‚° ë°±ì—”ë“œ(ì˜ˆ: c10d, NCCL)ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” c10dë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŠ” í™˜ê²½ì— ë”°ë¼ TCP ë˜ëŠ” Infinibandì™€ ê°™ì€ ë‹¤ì–‘í•œ í†µì‹  ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•  ìˆ˜ ìˆëŠ” PyTorchì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë¶„ì‚° ë°±ì—”ë“œì…ë‹ˆë‹¤.í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ ë‚´ì—ì„œ ë¶„ì‚° í›ˆë ¨ì„ í™œì„±í™”í•˜ê¸° ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.ëª¨ë“  ì›Œì»¤ íŒŒë“œì—ì„œ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹œì‘í•˜ì—¬ ê° í”„ë¡œì„¸ìŠ¤ê°€ ë¶„ì‚° í›ˆë ¨ì— ì°¸ì—¬í•˜ë„ë¡ í•©ë‹ˆë‹¤.  kubectl apply -f esm1nv_pretrain-job.yaml   ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ esm1nv-pretraining-worker-* íŒŒë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤  kubectl get pods   NAME READY STATUS RESTARTS AGE esm1nv-pretraining-worker-0 1/1 Running 0 11m esm1nv-pretraining-worker-1 1/1 Running 0 11m esm1nv-pretraining-worker-2 1/1 Running 0 11m esm1nv-pretraining-worker-3 1/1 Running 0 11m esm1nv-pretraining-worker-4 1/1 Running 0 11m esm1nv-pretraining-worker-5 1/1 Running 0 11m esm1nv-pretraining-worker-6 1/1 Running 0 11m esm1nv-pretraining-worker-7 1/1 Running 0 11m   8ê°œì˜ íŒŒë“œê°€ ì‹¤í–‰ ì¤‘ì¸ ê²ƒì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. íŒŒë“œ ì •ì˜ì—ì„œ ê°ê° 1ê°œì˜ GPU ì œí•œì´ ìˆëŠ” 8ê°œì˜ ì›Œì»¤ ë ˆí”Œë¦¬ì¹´ë¥¼ ì§€ì •í–ˆìŠµë‹ˆë‹¤. Karpenterê°€ ê°ê° 4ê°œì˜ GPUê°€ ìˆëŠ” 2ê°œì˜ g5.12xlarge ì¸ìŠ¤í„´ìŠ¤ë¥¼ í”„ë¡œë¹„ì €ë‹í–ˆìŠµë‹ˆë‹¤. &quot;nprocPerNode&quot;ë¥¼ &quot;4&quot;ë¡œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ ê° ë…¸ë“œëŠ” 4ê°œì˜ ì‘ì—…ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. ë¶„ì‚° pytorch í›ˆë ¨ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ pytorch ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.  ì •ë³´ ì´ í›ˆë ¨ ì‘ì—…ì€ g5.12xlarge ë…¸ë“œì—ì„œ ìµœì†Œ 3-4ì¼ ë™ì•ˆ ì‹¤í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ êµ¬ì„±ì€ Kubeflowì˜ PyTorch í›ˆë ¨ Custom Resource Definition (CRD)ì„ í™œìš©í•©ë‹ˆë‹¤. ì´ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë‚´ì—ì„œ ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ìì„¸í•œ ì¸ì‚¬ì´íŠ¸ì™€ íŒŒì¸íŠœë‹ ê°€ì´ë“œëŠ” BioNeMo ë¬¸ì„œë¥¼ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì •ë³´ Kubeflow training operator ë¬¸ì„œì— ë”°ë¥´ë©´ ë§ˆìŠ¤í„° ë ˆí”Œë¦¬ì¹´ íŒŒë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì²« ë²ˆì§¸ ì›Œì»¤ ë ˆí”Œë¦¬ì¹´ íŒŒë“œ(worker-0)ê°€ ë§ˆìŠ¤í„° íŒŒë“œë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.  ì´ í”„ë¡œì„¸ìŠ¤ì˜ ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:  kubectl logs esm1nv-pretraining-worker-0 Epoch 0: 7%|â–‹ | 73017/1017679 [00:38&lt;08:12, 1918.0%   ë˜í•œ í•´ë‹¹ ë…¸ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì¸ Kubernetes íŒŒë“œ ë‚´ì—ì„œ nvidia-smi ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ íŠ¹ì • ì›Œì»¤ ë…¸ë“œì˜ GPU ìƒíƒœ ìŠ¤ëƒ…ìƒ·ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ê°•ë ¥í•œ ê´€ì¸¡ì„±ì„ ì›í•œë‹¤ë©´ DCGM Exporterë¥¼ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  kubectl exec esm1nv-pretraining-worker-0 -- nvidia-smi Mon Feb 24 18:51:35 2025 +---------------------------------------------------------------------------------------+ | NVIDIA-SMI 535.230.02 Driver Version: 535.230.02 CUDA Version: 12.2 | |-----------------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+======================+======================| | 0 NVIDIA A10G On | 00000000:00:1E.0 Off | 0 | | 0% 33C P0 112W / 300W | 3032MiB / 23028MiB | 95% Default | | | | N/A | +-----------------------------------------+----------------------+----------------------+ +---------------------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=======================================================================================| +---------------------------------------------------------------------------------------+   ë¶„ì‚° í›ˆë ¨ì˜ ì´ì :â€‹  ì—¬ëŸ¬ ì›Œì»¤ íŒŒë“œì˜ ì—¬ëŸ¬ GPUì— í›ˆë ¨ ì›Œí¬ë¡œë“œë¥¼ ë¶„ì‚°í•¨ìœ¼ë¡œì¨ ëª¨ë“  GPUì˜ ê²°í•©ëœ ì—°ì‚° ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬ ëŒ€ê·œëª¨ ëª¨ë¸ì„ ë” ë¹ ë¥´ê²Œ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¨ì¼ GPUì˜ ë©”ëª¨ë¦¬ì— ë§ì§€ ì•Šì„ ìˆ˜ ìˆëŠ” ë” í° ë°ì´í„°ì…‹ë„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ê²°ë¡ â€‹  BioNeMoëŠ” ì‹ ì•½ ê°œë°œ ì˜ì—­ì„ ìœ„í•´ ë§ì¶¤í™”ëœ ê°•ë ¥í•œ ìƒì„±í˜• AI ë„êµ¬ì…ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” ê´‘ë²”ìœ„í•œ uniref50 ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì²˜ìŒë¶€í„° ì»¤ìŠ¤í…€ ëª¨ë¸ì„ ì‚¬ì „ í›ˆë ¨í•˜ëŠ” ê²ƒì„ ì£¼ë„ì ìœ¼ë¡œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ BioNeMoëŠ” NVidiaì—ì„œ ì œê³µí•˜ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹ ì†í•˜ê²Œ ì§„í–‰í•  ìˆ˜ ìˆëŠ” ìœ ì—°ì„±ì„ ì œê³µí•œë‹¤ëŠ” ì ì— ì£¼ëª©í•  ê°€ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. ì´ ëŒ€ì•ˆì  ì ‘ê·¼ ë°©ì‹ì€ BioNeMo í”„ë ˆì„ì›Œí¬ì˜ ê°•ë ¥í•œ ê¸°ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ ì›Œí¬í”Œë¡œìš°ë¥¼ í¬ê²Œ ê°„ì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì •ë¦¬ ğŸ‘ˆ ","version":"Next","tagName":"h3"},{"title":"Trainiumì—ì„œì˜ BERT-Large","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/BERT-Large","content":"Trainiumì—ì„œì˜ BERT-Large ì •ë³´ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤ ì´ ì„¹ì…˜ì€ í˜„ì¬ ì‘ì—… ì¤‘ì´ë©° EKSì—ì„œ ë°ì´í„° ë° ML ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ í¬ê´„ì ì¸ ë¦¬ì†ŒìŠ¤ ëª¨ìŒìœ¼ë¡œ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.","keywords":"","version":"Next"},{"title":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts","content":"","keywords":"","version":"Next"},{"title":"ê°œìš”â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ê°œìš”","content":" ì¶”ë¡  ì°¨íŠ¸ëŠ” ì—¬ëŸ¬ ë°°í¬ í”„ë ˆì„ì›Œí¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:  VLLM - ë¹ ë¥¸ ì‹œì‘ì´ ê°€ëŠ¥í•œ ë‹¨ì¼ ë…¸ë“œ ì¶”ë¡ Ray-VLLM - ìë™ ìŠ¤ì¼€ì¼ë§ ê¸°ëŠ¥ì´ ìˆëŠ” ë¶„ì‚° ì¶”ë¡ Triton-VLLM - NVIDIA ì¶”ë¡  ì„œë²„AIBrix - AIBrix ì „ìš© êµ¬ì„±ì´ í¬í•¨ëœ VLLMLeaderWorkerSet-VLLM - ëŒ€ê·œëª¨ ëª¨ë¸ì„ ìœ„í•œ ë©€í‹° ë…¸ë“œ ì¶”ë¡ Diffusers - ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ Hugging Face DiffusersS3 Model Copy - Hugging Faceì—ì„œ S3 ìŠ¤í† ë¦¬ì§€ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ  GPUì™€ AWS Neuron(Inferentia/Trainium) ê°€ì†ê¸° ëª¨ë‘ ì´ëŸ¬í•œ í”„ë ˆì„ì›Œí¬ì—ì„œ ì§€ì›ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ì‚¬ì „-ìš”êµ¬-ì‚¬í•­","content":" ì¶”ë¡  ì°¨íŠ¸ë¥¼ ë°°í¬í•˜ê¸° ì „ì— ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”:  GPU ë˜ëŠ” AWS Neuron ë…¸ë“œê°€ ìˆëŠ” Amazon EKS í´ëŸ¬ìŠ¤í„°(ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•œ ì¶”ë¡  ì¤€ë¹„ í´ëŸ¬ìŠ¤í„°)Helm 3.0+GPU ë°°í¬ì˜ ê²½ìš°: NVIDIA ë””ë°”ì´ìŠ¤ í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜ë¨Neuron ë°°í¬ì˜ ê²½ìš°: AWS Neuron ë””ë°”ì´ìŠ¤ í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜ë¨LeaderWorkerSet ë°°í¬ì˜ ê²½ìš°: LeaderWorkerSet CRD ì„¤ì¹˜ë¨Hugging Face Hub í† í°(hf-tokenì´ë¼ëŠ” Kubernetes ì‹œí¬ë¦¿ìœ¼ë¡œ ì €ì¥ë¨)Rayì˜ ê²½ìš°: KubeRay ì¸í”„ë¼AIBrixì˜ ê²½ìš°: AIBrix ì¸í”„ë¼S3 Model Copyì˜ ê²½ìš°: S3 ì“°ê¸° ê¶Œí•œì´ ìˆëŠ” ì„œë¹„ìŠ¤ ê³„ì •  ","version":"Next","tagName":"h2"},{"title":"ë¹ ë¥¸ ì‹œì‘â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ë¹ ë¥¸-ì‹œì‘","content":" ","version":"Next","tagName":"h2"},{"title":"1. Hugging Face í† í° ì‹œí¬ë¦¿ ìƒì„±â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#1-hugging-face-í† í°-ì‹œí¬ë¦¿-ìƒì„±","content":" Hugging Face í† í°ìœ¼ë¡œ Kubernetes ì‹œí¬ë¦¿ì„ ìƒì„±í•˜ì„¸ìš”:  kubectl create secret generic hf-token --from-literal=token=your_huggingface_token   ","version":"Next","tagName":"h3"},{"title":"2. ë¯¸ë¦¬ êµ¬ì„±ëœ ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#2-ë¯¸ë¦¬-êµ¬ì„±ëœ-ëª¨ë¸-ë°°í¬","content":" ì‚¬ìš© ê°€ëŠ¥í•œ ë¯¸ë¦¬ êµ¬ì„±ëœ ëª¨ë¸ ì¤‘ ì„ íƒí•˜ì—¬ ë°°í¬í•˜ì„¸ìš”:  ê²½ê³  ì´ëŸ¬í•œ ë°°í¬ì—ëŠ” GPU/Neuron ë¦¬ì†ŒìŠ¤ê°€ í•„ìš”í•˜ë©°, í™œì„±í™”ë˜ì–´ ìˆì–´ì•¼ í•˜ê³  CPU ì „ìš© ì¸ìŠ¤í„´ìŠ¤ë³´ë‹¤ ë¹„ìš©ì´ ë” ë§ì´ ë“­ë‹ˆë‹¤.  # ì°¨íŠ¸ ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update # GPUì—ì„œ vLLMìœ¼ë¡œ Qwen 3 1.7B ë°°í¬ helm install qwen3-inference ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-qwen3-1.7b-vllm.yaml # GPUì—ì„œ Ray-vLLMìœ¼ë¡œ DeepSeek R1 Distill ë°°í¬ helm install deepseek-inference ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-deepseek-r1-distill-llama-8b-ray-vllm-gpu.yaml   ","version":"Next","tagName":"h3"},{"title":"ì§€ì› ëª¨ë¸â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ì§€ì›-ëª¨ë¸","content":" ì¶”ë¡  ì°¨íŠ¸ì—ëŠ” ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì˜ ì¸ê¸° ëª¨ë¸ì„ ìœ„í•œ ë¯¸ë¦¬ êµ¬ì„±ëœ ê°’ íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:  ","version":"Next","tagName":"h2"},{"title":"ì–¸ì–´ ëª¨ë¸â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ì–¸ì–´-ëª¨ë¸","content":" DeepSeek R1 Distill Llama 8B - ê³ ê¸‰ ì¶”ë¡  ëª¨ë¸Llama 3.2 1B - ê²½ëŸ‰ ì–¸ì–´ ëª¨ë¸Llama 4 Scout 17B - ì¤‘ê°„ í¬ê¸° ì–¸ì–´ ëª¨ë¸Mistral Small 24B - íš¨ìœ¨ì ì¸ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸GPT OSS 20B - ì˜¤í”ˆì†ŒìŠ¤ GPT ë³€í˜•Qwen3 1.7B - ì»´íŒ©íŠ¸í•œ ë‹¤êµ­ì–´ ì–¸ì–´ ëª¨ë¸  ","version":"Next","tagName":"h3"},{"title":"Diffusion ëª¨ë¸â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#diffusion-ëª¨ë¸","content":" FLUX.1 Schnell - ë¹ ë¥¸ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±Stable Diffusion XL - ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±Stable Diffusion 3.5 - í–¥ìƒëœ ê¸°ëŠ¥ì´ ìˆëŠ” ìµœì‹  SD ëª¨ë¸Kolors - ì˜ˆìˆ ì  ì´ë¯¸ì§€ ìƒì„±OmniGen - ë©€í‹°ëª¨ë‹¬ ìƒì„±  ","version":"Next","tagName":"h3"},{"title":"Neuron ìµœì í™” ëª¨ë¸â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#neuron-ìµœì í™”-ëª¨ë¸","content":" Llama 2 13B - AWS Inferentiaì— ìµœì í™”ë¨Llama 3 70B - Inferentiaì—ì„œì˜ ëŒ€ê·œëª¨ ëª¨ë¸Llama 3.1 8B - íš¨ìœ¨ì ì¸ Inferentia ë°°í¬  ê° ëª¨ë¸ì—ëŠ” ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬(VLLM, Ray-VLLM, Triton-VLLM ë“±)ë¥¼ ìœ„í•œ ìµœì í™”ëœ êµ¬ì„±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ë°°í¬ ì˜ˆì œâ€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ë°°í¬-ì˜ˆì œ","content":" ","version":"Next","tagName":"h2"},{"title":"ì–¸ì–´ ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ì–¸ì–´-ëª¨ë¸-ë°°í¬","content":" # ì°¨íŠ¸ ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update # GPUì—ì„œ vLLMìœ¼ë¡œ Qwen 3 1.7B ë°°í¬ helm install qwen3-inference ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-qwen3-1.7b-vllm.yaml # GPUì—ì„œ Ray-vLLMìœ¼ë¡œ DeepSeek R1 Distill ë°°í¬ helm install deepseek-inference ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-deepseek-r1-distill-llama-8b-ray-vllm-gpu.yaml # LeaderWorkerSet-VLLMìœ¼ë¡œ Llama 4 Scout 17B ë°°í¬ helm install llama4-lws ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-4-scout-17b-lws-vllm.yaml   ","version":"Next","tagName":"h3"},{"title":"Diffusion ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#diffusion-ëª¨ë¸-ë°°í¬","content":" # ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ FLUX.1 Schnell ë°°í¬ helm install flux-diffusers ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-flux-1-diffusers.yaml # Stable Diffusion XL ë°°í¬ helm install sdxl-diffusers ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-stable-diffusion-xl-base-1-diffusers.yaml   ","version":"Next","tagName":"h3"},{"title":"Neuron ë°°í¬â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#neuron-ë°°í¬","content":" # Inferentiaì—ì„œ Llama 3.1 8B ë°°í¬ helm install llama31-neuron ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-31-8b-vllm-neuron.yaml # Inferentiaì—ì„œ Ray-VLLMìœ¼ë¡œ Llama 3 70B ë°°í¬ helm install llama3-70b-neuron ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-3-70b-ray-vllm-neuron.yaml   ","version":"Next","tagName":"h3"},{"title":"S3 Model Copyâ€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#s3-model-copy","content":" S3 Model Copy ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ Hugging Face Hubì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ S3 ìŠ¤í† ë¦¬ì§€ì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤:  ë” ë¹ ë¥¸ ë°°í¬ë¥¼ ìœ„í•´ S3ì— ëª¨ë¸ ì‚¬ì „ ì¤€ë¹„í”„ë¼ì´ë¹— S3 ë²„í‚·ì— ëª¨ë¸ ì €ì¥ì†Œ ìƒì„±AWS ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ì¶”ë¡  ì‹œì‘ ì‹œê°„ ë‹¨ì¶•  # Hugging Faceì—ì„œ S3ë¡œ Llama 3 8B ëª¨ë¸ ë³µì‚¬ helm install s3-copy-llama3 ai-on-eks/inference-charts \\ --values https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-s3-copy-llama3-8b.yaml   ì»¤ìŠ¤í…€ S3 Model Copyâ€‹  S3ì— ëª¨ë“  ëª¨ë¸ì„ ë³µì‚¬í•˜ê¸° ìœ„í•œ ì»¤ìŠ¤í…€ ê°’ íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”:  s3ModelCopy: namespace: default model: deepseek-ai/DeepSeek-R1 s3Path: my-models-bucket/ # ëª¨ë¸ì€ s3://my-models-bucket/deepseek-ai/DeepSeek-R1ë¡œ ë³µì‚¬ë©ë‹ˆë‹¤ serviceAccountName: s3-copy-service-account # S3 ì“°ê¸° ê¶Œí•œì´ ìˆëŠ” ì„œë¹„ìŠ¤ ê³„ì •   S3 ë³µì‚¬ ì‘ì—… ë°°í¬:  helm install custom-s3-copy ai-on-eks/inference-charts \\ --values custom-s3-copy-values.yaml   S3 ê¶Œí•œ ì„œë¹„ìŠ¤ ê³„ì •ì—ëŠ” ëŒ€ìƒ S3 ë²„í‚·ì— ì“°ê¸° ìœ„í•œ IAM ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ ê³„ì •ì— S3 ê¶Œí•œì„ ë¶€ì—¬í•˜ë ¤ë©´ Pod Identity ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”.  ","version":"Next","tagName":"h3"},{"title":"êµ¬ì„±â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#êµ¬ì„±","content":" ","version":"Next","tagName":"h2"},{"title":"ì£¼ìš” íŒŒë¼ë¯¸í„°â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ì£¼ìš”-íŒŒë¼ë¯¸í„°","content":" íŒŒë¼ë¯¸í„°\tì„¤ëª…\tê¸°ë³¸ê°’inference.accelerator\tê°€ì†ê¸° ìœ í˜•(gpu ë˜ëŠ” neuron)\tgpu inference.framework\tí”„ë ˆì„ì›Œí¬(vllm, ray-vllm, triton-vllm, aibrix ë“±)\tvllm inference.serviceName\tì¶”ë¡  ì„œë¹„ìŠ¤ ì´ë¦„\tinference inference.modelServer.deployment.replicas\të ˆí”Œë¦¬ì¹´ ìˆ˜\t1 model\tHugging Face Hubì˜ ëª¨ë¸ ID\tNousResearch/Llama-3.2-1B modelParameters.gpuMemoryUtilization\tGPU ë©”ëª¨ë¦¬ í™œìš©ë„\t0.8 modelParameters.maxModelLen\tìµœëŒ€ ëª¨ë¸ ì‹œí€€ìŠ¤ ê¸¸ì´\t8192 modelParameters.tensorParallelSize\tí…ì„œ ë³‘ë ¬ í¬ê¸°\t1 modelParameters.pipelineParallelSize\tíŒŒì´í”„ë¼ì¸ ë³‘ë ¬ í¬ê¸°\t1 s3ModelCopy.namespace\tS3 ëª¨ë¸ ë³µì‚¬ ì‘ì—…ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤\tdefault s3ModelCopy.model\tS3ì— ë³µì‚¬í•  Hugging Face ëª¨ë¸ ID\tì„¤ì • ì•ˆ ë¨ s3ModelCopy.s3Path\tëª¨ë¸ì„ ì—…ë¡œë“œí•  S3 ê²½ë¡œ\tì„¤ì • ì•ˆ ë¨ serviceAccountName\tì„œë¹„ìŠ¤ ê³„ì • ì´ë¦„\tdefault  ","version":"Next","tagName":"h3"},{"title":"ì»¤ìŠ¤í…€ êµ¬ì„±â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ì»¤ìŠ¤í…€-êµ¬ì„±","content":" ì»¤ìŠ¤í…€ ê°’ íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”:  inference: accelerator: gpu # ë˜ëŠ” neuron framework: vllm # vllm, ray-vllm, triton-vllm, aibrix, lws-vllm, diffusers serviceName: my-inference modelServer: deployment: replicas: 1 instanceType: g5.2xlarge model: &quot;NousResearch/Llama-3.2-1B&quot; modelParameters: gpuMemoryUtilization: 0.8 maxModelLen: 8192 tensorParallelSize: 1   ì»¤ìŠ¤í…€ ê°’ìœ¼ë¡œ ë°°í¬:  helm install my-inference ai-on-eks/inference-charts \\ --values custom-values.yaml   ","version":"Next","tagName":"h3"},{"title":"API ì‚¬ìš©ë²•â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#api-ì‚¬ìš©ë²•","content":" ë°°í¬ëœ ì„œë¹„ìŠ¤ëŠ” í”„ë ˆì„ì›Œí¬ì— ë”°ë¼ ë‹¤ë¥¸ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤:  ","version":"Next","tagName":"h2"},{"title":"VLLM/Ray-VLLMâ€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#vllmray-vllm","content":" /v1/models - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡/v1/chat/completions - ì±„íŒ… ì™„ì„± API/v1/completions - í…ìŠ¤íŠ¸ ì™„ì„± API/metrics - Prometheus ë©”íŠ¸ë¦­  ","version":"Next","tagName":"h3"},{"title":"Triton-VLLMâ€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#triton-vllm","content":" /v2/models - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡/v2/models/vllm_model/generate - ëª¨ë¸ ì¶”ë¡ /v2/health/ready - í—¬ìŠ¤ ì²´í¬  ","version":"Next","tagName":"h3"},{"title":"Diffusersâ€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#diffusers","content":" /v1/generations - ì´ë¯¸ì§€ ìƒì„± API  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ìš© ì˜ˆì œâ€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ì‚¬ìš©-ì˜ˆì œ","content":" í¬íŠ¸ í¬ì›Œë”©ìœ¼ë¡œ ì„œë¹„ìŠ¤ì— ì ‘ê·¼:  kubectl port-forward svc/&lt;service-name&gt; 8000   API í…ŒìŠ¤íŠ¸:  # ì±„íŒ… ì™„ì„± (VLLM/Ray-VLLM) curl -X POST http://localhost:8000/v1/chat/completions \\ -H &quot;Content-Type: application/json&quot; \\ -d '{ &quot;model&quot;: &quot;your-model-name&quot;, &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}], &quot;max_tokens&quot;: 100 }' # ì´ë¯¸ì§€ ìƒì„± (Diffusers) curl -X POST http://localhost:8000/v1/generations \\ -H 'Content-Type: application/json' \\ -d '{&quot;prompt&quot;: &quot;A beautiful sunset over mountains&quot;}'   ","version":"Next","tagName":"h3"},{"title":"ë¬¸ì œ í•´ê²°â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ë¬¸ì œ-í•´ê²°","content":" ","version":"Next","tagName":"h2"},{"title":"ì¼ë°˜ì ì¸ ë¬¸ì œâ€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ì¼ë°˜ì ì¸-ë¬¸ì œ","content":" íŒŒë“œê°€ Pending ìƒíƒœì—ì„œ ë©ˆì¶¤ GPU/Neuron ë…¸ë“œê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸ë¦¬ì†ŒìŠ¤ ìš”ì²­ì´ ì‚¬ìš© ê°€ëŠ¥í•œ í•˜ë“œì›¨ì–´ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸LeaderWorkerSet ë°°í¬ì˜ ê²½ìš°: LeaderWorkerSet CRDê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ Hugging Face í† í°ì´ hf-token ì‹œí¬ë¦¿ìœ¼ë¡œ ì˜¬ë°”ë¥´ê²Œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸Hugging Face Hubì— ëŒ€í•œ ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸ëª¨ë¸ IDê°€ ì •í™•í•˜ê³  ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸ ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜ gpuMemoryUtilization íŒŒë¼ë¯¸í„° ì¡°ì •(0.8ì—ì„œ 0.7ë¡œ ì¤„ì—¬ë³´ê¸°)ë” í° ëª¨ë¸ì˜ ê²½ìš° í…ì„œ ë³‘ë ¬í™” ì‚¬ìš© ê³ ë ¤ëŒ€ê·œëª¨ ëª¨ë¸ì˜ ê²½ìš° ì—¬ëŸ¬ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” LeaderWorkerSet ë˜ëŠ” Ray ë°°í¬ ì‚¬ìš© Ray ë°°í¬ ë¬¸ì œ KubeRay ì¸í”„ë¼ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸Ray í´ëŸ¬ìŠ¤í„° ìƒíƒœ ë° ì›Œì»¤ ì—°ê²° í™•ì¸Ray ë²„ì „ í˜¸í™˜ì„± í™•ì¸ Triton ë°°í¬ ë¬¸ì œ Triton ì„œë²„ ë¡œê·¸ì—ì„œ ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜ í™•ì¸ëª¨ë¸ ì €ì¥ì†Œ êµ¬ì„± í™•ì¸ì ì ˆí•œ í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ì— ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸  ","version":"Next","tagName":"h3"},{"title":"ë¡œê·¸â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ë¡œê·¸","content":" í”„ë ˆì„ì›Œí¬ì— ë”°ë¥¸ ë°°í¬ ë¡œê·¸ í™•ì¸:  ","version":"Next","tagName":"h3"},{"title":"ë¡œê·¸ í™•ì¸â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ë¡œê·¸-í™•ì¸","content":" # VLLM ë°°í¬ kubectl logs -l app.kubernetes.io/component=&lt;service-name&gt; # Ray ë°°í¬ kubectl logs -l ray.io/node-type=head kubectl logs -l ray.io/node-type=worker # LeaderWorkerSet ë°°í¬ kubectl logs -l leaderworkerset.sigs.k8s.io/role=leader   ","version":"Next","tagName":"h3"},{"title":"ë‹¤ìŒ ë‹¨ê³„â€‹","type":1,"pageTitle":"AI on EKS ì¶”ë¡  ì°¨íŠ¸","url":"/ai-on-eks/ko/docs/blueprints/inference/inference-charts#ë‹¤ìŒ-ë‹¨ê³„","content":" GPU ë°°í¬ë¥¼ ìœ„í•œ GPU ì „ìš© êµ¬ì„± ì‚´í´ë³´ê¸°Inferentia ë°°í¬ë¥¼ ìœ„í•œ Neuron ì „ìš© êµ¬ì„± ì•Œì•„ë³´ê¸° ","version":"Next","tagName":"h2"},{"title":"HuggingFace Optimum Neuronì„ ì‚¬ìš©í•œ Trn1ì—ì„œì˜ Llama 3 íŒŒì¸íŠœë‹","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama-LoRA-Finetuning","content":"","keywords":"","version":"Next"},{"title":"Llama 3ë€?â€‹","type":1,"pageTitle":"HuggingFace Optimum Neuronì„ ì‚¬ìš©í•œ Trn1ì—ì„œì˜ Llama 3 íŒŒì¸íŠœë‹","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama-LoRA-Finetuning#llama-3ë€","content":" Llama 3ëŠ” í…ìŠ¤íŠ¸ ìƒì„±, ìš”ì•½, ë²ˆì—­, ì§ˆì˜ì‘ë‹µê³¼ ê°™ì€ ì‘ì—…ì„ ìœ„í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì…ë‹ˆë‹¤. íŠ¹ì • ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"AWS Trainiumâ€‹","type":1,"pageTitle":"HuggingFace Optimum Neuronì„ ì‚¬ìš©í•œ Trn1ì—ì„œì˜ Llama 3 íŒŒì¸íŠœë‹","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama-LoRA-Finetuning#aws-trainium","content":" AWS Trainium (Trn1) ì¸ìŠ¤í„´ìŠ¤ëŠ” ê³ ì²˜ë¦¬ëŸ‰, ì €ì§€ì—° ë”¥ëŸ¬ë‹ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, Llama 3ì™€ ê°™ì€ ëŒ€ê·œëª¨ ëª¨ë¸ í›ˆë ¨ì— ì´ìƒì ì…ë‹ˆë‹¤. AWS Neuron SDKëŠ” ê³ ê¸‰ ì»´íŒŒì¼ëŸ¬ ê¸°ìˆ ê³¼ í˜¼í•© ì •ë°€ë„ í›ˆë ¨ìœ¼ë¡œ ëª¨ë¸ì„ ìµœì í™”í•˜ì—¬ Trainiumì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼œ ë” ë¹ ë¥´ê³  ì •í™•í•œ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"1. ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"HuggingFace Optimum Neuronì„ ì‚¬ìš©í•œ Trn1ì—ì„œì˜ Llama 3 íŒŒì¸íŠœë‹","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama-LoRA-Finetuning#1-ì†”ë£¨ì…˜-ë°°í¬","content":" ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"2. Llama í›ˆë ¨ ì‘ì—… ì‹œì‘â€‹","type":1,"pageTitle":"HuggingFace Optimum Neuronì„ ì‚¬ìš©í•œ Trn1ì—ì„œì˜ Llama 3 íŒŒì¸íŠœë‹","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama-LoRA-Finetuning#2-llama-í›ˆë ¨-ì‘ì—…-ì‹œì‘","content":" í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹œì‘í•˜ê¸° ì „ì— ë¨¼ì € ìœ í‹¸ë¦¬í‹° íŒŒë“œë¥¼ ë°°í¬í•©ë‹ˆë‹¤. ì´ íŒŒë“œì˜ ëŒ€í™”í˜• ì…¸ì— ì ‘ì†í•˜ì—¬ íŒŒì¸íŠœë‹ ì‘ì—…ì˜ ì§„í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•˜ê³ , íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ì— ì ‘ê·¼í•˜ë©°, ìƒ˜í”Œ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì´ ìƒì„±í•œ ì¶œë ¥ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  kubectl apply -f training-artifact-access-pod.yaml   í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ìš© ConfigMapì„ ìƒì„±í•©ë‹ˆë‹¤:  kubectl apply -f llama3-finetuning-script-configmap.yaml   í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ê°€ HuggingFaceì—ì„œ Llama 3 ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìœ¼ë ¤ë©´ ì¸ì¦ ë° ëª¨ë¸ ì ‘ê·¼ì„ ìœ„í•´ HuggingFace Hub ì ‘ê·¼ í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤. HuggingFace í† í° ìƒì„± ë° ê´€ë¦¬ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ Hugging Face Token Managementë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.  HuggingFace Hub í† í°ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. your_huggingface_hub_access_tokenì„ ì‹¤ì œ HuggingFace Hub ì ‘ê·¼ í† í°ìœ¼ë¡œ ëŒ€ì²´í•˜ì„¸ìš”.  export HUGGINGFACE_HUB_ACCESS_TOKEN=$(echo -n &quot;your_huggingface_hub_access_token&quot; | base64)   ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ Secretê³¼ íŒŒì¸íŠœë‹ Job ë¦¬ì†ŒìŠ¤ë¥¼ ë°°í¬í•©ë‹ˆë‹¤. ì´ ëª…ë ¹ì€ yamlì„ Kubernetes í´ëŸ¬ìŠ¤í„°ì— ì ìš©í•˜ê¸° ì „ì— HUGGINGFACE_HUB_ACCESS_TOKEN í™˜ê²½ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.  ì°¸ê³ : íŒŒì¸íŠœë‹ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ëŠ” us-west-2 ECR ì €ì¥ì†Œì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤. ì´ íŒŒì¸íŠœë‹ ì˜ˆì œë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ì„ íƒí•œ ë¦¬ì „ì— ë”°ë¼ ë‹¤ë¥¸ ì„ í˜¸ ë¦¬ì „ì„ ì œê³µí•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ HuggingFace ì›¹ì‚¬ì´íŠ¸ë¥¼ ê²€í† í•˜ì„¸ìš”. ë‹¤ë¥¸ ì§€ì› ë¦¬ì „ì„ ì„ íƒí•˜ëŠ” ê²½ìš° ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ê¸° ì „ì— lora-finetune-resources.yaml íŒŒì¼ì˜ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ URLì—ì„œ AWS ê³„ì • IDì™€ ë¦¬ì „ì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.  envsubst &lt; lora-finetune-resources.yaml | kubectl apply -f -   ","version":"Next","tagName":"h2"},{"title":"3. íŒŒì¸íŠœë‹ëœ Llama3 ëª¨ë¸ í™•ì¸â€‹","type":1,"pageTitle":"HuggingFace Optimum Neuronì„ ì‚¬ìš©í•œ Trn1ì—ì„œì˜ Llama 3 íŒŒì¸íŠœë‹","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama-LoRA-Finetuning#3-íŒŒì¸íŠœë‹ëœ-llama3-ëª¨ë¸-í™•ì¸","content":" ì‘ì—… ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤:  kubectl get jobs   ì°¸ê³ : ì»¨í…Œì´ë„ˆê°€ ìŠ¤ì¼€ì¤„ë§ë˜ì§€ ì•Šìœ¼ë©´ Karpenter ë¡œê·¸ì—ì„œ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”. ì„ íƒí•œ ê°€ìš© ì˜ì—­(AZ)ì´ë‚˜ ì„œë¸Œë„·ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ trn1.32xlarge EC2 ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ëŠ” ê²½ìš° ì´ëŸ° í˜„ìƒì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ë ¤ë©´ ai-on-eks/infra/base/terraformì— ìˆëŠ” main.tf íŒŒì¼ì˜ local.azs í•„ë“œë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”. ë˜í•œ ai-on-eks/infra/base/terraformì— ìˆëŠ” addons.tf íŒŒì¼ì˜ trainium-trn1 EC2NodeClassê°€ í•´ë‹¹ AZì˜ ì˜¬ë°”ë¥¸ ì„œë¸Œë„·ì„ ì°¸ì¡°í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ê·¸ëŸ° ë‹¤ìŒ ai-on-eks/infra/trainium-inferentiaì—ì„œ install.shë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ Terraformì„ í†µí•´ ë³€ê²½ ì‚¬í•­ì„ ì ìš©í•©ë‹ˆë‹¤.  íŒŒì¸íŠœë‹ ì‘ì—…ì˜ ë¡œê·¸ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê±°ë‚˜, íŠœë‹ëœ ëª¨ë¸ì— ì ‘ê·¼í•˜ê±°ë‚˜, íŒŒì¸íŠœë‹ëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ì—ì„œ ìƒì„±ëœ text-to-SQL ì¶œë ¥ì„ í™•ì¸í•˜ë ¤ë©´ ìœ í‹¸ë¦¬í‹° íŒŒë“œì—ì„œ ì…¸ì„ ì—´ê³  ì´ëŸ¬í•œ í•­ëª©ë“¤ì´ ìˆëŠ” /shared í´ë”ë¡œ ì´ë™í•©ë‹ˆë‹¤. íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì€ llama3_tuned_model_&lt;timestamp&gt; ì´ë¦„ì˜ í´ë”ì— ì €ì¥ë˜ë©°, ìƒ˜í”Œ í”„ë¡¬í”„íŠ¸ì—ì„œ ìƒì„±ëœ SQL ì¿¼ë¦¬ëŠ” ëª¨ë¸ í´ë” ì˜†ì— ìˆëŠ” llama3_finetuning.out ì´ë¦„ì˜ ë¡œê·¸ íŒŒì¼ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  kubectl exec -it training-artifact-access-pod -- /bin/bash cd /shared ls -l llama3_tuned_model* llama3_finetuning*   ","version":"Next","tagName":"h2"},{"title":"4. ì •ë¦¬â€‹","type":1,"pageTitle":"HuggingFace Optimum Neuronì„ ì‚¬ìš©í•œ Trn1ì—ì„œì˜ Llama 3 íŒŒì¸íŠœë‹","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama-LoRA-Finetuning#4-ì •ë¦¬","content":" ì°¸ê³ : ì¶”ê°€ AWS ë¹„ìš©ì„ í”¼í•˜ê¸° ìœ„í•´ í•­ìƒ ì •ë¦¬ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.  ì´ ì†”ë£¨ì…˜ì—ì„œ ìƒì„±ëœ ë¦¬ì†ŒìŠ¤ë¥¼ ì œê±°í•˜ë ¤ë©´ ai-on-eks ì €ì¥ì†Œ ë£¨íŠ¸ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  # Kubernetes ë¦¬ì†ŒìŠ¤ ì‚­ì œ: cd blueprints/training/llama-lora-finetuning-trn1 envsubst &lt; lora-finetune-resources.yaml | kubectl delete -f - kubectl delete -f llama3-finetuning-script-configmap.yaml kubectl delete -f training-artifact-access-pod.yaml   EKS í´ëŸ¬ìŠ¤í„° ë° ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì •ë¦¬:  cd ../../../infra/trainium-inferentia/terraform ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2","content":"","keywords":"","version":"Next"},{"title":"Llama-2ë€?â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#llama-2ë€","content":" Llama-2ëŠ” 2ì¡° ê°œì˜ í…ìŠ¤íŠ¸ ë° ì½”ë“œ í† í°ìœ¼ë¡œ í›ˆë ¨ëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì…ë‹ˆë‹¤. í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ê°€ì¥ í¬ê³  ê°•ë ¥í•œ LLM ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. Llama-2ëŠ” ìì—°ì–´ ì²˜ë¦¬, í…ìŠ¤íŠ¸ ìƒì„±, ë²ˆì—­ ë“± ë‹¤ì–‘í•œ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Llama-2ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì œê³µë˜ì§€ë§Œ, ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ëª¨ë¸ì„ ì²˜ìŒë¶€í„° ì‚¬ì „ í›ˆë ¨í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.  Llama-2-chatâ€‹  Llama-2ëŠ” ì—„ê²©í•œ í›ˆë ¨ ê³¼ì •ì„ ê±°ì¹œ ë›°ì–´ë‚œ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ê³µê°œì ìœ¼ë¡œ ì´ìš© ê°€ëŠ¥í•œ ì˜¨ë¼ì¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ì‚¬ì „ í›ˆë ¨ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.  Llama-2ëŠ” ì„¸ ê°€ì§€ ë‹¤ë¥¸ ëª¨ë¸ í¬ê¸°ë¡œ ì œê³µë©ë‹ˆë‹¤:  Llama-2-70b: 700ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ê°€ì¥ í° Llama-2 ëª¨ë¸ì…ë‹ˆë‹¤. ê°€ì¥ ê°•ë ¥í•œ Llama-2 ëª¨ë¸ì´ë©° ê°€ì¥ ê¹Œë‹¤ë¡œìš´ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Llama-2-13b: 130ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ì¤‘ê°„ í¬ê¸°ì˜ Llama-2 ëª¨ë¸ì…ë‹ˆë‹¤. ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„± ì‚¬ì´ì˜ ì¢‹ì€ ê· í˜•ì„ ì œê³µí•˜ë©° ë‹¤ì–‘í•œ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Llama-2-7b: 70ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§„ ê°€ì¥ ì‘ì€ Llama-2 ëª¨ë¸ì…ë‹ˆë‹¤. ê°€ì¥ íš¨ìœ¨ì ì¸ Llama-2 ëª¨ë¸ì´ë©° ìµœê³  ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì´ í•„ìš”í•˜ì§€ ì•Šì€ ì‘ì—…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì–´ë–¤ Llama-2 ëª¨ë¸ í¬ê¸°ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ë‚˜ìš”?â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#ì–´ë–¤-llama-2-ëª¨ë¸-í¬ê¸°ë¥¼-ì‚¬ìš©í•´ì•¼-í•˜ë‚˜ìš”","content":" ìµœì ì˜ Llama-2 ëª¨ë¸ í¬ê¸°ëŠ” íŠ¹ì • ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ë‹¬ë¼ì§€ë©°, ìµœê³  ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ í•­ìƒ ê°€ì¥ í° ëª¨ë¸ì´ í•„ìš”í•œ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. ì ì ˆí•œ Llama-2 ëª¨ë¸ í¬ê¸°ë¥¼ ì„ íƒí•  ë•Œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤, ì‘ë‹µ ì‹œê°„, ë¹„ìš© íš¨ìœ¨ì„±ê³¼ ê°™ì€ ìš”ì†Œë¥¼ í‰ê°€í•˜ê³  ê³ ë ¤í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ê²°ì •ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª©í‘œì™€ ì œì•½ ì¡°ê±´ì— ëŒ€í•œ ì¢…í•©ì ì¸ í‰ê°€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤.  ì„±ëŠ¥ í–¥ìƒLlama-2ëŠ” GPUì—ì„œ ê³ ì„±ëŠ¥ ì¶”ë¡ ì„ ë‹¬ì„±í•  ìˆ˜ ìˆì§€ë§Œ, Neuron ê°€ì†ê¸°ëŠ” ì„±ëŠ¥ì„ í•œ ë‹¨ê³„ ë” ëŒì–´ì˜¬ë¦½ë‹ˆë‹¤. Neuron ê°€ì†ê¸°ëŠ” ë¨¸ì‹  ëŸ¬ë‹ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•´ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì–´ Llama-2ì˜ ì¶”ë¡  ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¤ëŠ” í•˜ë“œì›¨ì–´ ê°€ì†ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŠ” Trn1/Inf2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ Llama-2ë¥¼ ë°°í¬í•  ë•Œ ë” ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ê³¼ ê°œì„ ëœ ì‚¬ìš©ì ê²½í—˜ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜ ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#ì†”ë£¨ì…˜-ì•„í‚¤í…ì²˜","content":" ì´ ì„¹ì…˜ì—ì„œëŠ” ì†”ë£¨ì…˜ì˜ ì•„í‚¤í…ì²˜ë¥¼ ìì„¸íˆ ì‚´í´ë´…ë‹ˆë‹¤.  Trn1.32xl ì¸ìŠ¤í„´ìŠ¤: ë¨¸ì‹  ëŸ¬ë‹ í›ˆë ¨ ì›Œí¬ë¡œë“œì— ìµœì í™”ëœ EC2 Trn1 (Trainium) ì¸ìŠ¤í„´ìŠ¤ íŒ¨ë°€ë¦¬ì˜ ì¼ë¶€ì¸ EC2 ê°€ì† ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì…ë‹ˆë‹¤.  MPI Worker Pods: MPI (Message Passing Interface) ì‘ì—…ì„ ì‹¤í–‰í•˜ë„ë¡ êµ¬ì„±ëœ Kubernetes íŒŒë“œì…ë‹ˆë‹¤. MPIëŠ” ë¶„ì‚° ë©”ëª¨ë¦¬ ë³‘ë ¬ ì»´í“¨íŒ…ì„ ìœ„í•œ í‘œì¤€ì…ë‹ˆë‹¤. ê° ì›Œì»¤ íŒŒë“œëŠ” 16ê°œì˜ Trainium ê°€ì†ê¸°ì™€ 8ê°œì˜ Elastic Fabric Adapters (EFA)ê°€ ì¥ì°©ëœ trn1.32xlarge ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤. EFAëŠ” Amazon EC2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” ê³ ì„±ëŠ¥ ì»´í“¨íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì§€ì›í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ ì¥ì¹˜ì…ë‹ˆë‹¤.  MPI Launcher Pod: ì›Œì»¤ íŒŒë“œ ì „ì²´ì—ì„œ MPI ì‘ì—…ì„ ì¡°ì •í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•˜ëŠ” íŒŒë“œì…ë‹ˆë‹¤. í›ˆë ¨ ì‘ì—…ì´ í´ëŸ¬ìŠ¤í„°ì— ì²˜ìŒ ì œì¶œë˜ë©´ MPI ëŸ°ì²˜ íŒŒë“œê°€ ìƒì„±ë˜ì–´ ì›Œì»¤ë“¤ì´ ì˜¨ë¼ì¸ ìƒíƒœê°€ ë˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ê³ , ê° ì›Œì»¤ì— ì—°ê²°í•œ ë‹¤ìŒ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.  MPI Operator: Kubernetesì—ì„œ ì˜¤í¼ë ˆì´í„°ëŠ” Kubernetes ì• í”Œë¦¬ì¼€ì´ì…˜ì„ íŒ¨í‚¤ì§•, ë°°í¬ ë° ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. MPI OperatorëŠ” MPI ì›Œí¬ë¡œë“œì˜ ë°°í¬ ë° ê´€ë¦¬ë¥¼ ìë™í™”í•©ë‹ˆë‹¤.  FSx for Lustre: ë¨¸ì‹  ëŸ¬ë‹, ê³ ì„±ëŠ¥ ì»´í“¨íŒ…(HPC), ë¹„ë””ì˜¤ ì²˜ë¦¬, ê¸ˆìœµ ëª¨ë¸ë§ê³¼ ê°™ì€ ì›Œí¬ë¡œë“œì— ì í•©í•œ ê³µìœ  ê³ ì„±ëŠ¥ íŒŒì¼ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. FSx for Lustre íŒŒì¼ ì‹œìŠ¤í…œì€ í›ˆë ¨ ì‘ì—…ì˜ ì›Œì»¤ íŒŒë“œ ê°„ì— ê³µìœ ë˜ì–´ í›ˆë ¨ ë°ì´í„°ì— ì ‘ê·¼í•˜ê³  ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë° ë¡œê·¸ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ì¤‘ì•™ ì €ì¥ì†Œë¥¼ ì œê³µí•©ë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#ì†”ë£¨ì…˜-ë°°í¬","content":" Amazon EKSì—ì„œ AWS Trainiumì„ ì‚¬ìš©í•˜ì—¬ Llama-2ë¥¼ í›ˆë ¨í•˜ëŠ” ë‹¨ê³„  ì°¸ê³ : ì´ ê²Œì‹œë¬¼ì€ Metaì˜ Llama í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ë©°, í† í¬ë‚˜ì´ì € íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê¸° ì „ì— ìˆ˜ë½í•´ì•¼ í•˜ëŠ” ì‚¬ìš©ì ë¼ì´ì„ ìŠ¤ë¡œ ë³´í˜¸ë©ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ì ‘ê·¼ ê¶Œí•œì„ ìš”ì²­í•˜ì—¬ Llama íŒŒì¼ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.  ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"ë¶„ì‚° í›ˆë ¨â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#ë¶„ì‚°-í›ˆë ¨","content":" EKS í´ëŸ¬ìŠ¤í„°ê°€ ë°°í¬ë˜ë©´ neuronx-nemo-megatron ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ê³  ì´ë¯¸ì§€ë¥¼ ECRì— í‘¸ì‹œí•˜ëŠ” ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"neuronx-nemo-megatron ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¹Œë“œâ€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#neuronx-nemo-megatron-ì»¨í…Œì´ë„ˆ-ì´ë¯¸ì§€-ë¹Œë“œ","content":" examples/llama2 ë””ë ‰í† ë¦¬ë¡œ ì´ë™  cd examples/llama2/   1-llama2-neuronx-pretrain-build-image.sh ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ neuronx-nemo-megatron ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ê³  ECRì— ì´ë¯¸ì§€ë¥¼ í‘¸ì‹œí•©ë‹ˆë‹¤.  ë¦¬ì „ì„ ì…ë ¥í•˜ë¼ëŠ” ë©”ì‹œì§€ê°€ í‘œì‹œë˜ë©´ ìœ„ì—ì„œ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ì‹œì‘í•œ ë¦¬ì „ì„ ì…ë ¥í•˜ì„¸ìš”.  ./1-llama2-neuronx-pretrain-build-image.sh   ì°¸ê³ : ì´ë¯¸ì§€ ë¹Œë“œ ë° ECR í‘¸ì‹œì—ëŠ” ì•½ 10ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤  ","version":"Next","tagName":"h3"},{"title":"CLI íŒŒë“œ ì‹œì‘ ë° ì—°ê²°â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#cli-íŒŒë“œ-ì‹œì‘-ë°-ì—°ê²°","content":" ì´ ë‹¨ê³„ì—ì„œëŠ” ê³µìœ  FSx ìŠ¤í† ë¦¬ì§€ì— ëŒ€í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ ìŠ¤í† ë¦¬ì§€ì— íŒŒì¼ì„ ë³µì‚¬í•˜ë ¤ë©´ ë¨¼ì € ìœ„ì—ì„œ ìƒì„±í•œ neuronx-nemo-megatron Docker ì´ë¯¸ì§€ë¥¼ ì‹¤í–‰í•˜ëŠ” CLI íŒŒë“œë¥¼ ì‹œì‘í•˜ê³  ì—°ê²°í•©ë‹ˆë‹¤.  ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ CLI íŒŒë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤:  ./2-launch-cmd-shell-pod.sh   ë‹¤ìŒìœ¼ë¡œ, CLI íŒŒë“œê°€ 'Running' ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ë‹¤ìŒ ëª…ë ¹ì„ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl get pod -w   CLI íŒŒë“œê°€ 'Running' ìƒíƒœê°€ ë˜ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ì—°ê²°í•©ë‹ˆë‹¤:  kubectl exec -it cli-cmd-shell -- /bin/bash   ","version":"Next","tagName":"h3"},{"title":"Llama í† í¬ë‚˜ì´ì € ë° Redpajama ë°ì´í„°ì…‹ì„ FSxì— ë‹¤ìš´ë¡œë“œâ€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#llama-í† í¬ë‚˜ì´ì €-ë°-redpajama-ë°ì´í„°ì…‹ì„-fsxì—-ë‹¤ìš´ë¡œë“œ","content":" CLI íŒŒë“œ ë‚´ì—ì„œ Llama í† í¬ë‚˜ì´ì € íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. ì´ íŒŒì¼ë“¤ì€ Metaì˜ Llama ë¼ì´ì„ ìŠ¤ë¡œ ë³´í˜¸ë˜ë¯€ë¡œ huggingface-cli login ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ì ‘ê·¼ í† í°ìœ¼ë¡œ Hugging Faceì— ë¡œê·¸ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ì ‘ê·¼ í† í°ì€ Hugging Face ì›¹ì‚¬ì´íŠ¸ì˜ Settings -&gt; Access Tokensì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  huggingface-cli login   í† í°ì„ ì…ë ¥í•˜ë¼ëŠ” ë©”ì‹œì§€ê°€ í‘œì‹œë˜ë©´ ì ‘ê·¼ í† í°ì„ ë¶™ì—¬ë„£ê³  ENTERë¥¼ ëˆ„ë¦…ë‹ˆë‹¤.  ë‹¤ìŒìœ¼ë¡œ, ë‹¤ìŒ python ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ llama7-7b í† í¬ë‚˜ì´ì € íŒŒì¼ì„ /shared/llama7b_tokenizerì— ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤:  python3 &lt;&lt;EOF import transformers tok = transformers.AutoTokenizer.from_pretrained(&quot;meta-llama/Llama-2-7b-hf&quot;) tok.save_pretrained(&quot;/shared/llama7b_tokenizer&quot;) EOF   ë‹¤ìŒìœ¼ë¡œ, RedPajama-Data-1T-Sample ë°ì´í„°ì…‹(10ì–µ ê°œì˜ í† í°ì„ í¬í•¨í•˜ëŠ” ì „ì²´ RedPajama ë°ì´í„°ì…‹ì˜ ì‘ì€ í•˜ìœ„ ì§‘í•©)ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.  CLI íŒŒë“œì— ì—°ê²°ëœ ìƒíƒœì—ì„œ gitì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤  cd /shared git clone https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T-Sample \\ data/RedPajama-Data-1T-Sample   ","version":"Next","tagName":"h3"},{"title":"ë°ì´í„°ì…‹ í† í°í™”â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#ë°ì´í„°ì…‹-í† í°í™”","content":" neuronx-nemo-megatronì— í¬í•¨ëœ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ í† í°í™”í•©ë‹ˆë‹¤. ì´ ì „ì²˜ë¦¬ ë‹¨ê³„ëŠ” trn1.32xl ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì•½ 60ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤.  cd /shared # í•„ìš”í•œ ìŠ¤í¬ë¦½íŠ¸ê°€ í¬í•¨ëœ neuronx-nemo-megatron ì €ì¥ì†Œ í´ë¡  git clone https://github.com/aws-neuron/neuronx-nemo-megatron.git # ê°œë³„ redpajama íŒŒì¼ì„ ë‹¨ì¼ jsonl íŒŒì¼ë¡œ ê²°í•© cat /shared/data/RedPajama-Data-1T-Sample/*.jsonl &gt; /shared/redpajama_sample.jsonl # llama í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ python3 neuronx-nemo-megatron/nemo/scripts/nlp_language_modeling/preprocess_data_for_megatron.py \\ --input=/shared/redpajama_sample.jsonl \\ --json-keys=text \\ --tokenizer-library=huggingface \\ --tokenizer-type=/shared/llama7b_tokenizer \\ --dataset-impl=mmap \\ --output-prefix=/shared/data/redpajama_sample \\ --append-eod \\ --need-pad-id \\ --workers=32   ","version":"Next","tagName":"h3"},{"title":"í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë°ì´í„°ì…‹ ë° í† í¬ë‚˜ì´ì € ê²½ë¡œ ìˆ˜ì •â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#í›ˆë ¨-ìŠ¤í¬ë¦½íŠ¸ì—ì„œ-ë°ì´í„°ì…‹-ë°-í† í¬ë‚˜ì´ì €-ê²½ë¡œ-ìˆ˜ì •","content":" ì°¸ê³ : ë‚˜ì¤‘ì— EKSì—ì„œ í›ˆë ¨ ì‘ì—…ì„ ì‹œì‘í•  ë•Œ í›ˆë ¨ íŒŒë“œëŠ” FSxì˜ neuronx-nemo-megatron/nemo/examples ë””ë ‰í† ë¦¬ì—ì„œ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë“  ë³€ê²½ ì‚¬í•­ì— ëŒ€í•´ neuronx-nemo-megatron ì»¨í…Œì´ë„ˆë¥¼ ë‹¤ì‹œ ë¹Œë“œí•˜ì§€ ì•Šê³ ë„ FSxì—ì„œ ì§ì ‘ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆì–´ í¸ë¦¬í•©ë‹ˆë‹¤.  test_llama.sh ìŠ¤í¬ë¦½íŠ¸ /shared/neuronx-nemo-megatron/nemo/examples/nlp/language_modeling/test_llama.shë¥¼ ìˆ˜ì •í•˜ì—¬ ë‹¤ìŒ ë‘ ì¤„ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì´ ì¤„ë“¤ì€ í›ˆë ¨ íŒŒë“œ ì›Œì»¤ì—ê²Œ FSx íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ Llama í† í¬ë‚˜ì´ì €ì™€ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìœ„ì¹˜ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.  ì‹¤í–‰:  sed -i 's#^\\(: ${TOKENIZER_PATH=\\).*#\\1/shared/llama7b_tokenizer}#' /shared/neuronx-nemo-megatron/nemo/examples/nlp/language_modeling/test_llama.sh sed -i 's#^\\(: ${DATASET_PATH=\\).*#\\1/shared/data/redpajama_sample_text_document}#' /shared/neuronx-nemo-megatron/nemo/examples/nlp/language_modeling/test_llama.sh   ë³€ê²½ ì „:  : ${TOKENIZER_PATH=$HOME/llamav2_weights/7b-hf} : ${DATASET_PATH=$HOME/examples_datasets/llama_7b/book.jsonl-processed_text_document}   ë³€ê²½ í›„:  : ${TOKENIZER_PATH=/shared/llama7b_tokenizer} : ${DATASET_PATH=/shared/data/redpajama_sample_text_document}   nanoì—ì„œ ë³€ê²½ ì‚¬í•­ì„ ì €ì¥í•˜ë ¤ë©´ CTRL-Xë¥¼ ëˆ„ë¥¸ ë‹¤ìŒ yë¥¼ ëˆ„ë¥´ê³  ENTERë¥¼ ëˆ„ë¦…ë‹ˆë‹¤.  ì™„ë£Œë˜ë©´ exitë¥¼ ì…ë ¥í•˜ê±°ë‚˜ CTRL-dë¥¼ ëˆŒëŸ¬ CLI íŒŒë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.  CLI íŒŒë“œê°€ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šìœ¼ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl delete pod cli-cmd-shell   ì´ì œ ì‚¬ì „ ì»´íŒŒì¼ ë° í›ˆë ¨ ì‘ì—…ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!  ë¨¼ì € ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ MPI ì˜¤í¼ë ˆì´í„°ê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤:  kubectl get all -n mpi-operator   MPI Operatorê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì§„í–‰í•˜ê¸° ì „ì— MPI Operator ì„¤ì¹˜ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”.  í›ˆë ¨ ì‘ì—…ì„ ì‹¤í–‰í•˜ê¸° ì „ì— ë¨¼ì € ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì¤€ë¹„í•˜ê¸° ìœ„í•´ ì‚¬ì „ ì»´íŒŒì¼ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ëŠ” Llama-2-7b ëª¨ë¸ì˜ ê¸°ë³¸ ì»´í“¨íŠ¸ ê·¸ë˜í”„ë¥¼ ì¶”ì¶œí•˜ê³  ì»´íŒŒì¼í•˜ì—¬ Trainium ê°€ì†ê¸°ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” Neuron ì‹¤í–‰ íŒŒì¼(NEFF)ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ NEFFëŠ” FSxì˜ ì˜êµ¬ Neuron ìºì‹œì— ì €ì¥ë˜ì–´ ë‚˜ì¤‘ì— í›ˆë ¨ ì‘ì—…ì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ì „ ì»´íŒŒì¼ ì‘ì—… ì‹¤í–‰â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#ì‚¬ì „-ì»´íŒŒì¼-ì‘ì—…-ì‹¤í–‰","content":" ì‚¬ì „ ì»´íŒŒì¼ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰  ./3-llama2-neuronx-mpi-compile.sh   4ê°œì˜ trn1.32xlarge ë…¸ë“œë¥¼ ì‚¬ìš©í•  ë•Œ ì‚¬ì „ ì»´íŒŒì¼ì€ ì•½ 10ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤.  kubectl get pods | grep compileì„ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ì»´íŒŒì¼ ì‘ì—…ì´ 'Completed'ë¡œ í‘œì‹œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.  ì‚¬ì „ ì»´íŒŒì¼ì´ ì™„ë£Œë˜ë©´ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ 4ê°œì˜ trn1.32xl ë…¸ë“œì—ì„œ ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  ","version":"Next","tagName":"h3"},{"title":"í›ˆë ¨ ì‘ì—… ì‹¤í–‰â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#í›ˆë ¨-ì‘ì—…-ì‹¤í–‰","content":" ./4-llama2-neuronx-mpi-train.sh   ","version":"Next","tagName":"h3"},{"title":"í›ˆë ¨ ì‘ì—… ì¶œë ¥ ë³´ê¸°â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#í›ˆë ¨-ì‘ì—…-ì¶œë ¥-ë³´ê¸°","content":" í›ˆë ¨ ì‘ì—… ì¶œë ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ë ¤ë©´ ë¨¼ì € í›ˆë ¨ ì‘ì—…ê³¼ ì—°ê²°ëœ ëŸ°ì²˜ íŒŒë“œì˜ ì´ë¦„ì„ ì°¾ìŠµë‹ˆë‹¤:  kubectl get pods | grep launcher   ëŸ°ì²˜ íŒŒë“œì˜ ì´ë¦„ì„ í™•ì¸í•˜ê³  'Running' ìƒíƒœì¸ ê²ƒì„ í™•ì¸í•œ í›„ ë‹¤ìŒ ë‹¨ê³„ëŠ” UIDë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì—ì„œ test-mpi-train-launcher-xxxë¥¼ ì‹¤ì œ ëŸ°ì²˜ íŒŒë“œ ì´ë¦„ìœ¼ë¡œ ëŒ€ì²´í•˜ë©´ UIDê°€ ì¶œë ¥ë©ë‹ˆë‹¤:  kubectl get pod test-mpi-train-launcher-xxx -o json | jq -r &quot;.metadata.uid&quot;   UIDë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œê·¸ ê²½ë¡œë¥¼ í™•ì¸í•˜ê³  í›ˆë ¨ ë¡œê·¸ë¥¼ tailí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì—ì„œ UIDë¥¼ ìœ„ì˜ ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ì„¸ìš”.  kubectl exec -it test-mpi-train-worker-0 -- tail -f /shared/nemo_experiments/UID/0/log   ë¡œê·¸ í™•ì¸ì´ ì™„ë£Œë˜ë©´ CTRL-Cë¥¼ ëˆŒëŸ¬ tail ëª…ë ¹ì„ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Trainium ê°€ì†ê¸° í™œìš©ë¥  ëª¨ë‹ˆí„°ë§â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#trainium-ê°€ì†ê¸°-í™œìš©ë¥ -ëª¨ë‹ˆí„°ë§","content":" Trainium ê°€ì†ê¸° í™œìš©ë¥ ì„ ëª¨ë‹ˆí„°ë§í•˜ë ¤ë©´ neuron-top ëª…ë ¹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Neuron-topì€ trn1/inf2/inf1 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ Neuron ë° ì‹œìŠ¤í…œ ê´€ë ¨ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•œ ì½˜ì†” ê¸°ë°˜ ë„êµ¬ì…ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ì›Œì»¤ íŒŒë“œ ì¤‘ í•˜ë‚˜ì—ì„œ neuron-topì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl exec -it test-mpi-train-worker-0 -- /bin/bash -l neuron-top   ","version":"Next","tagName":"h3"},{"title":"TensorBoardì—ì„œ í›ˆë ¨ ì‘ì—… ë©”íŠ¸ë¦­ ë³´ê¸°â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#tensorboardì—ì„œ-í›ˆë ¨-ì‘ì—…-ë©”íŠ¸ë¦­-ë³´ê¸°","content":" TensorBoardëŠ” í›ˆë ¨ ì‘ì—…ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  íƒìƒ‰í•˜ëŠ” ë° ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì›¹ ê¸°ë°˜ ì‹œê°í™” ë„êµ¬ì…ë‹ˆë‹¤. í›ˆë ¨ ë©”íŠ¸ë¦­ì„ ë¹ ë¥´ê²Œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìœ¼ë©° ì„œë¡œ ë‹¤ë¥¸ í›ˆë ¨ ì‹¤í–‰ ê°„ì˜ ë©”íŠ¸ë¦­ì„ ì‰½ê²Œ ë¹„êµí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  TensorBoard ë¡œê·¸ëŠ” FSx for Lustre íŒŒì¼ ì‹œìŠ¤í…œì˜ /shared/nemo_experiments/ ë””ë ‰í† ë¦¬ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ Llama-2 í›ˆë ¨ ì‘ì—… ì§„í–‰ ìƒí™©ì„ ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” TensorBoard ë°°í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:  ./5-deploy-tensorboard.sh   ë°°í¬ê°€ ì¤€ë¹„ë˜ë©´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìƒˆ TensorBoard ë°°í¬ì— ëŒ€í•œ ì•”í˜¸ë¡œ ë³´í˜¸ëœ URLì„ ì¶œë ¥í•©ë‹ˆë‹¤.  URLì„ ì‹¤í–‰í•˜ì—¬ í›ˆë ¨ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•©ë‹ˆë‹¤.  TensorBoard ì¸í„°í˜ì´ìŠ¤ë¥¼ ì—´ë©´ ì™¼ìª½ ë©”ë‰´ì—ì„œ í›ˆë ¨ ì‘ì—… UIDë¥¼ ì„ íƒí•œ ë‹¤ìŒ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì°½ì—ì„œ ë‹¤ì–‘í•œ í›ˆë ¨ ë©”íŠ¸ë¦­(ì˜ˆ: reduced-train-loss, throughput, grad-norm)ì„ íƒìƒ‰í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"í›ˆë ¨ ì‘ì—… ì¤‘ì§€â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#í›ˆë ¨-ì‘ì—…-ì¤‘ì§€","content":" í›ˆë ¨ ì‘ì—…ì„ ì¤‘ì§€í•˜ê³  ëŸ°ì²˜/ì›Œì»¤ íŒŒë“œë¥¼ ì œê±°í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl delete mpijob test-mpi-train   ê·¸ëŸ° ë‹¤ìŒ kubectl get podsë¥¼ ì‹¤í–‰í•˜ì—¬ ëŸ°ì²˜/ì›Œì»¤ íŒŒë“œê°€ ì œê±°ë˜ì—ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Trainium, Neuronx-Nemo-Megatron ë° MPI operatorë¥¼ ì‚¬ìš©í•œ Llama-2 ëª¨ë¸ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/Llama2#ì •ë¦¬","content":" ì´ ì†”ë£¨ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë¦¬ì†ŒìŠ¤ë¥¼ ì œê±°í•˜ë ¤ë©´ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:  cd ai-on-eks/infra/trainium-inferentia ./cleanup.sh  ","version":"Next","tagName":"h3"},{"title":"AI ì›Œí¬ë¡œë“œ ê°€ì´ë“œ","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance","content":"AI ì›Œí¬ë¡œë“œ ê°€ì´ë“œ ì´ ì„¹ì…˜ì€ Amazon EKSì—ì„œ AI ì›Œí¬ë¡œë“œë¥¼ êµ¬ì¶•í•˜ê³  ë°°í¬í•˜ëŠ” ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ ê°€ì´ë“œ ëª¨ìŒì…ë‹ˆë‹¤. ë³´ê³  ì‹¶ì€ ì£¼ì œì— ëŒ€í•œ ì•„ì´ë””ì–´ê°€ ìˆìœ¼ì‹œë©´, ì´ìŠˆë¥¼ ì—´ê³  ë…¼ì˜ë¥¼ ì‹œì‘í•´ ì£¼ì„¸ìš”. ì •ë³´ ì´ ì½˜í…ì¸ ëŠ” ì´ ë¶„ì•¼ì˜ íŒ¨í„´ ë°œì „ì— ë”°ë¼ ì •ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•  ê³„íšì¸ ì§„í™”í•˜ëŠ” ì½˜í…ì¸ ì…ë‹ˆë‹¤.","keywords":"","version":"Next"},{"title":"ë²¤ì¹˜ë§ˆí‚¹ ê°€ì´ë“œ (Inference Perf ì‚¬ìš©)","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking","content":"","keywords":"","version":"Next"},{"title":"ì´ ê°€ì´ë“œì—ì„œ ë‹¤ë£¨ëŠ” ë‚´ìš©â€‹","type":1,"pageTitle":"ë²¤ì¹˜ë§ˆí‚¹ ê°€ì´ë“œ (Inference Perf ì‚¬ìš©)","url":"/ai-on-eks/ko/docs/guidance/benchmarking#ì´-ê°€ì´ë“œì—ì„œ-ë‹¤ë£¨ëŠ”-ë‚´ìš©","content":" ì´ ê°€ì´ë“œëŠ” LLM ì¶”ë¡  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ì— ëŒ€í•œ í¬ê´„ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤:  ë²¤ì¹˜ë§ˆí¬ ê³¼ì œ ì´í•´í•˜ê¸° - LLM ë²¤ì¹˜ë§ˆí‚¹ì´ ë³µì¡í•œ ì´ìœ ì™€ ê¸°ì¡´ AI ëª¨ë¸ê³¼ì˜ ì°¨ì´ì LLM ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ í•µì‹¬ ë©”íŠ¸ë¦­ - í•„ìˆ˜ ë©”íŠ¸ë¦­(TTFT, ITL, TPS)ê³¼ ë°°í¬ì—ì„œì˜ ì˜ë¯¸Inference Perfë¡œ ë²¤ì¹˜ë§ˆí‚¹í•˜ê¸° - í‘œì¤€í™”ëœ Inference Perf ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì„±ëŠ¥ ì¸¡ì •í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ - ë² ì´ìŠ¤ë¼ì¸, í¬í™”, í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì‹¤ìš©ì ì¸ ì˜ˆì œë¦¬ì†ŒìŠ¤ - ì™„ì „í•œ ë°°í¬ ì˜ˆì œ ë° ì°¸ì¡° êµ¬ì„± ","version":"Next","tagName":"h2"},{"title":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2","content":"","keywords":"","version":"Next"},{"title":"Llama-2ë€?â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#llama-2ë€","content":" Llama-2ëŠ” í…ìŠ¤íŠ¸ ìƒì„±, ìš”ì•½, ë²ˆì—­, ì§ˆì˜ì‘ë‹µ ë“± ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ì‘ì—…ì„ ìœ„í•´ ì„¤ê³„ëœ ìµœì²¨ë‹¨ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì…ë‹ˆë‹¤. íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ íŒŒì¸íŠœë‹í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ë¶„ì‚° í›ˆë ¨ì„ ìœ„í•œ RayTrainê³¼ KubeRayì˜ ì¥ì â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#ë¶„ì‚°-í›ˆë ¨ì„-ìœ„í•œ-raytrainê³¼-kuberayì˜-ì¥ì ","content":" Llama-2ì™€ ê°™ì€ ëŒ€ê·œëª¨ ëª¨ë¸ì€ ë°©ëŒ€í•œ ì»´í“¨íŒ… ë° ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ì¸í•´ ë¶„ì‚° í›ˆë ¨ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. RayTrainê³¼ KubeRayì˜ ì¡°í•©ì€ íŠ¹íˆ AWS Trainiumê³¼ í•¨ê»˜ í™œìš©í•  ë•Œ ì´ëŸ¬í•œ ìš”êµ¬ì‚¬í•­ì„ íš¨ìœ¨ì ì´ê³  íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤:  RayTrain:â€‹  ê°„ì†Œí™”ëœ ë¶„ì‚° í›ˆë ¨: RayTrainì€ ë¶„ì‚° í›ˆë ¨ì˜ ë³µì¡ì„±ì„ ì¶”ìƒí™”í•˜ëŠ” Ray í”„ë ˆì„ì›Œí¬ ê¸°ë°˜ì˜ ê³ ìˆ˜ì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ìµœì†Œí•œì˜ ì½”ë“œ ë³€ê²½ìœ¼ë¡œ ì—¬ëŸ¬ ë…¸ë“œì— ê±¸ì³ Llama-2 í›ˆë ¨ì„ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Rayì˜ ì•¡í„° ê¸°ë°˜ ì•„í‚¤í…ì²˜ì™€ íƒœìŠ¤í¬ ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬ëŠ” ë¶„ì‚° ì›Œí¬ë¡œë“œì˜ íš¨ìœ¨ì ì¸ ì‹¤í–‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.ìœ ì—°í•œ ì „ëµ: RayTrainì€ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ì™€ ëª¨ë¸ ë³‘ë ¬ ì²˜ë¦¬ì™€ ê°™ì€ ë‹¤ì–‘í•œ ë¶„ì‚° í›ˆë ¨ ì „ëµì„ ì§€ì›í•©ë‹ˆë‹¤. ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ëŠ” ë°ì´í„°ì…‹ì„ ì—¬ëŸ¬ ë…¸ë“œì— ë¶„í• í•˜ê³ , ëª¨ë¸ ë³‘ë ¬ ì²˜ë¦¬ëŠ” ëª¨ë¸ ìì²´ë¥¼ ë¶„í• í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìœ ì—°ì„±ìœ¼ë¡œ ëª¨ë¸ì˜ íŠ¹ì • ìš”êµ¬ì‚¬í•­ê³¼ í›ˆë ¨ í™˜ê²½ì˜ ì•„í‚¤í…ì²˜ì— ë”°ë¼ í›ˆë ¨ì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.ì¥ì•  í—ˆìš©: RayTrainì—ëŠ” ë‚´ì¥ëœ ì¥ì•  í—ˆìš© ë©”ì»¤ë‹ˆì¦˜ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë…¸ë“œê°€ ì‹¤íŒ¨í•˜ë©´ Rayê°€ ë‹¤ë¥¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë…¸ë“œì—ì„œ íƒœìŠ¤í¬ë¥¼ ì¬ìŠ¤ì¼€ì¤„ë§í•˜ì—¬ í›ˆë ¨ ì‘ì—…ì´ ì¤‘ë‹¨ ì—†ì´ ê³„ì†ë©ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ëŒ€ê·œëª¨ ë¶„ì‚° í›ˆë ¨ í™˜ê²½ì—ì„œ ê²¬ê³ ì„±ì„ ìœ ì§€í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.ì‚¬ìš© í¸ì˜ì„±: RayTrainì€ ë¶„ì‚° í›ˆë ¨ ì‘ì—…ì˜ ì„¤ì •ê³¼ ì‹¤í–‰ì„ ë‹¨ìˆœí™”í•˜ëŠ” ì§ê´€ì ì¸ APIë¥¼ ì œê³µí•©ë‹ˆë‹¤. Hugging Face Transformersì™€ ê°™ì€ ì¸ê¸° ìˆëŠ” ë¨¸ì‹  ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ì˜ í†µí•©ìœ¼ë¡œ ê´‘ë²”ìœ„í•œ ìˆ˜ì • ì—†ì´ ê¸°ì¡´ ì›Œí¬í”Œë¡œìš°ì— RayTrainì„ ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  KubeRay:â€‹  Kubernetesì™€ì˜ í†µí•©: KubeRayëŠ” Kubernetesì˜ ë„¤ì´í‹°ë¸Œ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ Ray í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬, ê´€ë¦¬ ë° í™•ì¥í•©ë‹ˆë‹¤. ì´ í†µí•©ìœ¼ë¡œ Kubernetesì˜ ê°•ë ¥í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ Ray ì›Œí¬ë¡œë“œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.ë™ì  ìŠ¤ì¼€ì¼ë§: KubeRayëŠ” Ray í´ëŸ¬ìŠ¤í„°ì˜ ë™ì  ìŠ¤ì¼€ì¼ë§ì„ ì§€ì›í•©ë‹ˆë‹¤. Rayì˜ ë‚´ì¥ ì˜¤í† ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì›Œí¬ë¡œë“œ ìš”êµ¬ì— ë”°ë¼ ì¶”ê°€ ì•¡í„° ë ˆí”Œë¦¬ì¹´ë¥¼ ìš”ì²­í•  ìˆ˜ ìˆìœ¼ë©°, Karpenterë‚˜ Cluster Autoscalerì™€ ê°™ì€ Kubernetes ë„êµ¬ê°€ ì´ëŸ¬í•œ ìš”êµ¬ë¥¼ ì¶©ì¡±í•˜ê¸° ìœ„í•´ ìƒˆ ë…¸ë“œ ìƒì„±ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§: ì»´í“¨íŒ… ë¶€í•˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ë” ë§ì€ ì›Œì»¤ ë…¸ë“œë¥¼ ì¶”ê°€í•˜ì—¬ Ray í´ëŸ¬ìŠ¤í„°ë¥¼ ìˆ˜í‰ìœ¼ë¡œ í™•ì¥í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëŒ€ê·œëª¨ ë¶„ì‚° í›ˆë ¨ ë° ì¶”ë¡  ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Custom Resource Definitions (CRDs): KubeRayëŠ” Kubernetes CRDë¥¼ í™œìš©í•˜ì—¬ Ray í´ëŸ¬ìŠ¤í„°ì™€ ì‘ì—…ì„ ì •ì˜í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤. ì´ëŠ” Kubernetes ì—ì½”ì‹œìŠ¤í…œ ë‚´ì—ì„œ Ray ì›Œí¬ë¡œë“œë¥¼ ì²˜ë¦¬í•˜ëŠ” í‘œì¤€í™”ëœ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.ì¥ì•  í—ˆìš©: KubeRayëŠ” Kubernetesì˜ ìê°€ ì¹˜ìœ  ê¸°ëŠ¥ì„ í™œìš©í•©ë‹ˆë‹¤. Ray í—¤ë“œ ë…¸ë“œë‚˜ ì›Œì»¤ ë…¸ë“œê°€ ì‹¤íŒ¨í•˜ë©´ Kubernetesê°€ ìë™ìœ¼ë¡œ ì‹¤íŒ¨í•œ êµ¬ì„± ìš”ì†Œë¥¼ ë‹¤ì‹œ ì‹œì‘í•˜ì—¬ ìµœì†Œí•œì˜ ë‹¤ìš´íƒ€ì„ê³¼ ì§€ì†ì ì¸ ìš´ì˜ì„ ë³´ì¥í•©ë‹ˆë‹¤.ë¶„ì‚° ìŠ¤ì¼€ì¤„ë§: Rayì˜ ì•¡í„° ê¸°ë°˜ ëª¨ë¸ê³¼ ë¶„ì‚° íƒœìŠ¤í¬ ìŠ¤ì¼€ì¤„ë§ì´ Kubernetesì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ê³¼ ê²°í•©ë˜ì–´ ë…¸ë“œ ì¥ì•  ë°œìƒ ì‹œì—ë„ ê³ ê°€ìš©ì„±ê³¼ íš¨ìœ¨ì ì¸ íƒœìŠ¤í¬ ì‹¤í–‰ì„ ë³´ì¥í•©ë‹ˆë‹¤.ì„ ì–¸ì  êµ¬ì„±: KubeRayë¥¼ ì‚¬ìš©í•˜ë©´ ì„ ì–¸ì  YAML êµ¬ì„±ì„ ì‚¬ìš©í•˜ì—¬ Ray í´ëŸ¬ìŠ¤í„°ì™€ ì‘ì—…ì„ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë°°í¬ ë° ê´€ë¦¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ìˆœí™”í•˜ì—¬ Ray í´ëŸ¬ìŠ¤í„°ë¥¼ ë” ì‰½ê²Œ ì„¤ì •í•˜ê³  ìœ ì§€ ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.í†µí•© ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§: KubeRayëŠ” Prometheus ë° Grafanaì™€ ê°™ì€ Kubernetesì˜ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ë„êµ¬ì™€ í†µí•©ë©ë‹ˆë‹¤. ì´ëŠ” Ray í´ëŸ¬ìŠ¤í„°ì˜ ì„±ëŠ¥ê³¼ ìƒíƒœì— ëŒ€í•œ í¬ê´„ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì—¬ ë””ë²„ê¹…ê³¼ ìµœì í™”ë¥¼ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤: Kubernetesì˜ ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ ì§€ì›ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ìš© íš¨ìœ¨ì ìœ¼ë¡œ Ray í´ëŸ¬ìŠ¤í„°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•„ìš”ì— ë”°ë¼ í™•ì¥í•˜ëŠ” ëŠ¥ë ¥ì„ ìœ ì§€í•˜ë©´ì„œ ì €ë¹„ìš© ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  AWS Trainium:â€‹  ë”¥ëŸ¬ë‹ì— ìµœì í™”: AWS Trainium ê¸°ë°˜ Trn1 ì¸ìŠ¤í„´ìŠ¤ëŠ” ë”¥ëŸ¬ë‹ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•´ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ë†’ì€ ì²˜ë¦¬ëŸ‰ê³¼ ë‚®ì€ ì§€ì—° ì‹œê°„ì„ ì œê³µí•˜ì—¬ Llama-2ì™€ ê°™ì€ ëŒ€ê·œëª¨ ëª¨ë¸ í›ˆë ¨ì— ì´ìƒì ì…ë‹ˆë‹¤. Trainium ì¹©ì€ ê¸°ì¡´ í”„ë¡œì„¸ì„œì— ë¹„í•´ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí•˜ì—¬ í›ˆë ¨ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.Neuron SDK: AWS Neuron SDKëŠ” Trainiumì— ë§ê²Œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ìµœì í™”í•˜ë„ë¡ ë§ì¶¤í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê³ ê¸‰ ì»´íŒŒì¼ëŸ¬ ìµœì í™”ì™€ í˜¼í•© ì •ë°€ë„ í›ˆë ¨ ì§€ì›ê³¼ ê°™ì€ ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬ ì •í™•ë„ë¥¼ ìœ ì§€í•˜ë©´ì„œ í›ˆë ¨ ì›Œí¬ë¡œë“œë¥¼ ë”ìš± ê°€ì†í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì´ ì¡°í•©ì´ ê°•ë ¥í•œ ì´ìœ â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#ì´-ì¡°í•©ì´-ê°•ë ¥í•œ-ì´ìœ ","content":" ê°„ì†Œí™”ëœ ìŠ¤ì¼€ì¼ë§: RayTrainê³¼ KubeRayëŠ” ì—¬ëŸ¬ ë…¸ë“œì— ê±¸ì¹œ Llama-2 í›ˆë ¨ ìŠ¤ì¼€ì¼ë§ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤. Rayì˜ íš¨ìœ¨ì ì¸ ë¶„ì‚° ì‹¤í–‰ê³¼ KubeRayì˜ Kubernetes ë„¤ì´í‹°ë¸Œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ìœ¼ë¡œ Trn1 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ AWS Trainiumì˜ ì „ì²´ ì„±ëŠ¥ì„ í™œìš©í•˜ê¸° ìœ„í•´ í›ˆë ¨ ì›Œí¬ë¡œë“œë¥¼ ì‰½ê²Œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.ìµœì í™”ëœ ì„±ëŠ¥: Neuron SDKëŠ” Trainiumì˜ ì•„í‚¤í…ì²˜ì— ë§ê²Œ íŠ¹ë³„íˆ ìµœì í™”í•˜ì—¬ í›ˆë ¨ ì‘ì—…ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. Rayì˜ íš¨ìœ¨ì ì¸ ë¶„ì‚° íƒœìŠ¤í¬ ê´€ë¦¬ì™€ KubeRayì˜ ë¦¬ì†ŒìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ê³¼ ê²°í•©í•˜ì—¬ ì´ ì„¤ì •ì€ ìµœì ì˜ í›ˆë ¨ ì„±ëŠ¥ì„ ë³´ì¥í•©ë‹ˆë‹¤.ë¹„ìš© íš¨ìœ¨ì„±: Rayì˜ ì˜¤í† ìŠ¤ì¼€ì¼ë§ ê¸°ëŠ¥ê³¼ Kubernetesì˜ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ëŠ” ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í• ë‹¹í•˜ê³  ìˆ˜ìš”ì— ë”°ë¼ í´ëŸ¬ìŠ¤í„°ë¥¼ í™•ì¥í•˜ì—¬ ë¹„ìš©ì„ ìµœì í™”í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ë§Œ ì‚¬ìš©í•˜ì—¬ ë¶ˆí•„ìš”í•œ ì§€ì¶œì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ê¸°ìˆ  ì¡°í•©ì„ ì‚¬ìš©í•˜ë©´ ë¶„ì‚° í›ˆë ¨ê³¼ í•˜ë“œì›¨ì–´ì˜ ìµœì‹  ë°œì „ì„ í™œìš©í•˜ì—¬ Llama-2ë¥¼ íš¨ìœ¨ì ì´ê³  íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ì „ í›ˆë ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Volcanoë€?â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#volcanoë€","content":" VolcanoëŠ” Kubernetes ê¸°ë°˜ì˜ ì˜¤í”ˆì†ŒìŠ¤ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œìœ¼ë¡œ, ê³ ì„±ëŠ¥ ì»´í“¨íŒ…(HPC) ë° ë¨¸ì‹  ëŸ¬ë‹ ì›Œí¬ë¡œë“œë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•´ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Gang ìŠ¤ì¼€ì¤„ë§, ê³µì • ê³µìœ , ì„ ì ê³¼ ê°™ì€ ê³ ê¸‰ ìŠ¤ì¼€ì¤„ë§ ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, ì´ëŠ” Kubernetes í™˜ê²½ì—ì„œ ëŒ€ê·œëª¨ ë¶„ì‚° í›ˆë ¨ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Volcanoì˜ Gang ìŠ¤ì¼€ì¤„ë§ ì‘ë™ ë°©ì‹â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#volcanoì˜-gang-ìŠ¤ì¼€ì¤„ë§-ì‘ë™-ë°©ì‹","content":" Volcanoì˜ Gang ìŠ¤ì¼€ì¤„ë§ì€ ì‘ì—…(ë˜ëŠ” &quot;Gang&quot;)ì˜ ëª¨ë“  íŒŒë“œê°€ ë™ì‹œì— ìŠ¤ì¼€ì¤„ë§ë˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤. ì´ëŠ” ì—¬ëŸ¬ íŒŒë“œê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ê¸° ìœ„í•´ í•¨ê»˜ ì‹œì‘í•´ì•¼ í•˜ëŠ” ë¶„ì‚° í›ˆë ¨ ì›Œí¬ë¡œë“œì— ì¤‘ìš”í•©ë‹ˆë‹¤. Gangì˜ íŒŒë“œ ì¤‘ í•˜ë‚˜ë¼ë„ ë¦¬ì†ŒìŠ¤ ì œì•½ìœ¼ë¡œ ì¸í•´ ìŠ¤ì¼€ì¤„ë§í•  ìˆ˜ ì—†ëŠ” ê²½ìš° Gangì˜ ì–´ë–¤ íŒŒë“œë„ ì‹œì‘ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” ë¶€ë¶„ ì‹¤í–‰ì„ ë°©ì§€í•˜ê³  ì‹¤í–‰ì´ ì‹œì‘ë˜ê¸° ì „ì— ì‘ì—…ì— í•„ìš”í•œ ëª¨ë“  ë¦¬ì†ŒìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"1. ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#1-ì†”ë£¨ì…˜-ë°°í¬","content":" ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"2. Docker ì´ë¯¸ì§€ ë¹Œë“œ (ì„ íƒ ë‹¨ê³„)â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#2-docker-ì´ë¯¸ì§€-ë¹Œë“œ-ì„ íƒ-ë‹¨ê³„","content":" ë¸”ë£¨í”„ë¦°íŠ¸ ë°°í¬ë¥¼ ë‹¨ìˆœí™”í•˜ê¸° ìœ„í•´ ì´ë¯¸ Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ì—¬ í¼ë¸”ë¦­ ECRì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤. Docker ì´ë¯¸ì§€ë¥¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ë ¤ë©´ Dockerfileì„ ì—…ë°ì´íŠ¸í•˜ê³  ì„ íƒ ë‹¨ê³„ë¥¼ ë”°ë¼ Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ì™€ ìì²´ í”„ë¼ì´ë¹— ECRì„ ì‚¬ìš©í•˜ì—¬ RayCluster YAML íŒŒì¼ llama2-pretrain-trn1-raycluster.yamlë„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.  cd ai/training/raytrain-llama2-pretrain-trn1 ./kuberay-trn1-llama2-pretrain-build-image.sh   ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•œ í›„ ìƒì„±ëœ Docker ì´ë¯¸ì§€ URLê³¼ íƒœê·¸ë¥¼ ê¸°ë¡í•˜ì„¸ìš”. ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì´ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"3. KubeRay Operatorë¡œ Ray í´ëŸ¬ìŠ¤í„° ì‹œì‘â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#3-kuberay-operatorë¡œ-ray-í´ëŸ¬ìŠ¤í„°-ì‹œì‘","content":" 2ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ëŠ” ê²½ìš° YAML íŒŒì¼ì„ ìˆ˜ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì— kubectl apply ëª…ë ¹ì„ ì‹¤í–‰í•˜ë©´ ìš°ë¦¬ê°€ ê²Œì‹œí•œ í¼ë¸”ë¦­ ECR ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  2ë‹¨ê³„ì—ì„œ ì»¤ìŠ¤í…€ Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•œ ê²½ìš° ì´ì „ ë‹¨ê³„ì—ì„œ ì–»ì€ Docker ì´ë¯¸ì§€ URLê³¼ íƒœê·¸ë¡œ ai/training/raytrain-llama2-pretrain-trn1/llama2-pretrain-trn1-raycluster.yaml íŒŒì¼ì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.  YAML íŒŒì¼ì„ ì—…ë°ì´íŠ¸í•œ í›„(í•„ìš”í•œ ê²½ìš°) ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ EKS í´ëŸ¬ìŠ¤í„°ì—ì„œ KubeRay í´ëŸ¬ìŠ¤í„° íŒŒë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤:  kubectl apply -f llama2-pretrain-trn1-raycluster.yaml   íŒŒë“œ ìƒíƒœ í™•ì¸:  kubectl get pods -l &quot;ray.io/cluster=kuberay-trn1&quot;   ","version":"Next","tagName":"h2"},{"title":"Volcanoë¥¼ ì‚¬ìš©í•œ Ray í—¤ë“œ ë° ì›Œì»¤ íŒŒë“œì˜ Gang ìŠ¤ì¼€ì¤„ë§â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#volcanoë¥¼-ì‚¬ìš©í•œ-ray-í—¤ë“œ-ë°-ì›Œì»¤-íŒŒë“œì˜-gang-ìŠ¤ì¼€ì¤„ë§","content":" Llama2 í›ˆë ¨ì„ ìœ„í•œ Ray í´ëŸ¬ìŠ¤í„° ë°°í¬ ì»¨í…ìŠ¤íŠ¸ì—ì„œ VolcanoëŠ” Ray í—¤ë“œ ë° ì›Œì»¤ íŒŒë“œê°€ í•¨ê»˜ íš¨ìœ¨ì ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ë§ë˜ë„ë¡ í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ x86 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” Ray í—¤ë“œ íŒŒë“œëŠ” ë¶„ì‚° í›ˆë ¨ì„ ì¡°ì •í•˜ê³ , AWS Trainium (Trn1) ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” ì›Œì»¤ íŒŒë“œëŠ” ê³„ì‚° ì§‘ì•½ì ì¸ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.Volcanoì˜ Gang ìŠ¤ì¼€ì¤„ë§ì„ í™œìš©í•˜ì—¬ í—¤ë“œì™€ ëª¨ë“  ì›Œì»¤ íŒŒë“œì— í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ê°€ ë™ì‹œì— í• ë‹¹ë˜ë„ë¡ í•˜ì—¬ ë¶„ì‚° í›ˆë ¨ ì‘ì—…ì´ ì§€ì—° ì—†ì´ ì‹œì‘ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë‹¤ìŒì€ Llama2 í›ˆë ¨ì„ ìœ„í•œ RayClusterì™€ Volcanoë¥¼ í†µí•©í•˜ëŠ” ì˜ˆì œ êµ¬ì„±ì…ë‹ˆë‹¤:  ì •ë³´ Terraform ë¸”ë£¨í”„ë¦°íŠ¸ê°€ default ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— fsx-claim PVCë¥¼ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— ì´ ë°°í¬ì— default ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì „ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•˜ë ¤ë©´ PVCê°€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ë°”ì¸ë”©ë˜ë¯€ë¡œ FSX for Lustre íŒŒì¼ ì‹œìŠ¤í…œë„ ë™ì¼í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.  # Volcanoì™€ KubeRay ë¬¸ì„œ: https://docs.ray.io/en/master/cluster/kubernetes/k8s-ecosystem/volcano.html --- apiVersion: scheduling.volcano.sh/v1beta1 kind: Queue metadata: name: llama2-training-queue namespace: default spec: weight: 1 capability: cpu: '500' memory: 1500Gi --- apiVersion: ray.io/v1 kind: RayCluster metadata: name: kuberay-trn1 namespace: default labels: ray.io/scheduler-name: volcano volcano.sh/queue-name: llama2-training-queue spec: rayVersion: 2.22.0 headGroupSpec: ... ...   Running ìƒíƒœì˜ ray-head íŒŒë“œ 1ê°œì™€ ray-worker íŒŒë“œ 2ê°œê°€ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤:  ê²½ê³  ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¤ê³  íŒŒë“œê°€ ì¤€ë¹„ë˜ê¸°ê¹Œì§€ ìµœëŒ€ 10ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  NAME READY STATUS RESTARTS AGE kuberay-trn1-head-67t46 0/1 Pending 0 2m50s kuberay-trn1-worker-workergroup-fz8bs 0/1 Pending 0 2m50s kuberay-trn1-worker-workergroup-gpnxh 0/1 Pending 0 2m50s   í—¤ë“œ íŒŒë“œì˜ ë¡œê·¸ í™•ì¸:  Ray í—¤ë“œê°€ ì‹œì‘ë˜ì—ˆê³  í´ëŸ¬ìŠ¤í„°ê°€ ì‘ë™ ì¤‘ì„ì„ ë‚˜íƒ€ë‚´ëŠ” ë©”ì‹œì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.  kubectl logs kuberay-trn1-head-xxxxx   ","version":"Next","tagName":"h3"},{"title":"Ray ëŒ€ì‹œë³´ë“œ ì ‘ê·¼ (í¬íŠ¸ í¬ì›Œë”©):â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#ray-ëŒ€ì‹œë³´ë“œ-ì ‘ê·¼-í¬íŠ¸-í¬ì›Œë”©","content":" Ray ëŒ€ì‹œë³´ë“œëŠ” í´ëŸ¬ìŠ¤í„° ìƒíƒœì™€ ì‘ì—… ì§„í–‰ ìƒí™©ì— ëŒ€í•œ ê·€ì¤‘í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì ‘ê·¼í•˜ë ¤ë©´:  í¬íŠ¸ í¬ì›Œë”©:  ë¡œì»¬ ë¨¸ì‹ ì—ì„œ í´ëŸ¬ìŠ¤í„° ë‚´ í—¤ë“œ íŒŒë“œë¡œ Ray ëŒ€ì‹œë³´ë“œ í¬íŠ¸(8265)ë¥¼ í¬ì›Œë”©í•©ë‹ˆë‹¤.  kubectl port-forward service/kuberay-trn1-head-svc 8265:8265   ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8265ë¡œ ì´ë™í•˜ì—¬ ëŒ€ì‹œë³´ë“œë¥¼ í™•ì¸í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"4. FSx ê³µìœ  íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì‚¬ì „ í›ˆë ¨ ë°ì´í„° ìƒì„±â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#4-fsx-ê³µìœ -íŒŒì¼-ì‹œìŠ¤í…œì—ì„œ-ì‚¬ì „-í›ˆë ¨-ë°ì´í„°-ìƒì„±","content":" ê²½ê³  ë°ì´í„° ìƒì„± ë‹¨ê³„ëŠ” FSx for Lustreì— ëª¨ë“  ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë° ìµœëŒ€ 20ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ë‹¨ê³„ì—ì„œëŠ” KubeRayì˜ Job ì‚¬ì–‘ì„ í™œìš©í•˜ì—¬ ë°ì´í„° ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. Ray í—¤ë“œ íŒŒë“œì— ì§ì ‘ ì‘ì—…ì„ ì œì¶œí•©ë‹ˆë‹¤. ì´ ì‘ì—…ì€ ëª¨ë¸ì„ í›ˆë ¨í•  ì¤€ë¹„ë¥¼ í•˜ëŠ” ë° í•µì‹¬ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.  ê¸°ì¡´ RayClusterì— ì‘ì—…ì„ ì œì¶œí•˜ê¸° ìœ„í•´ clusterSelectorë¥¼ ì‚¬ìš©í•˜ëŠ” ì•„ë˜ RayJob ì •ì˜ ì‚¬ì–‘ì„ í™•ì¸í•˜ì„¸ìš”.  # ---------------------------------------------------------------------------- # RayJob: llama2-generate-pretraining-test-data # # ì„¤ëª…: # ì´ RayJobì€ Llama2 ëª¨ë¸ í›ˆë ¨ì— í•„ìš”í•œ ì‚¬ì „ í›ˆë ¨ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” # ì—­í• ì„ í•©ë‹ˆë‹¤. ì§€ì •ëœ ë°ì´í„°ì…‹ì—ì„œ ë°ì´í„°ë¥¼ ì†Œì‹±í•˜ê³  ì²˜ë¦¬í•˜ì—¬ í›„ì† í›ˆë ¨ ë‹¨ê³„ì—ì„œ # ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì€ ì´ëŸ¬í•œ ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•˜ëŠ” # Python ìŠ¤í¬ë¦½íŠ¸(`get_dataset.py`)ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. # ì‚¬ìš©ë²•: # `kubectl apply -f 1-llama2-pretrain-trn1-rayjob-create-test-data.yaml`ì„ ì‚¬ìš©í•˜ì—¬ # Kubernetes í´ëŸ¬ìŠ¤í„°ì— ì´ êµ¬ì„±ì„ ì ìš©í•©ë‹ˆë‹¤. # Ray í´ëŸ¬ìŠ¤í„°(`kuberay-trn1`)ê°€ ì§€ì •ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ì‹¤í–‰ ì¤‘ì´ê³  ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ì„¸ìš”. # ---------------------------------------------------------------------------- apiVersion: ray.io/v1 kind: RayJob metadata: name: llama2-generate-pretraining-test-data namespace: default spec: submissionMode: K8sJobMode entrypoint: &quot;python3 get_dataset.py&quot; runtimeEnvYAML: | working_dir: /llama2_pretrain env_vars: PYTHONUNBUFFERED: '0' resources: requests: cpu: &quot;6&quot; memory: &quot;30Gi&quot; clusterSelector: ray.io/cluster: kuberay-trn1 rayClusterNamespace: default # RayClusterê°€ ë°°í¬ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´ ttlSecondsAfterFinished: 60 # ì™„ë£Œ í›„ íŒŒë“œì˜ ìƒì¡´ ì‹œê°„(ì´ˆ)   ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± Ray ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl apply -f 1-llama2-pretrain-trn1-rayjob-create-test-data.yaml   ë‚´ë¶€ì—ì„œ ì¼ì–´ë‚˜ëŠ” ì¼:  ì‘ì—… ì‹œì‘: kubectlì„ ì‚¬ìš©í•˜ì—¬ KubeRay ì‘ì—… ì‚¬ì–‘ì„ ì œì¶œí•©ë‹ˆë‹¤. kuberay-trn1 í´ëŸ¬ìŠ¤í„°ì˜ Ray í—¤ë“œ íŒŒë“œê°€ ì´ ì‘ì—…ì„ ìˆ˜ì‹ í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.  ë°ì´í„° ìƒì„±: ì‘ì—…ì´ ai/training/raytrain-llama2-pretrain-trn1/llama2_pretrain/get_dataset.py ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ë©°, Hugging Face datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ì›ì‹œ ì˜ì–´ Wikipedia ë°ì´í„°ì…‹(&quot;wikicorpus&quot;)ì„ ê°€ì ¸ì˜¤ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤.  í† í°í™”: ìŠ¤í¬ë¦½íŠ¸ëŠ” Hugging Face transformersì˜ ì‚¬ì „ í›ˆë ¨ëœ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•©ë‹ˆë‹¤. í† í°í™”ëŠ” ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í…ìŠ¤íŠ¸ë¥¼ ë” ì‘ì€ ë‹¨ìœ„(ë‹¨ì–´ ë˜ëŠ” í•˜ìœ„ ë‹¨ì–´)ë¡œ ë¶„í•´í•©ë‹ˆë‹¤.  ë°ì´í„° ì €ì¥: í† í°í™”ëœ ë°ì´í„°ëŠ” ê¹”ë”í•˜ê²Œ ì •ë¦¬ë˜ì–´ FSx for Lustre ê³µìœ  íŒŒì¼ ì‹œìŠ¤í…œ ë‚´ì˜ íŠ¹ì • ë””ë ‰í† ë¦¬(/shared/wikicorpus_llama2_7B_tokenized_4k/)ì— ì €ì¥ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ì›Œì»¤ ë…¸ë“œê°€ ì‚¬ì „ í›ˆë ¨ ì¤‘ì— ì´ í‘œì¤€í™”ëœ ë°ì´í„°ì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì‘ì—… ëª¨ë‹ˆí„°ë§:â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#ì‘ì—…-ëª¨ë‹ˆí„°ë§","content":" ì‘ì—… ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ë ¤ë©´:  Ray ëŒ€ì‹œë³´ë“œ: Ray í—¤ë“œ íŒŒë“œì˜ IP ì£¼ì†Œì™€ í¬íŠ¸ 8265ë¥¼ í†µí•´ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” Ray ëŒ€ì‹œë³´ë“œë¡œ ì´ë™í•©ë‹ˆë‹¤. ì‘ì—… ìƒíƒœì— ëŒ€í•œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.        ë˜ëŠ” í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl get pods | grep llama2   ì¶œë ¥:  llama2-generate-pretraining-test-data-g6ccl 1/1 Running 0 5m5s   ë‹¤ìŒ ìŠ¤í¬ë¦°ìƒ·ì€ Lens K8s IDEì—ì„œ íŒŒë“œì˜ ë¡œê·¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"5. ì‚¬ì „ ì»´íŒŒì¼ ì‘ì—… ì‹¤í–‰ (ìµœì í™” ë‹¨ê³„)â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#5-ì‚¬ì „-ì»´íŒŒì¼-ì‘ì—…-ì‹¤í–‰-ìµœì í™”-ë‹¨ê³„","content":" ì •ë³´ ì‚¬ì „ ì»´íŒŒì¼ ì‘ì—…ì€ ìµœëŒ€ 6ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤  ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•˜ê¸° ì „ì— Neuron SDKì— ë§ê²Œ ëª¨ë¸ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ ì‚¬ì „ ì»´íŒŒì¼ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ Trn1 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Neuron SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì—°ì‚° ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•˜ê³  ìµœì í™”í•˜ì—¬ Trn1 í”„ë¡œì„¸ì„œì—ì„œ íš¨ìœ¨ì ì¸ í›ˆë ¨ì„ ìœ„í•´ ì¤€ë¹„í•©ë‹ˆë‹¤.  ì´ ë‹¨ê³„ì—ì„œëŠ” Neuron SDKê°€ Llama2 ì‚¬ì „ í›ˆë ¨ê³¼ ê´€ë ¨ëœ ì—°ì‚° ê·¸ë˜í”„ë¥¼ ì‹ë³„, ì»´íŒŒì¼ ë° ìºì‹œí•˜ëŠ” ì‚¬ì „ ì»´íŒŒì¼ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.  ì‚¬ì „ ì»´íŒŒì¼ ì‘ì—…ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì•„ë˜ RayJob ì •ì˜ ì‚¬ì–‘ì„ í™•ì¸í•˜ì„¸ìš”:  # ---------------------------------------------------------------------------- # RayJob: llama2-precompilation-job # # ì„¤ëª…: # ì´ RayJobì€ Llama2 ëª¨ë¸ í›ˆë ¨ì— í•„ìš”í•œ ì‚¬ì „ ì»´íŒŒì¼ ë‹¨ê³„ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤. # AWS Neuron ì¥ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë³‘ë ¬ë¡œ ì»´íŒŒì¼í•˜ê¸° ìœ„í•´ `--neuron_parallel_compile` # ì˜µì…˜ê³¼ í•¨ê»˜ Python ìŠ¤í¬ë¦½íŠ¸(`ray_train_llama2.py`)ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ëŠ” # AWS ì¸í”„ë¼ì—ì„œ íš¨ìœ¨ì ì¸ í›ˆë ¨ì„ ìœ„í•´ ëª¨ë¸ì„ ìµœì í™”í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤. # ì‚¬ìš©ë²•: # `kubectl apply -f 2-llama2-pretrain-trn1-rayjob-precompilation.yaml`ì„ ì‚¬ìš©í•˜ì—¬ # Kubernetes í´ëŸ¬ìŠ¤í„°ì— ì´ êµ¬ì„±ì„ ì ìš©í•©ë‹ˆë‹¤. # Ray í´ëŸ¬ìŠ¤í„°(`kuberay-trn1`)ê°€ ì§€ì •ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ì‹¤í–‰ ì¤‘ì´ê³  ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ì„¸ìš”. # ---------------------------------------------------------------------------- --- apiVersion: ray.io/v1 kind: RayJob metadata: name: llama2-precompilation-job namespace: default spec: submissionMode: K8sJobMode entrypoint: &quot;NEURON_NUM_DEVICES=32 python3 /llama2_pretrain/ray_train_llama2.py --neuron_parallel_compile&quot; runtimeEnvYAML: | working_dir: /llama2_pretrain env_vars: PYTHONUNBUFFERED: '0' clusterSelector: ray.io/cluster: kuberay-trn1 rayClusterNamespace: default # RayClusterê°€ ë°°í¬ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´ ttlSecondsAfterFinished: 60 # ì™„ë£Œ í›„ íŒŒë“œì˜ ìƒì¡´ ì‹œê°„(ì´ˆ)   ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ì‚¬ì „ ì»´íŒŒì¼ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl apply -f 2-llama2-pretrain-trn1-rayjob-precompilation.yaml   í™•ì¸ ë‹¨ê³„:  ì‘ì—… ì§„í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì˜¬ë°”ë¥´ê²Œ ì‹¤í–‰ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ê³¼ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:  Ray ëŒ€ì‹œë³´ë“œ: Ray í—¤ë“œ íŒŒë“œì˜ IP ì£¼ì†Œì™€ í¬íŠ¸ 8265ë¥¼ í†µí•´ Ray ëŒ€ì‹œë³´ë“œì— ì ‘ê·¼í•˜ì—¬ ì‘ì—… ìƒíƒœì— ëŒ€í•œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.      ë‹¤ìŒ ìŠ¤í¬ë¦°ìƒ·ì€ Lens K8s IDEì—ì„œ íŒŒë“œì˜ ë¡œê·¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"6. ë¶„ì‚° ì‚¬ì „ í›ˆë ¨ ì‘ì—… ì‹¤í–‰â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#6-ë¶„ì‚°-ì‚¬ì „-í›ˆë ¨-ì‘ì—…-ì‹¤í–‰","content":" ê²½ê³  ì´ ì‘ì—…ì€ ì—¬ëŸ¬ ì‹œê°„ ë™ì•ˆ ì‹¤í–‰ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì†ì‹¤ì´ ê°ì†Œí•˜ê³  ëª¨ë¸ì´ í•™ìŠµí•˜ê³  ìˆìŒì„ í™•ì¸í•œ í›„ Ctrl+Cë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ì—…ì„ ì·¨ì†Œí•´ë„ ë©ë‹ˆë‹¤.  ì´ì œ Llama 2 ëª¨ë¸ì˜ ì‹¤ì œ í›ˆë ¨ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤! ì´ ë‹¨ê³„ëŠ” RayJobì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì‚° ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ ì‘ì—…ì€ AWS Neuron ì¥ì¹˜ë¥¼ í™œìš©í•˜ì—¬ ì¤€ë¹„ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.  ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì•„ë˜ RayJob ì •ì˜ ì‚¬ì–‘ì„ í™•ì¸í•˜ì„¸ìš”:  # ---------------------------------------------------------------------------- # RayJob: llama2-pretraining-job # # ì„¤ëª…: # ì´ RayJobì€ Llama2 ëª¨ë¸ì˜ ì£¼ìš” ì‚¬ì „ í›ˆë ¨ ë‹¨ê³„ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤. # AWS Neuron ì¥ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ Python ìŠ¤í¬ë¦½íŠ¸(`ray_train_llama2.py`)ë¥¼ # ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ ë‹¨ê³„ëŠ” ì¤€ë¹„ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ì–¸ì–´ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤. # ì‚¬ìš©ë²•: # `kubectl apply -f 3-llama2-pretrain-trn1-rayjob.yaml`ì„ ì‚¬ìš©í•˜ì—¬ # Kubernetes í´ëŸ¬ìŠ¤í„°ì— ì´ êµ¬ì„±ì„ ì ìš©í•©ë‹ˆë‹¤. # Ray í´ëŸ¬ìŠ¤í„°(`kuberay-trn1`)ê°€ ì§€ì •ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ì‹¤í–‰ ì¤‘ì´ê³  ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ì„¸ìš”. # ---------------------------------------------------------------------------- --- apiVersion: ray.io/v1 kind: RayJob metadata: name: llama2-pretraining-job namespace: default spec: submissionMode: K8sJobMode entrypoint: &quot;NEURON_NUM_DEVICES=32 python3 ray_train_llama2.py&quot; runtimeEnvYAML: | working_dir: /llama2_pretrain env_vars: PYTHONUNBUFFERED: '0' clusterSelector: ray.io/cluster: kuberay-trn1 rayClusterNamespace: default # RayClusterê°€ ë°°í¬ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´ shutdownAfterJobFinishes: true activeDeadlineSeconds: 600 # ì‘ì—…ì´ 600ì´ˆ(10ë¶„)ë³´ë‹¤ ì˜¤ë˜ ì‹¤í–‰ë˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤ ttlSecondsAfterFinished: 60 # ì™„ë£Œ í›„ íŒŒë“œì˜ ìƒì¡´ ì‹œê°„(ì´ˆ)   ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  kubectl apply -f 3-llama2-pretrain-trn1-rayjob.yaml   ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§:  Ray ëŒ€ì‹œë³´ë“œë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ í„°ë¯¸ë„ì— ì¶œë ¥ë˜ëŠ” ë¡œê·¸ë¥¼ ê´€ì°°í•˜ì—¬ í›ˆë ¨ ì‘ì—…ì˜ ì§„í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ í•™ìŠµí•˜ê³  ìˆëŠ”ì§€ í‰ê°€í•˜ê¸° ìœ„í•´ í›ˆë ¨ ì†ì‹¤, í•™ìŠµë¥  ë° ê¸°íƒ€ ë©”íŠ¸ë¦­ê³¼ ê°™ì€ ì •ë³´ë¥¼ ì°¾ì•„ë³´ì„¸ìš”.    Ray ëŒ€ì‹œë³´ë“œ: Ray í—¤ë“œ íŒŒë“œì˜ IP ì£¼ì†Œì™€ í¬íŠ¸ 8265ë¥¼ í†µí•´ Ray ëŒ€ì‹œë³´ë“œì— ì ‘ê·¼í•˜ì—¬ ì‘ì—… ìƒíƒœì— ëŒ€í•œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.      ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"RayTrainê³¼ KubeRayë¥¼ í™œìš©í•œ Trn1ì—ì„œì˜ Llama2 ë¶„ì‚° ì‚¬ì „ í›ˆë ¨","url":"/ai-on-eks/ko/docs/blueprints/training/Neuron/RayTrain-Llama2#ì •ë¦¬","content":" ì´ ì†”ë£¨ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ëœ ë¦¬ì†ŒìŠ¤ë¥¼ ì œê±°í•˜ë ¤ë©´ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:  # RayCluster ë¦¬ì†ŒìŠ¤ ì‚­ì œ: cd ai/training/raytrain-llama2-pretrain-trn1 kubectl delete -f llama2-pretrain-trn1-raycluster.yaml # EKS í´ëŸ¬ìŠ¤í„° ë° ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì •ë¦¬: cd ai-on-eks/infra/trainium-inferentia ./cleanup.sh  ","version":"Next","tagName":"h3"},{"title":"Inference Perfë¡œ ë²¤ì¹˜ë§ˆí‚¹í•˜ê¸°","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/inference-perf","content":"Inference Perfë¡œ ë²¤ì¹˜ë§ˆí‚¹í•˜ê¸° ë²¤ì¹˜ë§ˆí‚¹ì„ ë” ì‰½ê³  ì¼ê´€ë˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´ Inference Perf ë„êµ¬ëŠ” ë‹¤ì–‘í•œ ì‹œìŠ¤í…œì—ì„œ LLM ì¶”ë¡  ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ë¹„êµí•˜ëŠ” í‘œì¤€í™”ëœ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. Inference Perf (GitHub - kubernetes-sigs/inference-perf: GenAI inference performance b...)ëŠ” GenAI ì¶”ë¡  ì›Œí¬ë¡œë“œ ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤, ëª¨ë¸ ì„œë²„ ë¶ˆê°€ì§€ë¡ ì  ë„êµ¬ì…ë‹ˆë‹¤. GPU, CPU ë° ë§ì¶¤í˜• ê°€ì†ê¸° ê°„ì˜ ë™ì¼ ì¡°ê±´ ë¹„êµë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬ ì…€í”„ í˜¸ìŠ¤íŒ… LLMì˜ ë²¤ì¹˜ë§ˆí‚¹ì„ ë” ì‰½ê³  ì¼ê´€ë˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ì‹¤ì œ ë° í•©ì„± ë°ì´í„°ì…‹, ì—¬ëŸ¬ APIì™€ ëª¨ë¸ ì„œë²„(vLLM, SGLang, TGI í¬í•¨), llm-d, Dynamo, Inference Gatewayì™€ ê°™ì€ í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•œ ëŒ€ê·œëª¨ ë°°í¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ì…ë ¥/ì¶œë ¥ ë¶„í¬(ê°€ìš°ì‹œì•ˆ, ê³ ì • ê¸¸ì´, ìµœì†Œ-ìµœëŒ€)ë¥¼ ì •ì˜í•˜ê³  ë²„ìŠ¤íŠ¸ íŠ¸ë˜í”½, í¬í™” ë˜ëŠ” ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì‹œë‚˜ë¦¬ì˜¤ì™€ ê°™ì€ ë‹¤ì–‘í•œ ë¶€í•˜ íŒ¨í„´ì„ ì‹œë®¬ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. wg-serving í‘œì¤€í™” ë…¸ë ¥ì˜ ì¼ë¶€ì¸ Inference PerfëŠ” Time to First Token, Intertoken Latency, Tokens per Secondì™€ ê°™ì€ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ì—¬ íŒ€ì´ ì‹œìŠ¤í…œ ê°„ì˜ ì„±ëŠ¥, ì²˜ë¦¬ëŸ‰ ë° ë¹„ìš© íš¨ìœ¨ì„±ì„ ë¹„êµí•˜ê³  ì¶”ì¸¡ì—ì„œ ë°ì´í„° ê¸°ë°˜ ê²°ì •ìœ¼ë¡œ ì´ë™í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.","keywords":"","version":"Next"},{"title":"LLM ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ í•µì‹¬ ë©”íŠ¸ë¦­","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/key-metrics-for-benchmarking-llms","content":"","keywords":"","version":"Next"},{"title":"Time to First Token (TTFT)â€‹","type":1,"pageTitle":"LLM ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ í•µì‹¬ ë©”íŠ¸ë¦­","url":"/ai-on-eks/ko/docs/guidance/benchmarking/key-metrics-for-benchmarking-llms#time-to-first-token-ttft","content":" Time to First Tokenì€ ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ì¶œë ¥ì˜ ì²« ë²ˆì§¸ í† í°ì„ ìƒì„±í•˜ëŠ” ë° ê±¸ë¦¬ëŠ” ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ì´ëŠ” ìš”ì²­ì„ ë³´ë‚´ê³  ì²« ë²ˆì§¸ ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì„ ë³´ëŠ” ì‚¬ì´ì˜ ì§€ì—°ì¸ ì‚¬ìš©ìì˜ ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  ìˆ˜ì‹: first_non_empty_token_received_time - request_send_time  í¬í•¨ ë‚´ìš©:  ìš”ì²­ ëŒ€ê¸°ì—´ ì‹œê°„ (ë‹¤ë¥¸ ìš”ì²­ì´ ì²˜ë¦¬ ì¤‘ì¸ ê²½ìš° ëŒ€ê¸° ì‹œê°„)Prefill ì‹œê°„ (KV ìºì‹œë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ ì „ì²´ ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëª¨ë¸)ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œê°„  ê¸°ìˆ ì  ê³ ë ¤ ì‚¬í•­:  ë” ê¸´ í”„ë¡¬í”„íŠ¸ëŠ” ë” í° TTFTë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤; ì–´í…ì…˜ ê³„ì‚°ì€ ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ì— ë”°ë¼ í™•ì¥ë©ë‹ˆë‹¤Inference Perfì™€ ê°™ì€ ë²¤ì¹˜ë§ˆí‚¹ ë„êµ¬ëŠ” ì˜ë¯¸ ìˆëŠ” ì¸¡ì •ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ì´ˆê¸° ë¹ˆ ì‘ë‹µì„ ë¬´ì‹œí•©ë‹ˆë‹¤TTFTëŠ” í˜„ì¬ ë°°í¬ êµ¬ì„±ì— ëŒ€í•œ ìµœì†Œ ì§€ì—° ì‹œê°„ ê¸°ì¤€ì„ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤; ì‚¬ìš©ìëŠ” ë™ì¼í•œ ì„¤ì • ë‚´ì—ì„œ TTFTë³´ë‹¤ ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ë³¼ ìˆ˜ ì—†ì§€ë§Œ, ì´ ê¸°ì¤€ì„ ì€ ëª¨ë¸ ì–‘ìí™”, ë” ë¹ ë¥¸ í•˜ë“œì›¨ì–´ ë˜ëŠ” ê°œì„ ëœ ë³‘ë ¬í™” ì „ëµê³¼ ê°™ì€ ìµœì í™”ë¥¼ í†µí•´ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ê³ ê¸‰ ìµœì í™” ì°¸ê³ : ì¼ë¶€ í”„ë¡œë•ì…˜ ë°°í¬ëŠ” ë¦¬ì†ŒìŠ¤ í™œìš©ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ prefillê³¼ í† í° ìƒì„± ë‹¨ê³„ê°€ ë³„ë„ì˜ ì¸í”„ë¼ì—ì„œ ì‹¤í–‰ë˜ëŠ” ë¶„ë¦¬ëœ prefill/decode ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤; ì´ëŠ” ì´ ê°€ì´ë“œì˜ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ë§Œ íŠ¹ìˆ˜í™”ëœ ì„¤ì •ì—ì„œ TTFTì— ìƒë‹¹í•œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Intertoken Latency (ITL)â€‹","type":1,"pageTitle":"LLM ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ í•µì‹¬ ë©”íŠ¸ë¦­","url":"/ai-on-eks/ko/docs/guidance/benchmarking/key-metrics-for-benchmarking-llms#intertoken-latency-itl","content":" Intertoken Latency(ì¶œë ¥ í† í°ë‹¹ ì‹œê°„ ë˜ëŠ” TPOTë¼ê³ ë„ í•¨)ëŠ” ëª¨ë¸ì´ ìƒì„±í•˜ëŠ” ì—°ì† í† í° ê°„ì˜ í‰ê·  ì§€ì—°ì„ ì¸¡ì •í•©ë‹ˆë‹¤. ì´ëŠ” ìƒì„±ì´ ì‹œì‘ëœ í›„ ëª¨ë¸ì´ ì¶œë ¥ì„ ì–¼ë§ˆë‚˜ ë¶€ë“œëŸ½ê³  ê¾¸ì¤€íˆ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ”ì§€ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.  ìˆ˜ì‹ (Inference Perf): generation_time / (output_tokens - 1)  í•µì‹¬ ì„¸ë¶€ ì‚¬í•­: ìˆ˜ì‹ì€ ë¶„ëª¨ì—ì„œ 1ì„ ë¹¼ì„œ TTFTë¥¼ ì œì™¸í•˜ë¯€ë¡œ ITLì€ ë””ì½”ë”©/ìƒì„± ë‹¨ê³„ë§Œì˜ ë©”íŠ¸ë¦­ì´ ë©ë‹ˆë‹¤.  ê¸°ìˆ ì  ê³ ë ¤ ì‚¬í•­:  ì¶œë ¥ì´ ì¦ê°€í•¨ì— ë”°ë¼ KV ìºì‹œê°€ ì¦ê°€í•˜ì—¬ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ê³¼ ì–´í…ì…˜ ê³„ì‚° ë¹„ìš©ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤ (ì…ë ¥ + ì¶œë ¥ ê¸¸ì´ì— ë¹„ë¡€)ì¼ê´€ëœ ITLì€ íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ì™€ ëŒ€ì—­í­ í™œìš©ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤ê¸´ ìƒì„± ì¤‘ ITLì´ ì¦ê°€í•˜ë©´ ë©”ëª¨ë¦¬ ëŒ€ì—­í­ ì œì•½ ë˜ëŠ” KV ìºì‹œ ì••ë ¥ì„ ì‹œì‚¬í•©ë‹ˆë‹¤ë‹¤ë¥¸ ë„êµ¬ëŠ” ITLì„ ë‹¤ë¥´ê²Œ ê³„ì‚°í•©ë‹ˆë‹¤; Inference PerfëŠ” TTFTë¥¼ ì œì™¸í•˜ëŠ” ë°˜ë©´ ì¼ë¶€ ë„êµ¬(ì˜ˆ: LLMPerf)ëŠ” í‰ê· ì— í¬í•¨í•©ë‹ˆë‹¤  ","version":"Next","tagName":"h3"},{"title":"Tokens per Second (TPS)â€‹","type":1,"pageTitle":"LLM ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ í•µì‹¬ ë©”íŠ¸ë¦­","url":"/ai-on-eks/ko/docs/guidance/benchmarking/key-metrics-for-benchmarking-llms#tokens-per-second-tps","content":" Tokens per SecondëŠ” ì‹œìŠ¤í…œì˜ ì „ì²´ ì²˜ë¦¬ëŸ‰, ì¦‰ ëª¨ë¸ì´ ëª¨ë“  í™œì„± ìš”ì²­ì—ì„œ ë§¤ì´ˆ ìƒì„±í•˜ëŠ” ì¶œë ¥ í† í° ìˆ˜ë¥¼ í¬ì°©í•©ë‹ˆë‹¤. ë” ë§ì€ ìš”ì²­ì´ ë³‘ë ¬ë¡œ ì‹¤í–‰ë¨ì— ë”°ë¼ TPSëŠ” ì¼ë°˜ì ìœ¼ë¡œ í•˜ë“œì›¨ì–´ê°€ í¬í™” ì§€ì ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ì¦ê°€í•©ë‹ˆë‹¤. ê·¸ ì´í›„ì—ëŠ” ë¦¬ì†ŒìŠ¤ê°€ ê³¼ë„í•˜ê²Œ í™œìš©ë¨ì— ë”°ë¼ ì„±ëŠ¥ì´ ì •ì²´ë˜ê±°ë‚˜ ì‹¬ì§€ì–´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë©”íŠ¸ë¦­ì€ íŒ€ì´ ì‹œìŠ¤í…œ ìš©ëŸ‰ì„ ì´í•´í•˜ê³  í™•ì¥ ë˜ëŠ” ë°°ì¹­ ì „ëµì„ ê³„íší•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  ìˆ˜ì‹ (Inference Perf): total_output_tokens / (last_response_time - first_request_time)  ì´í•´í•´ì•¼ í•  ë‘ ê°€ì§€ ê´€ì :  ì‹œìŠ¤í…œ TPS (ì´ ì²˜ë¦¬ëŸ‰): ëª¨ë“  ë™ì‹œ ìš”ì²­ì— ê±¸ì¹œ ì§‘ê³„ ìš©ëŸ‰, í¬í™”ê¹Œì§€ ë™ì‹œì„±ê³¼ í•¨ê»˜ ì¦ê°€ì‚¬ìš©ìë‹¹ TPS: ê°œë³„ ìš”ì²­ ì²˜ë¦¬ëŸ‰ (output_tokens / e2e_latency), ì‹œìŠ¤í…œ ë¶€í•˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ê°ì†Œ  ì¤‘ìš”í•œ ê´€ê³„: ë™ì‹œ ë¶€í•˜ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë³µì œë³¸ì„ ì´ˆê³¼í•˜ì—¬ ì¦ê°€í•˜ë©´, ì‹œìŠ¤í…œ TPSëŠ” ìƒìŠ¹í•˜ê³  ì‚¬ìš©ìë‹¹ TPSëŠ” í•˜ë½í•©ë‹ˆë‹¤ (ë™ì‹œ ìš”ì²­ ìˆ˜ê°€ ì‹œìŠ¤í…œì˜ ì¦‰ê°ì ì¸ ì„œë¹™ ìš©ëŸ‰ì„ ì´ˆê³¼í•œë‹¤ê³  ê°€ì •)  ê¸°ìˆ ì  ê³ ë ¤ ì‚¬í•­:  Inference PerfëŠ” ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ì¸ ì¸¡ì •ì„ ìœ„í•´ ì›Œë°ì—… ë° ì¿¨ë‹¤ìš´ ìš”ì²­ì„ ì œì™¸í•©ë‹ˆë‹¤ë‹¤ë¥¸ ë„êµ¬ëŠ” ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ê¸°ê°„ì„ í¬í•¨í•˜ì—¬ ì˜¤ë²„í—¤ë“œë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ë‹¨ì¼ ë™ì‹œì„± ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìµœëŒ€ 33%)í¬í™” ì§€ì ì€ TTFTê°€ ê¸‰ì¦í•˜ê³ , TPSê°€ ì •ì²´ë˜ë©°, ì˜¤ë¥˜ìœ¨ì´ ë‚˜íƒ€ë‚˜ê¸° ì‹œì‘í•˜ëŠ” ê³³ì…ë‹ˆë‹¤  ì¤‘ìš”í•œ ì´ìœ : TPSëŠ” ìš©ëŸ‰ ê³„íšì— í•„ìˆ˜ì ì…ë‹ˆë‹¤; ìµœëŒ€ ì§€ì† ê°€ëŠ¥í•œ ì²˜ë¦¬ëŸ‰ì„ ì´í•´í•˜ë©´ ì¸í”„ë¼ í¬ê¸° ì¡°ì • ë° í”„ë¡œë•ì…˜ ìš´ì˜ ì§€ì (ì¼ë°˜ì ìœ¼ë¡œ í¬í™”ì˜ 50-70%)ì„ ê²°ì •í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ","version":"Next","tagName":"h3"},{"title":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios","content":"","keywords":"","version":"Next"},{"title":"ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤â€‹","type":1,"pageTitle":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios#ì‚¬ìš©-ê°€ëŠ¥í•œ-ì‹œë‚˜ë¦¬ì˜¤","content":" ","version":"Next","tagName":"h2"},{"title":"í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì¤‘ ì„ íƒâ€‹","type":1,"pageTitle":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios#í•©ì„±-ë°ì´í„°ì™€-ì‹¤ì œ-ë°ì´í„°ì…‹-í…ŒìŠ¤íŠ¸-ì¤‘-ì„ íƒ","content":" ë²¤ì¹˜ë§ˆí‚¹ì— í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ë°ì´í„°ë¥¼ ì–¸ì œ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ì™€ ë°ì´í„°ì…‹ ì„ íƒì„ ìœ„í•œ ëª¨ë²” ì‚¬ë¡€ë¥¼ ì´í•´í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 1: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥â€‹","type":1,"pageTitle":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios#ì‹œë‚˜ë¦¬ì˜¤-1-ë² ì´ìŠ¤ë¼ì¸-ì„±ëŠ¥","content":" ê²½ìŸ ì—†ì´ ì‹œìŠ¤í…œì˜ ìµœì  ì„±ëŠ¥ì„ í™•ë¦½í•©ë‹ˆë‹¤. ëŒ€ê¸°ì—´ì´ë‚˜ ë¦¬ì†ŒìŠ¤ ê²½ìŸ ì—†ì´ ìµœìƒì˜ ì„±ëŠ¥ì„ ì´í•´í•˜ëŠ” ë° ì´ìƒì ì…ë‹ˆë‹¤.  ì‚¬ìš© ì‹œê¸°:  ìƒˆ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë°©ê¸ˆ ë°°í¬í–ˆì„ ë•Œì¸í”„ë¼ë¥¼ ë³€ê²½í–ˆì„ ë•Œìµœì í™”ë¥¼ ìœ„í•œ ê¹¨ë—í•œ ì°¸ì¡° ì§€ì ì´ í•„ìš”í•  ë•Œ  ","version":"Next","tagName":"h3"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 2: í¬í™” í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios#ì‹œë‚˜ë¦¬ì˜¤-2-í¬í™”-í…ŒìŠ¤íŠ¸","content":" ë‹¤ë‹¨ê³„ ë¶€í•˜ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì„±ëŠ¥ì´ ì €í•˜ë˜ê¸° ì „ ìµœëŒ€ ì§€ì† ê°€ëŠ¥í•œ ì²˜ë¦¬ëŸ‰ì„ ê²°ì •í•©ë‹ˆë‹¤.  ì‚¬ìš© ì‹œê¸°:  ìš©ëŸ‰ ê³„íš ì‹œì˜¤í† ìŠ¤ì¼€ì¼ë§ ì„ê³„ê°’ ì„¤ì • ì‹œí”„ë¡œë•ì…˜ ì¶œì‹œ ì „ ê²€ì¦ ì‹œ  ","version":"Next","tagName":"h3"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 3: ìë™ í¬í™” ê°ì§€â€‹","type":1,"pageTitle":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios#ì‹œë‚˜ë¦¬ì˜¤-3-ìë™-í¬í™”-ê°ì§€","content":" ìˆ˜ë™ QPS ì¶”ì¸¡ ì—†ì´ ìë™í™”ëœ ìš©ëŸ‰ ê²€ìƒ‰ì„ ìœ„í•´ sweep ëª¨ë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  ì‚¬ìš© ì‹œê¸°:  ì´ˆê¸° ë°°í¬ ì‹œCI/CD íŒŒì´í”„ë¼ì¸ë¹ ë¥¸ ìš©ëŸ‰ ì¬ê²€ì¦ ì‹œ  ","version":"Next","tagName":"h3"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 4: í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜â€‹","type":1,"pageTitle":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios#ì‹œë‚˜ë¦¬ì˜¤-4-í”„ë¡œë•ì…˜-ì‹œë®¬ë ˆì´ì…˜","content":" ê°€ë³€ ìš”ì²­ í¬ê¸°ì™€ ë²„ìŠ¤íŠ¸(Poisson) ë„ì°©ìœ¼ë¡œ ì‹¤ì œ íŠ¸ë˜í”½ì„ ë³µì œí•©ë‹ˆë‹¤.  ì‚¬ìš© ì‹œê¸°:  ì¶œì‹œ ì „ ìµœì¢… ê²€ì¦ ì‹œSLA ëª©í‘œ ì„¤ì • ì‹œí˜„ì‹¤ì ì¸ ì›Œí¬ë¡œë“œ ì²˜ë¦¬ ê²€ì¦ ì‹œ  ","version":"Next","tagName":"h3"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 5: ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸â€‹","type":1,"pageTitle":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios#ì‹œë‚˜ë¦¬ì˜¤-5-ì‹¤ì œ-ë°ì´í„°ì…‹-í…ŒìŠ¤íŠ¸","content":" ì‹¤ì œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì™€ ì¿¼ë¦¬ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡œë•ì…˜ ì¤€ë¹„ ì„±ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤.  ì‚¬ìš© ì‹œê¸°:  íŠ¹ì • íŒ¨í„´ì— ë§ê²Œ ëª¨ë¸ì´ ë¯¸ì„¸ ì¡°ì •ë˜ì—ˆì„ ë•Œëª¨ë¸ ë²„ì „ ë¹„êµ ì‹œì‹¤ì œ ì„±ëŠ¥ ë³´ì¥ì´ í•„ìš”í•  ë•Œ  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹","type":1,"pageTitle":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios#ì‚¬ì „-ìš”êµ¬-ì‚¬í•­","content":" ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ëŠ” ë°°í¬ë¥¼ ìœ„í•´ AI on EKS Benchmark Helm Chartë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì§„í–‰í•˜ê¸° ì „ì—:  Helm ì„¤ì¹˜ (ë²„ì „ 3.x ì´ìƒ)AI on EKS Helm ì €ì¥ì†Œ ì¶”ê°€: helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update EKS í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•œ kubectl ì ‘ê·¼ êµ¬ì„±ì¶”ë¡  ì„œë¹„ìŠ¤ ë°°í¬ (ì˜ˆ: ëª¨ë¸ì„ ì„œë¹™í•˜ëŠ” vLLM)  ","version":"Next","tagName":"h2"},{"title":"êµ¬í˜„ ì°¸ê³  ì‚¬í•­â€‹","type":1,"pageTitle":"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios#êµ¬í˜„-ì°¸ê³ -ì‚¬í•­","content":" ì•„ë˜ ê° ì‹œë‚˜ë¦¬ì˜¤ëŠ” ê¶Œì¥ ë°©ë²•ìœ¼ë¡œ Helm ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•œ ë°°í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì°¨íŠ¸ëŠ” ë‹¤ìŒì„ ì œê³µí•©ë‹ˆë‹¤:  ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì— ê±¸ì¹œ ì¼ê´€ëœ êµ¬ì„±íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ë¥¼ ìœ„í•œ ê°’ ê¸°ë°˜ ì‚¬ìš©ì ì •ì˜Pod ì–´í”¼ë‹ˆí‹° ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ê°€ í¬í•¨ëœ í”„ë¡œë•ì…˜ ì¤€ë¹„ ê¸°ë³¸ê°’ì¤‘ì•™ ì§‘ì¤‘ì‹ êµ¬ì„±ìœ¼ë¡œ ì‰¬ìš´ ìœ ì§€ ê´€ë¦¬  êµìœ¡ ëª©ì ì´ë‚˜ ì‚¬ìš©ì ì •ì˜ ë°°í¬ì˜ ê²½ìš° ê° ì‹œë‚˜ë¦¬ì˜¤ì—ëŠ” ì™„ì „í•œ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ êµ¬ì¡°ë¥¼ ë³´ì—¬ì£¼ëŠ” ì›ì‹œ Kubernetes YAMLì´ í¬í•¨ëœ ì ‘ì„ ìˆ˜ ìˆëŠ” ì„¹ì…˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ ëŒ€ì•ˆì  ì ‘ê·¼ ë°©ì‹ì€ ì‹œì‘ ì‹œ ë©”ì¸ ì»¨í…Œì´ë„ˆì— ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ëŠ” ëŸ°íƒ€ì„ ì¢…ì†ì„± ì„¤ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ","version":"Next","tagName":"h2"},{"title":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide","content":"","keywords":"","version":"Next"},{"title":"ë‹¨ê³„ 0: í™˜ê²½ ì„¤ì • (ì„ íƒ ì‚¬í•­)â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ë‹¨ê³„-0-í™˜ê²½-ì„¤ì •-ì„ íƒ-ï¿½ï¿½ì‚¬í•­","content":" ë°°í¬ ê²½ë¡œë¥¼ ì„ íƒí•˜ì‹­ì‹œì˜¤:  ","version":"Next","tagName":"h2"},{"title":"ê²½ë¡œ A (ê¶Œì¥): ai-on-eks ë¸”ë£¨í”„ë¦°íŠ¸ ì‚¬ìš©â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ê²½ë¡œ-a-ê¶Œì¥-ai-on-eks-ë¸”ë£¨í”„ë¦°íŠ¸-ì‚¬ìš©","content":" kube-prometheus-stackì„ ìë™ìœ¼ë¡œ ë°°í¬í•©ë‹ˆë‹¤ê³ ì •ëœ Prometheus URL: http://kube-prometheus-stack-prometheus.monitoring:9090íŒ”ë¡œìš°: https://awslabs.github.io/ai-on-eks/docs/infra/inference-ready-cluster  ","version":"Next","tagName":"h3"},{"title":"ê²½ë¡œ B: ê¸°ì¡´ EKS í´ëŸ¬ìŠ¤í„°â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ê²½ë¡œ-b-ê¸°ì¡´-eks-í´ëŸ¬ìŠ¤í„°","content":" ê¸°ì¡´ í´ëŸ¬ìŠ¤í„°ê°€ ìˆëŠ” ê²½ìš° ë‹¤ìŒ ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤:  Kubernetes 1.28+ ì´ìƒì˜ EKS í´ëŸ¬ìŠ¤í„°NVIDIA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ëœ GPU ë…¸ë“œ (g5.xlarge ì´ìƒ)Karpenter (ì„ íƒ ì‚¬í•­ì´ì§€ë§Œ ì˜¤í† ìŠ¤ì¼€ì¼ë§ì— ê¶Œì¥)S3 ì ‘ê·¼ì„ ìœ„í•´ êµ¬ì„±ëœ Pod Identity ë˜ëŠ” IRSAí´ëŸ¬ìŠ¤í„° ì ‘ê·¼ì´ êµ¬ì„±ëœ kubectlPrometheusê°€ ë¯¸ë¦¬ ë°°í¬ë˜ì–´ ìˆì–´ì•¼ í•¨ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì€ ë²¤ì¹˜ë§ˆí‚¹ì— ì„ íƒ ì‚¬í•­Prometheus ì„œë¹„ìŠ¤ ì´ë¦„ê³¼ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì•Œì•„ì•¼ í•¨ì˜ˆ: http://&lt;your-prometheus-service&gt;.&lt;namespace&gt;:9090  ","version":"Next","tagName":"h3"},{"title":"ë‹¨ê³„ 1: ì¶”ë¡  ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ë‹¨ê³„-1-ì¶”ë¡ -ëª¨ë¸-ë°°í¬","content":" ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— í™œì„± LLM ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.  ê²½ë¡œ A ì‚¬ìš©ì: ì‚¬ì „ êµ¬ì„±ëœ ì¶”ë¡  ë°°í¬ì™€ í•¨ê»˜ ai-on-eks ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬í•œ ê²½ìš° ë‹¨ê³„ 2ë¡œ ê±´ë„ˆë›°ì‹­ì‹œì˜¤.  ê²½ë¡œ B ì‚¬ìš©ì: inference-chartsë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ íƒí•œ ëª¨ë¸ë¡œ vLLMì„ ë°°í¬í•©ë‹ˆë‹¤:  # AI on EKS Helm ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update # vLLMìœ¼ë¡œ Qwen3-8B ë°°í¬ helm install qwen3-vllm ai-on-eks/inference-charts \\ --set model=Qwen/Qwen3-8B \\ --set inference.framework=vllm \\ --namespace default --create-namespace # ë°°í¬ í™•ì¸ kubectl get pods -n default -l app.kubernetes.io/name=inference-charts kubectl logs -n default -l app.kubernetes.io/name=inference-charts -f   ë²¤ì¹˜ë§ˆí‚¹ì„ ì§„í–‰í•˜ê¸° ì „ì— ëª¨ë¸ì´ ì¤€ë¹„ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì‹­ì‹œì˜¤. ì´ëŠ” ëª¨ë¸ í¬ê¸°ì™€ ë‹¤ìš´ë¡œë“œ ì†ë„ì— ë”°ë¼ ì¼ë°˜ì ìœ¼ë¡œ 3-10ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë‹¨ê³„ 2: AWS ìŠ¤í† ë¦¬ì§€ ì„¤ì • (S3 ì‚¬ìš© - ê¶Œì¥)â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ë‹¨ê³„-2-aws-ìŠ¤í† ë¦¬ì§€-ì„¤ì •-s3-ì‚¬ìš©---ê¶Œì¥","content":" ì°¸ê³ : ai-on-eks inference-ready-cluster ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•œ ê²½ìš° EKS Pod Identity Agent ì• ë“œì˜¨ì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì˜ ì• ë“œì˜¨ ì„¤ì¹˜ ëª…ë ¹ì„ ê±´ë„ˆë›°ê³  S3 ë²„í‚· ë° IAM ì—­í•  ìƒì„±ìœ¼ë¡œ ì§ì ‘ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  í•˜ë“œì½”ë”©ëœ ìê²© ì¦ëª… ì—†ì´ ë²¤ì¹˜ë§ˆí¬ Podê°€ S3ì— ê²°ê³¼ë¥¼ ì“¸ ìˆ˜ ìˆë„ë¡ AWS ìê²© ì¦ëª…ì„ ì„¤ì •í•©ë‹ˆë‹¤.  # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ë¥¼ ìœ„í•œ S3 ë²„í‚· ìƒì„± export BUCKET_NAME=&quot;inference-perf-results-$(aws sts get-caller-identity --query Account --output text)&quot; aws s3 mb s3://${BUCKET_NAME} --region us-west-2 # EKS Pod Identity Agent ì„¤ì¹˜ (ë¸”ë£¨í”„ë¦°íŠ¸ ì°¸ì¡°ì— ì´ë¯¸ ë°°í¬ë¨ - https://awslabs.github.io/ai-on-eks/docs/infra/inference-ready-cluster) aws eks create-addon \\ --cluster-name my-cluster \\ --addon-name eks-pod-identity-agent \\ --addon-version v1.3.0-eksbuild.1 # S3 ê¶Œí•œì´ ìˆëŠ” IAM ì—­í•  ìƒì„± cat &gt; trust-policy.json &lt;&lt;EOF { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [{ &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: { &quot;Service&quot;: &quot;pods.eks.amazonaws.com&quot; }, &quot;Action&quot;: [ &quot;sts:AssumeRole&quot;, &quot;sts:TagSession&quot; ] }] } EOF aws iam create-role \\ --role-name InferencePerfRole \\ --assume-role-policy-document file://trust-policy.json aws iam attach-role-policy \\ --role-name InferencePerfRole \\ --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess # Kubernetes ì„œë¹„ìŠ¤ ê³„ì •ì— ì—­í•  ì—°ê²° aws eks create-pod-identity-association \\ --cluster-name my-cluster \\ --namespace benchmarking \\ --service-account inference-perf-sa \\ --role-arn arn:aws:iam::ACCOUNT_ID:role/InferencePerfRole   ","version":"Next","tagName":"h2"},{"title":"ë‹¨ê³„ 3: ë²¤ì¹˜ë§ˆí¬ ë¦¬ì†ŒìŠ¤ ë°°í¬â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ë‹¨ê³„-3-ë²¤ì¹˜ë§ˆí¬-ë¦¬ì†ŒìŠ¤-ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"ì˜µì…˜ A: Helm ì°¨íŠ¸ ì‚¬ìš© (ê¶Œì¥)â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ì˜µì…˜-a-helm-ì°¨íŠ¸-ì‚¬ìš©-ê¶Œì¥","content":" AI on EKS Benchmark Helm ChartëŠ” ê°„ì†Œí™”ëœ êµ¬ì„± ê´€ë¦¬ì™€ í•¨ê»˜ í”„ë¡œë•ì…˜ ì¤€ë¹„ ë°°í¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ë²¤ì¹˜ë§ˆí¬ ì„¤ì¹˜:  # AI on EKS Helm ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update # í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ë°°í¬ helm install production-test ai-on-eks/benchmark-charts \\ --set benchmark.scenario=production \\ --set benchmark.target.baseUrl=http://qwen3-vllm.default:8000 \\ --set benchmark.target.modelName=qwen3-8b \\ --set benchmark.target.tokenizerPath=Qwen/Qwen3-8B \\ --namespace benchmarking --create-namespace   ì‚¬ìš©ì ì •ì˜ ê°’ìœ¼ë¡œ ì»¤ìŠ¤í„°ë§ˆì´ì§•:  # custom-benchmark.yaml benchmark: scenario: production target: baseUrl: http://qwen3-vllm.default:8000 modelName: qwen3-8b tokenizerPath: Qwen/Qwen3-8B # S3 ìŠ¤í† ë¦¬ì§€ êµ¬ì„± storage: s3: enabled: true bucketName: inference-perf-results path: &quot;inference-perf/results&quot; # ë™ì¼ AZ ë°°ì¹˜ë¥¼ ìœ„í•œ Pod ì–´í”¼ë‹ˆí‹° affinity: enabled: true targetLabels: app.kubernetes.io/component: qwen3-vllm # ë¦¬ì†ŒìŠ¤ í• ë‹¹ resources: requests: cpu: &quot;2&quot; memory: &quot;4Gi&quot; limits: cpu: &quot;4&quot; memory: &quot;8Gi&quot;   ì‚¬ìš©ì ì •ì˜ ê°’ìœ¼ë¡œ ë°°í¬:  helm install production-test ai-on-eks/benchmark-charts \\ -f custom-benchmark.yaml \\ --namespace benchmarking --create-namespace   Helm ì ‘ê·¼ ë°©ì‹ì˜ ì´ì :  ì¥í™©í•œ YAML ëŒ€ì‹  values.yamlì„ í†µí•œ ê°„ì†Œí™”ëœ êµ¬ì„±ì‚¬ì „ êµ¬ì„±ëœ ì‹œë‚˜ë¦¬ì˜¤ (baseline, saturation, sweep, production)Pod ì–´í”¼ë‹ˆí‹°, ë¦¬ì†ŒìŠ¤ ë° ì¢…ì†ì„±ì— ëŒ€í•œ ì¼ê´€ëœ ê¸°ë³¸ê°’Helm ë²„ì „ ê´€ë¦¬ë¥¼ í†µí•œ ì†ì‰¬ìš´ ì—…ê·¸ë ˆì´ë“œ ë° ë¡¤ë°±  ","version":"Next","tagName":"h3"},{"title":"ì˜µì…˜ B: ìˆ˜ë™ Kubernetes YAML (êµìœ¡ìš©)â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ì˜µì…˜-b-ìˆ˜ë™-kubernetes-yaml-êµìœ¡ìš©","content":" í•™ìŠµ ëª©ì ì´ë‚˜ ê³ ë„ë¡œ ì‚¬ìš©ì ì •ì˜ëœ ë°°í¬ì˜ ê²½ìš° Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¡œ ì§ì ‘ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ ëª¨ë“  ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì™„ì „í•œ íˆ¬ëª…ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.  í¼ì³ì„œ ë³´ê¸°: ìˆ˜ë™ YAML ë°°í¬ ì§€ì¹¨ ëª¨ë¸ ì¢…ì†ì„± ì²˜ë¦¬â€‹ ì¼ë¶€ ëª¨ë¸ì€ ê¸°ë³¸ inference-perf ì»¨í…Œì´ë„ˆì— í¬í•¨ë˜ì§€ ì•Šì€ ì¶”ê°€ Python íŒ¨í‚¤ì§€ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Mistral ë° Llama ëª¨ë¸ì—ëŠ” sentencepieceê°€ í•„ìš”í•©ë‹ˆë‹¤. Qwen3 ëª¨ë¸ì€ ì´ë¯¸ í¬í•¨ëœ tiktokenì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì¶”ê°€ íŒ¨í‚¤ì§€ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹: ì ‘ê·¼ ë°©ì‹ A: ëŸ°íƒ€ì„ ì„¤ì¹˜ (ê¶Œì¥ - ê°„ë‹¨)â€‹ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì „ ë©”ì¸ ì»¨í…Œì´ë„ˆ ì‹œì‘ì˜ ì¼ë¶€ë¡œ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤: spec: backoffLimit: 2 ttlSecondsAfterFinished: 3600 template: metadata: labels: app: inference-perf spec: restartPolicy: Never serviceAccountName: inference-perf-sa ... containers: - name: inference-perf image: quay.io/inference-perf/inference-perf:v0.2.0 command: [&quot;/bin/sh&quot;, &quot;-c&quot;] args: - | echo &quot;Installing dependencies...&quot; pip install --no-cache-dir sentencepiece==0.2.0 protobuf==5.29.2 echo &quot;Dependencies installed successfully&quot; echo &quot;Starting inference-perf...&quot; inference-perf --config_file /workspace/config.yml ì ‘ê·¼ ë°©ì‹ B: ì‚¬ìš©ì ì •ì˜ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ (ê³ ê¸‰)â€‹ ì¢…ì†ì„±ì´ ì‚¬ì „ ì„¤ì¹˜ëœ ì‚¬ìš©ì ì •ì˜ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤: FROM quay.io/inference-perf/inference-perf:v0.2.0 RUN pip install --no-cache-dir sentencepiece==0.2.0 protobuf==5.29.2 ê° ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:â€‹ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ì™€ ìœ ì—°ì„±ì„ ìœ„í•´ ì ‘ê·¼ ë°©ì‹ A ì‚¬ìš©í”„ë¡œë•ì…˜ ì¬í˜„ì„±ê³¼ ë” ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•´ ì ‘ê·¼ ë°©ì‹ B ì‚¬ìš© ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë° ì„œë¹„ìŠ¤ ê³„ì • ìƒì„±â€‹ cat &lt;&lt;EOF | kubectl apply -f - # ë²¤ì¹˜ë§ˆí¬ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ apiVersion: v1 kind: Namespace metadata: name: benchmarking --- # ì„œë¹„ìŠ¤ ê³„ì • (Pod Identityë¥¼ í†µí•´ AWS IAMì— ì—°ê²°) apiVersion: v1 kind: ServiceAccount metadata: name: inference-perf-sa namespace: benchmarking EOF HuggingFace í† í° Secret ìƒì„± (ì„ íƒ ì‚¬í•­ì´ì§€ë§Œ ê¶Œì¥)â€‹ ëª¨ë¸ì´ HuggingFaceì—ì„œ í† í¬ë‚˜ì´ì €ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê¸° ìœ„í•´ ì¸ì¦ì´ í•„ìš”í•œ ê²½ìš° ì•„ë˜ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ secretì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ ë°©ì‹ì€ ì‹¤ìˆ˜ë¡œ ë²„ì „ ê´€ë¦¬ì— ì»¤ë°‹ë  ìˆ˜ ìˆëŠ” YAML íŒŒì¼ì— secretì„ ì •ì˜í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ì•ˆì „í•©ë‹ˆë‹¤. ë‹¨ê³„ 1: HuggingFace í† í° ì–»ê¸° https://huggingface.co/settings/tokens ìœ¼ë¡œ ì´ë™ì½ê¸° í† í°ì´ ì—†ëŠ” ê²½ìš° ìƒì„± ë‹¨ê³„ 2: secret ìƒì„± kubectl create secret generic hf-token \\ --from-literal=token=YOUR_HUGGINGFACE_TOKEN_HERE \\ --namespace=benchmarking ë‹¨ê³„ 3: secretì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸ kubectl get secret hf-token -n benchmarking ë³´ì•ˆ ì°¸ê³ : Git ì €ì¥ì†Œì— secretì„ ì»¤ë°‹í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. í”„ë¡œë•ì…˜ ë°°í¬ì—ëŠ” í•­ìƒ ëª…ë ¹í˜• ëª…ë ¹ ë˜ëŠ” ì™¸ë¶€ secret ê´€ë¦¬ ë„êµ¬(AWS Secrets Manager, HashiCorp Vault ë“±)ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ConfigMap ë° Job ìƒì„±â€‹ cat &lt;&lt;EOF | kubectl apply -f - # ë²¤ì¹˜ë§ˆí¬ êµ¬ì„± apiVersion: v1 kind: ConfigMap metadata: name: inference-perf-config namespace: benchmarking data: config.yml: | # API êµ¬ì„± api: type: completion streaming: true # ë°ì´í„° ìƒì„± - í˜„ì‹¤ì ì¸ ë¶„í¬ë¥¼ ê°€ì§„ í•©ì„± data: type: synthetic input_distribution: mean: 512 std_dev: 128 min: 128 max: 2048 output_distribution: mean: 256 std_dev: 64 min: 32 max: 512 # ë¶€í•˜ íŒ¨í„´ - 5ë¶„ ë™ì•ˆ 10 QPSì˜ Poisson ë„ì°© load: type: poisson stages: - rate: 10 duration: 300 num_workers: 4 # ëª¨ë¸ ì„œë²„ server: type: vllm model_name: qwen3-8b base_url: http://qwen3-vllm.default:8000 ignore_eos: true # í† í¬ë‚˜ì´ì € tokenizer: pretrained_model_name_or_path: Qwen/Qwen3-8B # ìŠ¤í† ë¦¬ì§€ - ê²°ê³¼ê°€ S3ì— ìë™ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤ storage: simple_storage_service: bucket_name: &quot;inference-perf-results&quot; path: &quot;inference-perf/results&quot; # ì„ íƒ ì‚¬í•­: Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ # metrics: # type: prometheus # prometheus: # url: http://kube-prometheus-stack-prometheus.monitoring:9090 # scrape_interval: 15 EOF --- cat &lt;&lt;EOF | kubectl apply -f - # ë²¤ì¹˜ë§ˆí¬ Job apiVersion: batch/v1 kind: Job metadata: name: inference-perf-run namespace: benchmarking labels: app: inference-perf spec: backoffLimit: 2 ttlSecondsAfterFinished: 3600 template: metadata: labels: app: inference-perf spec: restartPolicy: Never serviceAccountName: inference-perf-sa # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ì¶”ë¡  Podì™€ ë™ì¼ AZ ë°°ì¹˜ affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchLabels: app.kubernetes.io/component: qwen3-vllm topologyKey: topology.kubernetes.io/zone containers: - name: inference-perf image: quay.io/inference-perf/inference-perf:v0.2.0 command: [&quot;/bin/sh&quot;, &quot;-c&quot;] args: - | echo &quot;Starting inference-perf...&quot; inference-perf --config_file /workspace/config.yml volumeMounts: - name: config mountPath: /workspace/config.yml subPath: config.yml env: - name: HF_TOKEN valueFrom: secretKeyRef: name: hf-token key: token optional: true resources: requests: cpu: &quot;2&quot; memory: &quot;4Gi&quot; limits: cpu: &quot;4&quot; memory: &quot;8Gi&quot; volumes: - name: config configMap: name: inference-perf-config EOF íŒ: í‘œì‹œëœ ë¦¬ì†ŒìŠ¤ ê°’ì€ ì‹œì‘ì ì…ë‹ˆë‹¤. ë” ë†’ì€ ë™ì‹œì„± ìˆ˜ì¤€ì´ë‚˜ ë” ê¸´ í…ŒìŠ¤íŠ¸ ê¸°ê°„ì˜ ê²½ìš° kubectl top pod -n benchmarkingìœ¼ë¡œ Pod ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì ì ˆíˆ ì¡°ì •í•˜ì‹­ì‹œì˜¤.    ","version":"Next","tagName":"h3"},{"title":"ë‹¨ê³„ 4: ë°°í¬ ë° ëª¨ë‹ˆí„°ë§â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ë‹¨ê³„-4-ë°°í¬-ë°-ëª¨ë‹ˆí„°ë§","content":" ","version":"Next","tagName":"h2"},{"title":"Helm ë°°í¬ì˜ ê²½ìš°:â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#helm-ë°°í¬ì˜-ê²½ìš°","content":" # Job ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ kubectl get jobs -n benchmarking -w # ë²¤ì¹˜ë§ˆí¬ ì§„í–‰ ìƒí™©ì„ ë³´ê¸° ìœ„í•´ ë¡œê·¸ íŒ”ë¡œìš° kubectl logs -n benchmarking -l app.kubernetes.io/component=benchmark -f # Helm ë¦´ë¦¬ìŠ¤ ìƒíƒœ í™•ì¸ helm status production-test -n benchmarking   ","version":"Next","tagName":"h3"},{"title":"ìˆ˜ë™ YAML ë°°í¬ì˜ ê²½ìš°:â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ìˆ˜ë™-yaml-ë°°í¬ì˜-ê²½ìš°","content":" ìœ„ì˜ ì˜µì…˜ Bì—ì„œ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ inference-perf-complete.yamlë¡œ ì €ì¥í•˜ê³  ë°°í¬í•©ë‹ˆë‹¤:  # ëª¨ë“  ë¦¬ì†ŒìŠ¤ ë°°í¬ kubectl apply -f inference-perf-complete.yaml # Job ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ kubectl get jobs -n benchmarking -w # ë²¤ì¹˜ë§ˆí¬ ì§„í–‰ ìƒí™©ì„ ë³´ê¸° ìœ„í•´ ë¡œê·¸ íŒ”ë¡œìš° kubectl logs -n benchmarking -l app=inference-perf -f   ","version":"Next","tagName":"h3"},{"title":"ë‹¨ê³„ 5: ê²°ê³¼ ê²€ìƒ‰â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ë‹¨ê³„-5-ê²°ê³¼-ê²€ìƒ‰","content":" ","version":"Next","tagName":"h2"},{"title":"S3 ìŠ¤í† ë¦¬ì§€ ì‚¬ìš© (ê¶Œì¥):â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#s3-ìŠ¤í† ë¦¬ì§€-ì‚¬ìš©-ê¶Œì¥","content":" ê²°ê³¼ê°€ S3 ë²„í‚·ì— ìë™ìœ¼ë¡œ ì—…ë¡œë“œë©ë‹ˆë‹¤. ì§ì ‘ ì ‘ê·¼í•©ë‹ˆë‹¤:  # S3ì—ì„œ ê²°ê³¼ ë‚˜ì—´ (ë‹¨ê³„ 2ì˜ ë²„í‚· ì´ë¦„ ì‚¬ìš©) aws s3 ls s3://${BUCKET_NAME}/inference-perf/ --recursive # íŠ¹ì • ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ aws s3 cp s3://${BUCKET_NAME}/inference-perf/20251020-143000/summary_lifecycle_metrics.json ./   ","version":"Next","tagName":"h3"},{"title":"ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ì‚¬ìš© (ëŒ€ì•ˆ):â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ë¡œì»¬-ìŠ¤í† ë¦¬ì§€-ì‚¬ìš©-ëŒ€ì•ˆ","content":" S3 ëŒ€ì‹  local_storageë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° Podê°€ ì¢…ë£Œë˜ê¸° ì „ì— ìˆ˜ë™ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë³µì‚¬í•´ì•¼ í•©ë‹ˆë‹¤:  # config.ymlì—ì„œ ë‹¤ìŒì„ ì‚¬ìš©í•©ë‹ˆë‹¤: storage: local_storage: path: &quot;reports-results&quot; # Pod ì´ë¦„ ê°€ì ¸ì˜¤ê¸° POD_NAME=$(kubectl get pods -n benchmarking -l app=inference-perf -o jsonpath='{.items[0].metadata.name}') # Podì—ì„œ ê²°ê³¼ ë³µì‚¬ kubectl cp benchmarking/$POD_NAME:/reports-* ./local-reports/   ","version":"Next","tagName":"h3"},{"title":"ìŠ¤í† ë¦¬ì§€ ë¹„êµ:â€‹","type":1,"pageTitle":"ì™„ì „í•œ ë°°í¬ ì˜ˆì œ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide#ìŠ¤í† ë¦¬ì§€-ë¹„êµ","content":" ê¸°ëŠ¥\të¡œì»¬ ìŠ¤í† ë¦¬ì§€\tS3 ìŠ¤í† ë¦¬ì§€ì„¤ì •\tí•„ìš” ì—†ìŒ\tAWS ìê²© ì¦ëª… í•„ìš” ì§€ì†ì„±\tìˆ˜ë™ ë³µì‚¬ í•„ìš”\tìë™ ì í•©í•œ ìš©ë„\të¹ ë¥¸ í…ŒìŠ¤íŠ¸, ì‹¤í—˜\tí”„ë¡œë•ì…˜, ìë™í™” ê²°ê³¼ ì ‘ê·¼\tkubectl cp ëª…ë ¹\tAWS S3 ëª…ë ¹/ì½˜ì†” ","version":"Next","tagName":"h3"},{"title":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks","content":"","keywords":"","version":"Next"},{"title":"ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ì‚¬ì „-ìš”êµ¬-ì‚¬í•­","content":" kubectl ì ‘ê·¼ ê°€ëŠ¥í•œ Kubernetes í´ëŸ¬ìŠ¤í„° (ë²„ì „ 1.21+)OpenAI í˜¸í™˜ API(vLLM, SGLang, TGI ë˜ëŠ” í˜¸í™˜ ê°€ëŠ¥)ê°€ ìˆëŠ” ë°°í¬ëœ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ì„ ìœ„í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€: quay.io/inference-perf/inference-perf:v0.2.0(ì„ íƒ ì‚¬í•­) í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•œ HuggingFace í† í°(ì„ íƒ ì‚¬í•­) S3 ìŠ¤í† ë¦¬ì§€ë¥¼ ìœ„í•œ AWS ìê²© ì¦ëª…  ","version":"Next","tagName":"h2"},{"title":"ëª¨ë¸ë³„ ì¢…ì†ì„±â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ëª¨ë¸ë³„-ì¢…ì†ì„±","content":" ì£¼ì˜: ë‹¤ë¥¸ ëª¨ë¸ì€ ë‹¤ë¥¸ í† í¬ë‚˜ì´ì € íŒ¨í‚¤ì§€ë¥¼ í•„ìš”ë¡œ í•©ë‹ˆë‹¤:  ëª¨ë¸ íŒ¨ë°€ë¦¬\tsentencepiece í•„ìš”?\tì˜ˆì‹œMistral (ëª¨ë“  ë²„ì „)\tì˜ˆ\tmistralai/Mistral-7B-Instruct-v0.3 Llama 2\tì˜ˆ\tmeta-llama/Llama-2-7b-hf Llama 3.1\tì˜ˆ\tmeta-llama/Meta-Llama-3.1-8B SmolLM2\tì•„ë‹ˆì˜¤\tHuggingFaceTB/SmolLM2-135M-Instruct GPT ëª¨ë¸\tì•„ë‹ˆì˜¤\të‹¤ì–‘í•œ GPT ë³€í˜•  Mistral ë˜ëŠ” Llama ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° sentencepiece íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. êµ¬í˜„ì— ëŒ€í•´ì„œëŠ” ì•„ë˜ì˜ &quot;ëª¨ë¸ ì¢…ì†ì„± ì²˜ë¦¬&quot; ì„¹ì…˜ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h2"},{"title":"ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ í”„ë ˆì„ì›Œí¬ ì•„í‚¤í…ì²˜ ì´í•´â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ì¶”ë¡ -ë²¤ì¹˜ë§ˆí¬-í”„ë ˆì„ì›Œí¬-ì•„í‚¤í…ì²˜-ì´í•´","content":" ë°°í¬í•˜ê¸° ì „ì— ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ë¥¼ ì •ì˜í•˜ëŠ” ì£¼ìš” êµ¬ì„± êµ¬ì„± ìš”ì†Œë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"API êµ¬ì„±â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#api-êµ¬ì„±","content":" ë„êµ¬ê°€ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ì™€ í†µì‹ í•˜ëŠ” ë°©ë²•ì„ ì •ì˜í•©ë‹ˆë‹¤. completion ë˜ëŠ” chat APIë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€, ìŠ¤íŠ¸ë¦¬ë°ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€(TTFT ë° ITL ë©”íŠ¸ë¦­ ì¸¡ì •ì— í•„ìš”) ì§€ì •í•©ë‹ˆë‹¤.  api: type: completion # completion ë˜ëŠ” chat streaming: true # TTFT/ITL ë©”íŠ¸ë¦­ì„ ìœ„í•´ í™œì„±í™”   ì˜¬ë°”ë¥¸ API ìœ í˜• ê²°ì •:  inference-charts ë°°í¬ëŠ” ëª¨ë¸ì˜ ê¸°ëŠ¥ì— ë”°ë¼ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‹ë³„í•˜ë ¤ë©´:  ë°©ë²• 1: vLLM ë°°í¬ ë¡œê·¸ í™•ì¸ (ê¶Œì¥)  vLLM ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ì‹œì‘ ì‹œ í™œì„±í™”ëœ API ì—”ë“œí¬ì¸íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤:  # í™œì„±í™”ëœ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë³´ì—¬ì£¼ëŠ” vLLM ì‹œì‘ ë¡œê·¸ ë³´ê¸° kubectl logs -n default -l app.kubernetes.io/name=inference-charts --tail=100 | grep -i &quot;route\\|endpoint\\|application&quot;   í™œì„±í™”ëœ ë¼ìš°íŠ¸ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì¶œë ¥ì„ ì°¾ìŠµë‹ˆë‹¤:  Route: /v1/completions â†’ type: completion ì‚¬ìš©Route: /v1/chat/completions â†’ type: chat ì‚¬ìš©  ë‘ ë¼ìš°íŠ¸ê°€ ëª¨ë‘ ë‚˜íƒ€ë‚˜ë©´ completionì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (ë²¤ì¹˜ë§ˆí‚¹ì— ë” ê°„ë‹¨).  ë°©ë²• 2: ëª¨ë¸ ê¸°ëŠ¥ í™•ì¸ (ì„ íƒ ì‚¬í•­)  ëª¨ë¸ì˜ ì´ë¡ ì  ê¸°ëŠ¥ì„ ì´í•´í•˜ë ¤ë©´ ëª¨ë¸ì˜ Hugging Face ëª¨ë¸ ì¹´ë“œë¥¼ ê²€í† í•˜ì‹­ì‹œì˜¤. ì •ì˜ëœ ì±„íŒ… í…œí”Œë¦¿ì´ ìˆëŠ” ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ chat completion APIë¥¼ ì§€ì›í•˜ì§€ë§Œ ì‹¤ì œ ë°°í¬ êµ¬ì„±ì´ í™œì„±í™”ëœ ê²ƒì„ ê²°ì •í•©ë‹ˆë‹¤.  ì°¸ê³ : OpenAI completion API (v1/completions)ëŠ” OpenAIì—ì„œ ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ vLLM, SGLang ë° TGIì—ì„œ ë„ë¦¬ ì§€ì›ë©ë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ inference-charts ë°°í¬ëŠ” ì¶”ê°€ êµ¬ì„± ì—†ì´ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ë°ì´í„° ìƒì„±â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ë°ì´í„°-ìƒì„±","content":" ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ë¡œ ì „ì†¡ë˜ëŠ” ë°ì´í„°ë¥¼ ì œì–´í•©ë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ì…‹(ShareGPT) ë˜ëŠ” ì œì–´ëœ ë¶„í¬ë¥¼ ê°€ì§„ í•©ì„± ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•©ì„± ë°ì´í„°ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ íŠ¹ì • ì…ë ¥/ì¶œë ¥ ê¸¸ì´ íŒ¨í„´ì´ í•„ìš”í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.  data: type: synthetic # shareGPT, synthetic, random, shared_prefix ë“± input_distribution: mean: 512 # í† í° ë‹¨ìœ„ í‰ê·  ì…ë ¥ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ std_dev: 128 # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ì˜ ë³€ë™ (í‰ê·  Â±128 í† í° ë‚´ 68%) min: 128 # ìµœì†Œ ì…ë ¥ í† í° (ë¶„í¬ í•˜í•œ í´ë¦¬í•‘) max: 2048 # ìµœëŒ€ ì…ë ¥ í† í° (ë¶„í¬ ìƒí•œ í´ë¦¬í•‘) output_distribution: mean: 256 # í† í° ë‹¨ìœ„ í‰ê·  ìƒì„± ì‘ë‹µ ê¸¸ì´ std_dev: 64 # ì‘ë‹µ ê¸¸ì´ì˜ ë³€ë™ (í‰ê·  Â±64 í† í° ë‚´ 68%) min: 32 # ìµœì†Œ ì¶œë ¥ í† í° (ë¶„í¬ í•˜í•œ í´ë¦¬í•‘) max: 512 # ìµœëŒ€ ì¶œë ¥ í† í° (ë¶„í¬ ìƒí•œ í´ë¦¬í•‘)   ","version":"Next","tagName":"h3"},{"title":"ë¶€í•˜ ìƒì„±â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ë¶€í•˜-ìƒì„±","content":" ë¶€í•˜ íŒ¨í„´ì„ ì •ì˜í•©ë‹ˆë‹¤ - ì´ˆë‹¹ ìš”ì²­ ìˆ˜ì™€ ê¸°ê°„. ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ë¥¸ ë¶€í•˜ ìˆ˜ì¤€ì„ í…ŒìŠ¤íŠ¸í•˜ê±°ë‚˜ ìë™ í¬í™” ê°ì§€ë¥¼ ìœ„í•´ sweep ëª¨ë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  load: type: constant # ê· ì¼í•œ ë„ì°©(ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¶€í•˜)ì—ëŠ” 'constant', ë²„ìŠ¤íŠ¸ íŠ¸ë˜í”½(í˜„ì‹¤ì ì¸ í”„ë¡œë•ì…˜)ì—ëŠ” 'poisson' ì‚¬ìš© stages: - rate: 10 # ì´ˆë‹¹ ìš”ì²­ ìˆ˜ (QPS) - ë” ë†’ì€ ì²˜ë¦¬ëŸ‰ì„ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ì¦ê°€, ê¸°ì¤€ì„ /ìµœì†Œ ë¶€í•˜ì—ëŠ” ê°ì†Œ duration: 300 # ì´ ë¹„ìœ¨ì„ ìœ ì§€í•  ì‹œê°„(ì´ˆ) - ë” ê¸´ ê¸°ê°„(300-600ì´ˆ)ì€ ì•ˆì •ì ì¸ ì¸¡ì •ì„ ë³´ì¥ num_workers: 4 # ë¶€í•˜ë¥¼ ìƒì„±í•˜ëŠ” ë™ì‹œ ì›Œì»¤ - inference-perfê°€ ëª©í‘œ ë¹„ìœ¨ì„ ë‹¬ì„±í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì¦ê°€ (ê²°ê³¼ì—ì„œ ìŠ¤ì¼€ì¤„ë§ ì§€ì—° í™•ì¸)   num_workers ì°¸ê³ : ì´ê²ƒì€ ë™ì‹œ ì‚¬ìš©ìê°€ ì•„ë‹Œ ë²¤ì¹˜ë§ˆí¬ ë„êµ¬ì˜ ë‚´ë¶€ ë³‘ë ¬ì„±ì„ ì œì–´í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ 4ëŠ” ëŒ€ë¶€ë¶„ì˜ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤. ê²°ê³¼ì—ì„œ ë†’ì€ schedule_delay (&gt; 10ms)ê°€ í‘œì‹œë˜ì–´ ë„êµ¬ê°€ ëª©í‘œ ë¹„ìœ¨ì„ ìœ ì§€í•  ìˆ˜ ì—†ìŒì„ ë‚˜íƒ€ë‚´ëŠ” ê²½ìš°ì—ë§Œ ì¦ê°€ì‹œí‚¤ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h3"},{"title":"ì„œë²„ êµ¬ì„±â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ì„œë²„-êµ¬ì„±","content":" ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ ì„¸ë¶€ ì •ë³´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤ - ì„œë²„ ìœ í˜•, ëª¨ë¸ ì´ë¦„ ë° URL.  server: type: vllm # vllm, sglang ë˜ëŠ” tgi model_name: qwen3-8b base_url: http://qwen3-vllm.default:8000 ignore_eos: true   ","version":"Next","tagName":"h3"},{"title":"ìŠ¤í† ë¦¬ì§€ êµ¬ì„±â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ìŠ¤í† ë¦¬ì§€-êµ¬ì„±","content":" ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ê°€ ì €ì¥ë˜ëŠ” ìœ„ì¹˜ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ëŠ” Pod íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥(ìˆ˜ë™ ë³µì‚¬ í•„ìš”)í•˜ê³ , S3 ìŠ¤í† ë¦¬ì§€ëŠ” ê²°ê³¼ë¥¼ AWS ë²„í‚·ì— ìë™ìœ¼ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.  storage: local_storage: # ê¸°ë³¸ê°’: Podì— ì €ì¥ path: &quot;reports-results&quot; # ì£¼ì˜: local_storage ê²°ê³¼ëŠ” Pod ì¢…ë£Œ ì‹œ ì†ì‹¤ë©ë‹ˆë‹¤ # ê²°ê³¼ë¥¼ ê²€ìƒ‰í•˜ë ¤ë©´ Job argsì— '&amp;&amp; sleep infinity'ë¥¼ ì¶”ê°€í•˜ê³  ë‹¤ìŒì„ ì‚¬ìš©í•©ë‹ˆë‹¤: # kubectl cp &lt;pod-name&gt;:/workspace/reports-* ./local-results -n benchmarking # ë˜ëŠ” simple_storage_service: # S3: ìë™ ì§€ì†ì„± bucket_name: &quot;my-results-bucket&quot; path: &quot;inference-perf/results&quot;   ","version":"Next","tagName":"h3"},{"title":"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (ì„ íƒ ì‚¬í•­)â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ë©”íŠ¸ë¦­-ìˆ˜ì§‘-ì„ íƒ-ì‚¬í•­","content":" ì¶”ë¡  ì„œë²„ê°€ ë©”íŠ¸ë¦­ì„ ë…¸ì¶œí•˜ëŠ” ê²½ìš° Prometheusì—ì„œ ê³ ê¸‰ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì„ í™œì„±í™”í•©ë‹ˆë‹¤.  metrics: type: prometheus prometheus: url: http://kube-prometheus-stack-prometheus.monitoring:9090 # ai-on-eks Path Aìš©; ì‚¬ìš©ì ì •ì˜ Prometheusì˜ ê²½ìš° ì„œë¹„ìŠ¤ ì´ë¦„/ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¡°ì • scrape_interval: 15   ì°¸ê³ : Prometheus URLì€ Kubernetes DNS í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: http://&lt;service-name&gt;.&lt;namespace&gt;:&lt;port&gt;. Prometheusê°€ ë‹¤ë¥¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤(ì˜ˆ: monitoring, observability)ì— ë°°í¬ëœ ê²½ìš° URLì„ ì ì ˆíˆ ì—…ë°ì´íŠ¸í•˜ì‹­ì‹œì˜¤. ë²¤ì¹˜ë§ˆí¬ Jobì€ benchmarking ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ í¬ë¡œìŠ¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì„œë¹„ìŠ¤ ì ‘ê·¼ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì¸í”„ë¼ í† í´ë¡œì§€â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ì¬í˜„-ï¿½ï¿½ê°€ëŠ¥í•œ-ê²°ê³¼ë¥¼-ìœ„í•œ-ì¸í”„ë¼-í† í´ë¡œì§€","content":" ì—¬ëŸ¬ ì‹¤í–‰ì— ê±¸ì³ ì •í™•í•˜ê³  ë¹„êµ ê°€ëŠ¥í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ìœ„í•´ inference-perf Jobì€ ì¶”ë¡  ë°°í¬ì™€ ë°˜ë“œì‹œ ë™ì¼í•œ AZì— ë°°ì¹˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì¤‘ìš”í•œ ì´ìœ :â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ì¤‘ìš”í•œ-ì´ìœ ","content":" ì ì ˆí•œ ë°°ì¹˜ ì—†ì´ëŠ” ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ê°€ ì‹ ë¢°í•  ìˆ˜ ì—†ê²Œ ë©ë‹ˆë‹¤:  í¬ë¡œìŠ¤ AZ ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì€ ìš”ì²­ë‹¹ 1-2msë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ì— ë”°ë¼ ê²°ê³¼ê°€ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•˜ê²Œ ë³€í•©ë‹ˆë‹¤ì„±ëŠ¥ ë³€í™”ê°€ ì‹¤ì œì¸ì§€ ì¸í”„ë¼ ë°°ì¹˜ ë•Œë¬¸ì¸ì§€ ê²°ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ìµœì í™” ê²°ì •ì´ ë¶ˆê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤  ","version":"Next","tagName":"h3"},{"title":"ë¬¸ì œì˜ ì˜ˆ:â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ë¬¸ì œì˜-ì˜ˆ","content":" ì²« ë²ˆì§¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰: - us-west-2aì˜ ë²¤ì¹˜ë§ˆí¬ Pod â†’ us-west-2aì˜ ì¶”ë¡  Pod - ê²°ê³¼: TTFT = 800ms ë‘ ë²ˆì§¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (Pod ì¬ì‹œì‘ í›„): - us-west-2bì˜ ë²¤ì¹˜ë§ˆí¬ Pod â†’ us-west-2aì˜ ì¶”ë¡  Pod - ê²°ê³¼: TTFT = 850ms   50ms ì°¨ì´ëŠ” í¬ë¡œìŠ¤ AZ ì§€ì—°ì´ì§€ ì‹¤ì œ ì„±ëŠ¥ ë³€í™”ê°€ ì•„ë‹™ë‹ˆë‹¤.  í¬ë¡œìŠ¤ AZ í…ŒìŠ¤íŠ¸ ì°¸ê³ : ë™ì¼ AZ ë°°ì¹˜ê°€ ê¸°ì¤€ì„  ë²¤ì¹˜ë§ˆí‚¹ ë° ì„±ëŠ¥ ìµœì í™”ì— ê¶Œì¥ë˜ì§€ë§Œ, í¬ë¡œìŠ¤ AZ í…ŒìŠ¤íŠ¸ëŠ” ì¶”ë¡  ì„œë¹„ìŠ¤ê°€ ì—¬ëŸ¬ ê°€ìš© ì˜ì—­ì— ê±¸ì³ ìˆëŠ” ê³ ê°€ìš©ì„±(HA) ë°°í¬ë¥¼ ê²€ì¦í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. í”„ë¡œë•ì…˜ ë°°í¬ê°€ ë‚´ê²°í•¨ì„±ì„ ìœ„í•´ ë‹¤ì¤‘ AZ ë¡œë“œ ë°¸ëŸ°ì‹±ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, í¬ë¡œìŠ¤ AZ ë°°ì¹˜ë¡œ ë³„ë„ì˜ ë²¤ì¹˜ë§ˆí¬ë¥¼ ìˆ˜í–‰í•˜ì—¬ ì˜ì—­ë³„ ë¼ìš°íŒ… ì¤‘ ì‚¬ìš©ìê°€ ê²½í—˜í•  ìˆ˜ ìˆëŠ” ì§€ì—° ì˜í–¥ì„ ì´í•´í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h3"},{"title":"í•„ìˆ˜ êµ¬ì„±:â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#í•„ìˆ˜-êµ¬ì„±","content":" ì´ ê°€ì´ë“œì˜ ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ Job ì˜ˆì œì—ëŠ” í‘œì¤€ Kubernetes í† í´ë¡œì§€ ë ˆì´ë¸” topology.kubernetes.io/zoneì„ ì‚¬ìš©í•˜ì—¬ ë™ì¼ AZ ë°°ì¹˜ë¥¼ ì ìš©í•˜ëŠ” affinity êµ¬ì„±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:  spec: template: spec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchLabels: app.kubernetes.io/component: qwen3-vllm topologyKey: topology.kubernetes.io/zone   ì¤‘ìš”: matchLabelsëŠ” ì‹¤ì œ vLLM ë°°í¬ ë ˆì´ë¸”ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ë°°í¬ì˜ Pod ë ˆì´ë¸”ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤:  kubectl get deployment qwen3-vllm -n default -o jsonpath='{.spec.template.metadata.labels}' &amp;&amp; echo   ì¼ë°˜ì ì¸ ë ˆì´ë¸” íŒ¨í„´:  í‘œì¤€ ë°°í¬: app: &lt;service-name&gt; (ê°„ë‹¨í•œ íŒ¨í„´)inference-charts ë°°í¬: app.kubernetes.io/component: &lt;service-name&gt; (ì´ ê°€ì´ë“œì˜ ì˜ˆì œì—ì„œ ì‚¬ìš©)ê¸°íƒ€ Helm ì°¨íŠ¸: app.kubernetes.io/name: &lt;service-name&gt;  ì˜ˆì œì˜ matchLabels ì„¹ì…˜ì„ ë°°í¬ì˜ ì‹¤ì œ Pod ë ˆì´ë¸”ê³¼ ì¼ì¹˜í•˜ë„ë¡ ì—…ë°ì´íŠ¸í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h3"},{"title":"í™•ì¸:â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#í™•ì¸","content":" ë°°í¬ í›„ ë‘ Podê°€ ë™ì¼í•œ AZì— ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤:  # ë‘ Pod ëª¨ë‘ í™•ì¸ - ë™ì¼í•œ ì˜ì—­ì„ í‘œì‹œí•´ì•¼ í•©ë‹ˆë‹¤ kubectl get pods -n default -o wide -l app.kubernetes.io/component=qwen3-vllm kubectl get pods -n benchmarking -o wide -l app=inference-perf # ì˜ˆìƒ ì¶œë ¥ - ë‘˜ ë‹¤ ë™ì¼í•œ ì˜ì—­: # qwen3-vllm-xxx ip-10-0-1-100.us-west-2a... # inference-perf-yyy ip-10-0-1-200.us-west-2a...   ","version":"Next","tagName":"h3"},{"title":"ì„ íƒ ì‚¬í•­: ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì¼ê´€ì„±â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ì„ íƒ-ì‚¬í•­-ì¸ìŠ¤í„´ìŠ¤-ìœ í˜•-ì¼ê´€ì„±","content":" ë²¤ì¹˜ë§ˆí¬ Podì˜ ì¸ìŠ¤í„´ìŠ¤ í¬ê¸° ì¡°ì •  ë²¤ì¹˜ë§ˆí¬ PodëŠ” GPU ê¸°ë°˜ ì¶”ë¡  ë°°í¬ì™€ ë³„ë„ì˜ CPU ë…¸ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤. m6i.2xlarge ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•(8 vCPU, 32 GB RAM)ì€ GPU ë…¸ë“œ ë¦¬ì†ŒìŠ¤ì™€ ê²½ìŸí•˜ì§€ ì•Šê³  ë¶€í•˜ ìƒì„±ì— ì¶©ë¶„í•œ ìš©ëŸ‰ì„ ì œê³µí•©ë‹ˆë‹¤.  ì¤‘ìš”: Pod ì–´í”¼ë‹ˆí‹° êµ¬ì„±(topology.kubernetes.io/zone)ì€ ë‘ Podê°€ ë™ì¼í•œ ë¬¼ë¦¬ì  ë…¸ë“œê°€ ì•„ë‹Œ ë™ì¼í•œ ê°€ìš© ì˜ì—­ì— ìˆë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„°ì—ëŠ” ë‹¤ìŒ ë‘ ê°€ì§€ ëª¨ë‘ë¥¼ ìœ„í•œ ìš©ëŸ‰ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤:  ì¶”ë¡ ì„ ìœ„í•œ GPU ë…¸ë“œ (ì˜ˆ: Qwen3-8Bì™€ ê°™ì€ ëª¨ë¸ìš© g5.2xlarge)ë²¤ì¹˜ë§ˆí‚¹ì„ ìœ„í•œ CPU ë…¸ë“œ (ì˜ˆ: m6i.2xlarge)  Karpenterë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë™ì¼í•œ AZì—ì„œ ì ì ˆí•œ ë…¸ë“œ ìœ í˜•ì„ ìë™ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤.  ìµœëŒ€ ì¬í˜„ì„±(ê¸°ì¤€ì„  ë²¤ì¹˜ë§ˆí¬, CI/CD íŒŒì´í”„ë¼ì¸)ì„ ìœ„í•´ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  spec: template: spec: nodeSelector: node.kubernetes.io/instance-type: m6i.2xlarge affinity: podAffinity: # ... ìœ„ì™€ ë™ì¼   ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì…€ë ‰í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:  ë¬¸ì„œí™”ë¥¼ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€ì„  ìƒì„±ì¼ê´€ëœ ê²°ê³¼ê°€ í•„ìš”í•œ CI/CD íŒŒì´í”„ë¼ì¸Karpenterê°€ ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ íŒ¨ë°€ë¦¬ë¥¼ í”„ë¡œë¹„ì €ë‹í•˜ëŠ” ê²ƒì„ ë°©ì§€  í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš°:  ë™ì¢… CPU ë…¸ë“œ í’€ë¹„êµ í…ŒìŠ¤íŠ¸ (ë™ì¼í•œ ì¸í”„ë¼ì—ì„œ ì „/í›„)  ","version":"Next","tagName":"h3"},{"title":"ë¬¸ì œ í•´ê²°:â€‹","type":1,"pageTitle":"EKSì—ì„œ Inference Perf ì‹¤í–‰í•˜ê¸°","url":"/ai-on-eks/ko/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks#ë¬¸ì œ-í•´ê²°","content":" ë²¤ì¹˜ë§ˆí¬ Jobì´ Pending ìƒíƒœë¡œ ìœ ì§€ë˜ëŠ” ê²½ìš°:  kubectl describe pod -n benchmarking &lt;pod-name&gt;   ì¼ë°˜ì ì¸ ë¬¸ì œ:  ëŒ€ìƒ AZì— ìš©ëŸ‰ ì—†ìŒ: í´ëŸ¬ìŠ¤í„°ë¥¼ í™•ì¥í•˜ê±°ë‚˜ preferredDuringSchedulingIgnoredDuringExecution ì‚¬ìš©ë ˆì´ë¸” ë¶ˆì¼ì¹˜: ë°°í¬ ë ˆì´ë¸”ì´ podAffinity ì…€ë ‰í„°ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸ ","version":"Next","tagName":"h3"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 3: ìë™ í¬í™” ê°ì§€","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/automatic-saturation-detection","content":"","keywords":"","version":"Next"},{"title":"ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 3: ìë™ í¬í™” ê°ì§€","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/automatic-saturation-detection#ì´-ì‹œë‚˜ë¦¬ì˜¤ë¥¼-ì‚¬ìš©í•´ì•¼-í•˜ëŠ”-ê²½ìš°","content":" ì ì ˆí•œ QPS í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì¶”ì¸¡í•˜ê³  ì‹¶ì§€ ì•Šì„ ë•Œ ìë™í™”ëœ ìš©ëŸ‰ ê²€ìƒ‰ì„ ìœ„í•´ sweep ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ì´ˆê¸° ë°°í¬, CI/CD íŒŒì´í”„ë¼ì¸ ë˜ëŠ” ì¸í”„ë¼ ë³€ê²½ í›„ ë¹ ë¥¸ ìš©ëŸ‰ ì¬ê²€ì¦ì— ì´ìƒì ì…ë‹ˆë‹¤. ë„êµ¬ê°€ ì‹œìŠ¤í…œì„ í”ŒëŸ¬ë”©í•˜ì—¬ í¬í™”ë¥¼ ê²½í—˜ì ìœ¼ë¡œ ê²°ì •í•œ ë‹¤ìŒ í•´ë‹¹ ì¤‘ìš” ì§€ì  ì£¼ë³€ì— í´ëŸ¬ìŠ¤í„°ëœ ì§€ëŠ¥í˜• í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ì„¤ê³„ì—ì„œ ì¸ê°„ í¸í–¥ì„ ì œê±°í•˜ê³  ë‹¤ì–‘í•œ í™˜ê²½ê³¼ íŒ€ì— ê±¸ì³ ì¼ê´€ë˜ê³  ì¬í˜„ ê°€ëŠ¥í•œ ë°©ë²•ë¡ ì„ ë³´ì¥í•˜ì§€ë§Œ, ê³¼í•™ì  ìë™í™”ë¥¼ ìœ„í•´ ì„¸ë°€í•œ ì œì–´ë¥¼ êµí™˜í•©ë‹ˆë‹¤.  íŠ¹ì • ë¶€í•˜ ëª©í‘œë¥¼ ê²€ì¦í•´ì•¼ í•˜ê±°ë‚˜(ì˜ˆ: &quot;20 QPSë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ê°€?&quot;) í”„ë¡œë•ì…˜ í™˜ê²½ì„ ìœ„í•œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¥¼ ì›í•  ë•Œ ì‹œë‚˜ë¦¬ì˜¤ 2ë¥¼ ì„ íƒí•˜ì‹­ì‹œì˜¤.  ì•Œ ìˆ˜ ì—†ëŠ” ìš©ëŸ‰ í•œê³„ë¥¼ ë°œê²¬í•˜ê±°ë‚˜ íŠ¹ì • QPS ê°’ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒë³´ë‹¤ ì¼ê´€ëœ ìë™í™” ë°©ë²•ë¡ ì´ ë” ì¤‘ìš”í•  ë•Œ ì‹œë‚˜ë¦¬ì˜¤ 3ì„ ì„ íƒí•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h2"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 3: ìë™ í¬í™” ê°ì§€","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/automatic-saturation-detection#ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"Helm ì°¨íŠ¸ ì‚¬ìš© (ê¶Œì¥)â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 3: ìë™ í¬í™” ê°ì§€","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/automatic-saturation-detection#helm-ì°¨íŠ¸-ì‚¬ìš©-ê¶Œì¥","content":" # AI on EKS Helm ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update # sweep ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì¹˜ helm install sweep-test ai-on-eks/benchmark-charts \\ --set benchmark.scenario=sweep \\ --set benchmark.target.baseUrl=http://qwen3-vllm.default:8000 \\ --set benchmark.target.modelName=qwen3-8b \\ --set benchmark.target.tokenizerPath=Qwen/Qwen3-8B \\ --namespace benchmarking --create-namespace # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ - ë¡œê·¸ì—ì„œ ìë™ ë‹¨ê³„ ìƒì„± í™•ì¸ kubectl logs -n benchmarking -l benchmark.scenario=sweep -f   ","version":"Next","tagName":"h3"},{"title":"Sweep ë§¤ê°œë³€ìˆ˜ ì‚¬ìš©ì ì •ì˜â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 3: ìë™ í¬í™” ê°ì§€","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/automatic-saturation-detection#sweep-ë§¤ê°œë³€ìˆ˜-ì‚¬ìš©ì-ì •ì˜","content":" í¬í™” í”„ë¡œë¸Œ ì„¤ì • ì¡°ì •:  # custom-sweep.yaml benchmark: scenario: sweep target: baseUrl: http://your-model.your-namespace:8000 scenarios: sweep: load: sweep: numRequests: 3000 # ë” í° ì‹œìŠ¤í…œì„ ìœ„í•œ ë” ë§ì€ ìš”ì²­ timeout: 90 # ë” ê¸´ í”„ë¡œë¸Œ ì‹œê°„ numStages: 7 # ë” ë§ì€ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ stageDuration: 240 # ë” ê¸´ ë‹¨ê³„ ê¸°ê°„ saturationPercentile: 99 # ë” ë³´ìˆ˜ì ì¸ ì¶”ì •   helm install sweep-test ai-on-eks/benchmark-charts -f custom-sweep.yaml -n benchmarking   ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” êµ¬ì„±:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 3: ìë™ í¬í™” ê°ì§€","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/automatic-saturation-detection#ì£¼ìš”-êµ¬ì„±","content":" ê°€ë³€ í•©ì„± ë°ì´í„° ë¶„í¬Sweep ëª¨ë“œ (ìë™): í¬í™” ì§€ì ì„ ë°œê²¬í•˜ê¸° ìœ„í•´ 60ì´ˆ ë™ì•ˆ êµ¬ì„± ê°€ëŠ¥í•œ ìš”ì²­ ìˆ˜(ê¸°ë³¸ê°’: 2000)ë¡œ ì‹œìŠ¤í…œì„ í”ŒëŸ¬ë”©í¬í™” ì£¼ë³€ì˜ ê¸°í•˜í•™ì  í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•œ ìë™ ìƒì„± í…ŒìŠ¤íŠ¸ ë‹¨ê³„ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”  ","version":"Next","tagName":"h2"},{"title":"ê²°ê³¼ ì´í•´:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 3: ìë™ í¬í™” ê°ì§€","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/automatic-saturation-detection#ê²°ê³¼-ì´í•´","content":" ë„êµ¬ì˜ ì „ì²˜ë¦¬ ë‹¨ê³„ëŠ” 60ì´ˆ ë™ì•ˆ 2000ê°œì˜ ìš”ì²­ìœ¼ë¡œ ì‹œìŠ¤í…œì„ í”ŒëŸ¬ë”©í•˜ê³  ì²˜ë¦¬ ì†ë„ë¥¼ ì¸¡ì •í•˜ì—¬ í¬í™”ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤; saturation_percentile: 95ëŠ” ë³´ìˆ˜ì ì¸ ì¶”ì •ì„ ìœ„í•´ ê´€ì°°ëœ ì†ë„ì˜ 95ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ë¡œê·¸ì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±ëœ ë‹¨ê³„ë¥¼ ê²€í† í•˜ê³ (ê¸°í•˜í•™ì  í´ëŸ¬ìŠ¤í„°ë§ì€ í¬í™” ê·¼ì²˜ì—ì„œ 4, 8, 14, 17, 18 QPSì™€ ê°™ì´ ë” ì´˜ì´˜í•œ ê°„ê²©ì„ ìƒì„±) ê°ì§€ëœ í¬í™” ì§€ì ì„ ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ê¸°ëŒ€ì¹˜ì™€ ë¹„êµí•˜ì‹­ì‹œì˜¤. ìƒë‹¹í•œ ë¶ˆì¼ì¹˜ëŠ” ë†“ì³¤ì„ ìˆ˜ ìˆëŠ” ëŒ€ê¸°ì—´ ë³‘ëª© ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ì œì•½ì„ ë“œëŸ¬ë‚´ë©°, ê¸°í•˜í•™ì  ë¶„í¬ëŠ” ì„±ëŠ¥ì´ ì•ˆì •ì—ì„œ ì €í•˜ë¡œ ì „í™˜ë˜ëŠ” ì •í™•í•œ ì§€ì ì—ì„œ í’ë¶€í•œ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  í¬í™” í”„ë¡œë¸Œ êµ¬ì„±: sweep êµ¬ì„±ì˜ numRequests ë§¤ê°œë³€ìˆ˜ëŠ” ì´ˆê¸° í¬í™” ë°œê²¬ ë‹¨ê³„ ë™ì•ˆ ì „ì†¡ë˜ëŠ” ìš”ì²­ ìˆ˜ë¥¼ ì œì–´í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ 2000ì€ ëŒ€ë¶€ë¶„ì˜ ë°°í¬ì— ì í•©í•˜ì§€ë§Œ ì˜ˆìƒ ìš©ëŸ‰ì— ë”°ë¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ëŒ€ì•ˆ: ì›ì‹œ Kubernetes YAML --- apiVersion: v1 kind: ConfigMap metadata: name: inference-perf-sweep namespace: benchmarking data: config.yml: | api: type: completion streaming: true data: type: synthetic input_distribution: mean: 512 std_dev: 128 min: 128 max: 2048 output_distribution: mean: 256 std_dev: 64 min: 32 max: 512 load: type: constant stages: [] # sweepì— ì˜í•´ ìë™ ìƒì„± sweep: type: geometric num_requests: 2000 timeout: 60 num_stages: 5 stage_duration: 180 saturation_percentile: 95 num_workers: 8 server: type: vllm model_name: qwen3-8b base_url: http://qwen3-vllm.default:8000 ignore_eos: true tokenizer: pretrained_model_name_or_path: Qwen/Qwen3-8B storage: simple_storage_service: bucket_name: &quot;inference-perf-results&quot; path: &quot;sweep-test/results&quot; --- apiVersion: batch/v1 kind: Job metadata: name: inference-perf-sweep namespace: benchmarking spec: backoffLimit: 2 ttlSecondsAfterFinished: 3600 template: spec: restartPolicy: Never serviceAccountName: inference-perf-sa affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchLabels: app.kubernetes.io/component: qwen3-vllm topologyKey: topology.kubernetes.io/zone containers: - name: inference-perf image: quay.io/inference-perf/inference-perf:v0.2.0 command: [&quot;/bin/sh&quot;, &quot;-c&quot;] args: - | inference-perf --config_file /workspace/config.yml volumeMounts: - name: config mountPath: /workspace/config.yml subPath: config.yml resources: requests: cpu: &quot;2&quot; memory: &quot;4Gi&quot; limits: cpu: &quot;4&quot; memory: &quot;8Gi&quot; volumes: - name: config configMap: name: inference-perf-sweep  ","version":"Next","tagName":"h2"},{"title":"ë¦¬ì†ŒìŠ¤","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/resources","content":"","keywords":"","version":"Next"},{"title":"Helm ì°¨íŠ¸ ì €ì¥ì†Œâ€‹","type":1,"pageTitle":"ë¦¬ì†ŒìŠ¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/resources#helm-ì°¨íŠ¸-ì €ì¥ì†Œ","content":" ê³µì‹ ë²¤ì¹˜ë§ˆí¬ ì°¨íŠ¸ëŠ” AI on EKS Charts ì €ì¥ì†Œì—ì„œ ìœ ì§€ ê´€ë¦¬ë©ë‹ˆë‹¤. ì´ ì €ì¥ì†Œì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:  values.yaml: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì˜µì…˜ì´ í¬í•¨ëœ ì™„ì „í•œ êµ¬ì„± ì°¸ì¡°templates/: job, configmap ë° ì„œë¹„ìŠ¤ ê³„ì •ì„ ìœ„í•œ Kubernetes ë¦¬ì†ŒìŠ¤ í…œí”Œë¦¿scenarios/: ì‚¬ì „ êµ¬ì„±ëœ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜ (baseline, saturation, sweep, production)README.md: ìì„¸í•œ ì‚¬ìš© ì§€ì¹¨ ë° ì˜ˆì œ  ","version":"Next","tagName":"h2"},{"title":"values.yamlì„ í†µí•œ ì‚¬ìš©ì ì •ì˜â€‹","type":1,"pageTitle":"ë¦¬ì†ŒìŠ¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/resources#valuesyamlì„-í†µí•œ-ì‚¬ìš©ì-ì •ì˜","content":" ê¸°ë³¸ê°’ì„ ì¬ì •ì˜í•˜ê¸° ìœ„í•œ ì‚¬ìš©ì ì •ì˜ values íŒŒì¼ ìƒì„±:  # custom-benchmark.yaml benchmark: scenario: saturation target: baseUrl: http://your-model.your-namespace:8000 modelName: your-model-name # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„¤ì • ì¬ì •ì˜ scenarios: saturation: load: stages: - rate: 10 duration: 300 - rate: 50 duration: 300 # ë¦¬ì†ŒìŠ¤ í• ë‹¹ resources: requests: cpu: &quot;4&quot; memory: &quot;8Gi&quot; # Pod ì–´í”¼ë‹ˆí‹° ì‚¬ìš©ì ì •ì˜ affinity: enabled: true targetLabels: app: your-inference-service   ì‚¬ìš©ì ì •ì˜ ê°’ìœ¼ë¡œ ë°°í¬:  helm install my-benchmark ai-on-eks/benchmark-charts -f custom-benchmark.yaml -n benchmarking   ","version":"Next","tagName":"h3"},{"title":"ëŒ€ì•ˆ: SentencePieceê°€ í¬í•¨ëœ ì‚¬ìš©ì ì •ì˜ ì»¨í…Œì´ë„ˆâ€‹","type":1,"pageTitle":"ë¦¬ì†ŒìŠ¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/resources#ëŒ€ì•ˆ-sentencepieceê°€-í¬í•¨ëœ-ì‚¬ìš©ì-ì •ì˜-ì»¨í…Œì´ë„ˆ","content":" Helm ì°¨íŠ¸ ì™¸ë¶€ì˜ ì‚¬ìš©ì ì •ì˜ ë°°í¬ì˜ ê²½ìš° ì¢…ì†ì„±ì´ ì‚¬ì „ ì„¤ì¹˜ëœ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  # ì‚¬ìš©ì ì •ì˜ Dockerfile ìƒì„± cat &gt; Dockerfile &lt;&lt;'EOF' FROM quay.io/inference-perf/inference-perf:v0.2.0 # sentencepiece ì„¤ì¹˜ RUN pip install --no-cache-dir sentencepiece protobuf USER 1000 EOF # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë¹Œë“œ ë° í‘¸ì‹œ docker build -t &lt;your-registry&gt;/inference-perf:v0.2.0-sentencepiece . docker push &lt;your-registry&gt;/inference-perf:v0.2.0-sentencepiece # ìƒˆ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë„ë¡ Job ì—…ë°ì´íŠ¸ kubectl patch job inference-perf-run -n benchmarking \\ --type='json' \\ -p='[{&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/template/spec/containers/0/image&quot;, &quot;value&quot;:&quot;&lt;your-registry&gt;/inference-perf:v0.2.0-sentencepiece&quot;}]'   ","version":"Next","tagName":"h2"},{"title":"ëŒ€ì•ˆ: ì™„ì „í•œ Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸â€‹","type":1,"pageTitle":"ë¦¬ì†ŒìŠ¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/resources#ëŒ€ì•ˆ-ì™„ì „í•œ-kubernetes-ë§¤ë‹ˆí˜ìŠ¤íŠ¸","content":" ìˆ˜ë™ ë°°í¬ ë˜ëŠ” êµìœ¡ ëª©ì ìœ¼ë¡œ ëŸ°íƒ€ì„ ì¢…ì†ì„± ì„¤ì¹˜ê°€ í¬í•¨ëœ ì™„ì „í•œ YAML ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì…ë‹ˆë‹¤:  cat &gt; inference-perf-fixed.yaml &lt;&lt;'EOF' --- apiVersion: v1 kind: Namespace metadata: name: benchmarking --- apiVersion: v1 kind: ServiceAccount metadata: name: inference-perf-sa namespace: benchmarking --- apiVersion: v1 kind: ConfigMap metadata: name: inference-perf-config namespace: benchmarking data: config.yml: | load_generator: concurrency: 10 duration: 60 model: model_name: qwen3-8b base_url: http://qwen3-vllm.default:8000 ignore_eos: true tokenizer: pretrained_model_name_or_path: Qwen/Qwen3-8B storage: simple_storage_service: bucket_name: &quot;inference-perf-results&quot; path: &quot;inference-perf/results&quot; --- apiVersion: batch/v1 kind: Job metadata: name: inference-perf-run namespace: benchmarking labels: app: inference-perf spec: backoffLimit: 2 ttlSecondsAfterFinished: 3600 template: metadata: labels: app: inference-perf spec: restartPolicy: Never serviceAccountName: inference-perf-sa # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ì¶”ë¡  Podì™€ ë™ì¼ AZ ë°°ì¹˜ affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchLabels: app.kubernetes.io/component: qwen3-vllm topologyKey: topology.kubernetes.io/zone containers: - name: inference-perf image: quay.io/inference-perf/inference-perf:v0.2.0 command: [&quot;/bin/sh&quot;, &quot;-c&quot;] args: - | echo &quot;Installing dependencies...&quot; pip install --no-cache-dir sentencepiece==0.2.0 protobuf==5 echo &quot;Dependencies installed successfully&quot; echo &quot;Starting inference-perf...&quot; inference-perf --config_file /workspace/config.yml volumeMounts: - name: config mountPath: /workspace/config.yml subPath: config.yml resources: requests: cpu: &quot;2&quot; memory: &quot;4Gi&quot; limits: cpu: &quot;4&quot; memory: &quot;8Gi&quot; volumes: - name: config configMap: name: inference-perf-config EOF   ","version":"Next","tagName":"h2"},{"title":"ì‹¤í–‰â€‹","type":1,"pageTitle":"ë¦¬ì†ŒìŠ¤","url":"/ai-on-eks/ko/docs/guidance/benchmarking/resources#ì‹¤í–‰","content":" kubectl apply -f inference-perf-fixed.yaml  ","version":"Next","tagName":"h2"},{"title":"í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì¤‘ ì„ íƒ","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/choosing-synthetic-vs-real","content":"","keywords":"","version":"Next"},{"title":"ê¸°ë³¸ ê¶Œì¥ ì‚¬í•­: ê°€ëŠ¥í•˜ë©´ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©â€‹","type":1,"pageTitle":"í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì¤‘ ì„ íƒ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/choosing-synthetic-vs-real#ê¸°ë³¸-ê¶Œì¥-ì‚¬í•­-ê°€ëŠ¥í•˜ë©´-ì‹¤ì œ-ë°ì´í„°-ì‚¬ìš©","content":" ì‹¤ì œ í”„ë¡œë•ì…˜ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ê°€ì¥ ì •í™•í•œ ì„±ëŠ¥ ì˜ˆì¸¡ì„ ì œê³µí•©ë‹ˆë‹¤:  ì…ë ¥ í† í° ë¶„í¬ê°€ ì‹¤ì œ ì‚¬ìš©ì ë™ì‘ê³¼ ì¼ì¹˜ì¿¼ë¦¬ ë³µì¡ì„±ì´ ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ë°˜ì˜ì„±ëŠ¥ ê²°ê³¼ê°€ í”„ë¡œë•ì…˜ ê²½í—˜ê³¼ ì§ì ‘ ìƒê´€í•©ì„± ë°ì´í„°ê°€ ë†“ì¹  ìˆ˜ ìˆëŠ” íŠ¹ì • í”„ë¡¬í”„íŠ¸ íŒ¨í„´ì˜ ë¬¸ì œ ì‹ë³„  ","version":"Next","tagName":"h2"},{"title":"í•©ì„± ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš° (ì‹œë‚˜ë¦¬ì˜¤ 1-4):â€‹","type":1,"pageTitle":"í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì¤‘ ì„ íƒ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/choosing-synthetic-vs-real#í•©ì„±-ë°ì´í„°ë¥¼-ì‚¬ìš©í•´ì•¼-í•˜ëŠ”-ê²½ìš°-ì‹œë‚˜ë¦¬ì˜¤-1-4","content":" í”„ë¡œë•ì…˜ ë°ì´í„°ê°€ ì¡´ì¬í•˜ê¸° ì „ ì´ˆê¸° ë°°í¬ ê²€ì¦ë‹¤ë¥¸ ì‹œìŠ¤í…œ ê°„ì˜ í‘œì¤€í™”ëœ ë¹„êµ (ë™ì¼ ì¡°ê±´)ê·¹ë‹¨ì ì¸ ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ (ë§¤ìš° ê¸´ í”„ë¡¬í”„íŠ¸, ë²„ìŠ¤íŠ¸ íŒ¨í„´)í˜„ì‹¤ì„±ë³´ë‹¤ ì¼ê´€ì„±ì´ ë” ì¤‘ìš”í•œ ë¹ ë¥¸ CI/CD ê²€ì¦ì‹¤ì œ ë°ì´í„°ë¥¼ ê³µìœ í•  ìˆ˜ ì—†ëŠ” ê³µê°œ ë²¤ì¹˜ë§ˆí‚¹  ","version":"Next","tagName":"h2"},{"title":"ëª¨ë²” ì‚¬ë¡€: ì§€ì†ì ì¸ ë°ì´í„°ì…‹ ê²€ì¦â€‹","type":1,"pageTitle":"í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì¤‘ ì„ íƒ","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/choosing-synthetic-vs-real#ëª¨ë²”-ì‚¬ë¡€-ì§€ì†ì ì¸-ë°ì´í„°ì…‹-ê²€ì¦","content":" í”„ë¡œë•ì…˜ ì›Œí¬ë¡œë“œëŠ” ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì§„í™”í•©ë‹ˆë‹¤. ë²¤ì¹˜ë§ˆí¬ê°€ ëŒ€í‘œì„±ì„ ìœ ì§€í•˜ë„ë¡ í•˜ë ¤ë©´:  ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì„ ìœ„í•´ ì£¼ê¸°ì ìœ¼ë¡œ ìµëª…í™”ëœ í”„ë¡œë•ì…˜ í”„ë¡¬í”„íŠ¸ ìº¡ì²˜í…ŒìŠ¤íŠ¸ ë°ì´í„°ì™€ í”„ë¡œë•ì…˜ íŠ¸ë˜í”½ ê°„ì˜ ë¶„í¬ ë“œë¦¬í”„íŠ¸ ëª¨ë‹ˆí„°ë§:   # í† í° ê¸¸ì´ ë¶„í¬ ë¹„êµ # í”„ë¡œë•ì…˜: median=450, p95=1200 # í…ŒìŠ¤íŠ¸ ë°ì´í„°: median=512, p95=2048 # â†’ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ TTFTë¥¼ ê³¼ëŒ€í‰ê°€í•  ìˆ˜ ìˆìŒ   í˜„ì¬ í”„ë¡œë•ì…˜ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ë„ë¡ ë¶„ê¸°ë³„ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒˆë¡œ ê³ ì¹¨ì‹œê°„ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•´ ë°ì´í„°ì…‹ ë²„ì „ ê´€ë¦¬  ì´ëŠ” ì¶”ë¡  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ì— ì ìš©ëœ ì „í†µì ì¸ ML ì§€ì†ì  í‰ê°€ ê´€í–‰ì„ ë°˜ì˜í•©ë‹ˆë‹¤. ","version":"Next","tagName":"h2"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 1: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/baseline-performance","content":"","keywords":"","version":"Next"},{"title":"ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 1: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/baseline-performance#ì´-ì‹œë‚˜ë¦¬ì˜¤ë¥¼-ì‚¬ìš©í•´ì•¼-í•˜ëŠ”-ê²½ìš°","content":" ê²½ìŸ ì—†ì´ ì‹œìŠ¤í…œì˜ ìµœì  ì„±ëŠ¥ì„ í™•ë¦½í•  ë•Œ ë² ì´ìŠ¤ë¼ì¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ë³¸ì§ˆì ìœ¼ë¡œ ì¸í”„ë¼ì˜ ë°”ì´íƒˆ ì‚¬ì¸ì„ ì¸¡ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ê²ƒì€ ìš©ëŸ‰ ê³„íšì´ë‚˜ ìµœì í™” ì‘ì—… ì „ ì‹œì‘ì ìœ¼ë¡œ, ìƒˆ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë°©ê¸ˆ ë°°í¬í–ˆê±°ë‚˜ ì¸í”„ë¼ë¥¼ ë³€ê²½í–ˆì„ ë•Œ ì´ìƒì ì…ë‹ˆë‹¤. &quot;ì´ ì‹œìŠ¤í…œì´ ì œê³µí•  ìˆ˜ ìˆëŠ” ìµœê³ ì˜ ì„±ëŠ¥ì€ ë¬´ì—‡ì¸ê°€?&quot;ë¼ëŠ” ì§ˆë¬¸ì— ëŒ€ê¸°ì—´ì´ë‚˜ ë¦¬ì†ŒìŠ¤ ê²½ìŸ ì—†ì´ ë‹µí•˜ë©°, í–¥í›„ ëª¨ë“  í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê¹¨ë—í•œ ì°¸ì¡° ì§€ì ì„ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 1: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/baseline-performance#ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"Helm ì°¨íŠ¸ ì‚¬ìš© (ê¶Œì¥)â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 1: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/baseline-performance#helm-ì°¨íŠ¸-ì‚¬ìš©-ê¶Œì¥","content":" # AI on EKS Helm ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update # ë² ì´ìŠ¤ë¼ì¸ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì¹˜ helm install baseline-test ai-on-eks/benchmark-charts \\ --set benchmark.scenario=baseline \\ --set benchmark.target.baseUrl=http://qwen3-vllm.default:8000 \\ --set benchmark.target.modelName=qwen3-8b \\ --set benchmark.target.tokenizerPath=Qwen/Qwen3-8B \\ --namespace benchmarking --create-namespace # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ kubectl logs -n benchmarking -l benchmark.scenario=baseline -f   ","version":"Next","tagName":"h3"},{"title":"êµ¬ì„± ì‚¬ìš©ì ì •ì˜â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 1: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/baseline-performance#êµ¬ì„±-ì‚¬ìš©ì-ì •ì˜","content":" --set ë˜ëŠ” ì‚¬ìš©ì ì •ì˜ values íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ê°’ì„ ì¬ì •ì˜í•©ë‹ˆë‹¤:  # í…ŒìŠ¤íŠ¸ ê¸°ê°„ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ì¡°ì • helm install baseline-test ai-on-eks/benchmark-charts \\ --set benchmark.scenario=baseline \\ --set benchmark.target.baseUrl=http://your-model.your-namespace:8000 \\ --set benchmark.scenarios.baseline.load.stages[0].duration=600 \\ --set benchmark.resources.main.requests.cpu=4 \\ --namespace benchmarking   ë˜ëŠ” ì‚¬ìš©ì ì •ì˜ my-values.yaml ìƒì„±:  benchmark: scenario: baseline target: baseUrl: http://your-model.your-namespace:8000 modelName: your-model-name scenarios: baseline: load: stages: - rate: 1 duration: 600 # ë” ê¸´ í…ŒìŠ¤íŠ¸   helm install baseline-test ai-on-eks/benchmark-charts -f my-values.yaml -n benchmarking   ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” êµ¬ì„±:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 1: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/baseline-performance#ì£¼ìš”-êµ¬ì„±","content":" ê³ ì • ê¸¸ì´ í•©ì„± ë°ì´í„° (512 ì…ë ¥ / 128 ì¶œë ¥ í† í°)300ì´ˆ ë™ì•ˆ 1 QPSì˜ ì¼ì •í•œ ë¶€í•˜ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”Pod ì–´í”¼ë‹ˆí‹°ê°€ ì¶”ë¡  Podì™€ ë™ì¼ AZ ë°°ì¹˜ë¥¼ ë³´ì¥  ","version":"Next","tagName":"h2"},{"title":"ê²°ê³¼ ì´í•´:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 1: ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/baseline-performance#ê²°ê³¼-ì´í•´","content":" 1 QPSì—ì„œì˜ TTFTì™€ ITLì€ ì´ë¡ ì  ìµœì†Œ ì§€ì—° ì‹œê°„ì„ ë‚˜íƒ€ë‚´ë©°, ëŒ€ê¸°ì—´ì´ë‚˜ ê²½ìŸ ì—†ì´ ì‹œìŠ¤í…œì´ ì‘ë‹µí•  ìˆ˜ ìˆëŠ” ì ˆëŒ€ì ìœ¼ë¡œ ê°€ì¥ ë¹ ë¥¸ ì†ë„ì…ë‹ˆë‹¤. ë² ì´ìŠ¤ë¼ì¸ TTFTê°€ 800msì´ë©´ ë³µì œë³¸ ì¶”ê°€, ë¡œë“œ ë°¸ëŸ°ì„œ ë˜ëŠ” ì˜¤í† ìŠ¤ì¼€ì¼ë§ê³¼ ê°™ì€ ìµœì í™”ì™€ ê´€ê³„ì—†ì´ ì‚¬ìš©ìëŠ” ë” ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²ƒë“¤ì€ ë‹¨ì¼ ìš”ì²­ ì†ë„ê°€ ì•„ë‹Œ ì²˜ë¦¬ëŸ‰ê³¼ ë™ì‹œì„±ì„ ê°œì„ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì— ì„±ëŠ¥ í•˜í•œìœ¼ë¡œ ì§‘ì¤‘í•˜ì‹­ì‹œì˜¤: ìŠ¤ì¼€ì¤„ ì§€ì—°ì€ ê±°ì˜ 0(&lt;10ms)ì´ì–´ì•¼ í•˜ë©°, í¸ì°¨ê°€ ìˆìœ¼ë©´ í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ ìì²´ì— ë” ë§ì€ ë¦¬ì†ŒìŠ¤ê°€ í•„ìš”í•¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë² ì´ìŠ¤ë¼ì¸ ìˆ˜ì¹˜ë¥¼ ì„œë¹„ìŠ¤ ìˆ˜ì¤€ ê³„ì•½(SLA) ëª©í‘œì™€ ë¹„êµí•˜ì‹­ì‹œì˜¤; ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ì´ ìš”êµ¬ ì‚¬í•­ì„ ì¶©ì¡±í•˜ì§€ ì•Šìœ¼ë©´ ê·œëª¨ì— ëŒ€í•´ ê±±ì •í•˜ê¸° ì „ì— ëª¨ë¸/í•˜ë“œì›¨ì–´ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤. ìš©ëŸ‰ì„ ì¶”ê°€í•´ë„ ê·¼ë³¸ì ì¸ ì¶”ë¡  ì†ë„ëŠ” ê°œì„ ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  ëŒ€ì•ˆ: ì›ì‹œ Kubernetes YAML (êµìœ¡ ëª©ì  ë˜ëŠ” ì‚¬ìš©ì ì •ì˜ ë°°í¬ìš©) Helmì„ ì‚¬ìš©í•˜ì§€ ì•Šê±°ë‚˜ ê°’ì„ ë„˜ì–´ì„œ ì‚¬ìš©ì ì •ì˜í•´ì•¼ í•˜ëŠ” ê²½ìš° ì™„ì „í•œ Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: --- apiVersion: v1 kind: ConfigMap metadata: name: inference-perf-baseline namespace: benchmarking data: config.yml: | api: type: completion streaming: true data: type: synthetic input_distribution: mean: 512 std_dev: 0 min: 512 max: 512 output_distribution: mean: 128 std_dev: 0 min: 128 max: 128 load: type: constant stages: - rate: 1 duration: 300 num_workers: 4 server: type: vllm model_name: qwen3-8b base_url: http://qwen3-vllm.default:8000 ignore_eos: true tokenizer: pretrained_model_name_or_path: Qwen/Qwen3-8B storage: simple_storage_service: bucket_name: &quot;inference-perf-results&quot; path: &quot;baseline-test/results&quot; --- apiVersion: batch/v1 kind: Job metadata: name: inference-perf-baseline namespace: benchmarking spec: backoffLimit: 2 ttlSecondsAfterFinished: 3600 template: spec: restartPolicy: Never serviceAccountName: inference-perf-sa affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchLabels: app.kubernetes.io/component: qwen3-vllm topologyKey: topology.kubernetes.io/zone containers: - name: inference-perf image: quay.io/inference-perf/inference-perf:v0.2.0 command: [&quot;/bin/sh&quot;, &quot;-c&quot;] args: - | inference-perf --config_file /workspace/config.yml volumeMounts: - name: config mountPath: /workspace/config.yml subPath: config.yml resources: requests: cpu: &quot;2&quot; memory: &quot;4Gi&quot; limits: cpu: &quot;4&quot; memory: &quot;8Gi&quot; volumes: - name: config configMap: name: inference-perf-baseline ë‹¤ìŒìœ¼ë¡œ ì ìš©: kubectl apply -f 01-scenario-baseline.yaml ","version":"Next","tagName":"h2"},{"title":"ë²¤ì¹˜ë§ˆí¬ ê³¼ì œ ì´í•´í•˜ê¸°","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/understanding-the-benchmark-challenge","content":"ë²¤ì¹˜ë§ˆí¬ ê³¼ì œ ì´í•´í•˜ê¸° ë” ë§ì€ ì¡°ì§ì´ ìì²´ ì¸í”„ë¼ì— ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ë°°í¬í•¨ì— ë”°ë¼ ì„±ëŠ¥ ì¸¡ì • ë°©ë²•ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ê³µí†µì ì¸ ê³¼ì œê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ê°ë“¤ì€ ì¢…ì¢… ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤: ì…€í”„ í˜¸ìŠ¤íŒ… LLMì„ ì–´ë–»ê²Œ ë²¤ì¹˜ë§ˆí‚¹í•´ì•¼ í•˜ë‚˜ìš”? ì–´ë–¤ ë©”íŠ¸ë¦­ì´ ì¤‘ìš”í•œê°€ìš”? ê·¸ë¦¬ê³  ê·¸ ìˆ«ìë“¤ì´ ì‹¤ì œ ì›Œí¬ë¡œë“œì— ëŒ€í•´ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”? LLM ë²¤ì¹˜ë§ˆí‚¹ì€ ê¸°ì¡´ AI ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê²ƒì²˜ëŸ¼ ê°„ë‹¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. LLMì€ ìˆ˜ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©° ì„±ëŠ¥ì€ í•˜ë“œì›¨ì–´ ì„¤ì •, ë©”ëª¨ë¦¬ ëŒ€ì—­í­, ì–‘ìí™”, KV ìºì‹œ ë™ì‘, ë³‘ë ¬í™” ì „ëµ ë“± ë§ì€ ìš”ì¸ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. êµ¬ì„±, í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ë˜ëŠ” ì‚¬ìš©ì ë™ì‘ì˜ ì‘ì€ ë³€í™”ë„ ì²˜ë¦¬ëŸ‰ê³¼ ì§€ì—° ì‹œê°„ì— í° ì°¨ì´ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í”„ë¡œë•ì…˜ ì›Œí¬ë¡œë“œëŠ” ì˜ˆê¸°ì¹˜ ì•Šê²Œ ë³€í•  ìˆ˜ ìˆìœ¼ë©°, í…ŒìŠ¤íŠ¸í•˜ì§€ ì•Šì•˜ë˜ ìƒí™©ì—ì„œ ì‚¬ìš©ìê°€ ê°‘ìê¸° ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ìµœëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë©ë‹ˆë‹¤. ì‚¬ìš© ì‚¬ë¡€ì— ëŒ€í•´ í—ˆìš© ê°€ëŠ¥í•œ ì‘ë‹µ í’ˆì§ˆì„ ë‹¬ì„±í•œ í›„ì—ëŠ” ì„±ëŠ¥ì´ ë‹¤ìŒìœ¼ë¡œ ì¤‘ìš”í•œ ê´€ì‹¬ì‚¬ê°€ ë©ë‹ˆë‹¤. ëª¨ë¸ì´ ì‚¬ìš©ì ê¸°ëŒ€ë¥¼ ì¶©ì¡±í•  ë§Œí¼ ë¹ ë¥´ê²Œ ì‘ë‹µí•  ìˆ˜ ìˆë‚˜ìš”? ê·¸ë¦¬ê³  10ëª…ì˜ ë™ì‹œ ì‚¬ìš©ìë“  10,000ëª…ì˜ ë™ì‹œ ì‚¬ìš©ìë“  ì‹¤ì œ ì›Œí¬ë¡œë“œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í™•ì¥í•  ìˆ˜ ìˆë‚˜ìš”? ì´ëŸ¬í•œ ì§ˆë¬¸ì€ ì‚¬ìš©ì ê²½í—˜, ì¸í”„ë¼ ë¹„ìš© ë° ë°°í¬ì˜ ì‹¤í–‰ ê°€ëŠ¥ì„±ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ëª…í™•í•œ ë²¤ì¹˜ë§ˆí‚¹ í”„ë ˆì„ì›Œí¬ê°€ ì—†ìœ¼ë©´ íŒ€ì€ í•˜ë“œì›¨ì–´ ì˜µì…˜ì„ ë¹„êµí•˜ê³ , ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ íŠœë‹í•˜ê±°ë‚˜, ë°°í¬ ë¹„ìš©ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” ì¶”ë¡  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ì— ì´ˆì ì„ ë§ì¶”ê³  ìˆìœ¼ë©°, ê³ ê°ì´ ë°°í¬ êµ¬ì„±ì„ ìµœì í™”í•˜ê³ , ì£¼ìš” ë©”íŠ¸ë¦­ì„ ì‹¤ì œë¡œ ì´í•´í•˜ë©°, ì¶”ë¡  ì„±ëŠ¥ì„ ë¶„ì„í•˜ê³  ê°œì„ í•˜ê¸° ìœ„í•œ ì²´ê³„ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ êµ¬í˜„í•  ìˆ˜ ìˆë„ë¡ ì²˜ë¦¬ëŸ‰, ì§€ì—° ì‹œê°„ ë° ë¦¬ì†ŒìŠ¤ í™œìš©ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.","keywords":"","version":"Next"},{"title":"Amazon EKSì—ì„œ AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¬¸ì œ í•´ê²°","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/container-startup-time","content":"","keywords":"","version":"Next"},{"title":"ì½œë“œ ìŠ¤íƒ€íŠ¸ ê³¼ì œâ€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/guidance/container-startup-time#ì½œë“œ-ìŠ¤íƒ€íŠ¸-ê³¼ì œ","content":" AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì»¨í…Œì´ë„ˆí™”ë¥¼ í†µí•´ ì¡°ì§ì€ ë³€ë™í•˜ëŠ” ìˆ˜ìš”ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ Kubernetesì˜ ìë™ ìŠ¤ì¼€ì¼ë§, ê³ ê°€ì˜ GPU í•˜ë“œì›¨ì–´ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ í†µí•© ë¦¬ì†ŒìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, ë°°í¬ íŒŒì´í”„ë¼ì¸ê³¼ ìš´ì˜ì„ ë‹¨ìˆœí™”í•˜ê¸° ìœ„í•œ ì„ ì–¸ì  êµ¬ì„±ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  KubernetesëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ì„ ë” ì‰½ê²Œ ë§Œë“œëŠ” ë§ì€ ì´ì ì„ ì œê³µí•˜ì§€ë§Œ, ì• í”Œë¦¬ì¼€ì´ì…˜ ì½œë“œ ìŠ¤íƒ€íŠ¸ëŠ” ì—¬ì „íˆ ê³¼ì œì…ë‹ˆë‹¤.  í—ˆìš© ê°€ëŠ¥í•œ ì‹œì‘ ì‹œê°„ì€ AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ë§ˆë‹¤ ë‹¤ë¥´ì§€ë§Œ, ìˆ˜ì‹­ ì´ˆì—ì„œ ìˆ˜ ë¶„ì˜ ì§€ì—°ì€ ì‹œìŠ¤í…œ ì „ì²´ì— ì—°ì‡„ íš¨ê³¼ë¥¼ ì¼ìœ¼ì¼œ ì‚¬ìš©ì ê²½í—˜, ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥, ìš´ì˜ íš¨ìœ¨ì„±, ì¸í”„ë¼ ë¹„ìš© ë° ì¶œì‹œ ì‹œê°„ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.  ì£¼ìš” ì˜í–¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:  ìš”ì²­ ì§€ì—° ì‹œê°„ ì¦ê°€ ë° ì‚¬ìš©ì ê²½í—˜ ì €í•˜ìœ íœ´ ìƒíƒœì˜ ê³ ê°€ GPU ë¦¬ì†ŒìŠ¤íŠ¸ë˜í”½ ê¸‰ì¦ ì‹œ ì˜¤í† ìŠ¤ì¼€ì¼ë§ í”„ë¡œì„¸ìŠ¤ì˜ ì‘ë‹µì„± ê°ì†Œë°°í¬, ì‹¤í—˜, í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹… ì¤‘ ê¸´ í”¼ë“œë°± ë£¨í”„  ì´ ê°€ì´ë“œì˜ ì†”ë£¨ì…˜ì„ íš¨ê³¼ì ìœ¼ë¡œ í‰ê°€í•˜ê³  êµ¬í˜„í•˜ë ¤ë©´ ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œê°„ì— ê¸°ì—¬í•˜ëŠ” ì—¬ëŸ¬ ë³µí•© ìš”ì¸ì„ ê°œëµì ìœ¼ë¡œ ì„¤ëª…í•˜ê³  ë‚˜ì¤‘ì— ë” ìì„¸íˆ ì‚´í´ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤:  ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í˜¸ìŠ¤íŒ…í•˜ê¸° ìœ„í•œ ì»´í“¨íŒ… ìš©ëŸ‰(ì˜ˆ: Amazon EC2 ì¸ìŠ¤í„´ìŠ¤)ì˜ í”„ë¡œë¹„ì €ë‹ ë° ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì¼ë°˜ì ìœ¼ë¡œ í° ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì™€ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ  ê°€ì´ë“œì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì—ì„œëŠ” Amazon Elastic Kubernetes Service(Amazon EKS)ì— ë°°í¬ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ì´ëŸ¬í•œ ìš”ì¸ì— ëŒ€í•œ ê¶Œì¥ íŒ¨í„´ê³¼ ì†”ë£¨ì…˜ì„ ì‚´í´ë´…ë‹ˆë‹¤.  ê° ì†”ë£¨ì…˜ì€ ë‹¤ìŒ ì¸¡ë©´ì„ ë‹¤ë£¨ëŠ” êµ¬í˜„ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤:  ê¶Œì¥ë˜ëŠ” AWS ë° Kubernetes ì•„í‚¤í…ì²˜ì— ëŒ€í•œ ì‹¬ì¸µ ë…¼ì˜ì½”ë“œ ì˜ˆì œì™€ í•¨ê»˜ êµ¬í˜„ ì„¸ë¶€ ì •ë³´ì£¼ìš” ëª©ì ì— ë„ì›€ì´ ë˜ëŠ” ë°©ë²•ë‹¤ë¥¸ ì†”ë£¨ì…˜ê³¼ì˜ ì¶”ê°€ì ì¸ ì ì¬ì  ì´ì  ë° í†µí•©ê³ ë ¤í•´ì•¼ í•  íŠ¸ë ˆì´ë“œì˜¤í”„  ","version":"Next","tagName":"h2"},{"title":"ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œê°„ ê°œì„ â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/guidance/container-startup-time#ì»¨í…Œì´ë„ˆ-ì‹œì‘-ì‹œê°„-ê°œì„ ","content":" ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í’€ ì‹œê°„ì€ AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹œì‘ ì§€ì—°ì— ì£¼ìš” ê¸°ì—¬ ìš”ì¸ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ í”„ë ˆì„ì›Œí¬ ì¢…ì†ì„±(ì˜ˆ: PyTorch ë˜ëŠ” TensorFlow), ëŸ°íƒ€ì„(ì˜ˆ: TorchServe, Triton ë˜ëŠ” Ray Serve), ë²ˆë“¤ëœ ëª¨ë¸ íŒŒì¼ ë° ê´€ë ¨ ì•„í‹°íŒ©íŠ¸ì˜ í¬í•¨ìœ¼ë¡œ ì¸í•´ ì—¬ëŸ¬ ê¸°ê°€ë°”ì´íŠ¸ í¬ê¸°ì— ë„ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ì„¹ì…˜ì—ì„œëŠ” ë‹¤ìŒ ì†”ë£¨ì…˜ì— ì§‘ì¤‘í•©ë‹ˆë‹¤:  ì´ë¯¸ì§€ì˜ ì „ì²´ í¬ê¸° ì¤„ì´ê¸°ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í’€ í”„ë¡œì„¸ìŠ¤ë¥¼ ë” íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“¤ê¸°  ì†”ë£¨ì…˜ê³¼ ê·¸ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì‚´í´ë³¼ ë•Œ, ê·¸ë¦¼ 1ì˜ ë‹¤ì´ì–´ê·¸ë¨ì— í‘œì‹œëœ ê²ƒì²˜ëŸ¼ AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆë¥¼ ë§Œë“œëŠ” ë° ë“¤ì–´ê°€ëŠ” ë‹¤ì–‘í•œ ë ˆì´ì–´ì™€ êµ¬ì„± ìš”ì†Œë¥¼ ì°¸ì¡°í•  ê²ƒì…ë‹ˆë‹¤.  ê·¸ë¦¼ 1: AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë ˆì´ì–´  ë‹¤ì´ì–´ê·¸ë¨ì—ì„œ í•˜ìœ„ ë ˆì´ì–´ëŠ” ì´ë¯¸ ìƒìœ„ ë ˆì´ì–´ì˜ ì•„í‹°íŒ©íŠ¸ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì˜ˆ: pytorch/pytorch ê¸°ë³¸ OS ì´ë¯¸ì§€ì— ë²ˆë“¤ë˜ì–´ ìˆê³  ë³„ë„ë¡œ ì„¤ì¹˜ë˜ì§€ ì•Šì€ PyTorch AI/ML í”„ë ˆì„ì›Œí¬ ë° ì¶”ë¡  ëŸ°íƒ€ì„ êµ¬ì„± ìš”ì†Œ). ì´ëŠ” ìµœì í™”ë¥¼ ë‹¨ìˆœí™”í•˜ê±°ë‚˜ ë³µì¡í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ","version":"Next","tagName":"h2"},{"title":"í’€ í”„ë¡œì„¸ìŠ¤ ê°€ì†í™”","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/accelerate-pull-process","content":"í’€ í”„ë¡œì„¸ìŠ¤ ê°€ì†í™” ì´ ì„¹ì…˜ì˜ ì†”ë£¨ì…˜ì€ ì´ë¯¸ì§€ í’€ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°œì„ í•˜ì—¬ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œê°„ì„ ì¤„ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ ê³„ì¸µí™”ëœ ë‚´ë¶€ êµ¬ì¡°ì— ì˜ì¡´í•˜ì—¬ ì»¨í…Œì´ë„ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ë ˆì´ì–´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë°©ë²•ì„ ë³€ê²½í•˜ê±°ë‚˜ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì™„ì „íˆ ê±´ë„ˆë›°ì–´ ì´ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ëŠ” Amazon ECRê³¼ ê°™ì€ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì €ì¥ëœ ì½˜í…ì¸  ì£¼ì†Œ ì§€ì • ê°€ëŠ¥ blobìœ¼ë¡œ êµ¬í˜„ëœ ë ˆì´ì–´ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. Podê°€ ì›Œì»¤ ë…¸ë“œì— ìŠ¤ì¼€ì¤„ë§ë˜ë©´ ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„(ì¼ë°˜ì ìœ¼ë¡œ containerd)ì€ OverlayFSì™€ ê°™ì€ ìœ ë‹ˆì˜¨ íŒŒì¼ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ì½ê¸° ì „ìš© ë ˆì´ì–´ë¥¼ ê²€ìƒ‰í•˜ê³  ë§ˆìš´íŠ¸í•œ ë‹¤ìŒ ì»¨í…Œì´ë„ˆ íŒŒì¼ ì‹œìŠ¤í…œì„ ì™„ì„±í•˜ê¸° ìœ„í•´ ìƒë‹¨ì— ì“°ê¸° ê°€ëŠ¥í•œ ì„ì‹œ ë ˆì´ì–´ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤. containerdëŠ” ì—¬ëŸ¬ í”ŒëŸ¬ê·¸ ê°€ëŠ¥í•œ êµ¬ì„± ìš”ì†Œê°€ ìˆëŠ” ëª¨ë“ˆì‹ ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ìœ¼ë¡œ êµ¬í˜„ë©ë‹ˆë‹¤. ì²˜ìŒ ë‘ ì†”ë£¨ì…˜ì˜ ì´ˆì ì¸ snapshotterëŠ” ì´ë¯¸ì§€ ë ˆì´ì–´ì˜ ì¡°ë¦½ì„ ë‹´ë‹¹í•˜ëŠ” í”ŒëŸ¬ê·¸ ê°€ëŠ¥í•œ êµ¬ì„± ìš”ì†Œì…ë‹ˆë‹¤. ê¸°ë³¸ OverlayFS snapshotterëŠ” ì»¨í…Œì´ë„ˆ ì‹œì‘ ì „ì— ì´ë¯¸ì§€ ë ˆì´ì–´ë¥¼ ë””ìŠ¤í¬ì— ì™„ì „íˆ ì–¸íŒ©í•˜ë©° ì§€ì—° ë˜ëŠ” ë¶€ë¶„ ë ˆì´ì–´ ì¶”ì¶œì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë“  ë ˆì´ì–´ê°€ ì–¸íŒ©ë˜ê³  OverlayFSë¥¼ í†µí•´ ë§ˆìš´íŠ¸ëœ í›„ì—ì•¼ ì»¨í…Œì´ë„ˆì˜ í†µí•© íŒŒì¼ ì‹œìŠ¤í…œì´ ì œê³µë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ì„¤ëª…í•œ í”„ë¡œì„¸ìŠ¤ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” ì°¨ë‹¨ì ì´ê³  ìˆœì°¨ì ì´ë¯€ë¡œ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œê°„ì— ë§¤ìš° í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ê° ë ˆì´ì–´ë¥¼ ë””ìŠ¤í¬ì— ì™„ì „íˆ ì¶”ì¶œí•˜ëŠ” ëŒ€ì‹ , SOCI(Seekable OCI) ë˜ëŠ” Nydusì™€ ê°™ì€ ê³ ê¸‰ snapshotterëŠ” ê°€ìƒì˜ ë§ˆìš´íŠ¸ ê°€ëŠ¥í•œ ìŠ¤ëƒ…ìƒ·ì„ ìƒì„±í•˜ì—¬ ì ‘ê·¼í•  ë•Œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë‚˜ ì›ê²© ìŠ¤í† ë¦¬ì§€ì—ì„œ íŒŒì¼ì„ ì§€ì—° ë¡œë”©í•©ë‹ˆë‹¤. ì´ëŠ” I/O ì˜¤ë²„í—¤ë“œê°€ ë‚®ê³  ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œê°„ì„ í¬ê²Œ ê°œì„ í•©ë‹ˆë‹¤. ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë ˆì´ì–´ ê²€ìƒ‰ ë° ì €ì¥ì„ ìµœì í™”í•˜ì—¬ í’€ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°œì„ í•˜ëŠ” ëŒ€ì‹ , ë§ˆì§€ë§‰ ì†”ë£¨ì…˜ì€ CI/CD í”„ë¡œì„¸ìŠ¤ ì¤‘ì— Bottlerocket EC2 ë¨¸ì‹ ì˜ ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ ìºì‹œì¸ ë°ì´í„° ë³¼ë¥¨ì— ëª¨ë“  ì´ë¯¸ì§€ ë ˆì´ì–´ë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜µë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ í”„ë¡œì„¸ìŠ¤ëŠ” ë³¼ë¥¨ì˜ ìŠ¤ëƒ…ìƒ·ì„ ê°€ì ¸ì™€ EKS Bottlerocket ì›Œì»¤ ë…¸ë“œì— ë§ˆìš´íŠ¸í•˜ì—¬ ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ì— ëŒ€í•œ ì›Œë°ì—…ëœ ìºì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.","keywords":"","version":"Next"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 2: í¬í™” í…ŒìŠ¤íŠ¸","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/saturation-testing","content":"","keywords":"","version":"Next"},{"title":"ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 2: í¬í™” í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/saturation-testing#ì´-ì‹œë‚˜ë¦¬ì˜¤ë¥¼-ì‚¬ìš©í•´ì•¼-í•˜ëŠ”-ê²½ìš°","content":" ì„±ëŠ¥ì´ ì €í•˜ë˜ê¸° ì „ ì‹œìŠ¤í…œì˜ ìµœëŒ€ ì§€ì† ê°€ëŠ¥í•œ ì²˜ë¦¬ëŸ‰ì„ ê²½í—˜ì ìœ¼ë¡œ ê²°ì •í•´ì•¼ í•  ë•Œ ë‹¤ë‹¨ê³„ í¬í™” í…ŒìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ì´ê²ƒì€ í”„ë¡œë•ì…˜ ì¶œì‹œ ì „, ìš©ëŸ‰ì„ ê³„íší•  ë•Œ ë˜ëŠ” ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì„ê³„ê°’ì„ ì„¤ì •í•  ë•Œ ì¤‘ìš”í•©ë‹ˆë‹¤. &quot;ì‹ ë¢°ì„± ìˆê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìµœê³  QPSëŠ” ë¬´ì—‡ì¸ê°€?&quot;ë¼ëŠ” ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤. ì²´ê³„ì ì¸ ë¶€í•˜ ì¦ê°€ë¥¼ í†µí•´ ì§€ì—° ì‹œê°„ì´ ìƒìŠ¹í•˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë‚˜íƒ€ë‚˜ëŠ” ì§€ì ì„ ê´€ì°°í•˜ì—¬ ë§ˆì¼€íŒ… ìë£Œì™€ ì´ë¡ ì  ê³„ì‚°ì´ ì¢…ì¢… ê³¼ëŒ€í‰ê°€í•˜ëŠ” ì§„ì •í•œ ìš©ëŸ‰ í•œê³„ë¥¼ ë°í™ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 2: í¬í™” í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/saturation-testing#ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"Helm ì°¨íŠ¸ ì‚¬ìš© (ê¶Œì¥)â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 2: í¬í™” í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/saturation-testing#helm-ì°¨íŠ¸-ì‚¬ìš©-ê¶Œì¥","content":" # AI on EKS Helm ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update # í¬í™” ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì¹˜ helm install saturation-test ai-on-eks/benchmark-charts \\ --set benchmark.scenario=saturation \\ --set benchmark.target.baseUrl=http://qwen3-vllm.default:8000 \\ --set benchmark.target.modelName=qwen3-8b \\ --set benchmark.target.tokenizerPath=Qwen/Qwen3-8B \\ --namespace benchmarking --create-namespace # ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ í†µí•œ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ kubectl logs -n benchmarking -l benchmark.scenario=saturation -f   ","version":"Next","tagName":"h3"},{"title":"ë¶€í•˜ ë‹¨ê³„ ì‚¬ìš©ì ì •ì˜â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 2: í¬í™” í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/saturation-testing#ë¶€í•˜-ë‹¨ê³„-ì‚¬ìš©ì-ì •ì˜","content":" ì˜ˆìƒ ìš©ëŸ‰ì— ë§ê²Œ QPS ë‹¨ê³„ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤:  # custom-saturation.yaml benchmark: scenario: saturation target: baseUrl: http://your-model.your-namespace:8000 scenarios: saturation: load: stages: - rate: 10 duration: 180 - rate: 25 duration: 180 - rate: 50 duration: 180 - rate: 75 duration: 180   helm install saturation-test ai-on-eks/benchmark-charts -f custom-saturation.yaml -n benchmarking   ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” êµ¬ì„±:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 2: í¬í™” í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/saturation-testing#ì£¼ìš”-êµ¬ì„±","content":" ê°€ë³€ í•©ì„± ë°ì´í„° ë¶„í¬ (í‰ê·  512/256 í† í°, í˜„ì‹¤ì ì¸ ë¶„ì‚°)ë‹¤ë‹¨ê³„ ì¼ì • ë¶€í•˜: 5 â†’ 10 â†’ 20 â†’ 40 QPS (ê° 3ë¶„)ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”8ê°œì˜ ë™ì‹œ ì›Œì»¤  ","version":"Next","tagName":"h2"},{"title":"ê²°ê³¼ ì´í•´:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 2: í¬í™” í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/saturation-testing#ê²°ê³¼-ì´í•´","content":" ëª¨ë“  ë‹¨ê³„ì— ê±¸ì³ P50, P95 ë° P99 ì§€ì—° ì‹œê°„ì„ í”Œë¡œíŒ…í•˜ì—¬ í¬í™” ì§€ì ì„ ì‹œê°ì ìœ¼ë¡œ ì‹ë³„í•˜ì‹­ì‹œì˜¤. ë°±ë¶„ìœ„ìˆ˜ê°€ ê¸‰ê²©íˆ ê°ˆë¼ì§€ê±°ë‚˜ ì˜¤ë¥˜ìœ¨ì´ ê¸‰ì¦í•˜ëŠ” ë‹¨ê³„ë¥¼ ì°¾ìœ¼ì‹­ì‹œì˜¤. ì§€ì—° ì‹œê°„ ê³¡ì„ ì˜ &quot;ë¬´ë¦&quot;(í•˜í‚¤ ìŠ¤í‹±ì²˜ëŸ¼ ìœ„ë¡œ êº¾ì´ëŠ” ê³³)ì€ ì‹œìŠ¤í…œì´ ì²˜ë¦¬í•œ ì´ë¡ ì  ìµœëŒ€ QPSê°€ ì•„ë‹Œ ì‹¤ì§ˆì ì¸ ìš©ëŸ‰ í•œê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. íŠ¸ë˜í”½ ê¸‰ì¦ì— ëŒ€í•œ ì—¬ìœ ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ì´ í¬í™” ì§€ì ë³´ë‹¤ 20-30% ë‚®ê²Œ í”„ë¡œë•ì…˜ ëª©í‘œë¥¼ ì„¤ì •í•˜ì‹­ì‹œì˜¤; í¬í™”ê°€ 35 QPSì—ì„œ ë°œìƒí•˜ë©´ 24-28 QPS ì§€ì† ë¶€í•˜ë¥¼ ëª©í‘œë¡œ í•˜ì‹­ì‹œì˜¤. ë™ì¼í•œ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ë¥¸ ëª¨ë¸ êµ¬ì„±ì´ë‚˜ í•˜ë“œì›¨ì–´ ì„¤ì •ì„ ë¹„êµí•˜ì—¬ ë²¤ë” ì£¼ì¥ì´ ì•„ë‹Œ ë°ì´í„°ì— ê¸°ë°˜í•œ ê°ê´€ì ì¸ í™•ì¥ ê²°ì •ì„ ë‚´ë¦¬ì‹­ì‹œì˜¤.  ëŒ€ì•ˆ: ì›ì‹œ Kubernetes YAML --- apiVersion: v1 kind: ConfigMap metadata: name: inference-perf-saturation namespace: benchmarking data: config.yml: | api: type: completion streaming: true data: type: synthetic input_distribution: mean: 512 std_dev: 128 min: 128 max: 2048 output_distribution: mean: 256 std_dev: 64 min: 32 max: 512 load: type: constant stages: - rate: 5 duration: 180 - rate: 10 duration: 180 - rate: 20 duration: 180 - rate: 40 duration: 180 num_workers: 8 server: type: vllm model_name: qwen3-8b base_url: http://qwen3-vllm.default:8000 ignore_eos: true tokenizer: pretrained_model_name_or_path: Qwen/Qwen3-8B storage: simple_storage_service: bucket_name: &quot;inference-perf-results&quot; path: &quot;saturation-test/results&quot; --- apiVersion: batch/v1 kind: Job metadata: name: inference-perf-saturation namespace: benchmarking spec: backoffLimit: 2 ttlSecondsAfterFinished: 3600 template: spec: restartPolicy: Never serviceAccountName: inference-perf-sa affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchLabels: app.kubernetes.io/component: qwen3-vllm topologyKey: topology.kubernetes.io/zone containers: - name: inference-perf image: quay.io/inference-perf/inference-perf:v0.2.0 command: [&quot;/bin/sh&quot;, &quot;-c&quot;] args: - | inference-perf --config_file /workspace/config.yml volumeMounts: - name: config mountPath: /workspace/config.yml subPath: config.yml resources: requests: cpu: &quot;2&quot; memory: &quot;4Gi&quot; limits: cpu: &quot;4&quot; memory: &quot;8Gi&quot; volumes: - name: config configMap: name: inference-perf-saturation  ","version":"Next","tagName":"h2"},{"title":"containerd snapshotter ì‚¬ìš©","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/accelerate-pull-process/containerd-snapshotter","content":"","keywords":"","version":"Next"},{"title":"SOCI snapshotter ì‚¬ìš©â€‹","type":1,"pageTitle":"containerd snapshotter ì‚¬ìš©","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/accelerate-pull-process/containerd-snapshotter#soci-snapshotter-ì‚¬ìš©","content":" ì´ ì†”ë£¨ì…˜ì€ SOCI snapshotter(v0.11.0+)ë¥¼ containerdì— í”ŒëŸ¬ê·¸ì¸í•˜ì—¬ ì´ë¯¸ì§€ í’€ í”„ë¡œì„¸ìŠ¤ë¥¼ ìœ ê¸°ì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ë° ë‹¨ìˆœíˆ ì˜ì¡´í•©ë‹ˆë‹¤. ì´ê²ƒì€ í˜„ì¬ EKS AMIì˜ ê¸°ë³¸ê°’ì´ ì•„ë‹ˆì§€ë§Œ ê²°êµ­ ê¸°ë³¸ê°’ì´ ë  ê²ƒì…ë‹ˆë‹¤.  ì•„í‚¤í…ì²˜ ê°œìš”  ì•„í‚¤í…ì²˜ ë³€ê²½ì´ ì—†ìŠµë‹ˆë‹¤. ê´€ë ¨ Karpenter ë…¸ë“œ í´ë˜ìŠ¤ì˜ userData ë˜ëŠ” ë¹„ Karpenter ì¸ìŠ¤í„´ìŠ¤ í”„ë¡œë¹„ì €ë‹ ë°©ì‹ì„ ìœ„í•œ ì‹œì‘ í…œí”Œë¦¿ì„ í†µí•´ ì›Œì»¤ ë…¸ë“œì— snapshotterë¥¼ ë¶€íŠ¸ìŠ¤íŠ¸ë©í•´ì•¼ í•©ë‹ˆë‹¤.  ìƒˆë¡œìš´ SOCI snapshotter êµ¬í˜„ì€ containerd 2.1.0ì—ì„œ ë„ì…ëœ ë©€í‹°íŒŒíŠ¸ ë ˆì´ì–´ í˜ì¹˜ì™€ ì•„ì´ë””ì–´ê°€ ìœ ì‚¬í•˜ê²Œ í° ë ˆì´ì–´ë¥¼ ì²­í¬ë¡œ í’€í•  ìˆ˜ ìˆëŠ” ë¹„ì§€ì—° ë¡œë”© í’€ ëª¨ë“œë¥¼ ë„ì…í•˜ì—¬ ë” ë¹ ë¥´ê²Œ í’€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¸ë©”ëª¨ë¦¬ ëŒ€ì‹  ì„ì‹œ íŒŒì¼ ë²„í¼ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ SOCIëŠ” ë ˆì´ì–´ ì €ì¥ ë° ì••ì¶• í•´ì œ ì‘ì—…ì„ ë³‘ë ¬í™”í•  ìˆ˜ ìˆì–´ í›¨ì”¬ ë¹ ë¥¸ ì´ë¯¸ì§€ í’€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤(í•˜ë“œì›¨ì–´ ì œí•œì´ í—ˆìš©í•˜ëŠ” í•œ).  êµ¬í˜„ ê°€ì´ë“œ  ì•„ë˜ëŠ” ìœ„ ë³€ê²½ ì‚¬í•­ì˜ ê°œëµì ì¸ êµ¬í˜„ì…ë‹ˆë‹¤:  ì •ë³´ SOCI snapshotter ì‚¬ìš© ë°©ë²•ì— ëŒ€í•œ ì™„ì „í•œ ì˜ˆì œëŠ” ì´ ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  apiVersion: karpenter.k8s.aws/v1 kind: EC2NodeClass metadata: name: soci-snapshotter spec: role: KarpenterNodeRole-my-cluster instanceStorePolicy: RAID0 subnetSelectorTerms: - tags: karpenter.sh/discovery: my-cluster-private securityGroupSelectorTerms: - tags: karpenter.sh/discovery: my-cluster-private amiSelectorTerms: - alias: al2023@latest userData: | MIME-Version: 1.0 Content-Type: multipart/mixed; boundary=&quot;//&quot; --// Content-Type: text/x-shellscript; charset=&quot;us-ascii&quot; # 1. ì•„í‚¤í…ì²˜ ê°ì§€ # 2. https://github.com/awslabs/soci-snapshotter/releases/download/...ì—ì„œ # v0.11.0+ SOCI snapshotter ë²„ì „ ë‹¤ìš´ë¡œë“œ # 3. config.toml íŒŒì¼ì„ ìƒì„±í•˜ì—¬ snapshotter êµ¬ì„± # 4. systemd êµ¬ì„± íŒŒì¼ì„ ìƒì„±í•˜ì—¬ snapshotter ì„œë¹„ìŠ¤ êµ¬ì„± # 5. snapshotter í™œì„±í™” --// Content-Type: application/node.eks.aws apiVersion: node.eks.aws/v1alpha1 kind: NodeConfig spec: kubelet: config: imageServiceEndpoint: unix:///run/soci-snapshotter-grpc/soci-snapshotter-grpc.sock containerd: config: | [proxy_plugins.soci] type = &quot;snapshot&quot; address = &quot;/run/soci-snapshotter-grpc/soci-snapshotter-grpc.sock&quot; [proxy_plugins.soci.exports] root = &quot;/var/lib/containerd/io.containerd.snapshotter.v1.soci&quot; [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd] snapshotter = &quot;soci&quot; disable_snapshot_annotations = false discard_unpacked_layers = false --//   ì£¼ìš” ì´ì   ì†”ë£¨ì…˜ì€ ì›Œì»¤ ë…¸ë“œì˜ containerdì— ë” ì„±ëŠ¥ì´ ì¢‹ì€ snapshotterë¥¼ í”ŒëŸ¬ê·¸ì¸í•˜ì—¬ ì´ë¯¸ì§€ í’€ í”„ë¡œì„¸ìŠ¤ë¥¼ ì§ì ‘ ê°œì„ í•©ë‹ˆë‹¤.  ì¶”ê°€ ì´ì   ì´ ì†”ë£¨ì…˜ì€ ê°œë°œ í”„ë¡œì„¸ìŠ¤ì— ë³€ê²½ì´ í•„ìš” ì—†ê³  ì¶”ê°€ ì¸í”„ë¼ê°€ í•„ìš” ì—†ìœ¼ë©° ê¸°ë³¸ê°’ìœ¼ë¡œ í™œì„±í™”ë˜ë©´ ì½”ë“œë‚˜ êµ¬ì„±ì— ë³€ê²½ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.  íŠ¸ë ˆì´ë“œì˜¤í”„  snapshotterê°€ ê¸°ë³¸ê°’ì´ ë˜ê¸° ì „ì—ëŠ” ìœ„ì—ì„œ ì„¤ëª…í•œ ì›Œì»¤ ë…¸ë“œì˜ userData ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ êµ¬í˜„í•˜ê³  ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì´ ë˜ë©´ â†’ ì—†ìŒ. ","version":"Next","tagName":"h2"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 4: í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/production-simulation","content":"","keywords":"","version":"Next"},{"title":"ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 4: í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/production-simulation#ì´-ì‹œë‚˜ë¦¬ì˜¤ë¥¼-ì‚¬ìš©í•´ì•¼-í•˜ëŠ”-ê²½ìš°","content":" ì¶œì‹œ ì „ ìµœì¢… ê²€ì¦ìœ¼ë¡œ í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜ì„ ë°°í¬í•˜ì‹­ì‹œì˜¤; ê· ì¼í•œ ë¶€í•˜ ëŒ€ì‹  ê°€ë³€ ìš”ì²­ í¬ê¸°ì™€ Poisson(ë²„ìŠ¤íŠ¸) ë„ì°©ìœ¼ë¡œ ì‹¤ì œ íŠ¸ë˜í”½ í˜¼ë€ì„ ë³µì œí•©ë‹ˆë‹¤. ë² ì´ìŠ¤ë¼ì¸ ë° í¬í™” í…ŒìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì í™”í•œ í›„ &quot;í˜„ì‹¤ì ì¸ ì¡°ê±´ì—ì„œ ì‚¬ìš©ìê°€ ì¢‹ì€ ê²½í—˜ì„ í•  ê²ƒì¸ê°€?&quot;ë¼ëŠ” ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì´ê²ƒì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ì‹¤ì œ í”„ë¡œë•ì…˜ íŠ¸ë˜í”½ì€ ì‹œê³„ì²˜ëŸ¼ ë„ì°©í•˜ëŠ” ë™ì¼í•œ 512 í† í° ìš”ì²­ìœ¼ë¡œ êµ¬ì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤; ì‚¬ìš©ìëŠ” ë¬´ì‘ìœ„ ê°„ê²©ìœ¼ë¡œ ë‹¤ì–‘í•œ ê¸¸ì´ë¥¼ ë³´ë‚´ë©°, ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹œìŠ¤í…œì´ SLA ì„¤ì •ì„ ìœ„í•œ í—ˆìš© ê°€ëŠ¥í•œ ë°±ë¶„ìœ„ìˆ˜ ì§€ì—° ì‹œê°„ì„ ìœ ì§€í•˜ë©´ì„œ ê·¸ ì´ì§ˆì„±ì„ ì²˜ë¦¬í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 4: í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/production-simulation#ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"Helm ì°¨íŠ¸ ì‚¬ìš© (ê¶Œì¥)â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 4: í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/production-simulation#helm-ì°¨íŠ¸-ì‚¬ìš©-ê¶Œì¥","content":" # AI on EKS Helm ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update # í”„ë¡œë•ì…˜ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì¹˜ helm install production-sim ai-on-eks/benchmark-charts \\ --set benchmark.scenario=production \\ --set benchmark.target.baseUrl=http://qwen3-vllm.default:8000 \\ --set benchmark.target.modelName=qwen3-8b \\ --set benchmark.target.tokenizerPath=Qwen/Qwen3-8B \\ --namespace benchmarking --create-namespace # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ - ë²„ìŠ¤íŠ¸ íŠ¸ë˜í”½ìœ¼ë¡œ ì¸í•œ ê°€ë³€ ì§€ì—° ì‹œê°„ ì˜ˆìƒ kubectl logs -n benchmarking -l benchmark.scenario=production -f   ","version":"Next","tagName":"h3"},{"title":"íŠ¸ë˜í”½ íŒ¨í„´ ì‚¬ìš©ì ì •ì˜â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 4: í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/production-simulation#íŠ¸ë˜í”½-íŒ¨í„´-ì‚¬ìš©ì-ì •ì˜","content":" ë²„ìŠ¤íŠ¸ ë¹„ìœ¨ ë° ë³€ë™ì„± ì¡°ì •:  # custom-production.yaml benchmark: scenario: production target: baseUrl: http://your-model.your-namespace:8000 scenarios: production: data: input: mean: 2048 # ë” ê¸´ í‰ê·  í”„ë¡¬í”„íŠ¸ stdDev: 1024 # ë” ë†’ì€ ë³€ë™ì„± min: 256 max: 8192 load: type: poisson # ë²„ìŠ¤íŠ¸ ë„ì°© ìœ ì§€ stages: - rate: 20 # ë” ë†’ì€ ëª©í‘œ QPS duration: 900 # ë” ê¸´ í…ŒìŠ¤íŠ¸ (15ë¶„)   helm install production-sim ai-on-eks/benchmark-charts -f custom-production.yaml -n benchmarking   ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” êµ¬ì„±:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 4: í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/production-simulation#ì£¼ìš”-êµ¬ì„±","content":" ê°€ë³€ í•©ì„± ë°ì´í„° (ì…ë ¥/ì¶œë ¥ì— ëŒ€í•œ ê°€ìš°ì‹œì•ˆ ë¶„í¬)ë„“ì€ í† í° ë¶„í¬ (í‰ê·  1024/512, ë†’ì€ ë¶„ì‚°)ê· ì¼í•œ ë¶€í•˜ ëŒ€ì‹  Poisson(ë²„ìŠ¤íŠ¸) ë„ì°©ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”8ê°œì˜ ë™ì‹œ ì›Œì»¤  ","version":"Next","tagName":"h2"},{"title":"ê²°ê³¼ ì´í•´:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 4: í”„ë¡œë•ì…˜ ì‹œë®¬ë ˆì´ì…˜","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/production-simulation#ê²°ê³¼-ì´í•´","content":" P99 ë° P95 ì§€ì—° ì‹œê°„ì—ë§Œ ì§‘ì¤‘í•˜ì‹­ì‹œì˜¤; ì´ëŸ¬í•œ ë°±ë¶„ìœ„ìˆ˜ëŠ” 99%ì™€ 95%ì˜ ì‚¬ìš©ìê°€ ê²½í—˜í•˜ëŠ” ìµœì•…ì˜ ê²½í—˜ì„ ë‚˜íƒ€ë‚´ë©°, ë‚˜ìœ í…Œì¼ ì„±ëŠ¥ì„ ìˆ¨ê¸°ëŠ” í‰ê· ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ë„“ì€ ì…ë ¥/ì¶œë ¥ ë¶„í¬ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë³€ë™ì„±ì„ ìƒì„±í•˜ë¯€ë¡œ ë² ì´ìŠ¤ë¼ì¸ í…ŒìŠ¤íŠ¸ë³´ë‹¤ ë” ë†’ì€ ë¶„ì‚°ì„ ì˜ˆìƒí•˜ì‹­ì‹œì˜¤; ì´ê²ƒì€ ì •ìƒì´ë©° í”„ë¡œë•ì…˜ í˜„ì‹¤ì„ ë°˜ì˜í•©ë‹ˆë‹¤. Poisson ë²„ìŠ¤íŠ¸ëŠ” ì§€ì† ê°€ëŠ¥í•œ í‰ê·  ë¹„ìœ¨ì—ì„œë„ ì„ì‹œ ëŒ€ê¸°ì—´ ì¶•ì ì„ ìœ ë°œí•˜ë¯€ë¡œ, P99ê°€ ê· ì¼ ë¶€í•˜ í…ŒìŠ¤íŠ¸ê°€ ì œì•ˆí•œ ê²ƒë³´ë‹¤ ìƒë‹¹íˆ ë‚˜ì˜ë©´ ì˜ˆìƒë³´ë‹¤ ë” ë§ì€ ì—¬ìœ ê°€ í•„ìš”í•©ë‹ˆë‹¤. í‰ê· ì´ ì•„ë‹Œ ì´ëŸ¬í•œ í˜„ì‹¤ì ì¸ ë°±ë¶„ìœ„ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SLAë¥¼ ì„¤ì •í•˜ì‹­ì‹œì˜¤; P99 TTFTê°€ 1200msì´ë©´ í‰ê· ì´ 400msì¼ ìˆ˜ ìˆì–´ë„ 1ì´ˆ ë¯¸ë§Œ ì§€ì—° ì‹œê°„ì„ ì•½ì†í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.  ëŒ€ì•ˆ: ì›ì‹œ Kubernetes YAML --- apiVersion: v1 kind: ConfigMap metadata: name: inference-perf-production namespace: benchmarking data: config.yml: | api: type: completion streaming: true data: type: synthetic input_distribution: mean: 1024 std_dev: 512 min: 128 max: 4096 output_distribution: mean: 512 std_dev: 256 min: 50 max: 2048 load: type: poisson # í˜„ì‹¤ì ì¸ ë²„ìŠ¤íŠ¸ ë„ì°© stages: - rate: 15 duration: 600 num_workers: 8 server: type: vllm model_name: qwen3-8b base_url: http://qwen3-vllm.default:8000 ignore_eos: true tokenizer: pretrained_model_name_or_path: Qwen/Qwen3-8B storage: simple_storage_service: bucket_name: &quot;inference-perf-results&quot; path: &quot;production-sim/results&quot; --- apiVersion: batch/v1 kind: Job metadata: name: inference-perf-production namespace: benchmarking spec: backoffLimit: 2 ttlSecondsAfterFinished: 3600 template: spec: restartPolicy: Never serviceAccountName: inference-perf-sa affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchLabels: app.kubernetes.io/component: qwen3-vllm topologyKey: topology.kubernetes.io/zone containers: - name: inference-perf image: quay.io/inference-perf/inference-perf:v0.2.0 command: [&quot;/bin/sh&quot;, &quot;-c&quot;] args: - | inference-perf --config_file /workspace/config.yml volumeMounts: - name: config mountPath: /workspace/config.yml subPath: config.yml resources: requests: cpu: &quot;2&quot; memory: &quot;4Gi&quot; limits: cpu: &quot;4&quot; memory: &quot;8Gi&quot; volumes: - name: config configMap: name: inference-perf-production  ","version":"Next","tagName":"h2"},{"title":"ì‹œë‚˜ë¦¬ì˜¤ 5: ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/real-dataset-testing","content":"","keywords":"","version":"Next"},{"title":"ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 5: ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/real-dataset-testing#ì´-ì‹œë‚˜ë¦¬ì˜¤ë¥¼-ì‚¬ìš©í•´ì•¼-í•˜ëŠ”-ê²½ìš°","content":" ì‹¤ì œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì™€ ì¿¼ë¦¬ íŒ¨í„´ìœ¼ë¡œ í”„ë¡œë•ì…˜ ì¤€ë¹„ ì„±ëŠ¥ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. ì´ê²ƒì€ ëª¨ë¸ì´ íŠ¹ì • ëŒ€í™” íŒ¨í„´ì— ë§ê²Œ ë¯¸ì„¸ ì¡°ì •ë˜ì—ˆì„ ë•Œ, ì‹¤ì œ ì„±ëŠ¥ ë³´ì¥ì´ ìˆëŠ” ëª¨ë¸ ë²„ì „ì„ ë¹„êµí•  ë•Œ, ë˜ëŠ” ì´í•´ê´€ê³„ìì—ê²Œ &quot;ì´ê²ƒì€ ì´ë¡ ì  ë°ì´í„°ê°€ ì•„ë‹Œ ì‹¤ì œ ëŒ€í™”ì—ì„œ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ì…ë‹ˆë‹¤&quot;ë¼ê³  ë§í•´ì•¼ í•  ë•Œ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ë¶„í¬ì— ëŒ€í•œ ì œì–´ê°€ ì ì–´ì§€ëŠ” íŠ¸ë ˆì´ë“œì˜¤í”„ê°€ ìˆì§€ë§Œ, ì§„ì •ì„±ê³¼ í•©ì„± ë°ì´í„°ê°€ ë†“ì¹˜ëŠ” ì—£ì§€ ì¼€ì´ìŠ¤ë¥¼ ë°œê²¬í•˜ëŠ” ëŠ¥ë ¥ì„ ì–»ìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 5: ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/real-dataset-testing#ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"Helm ì°¨íŠ¸ ì‚¬ìš© (ê¶Œì¥)â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 5: ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/real-dataset-testing#helm-ì°¨íŠ¸-ì‚¬ìš©-ê¶Œì¥","content":" # AI on EKS Helm ì €ì¥ì†Œ ì¶”ê°€ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update # ShareGPT ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ëŠ” ë™ì¼í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ ì‹¤ì œ ë°ì´í„° ì‚¬ìš© helm install sharegpt-test ai-on-eks/benchmark-charts \\ --set benchmark.scenario=baseline \\ --set benchmark.target.baseUrl=http://qwen3-vllm.default:8000 \\ --set benchmark.target.modelName=qwen3-8b \\ --set benchmark.target.tokenizerPath=Qwen/Qwen3-8B \\ --namespace benchmarking --create-namespace # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ë³µì¡ì„± íŒ¨í„´ ëª¨ë‹ˆí„°ë§ kubectl logs -n benchmarking -l app.kubernetes.io/component=benchmark -f   ì°¸ê³ : ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ëŠ” ì‹œë‚˜ë¦¬ì˜¤ 1-4ì™€ ë™ì¼í•œ ë¶€í•˜ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì§€ë§Œ, data.type: synthetic ëŒ€ì‹  data.type: shareGPTë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤(baseline, saturation, sweep ë˜ëŠ” production)ì— ì‹¤ì œ ë°ì´í„°ë¥¼ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ ì‚¬ìš©â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 5: ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/real-dataset-testing#ì‚¬ìš©ì-ì •ì˜-ë°ì´í„°ì…‹-ì‚¬ìš©","content":" ìì²´ ëŒ€í™” ë°ì´í„°ì…‹ ì œê³µ:  # custom-dataset.yaml benchmark: scenario: saturation # ë˜ëŠ” ë‹¤ë¥¸ ì‹œë‚˜ë¦¬ì˜¤ target: baseUrl: http://your-model.your-namespace:8000 # ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ë„ë¡ ë°ì´í„° êµ¬ì„± ì¬ì •ì˜ customData: enabled: true type: custom path: /path/to/your/conversations.json format: sharegpt # ë˜ëŠ” openai, alpaca ë“±   ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ì˜ ê²½ìš° ConfigMap ë˜ëŠ” PersistentVolumeì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° íŒŒì¼ì„ ë²¤ì¹˜ë§ˆí¬ Podì— ë§ˆìš´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” êµ¬ì„±:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 5: ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/real-dataset-testing#ì£¼ìš”-êµ¬ì„±","content":" ShareGPT ì‹¤ì œ ëŒ€í™” ë°ì´í„°ì…‹ (ì„ íƒí•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¼ ë‹¤ë¦„)ëª¨ë“  ë¶€í•˜ íŒ¨í„´ (constant/poisson, ì„ íƒí•œ ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¼ ë‹¤ë¦„)ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ë³µì¡ì„± ë° ê¸¸ì´ ë¶„ì‚°  ","version":"Next","tagName":"h2"},{"title":"ê²°ê³¼ ì´í•´:â€‹","type":1,"pageTitle":"ì‹œë‚˜ë¦¬ì˜¤ 5: ì‹¤ì œ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸","url":"/ai-on-eks/ko/docs/guidance/benchmarking/test-scenarios/real-dataset-testing#ê²°ê³¼-ì´í•´","content":" ì‹¤ì œ ëŒ€í™”ëŠ” í•©ì„± ë°ì´í„°ì— ì—†ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë³µì¡ì„± íŒ¨í„´ê³¼ ì—£ì§€ ì¼€ì´ìŠ¤ë¥¼ ë“œëŸ¬ëƒ…ë‹ˆë‹¤. ëŠë¦° ì²˜ë¦¬ë¥¼ ìœ ë°œí•˜ëŠ” ë¬¸ì œê°€ ìˆëŠ” ëŒ€í™” êµ¬ì¡°ë‚˜ í‘œí˜„ì„ ë…¸ì¶œí•˜ëŠ” ì§€ì—° ì‹œê°„ ì´ìƒì¹˜ë¥¼ ì°¾ìœ¼ì‹­ì‹œì˜¤. ìœ ì‚¬í•œ QPSì—ì„œ ì‹¤ì œ ë°ì´í„° ì„±ëŠ¥ì„ í•©ì„± í…ŒìŠ¤íŠ¸ì™€ ë¹„êµí•˜ì‹­ì‹œì˜¤; ìƒë‹¹í•œ ì €í•˜ëŠ” ì‹¤ì œ ëŒ€í™”ê°€ í•©ì„± ë§¤ê°œë³€ìˆ˜ê°€ ê°€ì •í•œ ê²ƒë³´ë‹¤ ë” ë³µì¡í•¨ì„ ì‹œì‚¬í•˜ë©°, í–¥í›„ í•©ì„± í…ŒìŠ¤íŠ¸ë¥¼ ë³´ì •í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ë‹¤ì¤‘ í„´ ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„ì‚°ìœ¼ë¡œ ì¸í•´ TTFT ë³€ë™ì„±ì´ ë” ë†’ì•„ì§€ë©°, íŠ¹ì • ëŒ€í™” ìœ í˜•ì— ëŒ€í•œ ì¼ê´€ëœ ì˜¤ë¥˜ íŒ¨í„´ì€ í‘œì í™”ëœ ìµœì í™”ê°€ í•„ìš”í•œ í”„ë¡œë•ì…˜ ì·¨ì•½ì ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤. í•©ì„± ë°ì´í„°ê°€ ì•„ë‹Œ ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´í•´ê´€ê³„ì ì•½ì†ì„ ìœ„í•œ ê¸°ì¤€ìœ¼ë¡œ ì´ëŸ¬í•œ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤. &quot;P99 ì§€ì—° ì‹œê°„ì€ Xì…ë‹ˆë‹¤&quot;ë¼ëŠ” ì•½ì†ì„ í•©ì„±ì´ ì•„ë‹Œ ì‹¤ì œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì‹­ì‹œì˜¤.  ì¤‘ìš”: ë“œë¦¬í”„íŠ¸ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ìµœê·¼ ìµëª…í™”ëœ í”„ë¡œë•ì…˜ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì •ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì‹­ì‹œì˜¤. ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì´ 6ê°œì›” ì „ì´ì§€ë§Œ ì‚¬ìš©ì í–‰ë™ì´ ë” ê¸´ í”„ë¡¬í”„íŠ¸ë¡œ ë°”ë€Œì—ˆë‹¤ë©´ ì„±ëŠ¥ ì˜ˆì¸¡ì´ ë¶€ì •í™•í•  ê²ƒì…ë‹ˆë‹¤.  ëŒ€ì•ˆ: ì›ì‹œ Kubernetes YAML --- apiVersion: v1 kind: ConfigMap metadata: name: inference-perf-sharegpt namespace: benchmarking data: config.yml: | api: type: completion streaming: true data: type: shareGPT # ì‹¤ì œ ëŒ€í™” ë°ì´í„° load: type: constant stages: - rate: 10 duration: 300 num_workers: 4 server: type: vllm model_name: qwen3-8b base_url: http://qwen3-vllm.default:8000 ignore_eos: true tokenizer: pretrained_model_name_or_path: Qwen/Qwen3-8B storage: simple_storage_service: bucket_name: &quot;inference-perf-results&quot; path: &quot;sharegpt-test/results&quot; --- apiVersion: batch/v1 kind: Job metadata: name: inference-perf-sharegpt namespace: benchmarking spec: backoffLimit: 2 ttlSecondsAfterFinished: 3600 template: spec: restartPolicy: Never serviceAccountName: inference-perf-sa affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchLabels: app.kubernetes.io/component: qwen3-vllm topologyKey: topology.kubernetes.io/zone containers: - name: inference-perf image: quay.io/inference-perf/inference-perf:v0.2.0 command: [&quot;/bin/sh&quot;, &quot;-c&quot;] args: - | inference-perf --config_file /workspace/config.yml volumeMounts: - name: config mountPath: /workspace/config.yml subPath: config.yml resources: requests: cpu: &quot;2&quot; memory: &quot;4Gi&quot; limits: cpu: &quot;4&quot; memory: &quot;8Gi&quot; volumes: - name: config configMap: name: inference-perf-sharegpt  ","version":"Next","tagName":"h2"},{"title":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸°","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size","content":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸° ì´ë¯¸ì§€ ì••ì¶• í¬ê¸°(ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ì°¨ì§€í•˜ëŠ” í¬ê¸°)ëŠ” í’€ ì‹œê°„ê³¼ ì§ì ‘ì ìœ¼ë¡œ ìƒê´€ê´€ê³„ê°€ ìˆìœ¼ë©°, ì´ë¯¸ì§€ ë¹„ì••ì¶• í¬ê¸°(ë‹¤ìš´ë¡œë“œëœ í›„ ì´ë¯¸ì§€ì˜ í¬ê¸°)ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ë¶€íŠ¸ìŠ¤íŠ¸ë©í•˜ëŠ” ë° ê±¸ë¦¬ëŠ” ì‹œê°„ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. í¬ê¸°ê°€ í´ìˆ˜ë¡ ì´ë¯¸ì§€ ë ˆì´ì–´ë¥¼ ì••ì¶• í•´ì œí•˜ê³  ì¶”ì¶œí•˜ë©° ë§ˆìš´íŠ¸í•˜ê³  ì»¨í…Œì´ë„ˆ íŒŒì¼ ì‹œìŠ¤í…œìœ¼ë¡œ ê²°í•©í•˜ëŠ” ë° ë” ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. ì´ë¯¸ì§€ ë ˆì´ì–´ ìˆ˜, êµ¬ì¡°, ì¤‘ë³µ ì œê±° ë° ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ ìºì‹œ íš¨ìœ¨ì„± ë˜ëŠ” ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê·¼ì ‘ì„±ê³¼ ê°™ì€ ë‹¤ë¥¸ ê¸°ì—¬ ìš”ì¸ì´ ìˆì§€ë§Œ, í¬ê¸° ìµœì í™”ì— íŠ¹ë³„íˆ ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ëŠ” ê²ƒì€ ì‹œì‘ ì§€ì—° ì‹œê°„ì„ ì¤„ì´ëŠ” ì—¬ì •ì—ì„œ ì¤‘ìš”í•œ ë‹¨ê³„ì…ë‹ˆë‹¤. AWS Container Build lensì— ì„¤ëª…ëœ ëŒ€ë¡œ, ë©€í‹° ìŠ¤í…Œì´ì§€ ë¹Œë“œ ë° ë¡œë”©ê³¼ ìºì‹±ì— ë„ì›€ì´ ë˜ëŠ” ë ˆì´ì–´ êµ¬ì¡°í™”ì™€ ê°™ì€ ì „í†µì ì¸ ìµœì í™” ê¸°ë²•ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ ìœ í˜•ì— ê´€ê³„ì—†ì´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸°ì™€ ì „ë°˜ì ì¸ ì„±ëŠ¥ ë° ë¹„ìš© íš¨ìœ¨ì„±ì— ê¸°ë³¸ì ì¸ ê°œì„ ì„ ì œê³µí•©ë‹ˆë‹¤. AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì˜ ê²½ìš°, ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†Œ(íŠ¹íˆ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë° ì„œë¹™ í”„ë ˆì„ì›Œí¬)ê°€ ì¢…ì¢… ì—¬ëŸ¬ ê¸°ê°€ë°”ì´íŠ¸(GB) í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ê¸° ë•Œë¬¸ì— ëŒ€ê·œëª¨ êµ¬ì„± ìš”ì†Œë¥¼ ë¶„ë¦¬í•˜ë©´ ì¶”ê°€ì ìœ¼ë¡œ ìƒë‹¹í•œ í¬ê¸° ê°ì†Œë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì„¹ì…˜ì˜ ì†”ë£¨ì…˜ì€ ì „í†µì ì¸ ìµœì í™” ê¸°ë²•ê³¼ ì´ëŸ¬í•œ ëŒ€ê·œëª¨ êµ¬ì„± ìš”ì†Œë¥¼ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ Amazon S3 ë˜ëŠ” Amazon FSxì™€ ê°™ì€ ë‹¤ë¥¸ ì „ë‹¬ ì‹œìŠ¤í…œìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ì•„í‚¤í…ì²˜ íŒ¨í„´ì— ì´ˆì ì„ ë§ì¶¥ë‹ˆë‹¤. ì¬ë°°ì¹˜ëœ êµ¬ì„± ìš”ì†ŒëŠ” ì—¬ì „íˆ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•´ì•¼ í•˜ë¯€ë¡œ ìƒˆë¡œìš´ ì „ë‹¬ ì‹œìŠ¤í…œì´ ì´ë¯¸ì§€ í’€ í”„ë¡œì„¸ìŠ¤ë³´ë‹¤ ë¹¨ë¼ì•¼ í•©ë‹ˆë‹¤. í›„ì† í’€ í”„ë¡œì„¸ìŠ¤ ê°€ì†í™” ì„¹ì…˜ì—ì„œëŠ” ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ê²€ìƒ‰ì„ ìµœì í™”í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.","keywords":"","version":"Next"},{"title":"EBS ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ Bottlerocket ë°ì´í„° ë³¼ë¥¨ì— ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¯¸ë¦¬ ë¡œë“œ","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/accelerate-pull-process/prefecthing-images-on-br","content":"","keywords":"","version":"Next"},{"title":"ì´ ìŠ¤í¬ë¦½íŠ¸ ê°œìš”â€‹","type":1,"pageTitle":"EBS ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ Bottlerocket ë°ì´í„° ë³¼ë¥¨ì— ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¯¸ë¦¬ ë¡œë“œ","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/accelerate-pull-process/prefecthing-images-on-br#ì´-ìŠ¤í¬ë¦½íŠ¸-ê°œìš”","content":"   EKSìš© Bottlerocket AMIë¡œ EC2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.Amazon System Managerë¥¼ í†µí•´ ì¸ìŠ¤í„´ìŠ¤ì— ì ‘ê·¼í•©ë‹ˆë‹¤.Amazon System Manager Run Commandë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ EC2ì—ì„œ ìºì‹œí•  ì´ë¯¸ì§€ë¥¼ í’€í•©ë‹ˆë‹¤.ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¢…ë£Œí•˜ê³  ë°ì´í„° ë³¼ë¥¨ì— ëŒ€í•œ EBS ìŠ¤ëƒ…ìƒ·ì„ ë¹Œë“œí•©ë‹ˆë‹¤.ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì‚¬ìš© ì˜ˆâ€‹","type":1,"pageTitle":"EBS ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ Bottlerocket ë°ì´í„° ë³¼ë¥¨ì— ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¯¸ë¦¬ ë¡œë“œ","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/accelerate-pull-process/prefecthing-images-on-br#ì‚¬ìš©-ì˜ˆ","content":" git clone https://github.com/aws-samples/bottlerocket-images-cache/ cd bottlerocket-images-cache/ # ì—°ê²° ëŠê¹€ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í„°ë¯¸ë„ì—ì„œ nohup ì‚¬ìš© â¯ nohup ./snapshot.sh --snapshot-size 150 -r us-west-2 \\ docker.io/rayproject/ray-ml:2.10.0-py310-gpu,public.ecr.aws/data-on-eks/ray2.11.0-py310-gpu-stablediffusion:latest &amp; â¯ tail -f nohup.out 2024-07-15 17:18:53 I - [1/8] Deploying EC2 CFN stack ... 2024-07-15 17:22:07 I - [2/8] Launching SSM . 2024-07-15 17:22:08 I - SSM launched in instance i-07d10182abc8a86e1. 2024-07-15 17:22:08 I - [3/8] Stopping kubelet.service .. 2024-07-15 17:22:10 I - Kubelet service stopped. 2024-07-15 17:22:10 I - [4/8] Cleanup existing images .. 2024-07-15 17:22:12 I - Existing images cleaned 2024-07-15 17:22:12 I - [5/8] Pulling images: 2024-07-15 17:22:12 I - Pulling docker.io/rayproject/ray-ml:2.10.0-py310-gpu - amd64 ... 2024-07-15 17:27:50 I - docker.io/rayproject/ray-ml:2.10.0-py310-gpu - amd64 pulled. 2024-07-15 17:27:50 I - Pulling docker.io/rayproject/ray-ml:2.10.0-py310-gpu - arm64 ... 2024-07-15 17:27:58 I - docker.io/rayproject/ray-ml:2.10.0-py310-gpu - arm64 pulled. 2024-07-15 17:27:58 I - Pulling public.ecr.aws/data-on-eks/ray2.11.0-py310-gpu-stablediffusion:latest - amd64 ... 2024-07-15 17:31:34 I - public.ecr.aws/data-on-eks/ray2.11.0-py310-gpu-stablediffusion:latest - amd64 pulled. 2024-07-15 17:31:34 I - Pulling public.ecr.aws/data-on-eks/ray2.11.0-py310-gpu-stablediffusion:latest - arm64 ... 2024-07-15 17:31:36 I - public.ecr.aws/data-on-eks/ray2.11.0-py310-gpu-stablediffusion:latest - arm64 pulled. 2024-07-15 17:31:36 I - [6/8] Stopping instance ... 2024-07-15 17:32:25 I - Instance i-07d10182abc8a86e1 stopped 2024-07-15 17:32:25 I - [7/8] Creating snapshot ... 2024-07-15 17:38:36 I - Snapshot snap-0c6d965cf431785ed generated. 2024-07-15 17:38:36 I - [8/8] Cleanup. 2024-07-15 17:38:37 I - Stack deleted. 2024-07-15 17:38:37 I - -------------------------------------------------- 2024-07-15 17:38:37 I - All done! Created snapshot in us-west-2: snap-0c6d965cf431785ed   ìŠ¤ëƒ…ìƒ· ID snap-0c6d965cf431785edë¥¼ ë³µì‚¬í•˜ì—¬ ì›Œì»¤ ë…¸ë“œì˜ ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Amazon EKS ë° Karpenterì™€ í•¨ê»˜ ìŠ¤ëƒ…ìƒ· ì‚¬ìš©  Karpenter ë…¸ë“œ í´ë˜ìŠ¤ì—ì„œ snapshotIDë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤(ë˜ ë‹¤ë¥¸ ì˜µì…˜ì€ ì´ ì €ì¥ì†Œì˜ Infrastructure Blueprintsë¥¼ ì‚¬ìš©í•˜ê³  IaC êµ¬ì„±ì˜ ì¼ë¶€ë¡œ snapshotIDë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤). EC2NodeClassì— ì½˜í…ì¸ ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤:  apiVersion: karpenter.k8s.aws/v1beta1 kind: EC2NodeClass metadata: name: default spec: amiFamily: Bottlerocket # OSê°€ BottleRocketì¸ì§€ í™•ì¸ blockDeviceMappings: - deviceName: /dev/xvdb ebs: volumeSize: 150Gi volumeType: gp3 kmsKeyID: &quot;arn:aws:kms:&lt;REGION&gt;:&lt;ACCOUNT_ID&gt;:key/1234abcd-12ab-34cd-56ef-1234567890ab&quot; # ì‚¬ìš©ì ì •ì˜ KMS í‚¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° KMS ID ì§€ì • snapshotID: snap-0123456789 # ì—¬ê¸°ì— ìŠ¤ëƒ…ìƒ· ID ì§€ì •   ì¢…ë‹¨ ê°„ ë°°í¬ ì˜ˆì œ  ì¢…ë‹¨ ê°„ ë°°í¬ ì˜ˆì œëŠ” GPUì—ì„œì˜ Stable Diffusionì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ","version":"Next","tagName":"h2"},{"title":"EKS ëª¨ë²” ì‚¬ë¡€","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/eks-best-practices","content":"EKS ëª¨ë²” ì‚¬ë¡€ AI/ML ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ Amazon EKS ëª¨ë²” ì‚¬ë¡€ ê°€ì´ë“œëŠ” Amazon EKSìš© AWS ë¬¸ì„œ ì‚¬ì´íŠ¸ì—ì„œ ê´€ë¦¬ë©ë‹ˆë‹¤. ëª¨ë²” ì‚¬ë¡€ ê¶Œì¥ ì‚¬í•­ì€ í•´ë‹¹ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.","keywords":"","version":"Next"},{"title":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size/optimize-image-size","content":"","keywords":"","version":"Next"},{"title":"ì ì ˆí•œ ë² ì´ìŠ¤ ì´ë¯¸ì§€ ì„ íƒâ€‹","type":1,"pageTitle":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size/optimize-image-size#ì ì ˆí•œ-ë² ì´ìŠ¤-ì´ë¯¸ì§€-ì„ íƒ","content":" ë‹¤ì–‘í•œ AI/ML í”„ë ˆì„ì›Œí¬ì™€ í”Œë«í¼ì€ í¸ì˜ì„±ì„ ì œê³µí•˜ê³  ì‹¤í—˜ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ì´ë¯¸ì§€ëŠ” ê°€ëŠ¥í•œ í•œ ë„“ì€ ê¸°ëŠ¥ ì„¸íŠ¸ë¥¼ ë‹¤ë£¨ë ¤ê³  í•˜ë¯€ë¡œ ë‹¤ì–‘í•œ ëŸ°íƒ€ì„, í”„ë ˆì„ì›Œí¬ ë˜ëŠ” ì§€ì›ë˜ëŠ” APIë¥¼ í¬í•¨í•  ìˆ˜ ìˆì–´ ë¹„ëŒ€í™”ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ì–‘í•œ PyTorch ì´ë¯¸ì§€ ë³€í˜•ì€ ë§¤ìš° ë‹¤ë¥¸ í¬ê¸°ë¥¼ ê°€ì§‘ë‹ˆë‹¤: ê°œë°œ ë„êµ¬, ì»´íŒŒì¼ëŸ¬ ë“±ì„ í¬í•¨í•˜ëŠ” 2.7.1-cuda11.8-cudnn9-devel (6.66 GB)ë¶€í„° ëŸ°íƒ€ì„ë§Œ í¬í•¨í•˜ëŠ” 2.7.1-cuda11.8-cudnn9-runtime (3.03 GB)ê¹Œì§€ ìˆìŠµë‹ˆë‹¤. vLLM í”„ë¡œì íŠ¸ëŠ” OpenAI ì‚¬ì–‘, Sagemaker í†µí•© ë“±ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì´ íŒ¨í‚¤ì§•ëœ ì—¬ëŸ¬ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë³€í˜•ì„ ì œê³µí•©ë‹ˆë‹¤.  ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í•„ìš”ë¥¼ ì¶©ì¡±í•˜ëŠ” ë” ì‘ì€ ë² ì´ìŠ¤ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ë©´ í° ì°¨ì´ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì£¼ì˜í•  ì ì€ ë” ì‘ì€ ëŸ°íƒ€ì„ ì „ìš© ì´ë¯¸ì§€ì—ëŠ” JIT ì»´íŒŒì¼ì´ë‚˜ ë™ì  ìµœì í™”ê°€ í¬í•¨ë˜ì§€ ì•Šì•„ ë” ëŠë¦° ì½”ë“œ ê²½ë¡œì— ë¹ ì ¸ ì‹œì‘ ì‹œê°„ì´ ì¤„ì–´ë“¤ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.  í¬ê´„ì ì¸ ì ‘ê·¼ ë°©ì‹ì€ ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤:  ë‹¤ì–‘í•œ ë² ì´ìŠ¤ ì´ë¯¸ì§€ë¡œ ì›Œí¬ë¡œë“œ ë²¤ì¹˜ë§ˆí‚¹í•„ìš”í•œ ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ í¬í•¨í•˜ëŠ” ì‚¬ìš©ì ì •ì˜ ë¹Œë“œ ê³ ë ¤ì´ë¯¸ì§€ í’€ ì‹œê°„ ê°œì„  ì™¸ì— ì „ì²´ ì½œë“œ ìŠ¤íƒ€íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸  ","version":"Next","tagName":"h2"},{"title":"ë©€í‹° ìŠ¤í…Œì´ì§€ ë¹Œë“œ ì‚¬ìš©â€‹","type":1,"pageTitle":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size/optimize-image-size#ë©€í‹°-ìŠ¤í…Œì´ì§€-ë¹Œë“œ-ì‚¬ìš©","content":" Docker/BuildKit, Podman, Finch/Buildkitê³¼ ê°™ì€ ì—¬ëŸ¬ í”Œë«í¼ì—ì„œ ì§€ì›í•˜ëŠ” ë©€í‹° ìŠ¤í…Œì´ì§€ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¹Œë“œë¥¼ í†µí•´ ë‹¨ì¼ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ ì—¬ëŸ¬ FROM ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ë¹Œë“œ í”„ë¡œì„¸ìŠ¤ì™€ ì•„í‹°íŒ©íŠ¸ë¥¼ ëŸ°íƒ€ì„ ê´€ì‹¬ì‚¬ì™€ ë¶„ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë©€í‹° ìŠ¤í…Œì´ì§€ ë¹Œë“œ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ íŒŒì¼ì€ ë‹¤ìŒê³¼ ìœ ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  # ì™¸ë¶€ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•„í‹°íŒ©íŠ¸ë¥¼ ë³µì‚¬í•˜ëŠ” ë¹Œë“œ ìŠ¤í…Œì´ì§€ FROM python:3.12-slim-bookworm AS builder COPY --from=ghcr.io/astral-sh/uv:0.7.11 /uv /uvx /bin/ ... # ëŸ°íƒ€ì„ ìŠ¤í…Œì´ì§€ FROM python:3.12-slim-bookworm ... COPY --from=models some-model /app/models/some-model/configs COPY --from=builder --chown=app:app /app/.venv ./.venv COPY --from=builder --chown=app:app /app/main.py ./main.py ... CMD [&quot;sh&quot;, &quot;-c&quot;, &quot;exec fastapi run --host 0.0.0.0 --port 80 /app/main.py&quot;]   ì •ë³´ ì¼ë°˜ì ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ì†ì„±ì„ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì— ë² ì´í‚¹í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, ëŒ€ê·œëª¨ ëª¨ë¸ íŒŒì¼(ìˆ˜ GBì—ì„œ ìˆ˜ì‹­ GB ë²”ìœ„)ì„ ë³µì‚¬í•˜ëŠ” ê²ƒì€ ì¼ë°˜ì ìœ¼ë¡œ ê¶Œì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” í’€ ì‹œê°„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸° ì¦ê°€, ì•±ê³¼ ëª¨ë¸ì— ëŒ€í•œ ë³„ë„ì˜ ë¦´ë¦¬ìŠ¤ ë¼ì´í”„ì‚¬ì´í´, ì—¬ëŸ¬ ì•± ê°„ì— ëª¨ë¸ì„ ê³µìœ í•  ë•Œ ì ì¬ì ì¸ ìŠ¤í† ë¦¬ì§€ ì¤‘ë³µ ë•Œë¬¸ì…ë‹ˆë‹¤.  í•„ìš”í•œ ì•„í‹°íŒ©íŠ¸ë§Œ ë³µì‚¬í•˜ë©´ ë¹Œë“œ ê²°ê³¼ì˜ ì–´ë–¤ êµ¬ì„± ìš”ì†Œê°€ ìµœì¢… ëŸ°íƒ€ì„ ì´ë¯¸ì§€ì— í¬í•¨ë ì§€ ì„¸ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆì–´ í¬ê¸°ê°€ ì¤„ì–´ë“­ë‹ˆë‹¤(ë³´ì•ˆì´ë‚˜ ì›Œí¬í”Œë¡œìš° ë‹¨ìˆœì„±ê³¼ ê°™ì€ ë‹¤ë¥¸ ì´ì ê³¼ í•¨ê»˜).  ìœ„ì˜ ì˜ˆì—ì„œ ìš°ë¦¬ëŠ” COPY --fromì˜ ë‘ ê°€ì§€ ë‹¤ë¥¸ ë³€í˜•(ëŒ€ë¶€ë¶„ì˜ ì¸ê¸° ìˆëŠ” ì´ë¯¸ì§€ ë¹Œë“œ í”Œë«í¼ì—ì„œ BuildKitì„ í†µí•´ ì§€ì›ë¨)ë„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤:  COPY --from=&lt;ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ ì´ë¯¸ì§€ ê²½ë¡œì™€ ê°€ì ¸ì˜¬ ë¶€ë¶„&gt; ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì €ì¥ëœ ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì • íŒŒì¼ê³¼ í´ë”ë§Œ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤COPY --from=&lt;ë¹Œë“œ ì»¨í…ìŠ¤íŠ¸ ì´ë¦„&gt; --build-context models=/path/to/local/folderë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹Œë“œ ëª…ë ¹ì— ë§¤ê°œë³€ìˆ˜ë¡œ ì œê³µëœ ë¡œì»¬ í´ë”ì—ì„œ íŠ¹ì • íŒŒì¼ê³¼ í´ë”ë§Œ ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤  .dockerignoreë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì¼ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ê´€í–‰ì´ë©° ìœ„ì˜ í”„ë¡œì„¸ìŠ¤ì™€ í•¨ê»˜ ì‚¬ìš©í•´ì•¼ í•˜ì§€ë§Œ COPY --from=... ëª…ë ¹ì—ëŠ” ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  ë˜í•œ ì´ ê¸°ë²•ì€ ë‹¤ìŒì„ ì‚¬ìš©í•˜ì—¬ ë”ìš± ê°œì„ í•  ìˆ˜ ìˆì§€ë§Œ(ë•Œë¡œëŠ” ë¯¸ë¯¸í•˜ê²Œ), ì£¼ì˜ ì‚¬í•­ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë ˆì´ì–´ ìµœì í™” ê¸°ë²• ì ìš©â€‹","type":1,"pageTitle":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size/optimize-image-size#ë ˆì´ì–´-ìµœì í™”-ê¸°ë²•-ì ìš©","content":" ì´ë¯¸ì§€ ë ˆì´ì–´(ì´ì œ ì´ í¬ê¸°ê°€ ë” ì‘ìŒ)ê°€ í’€ í”„ë¡œì„¸ìŠ¤ ì¤‘ì— ë‹¤ìš´ë¡œë“œë˜ë©´ ì»¨í…Œì´ë„ˆì˜ íŒŒì¼ ì‹œìŠ¤í…œì„ ì¡°ë¦½í•˜ê¸° ìœ„í•´ ì••ì¶•ì´ í•´ì œë˜ê³  ì–¸íŒ©ë©ë‹ˆë‹¤. ì´ë¯¸ì§€ ë ˆì´ì–´ì˜ ì–‘ê³¼ í¬ê¸°ëŠ” í•´ë‹¹ í”„ë¡œì„¸ìŠ¤ì˜ ê¸°ê°„ì— ì˜í–¥ì„ ë¯¸ì³ ìµœì í™”ì˜ ë˜ ë‹¤ë¥¸ í›„ë³´ê°€ ë©ë‹ˆë‹¤.  ì¼ë°˜ì ìœ¼ë¡œ ì–¸ê¸‰ë˜ëŠ” ìµœì í™” ì¤‘ í•˜ë‚˜ëŠ” RUN ë˜ëŠ” COPY ëª…ë ¹ì„ ê²°í•©í•˜ì—¬ ë” ì ì€ ìˆ˜ì˜ ë” í° ë ˆì´ì–´ë¥¼ ë§Œë“œëŠ” ê²ƒìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì¼ë°˜ì ì¸ ì˜ˆê°€ ìˆìŠµë‹ˆë‹¤:  FROM ... RUN apt-get update &amp;&amp; \\ apt-get install -y --no-install-recommends \\ build-essential \\ libssl-dev \\ pkg-config &amp;&amp; \\ rm -rf /var/lib/apt/lists/* &amp;&amp; \\ apt-get clean   ë©€í‹° ìŠ¤í…Œì´ì§€ ë¹Œë“œë¥¼ ì ìš©í•˜ë¼ëŠ” ê¶Œì¥ ì‚¬í•­ì˜ ë§¥ë½ì—ì„œ RUNì€ ë§ˆì§€ë§‰ ëŸ°íƒ€ì„ ìŠ¤í…Œì´ì§€ì˜ ì¼ë¶€ê°€ ì•„ë‹Œ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ìƒì ìœ¼ë¡œëŠ” ëª¨ë“  ì‹¤í–‰ì´ ì´ì „ ë¹Œë“œ ìŠ¤í…Œì´ì§€ì—ì„œ ìˆ˜í–‰ë˜ê³  ì²˜ë¦¬ëœ ì•„í‹°íŒ©íŠ¸ë§Œ ëŸ°íƒ€ì„ ìŠ¤í…Œì´ì§€ì˜ ì˜ë„ëœ ìœ„ì¹˜ì— ë³µì‚¬ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  ëŸ°íƒ€ì„ ìŠ¤í…Œì´ì§€ì˜ COPY ëª…ë ¹ì€ ì´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì í™”í•  ìˆ˜ ìˆì§€ë§Œ, í•œ ê°€ì§€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ëŒ€ìƒì´ë‚˜ ì—¬ëŸ¬ ì†ŒìŠ¤ ìŠ¤í…Œì´ì§€ë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì´ëŸ¬í•œ ëª…ë ¹ì„ í•˜ë‚˜ë¡œ ê²°í•©í•˜ëŠ” ê²ƒì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤:  COPY --from=models some-model /app/models/some-model/configs COPY --from=builder1 --chown=app:app /app/.venv ./.venv COPY --from=builder1 --chown=app:app /app/main.py ./main.py COPY --from=builder2 --chown=app:app /app/config.json ./config.json   ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ìµœì¢… í´ë” êµ¬ì¡°ê°€ ìƒì„±ëœ í›„ ë‹¨ì¼ ëª…ë ¹ì„ í†µí•´ ë³µì‚¬ë˜ëŠ” ì¶”ê°€ ë³µì‚¬ ìŠ¤í…Œì´ì§€ë¥¼ ë„ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  FROM python:3.12-bookworm AS builder1 WORKDIR /app ... FROM pytorch/pytorch:2.7.1-cuda11.8-cudnn9-devel AS builder2 WORKDIR /app ... FROM scratch AS assembly ... COPY --from=models some-model/weights /app/models/some-model/weights COPY --from=builder1 /app/.venv /app/venv COPY --from=builder1 /app/main.py /app/main.py COPY --from=builder2 /dist/config.json /app/config.json FROM python:3.12-slim-bookworm COPY --from=assembly --chown=app:app /app /app CMD [&quot;python&quot;, &quot;main.py&quot;]   ìœ„ì˜ ë‹¨ê³„ê°€ ì „ì²´ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œê°„ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ë”ë¼ë„ ì´ ê°€ì´ë“œì˜ ë‹¤ë¥¸ ì†”ë£¨ì…˜ì— ë¹„í•´ ì¢…ì¢… ë¬´ì‹œí•  ìˆ˜ ìˆìœ¼ë©° ê¸°ë²•ì— ì‹œê°„ì„ íˆ¬ìí•˜ê¸° ì „ì— í‰ê°€í•´ì•¼ í•©ë‹ˆë‹¤.  ê°œì„  ì‚¬í•­ì€ ë‹¤ìŒì„ í¬í•¨í•˜ëŠ” íŠ¸ë ˆì´ë“œì˜¤í”„ì— ëŒ€í•´ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•´ì•¼ í•©ë‹ˆë‹¤:  ë ˆì´ì–´ê°€ ì˜¬ë°”ë¥´ê²Œ ì •ë ¬ë˜ì§€ ì•Šì€ ê²½ìš° ë” ì ì€ ìˆ˜ì˜ ë” í° ë ˆì´ì–´ë¡œ ì¸í•œ ë” ë‚®ì€ ì„¸ë¶„ì„±ìœ¼ë¡œ ìºì‹œ íš¨ìœ¨ì„± ê°ì†ŒëŸ°íƒ€ì„ ë ˆì´ì–´ ìµœì í™”ë¥¼ ìœ„í•œ ë” ë§ì€ ì…”í”Œë§ìœ¼ë¡œ ì¸í•œ ë¹Œë“œ ì‹œê°„ ","version":"Next","tagName":"h2"},{"title":"ê´€ì¸¡ì„±","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/observability","content":"","keywords":"","version":"Next"},{"title":"ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"ê´€ì¸¡ì„±","url":"/ai-on-eks/ko/docs/guidance/observability#ì•„í‚¤í…ì²˜","content":"   ","version":"Next","tagName":"h2"},{"title":"í¬í•¨ ë‚´ìš©â€‹","type":1,"pageTitle":"ê´€ì¸¡ì„±","url":"/ai-on-eks/ko/docs/guidance/observability#í¬í•¨-ë‚´ìš©","content":" PrometheusOpenSearchFluentBitKube State MetricsMetrics ServerAlertmanagerGrafanaAI/ML ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ Pod/Service ëª¨ë‹ˆí„°AI/ML ëŒ€ì‹œë³´ë“œ  ","version":"Next","tagName":"h2"},{"title":"í•„ìš”ì„±â€‹","type":1,"pageTitle":"ê´€ì¸¡ì„±","url":"/ai-on-eks/ko/docs/guidance/observability#í•„ìš”ì„±","content":" AI/ML ì›Œí¬ë¡œë“œì˜ ì„±ëŠ¥ì„ ì´í•´í•˜ëŠ” ê²ƒì€ ì–´ë µìŠµë‹ˆë‹¤: GPUê°€ ì¶©ë¶„íˆ ë¹ ë¥´ê²Œ ë°ì´í„°ë¥¼ ë°›ê³  ìˆëŠ”ê°€? CPUê°€ ë³‘ëª©ì¸ê°€? ìŠ¤í† ë¦¬ì§€ê°€ ì¶©ë¶„íˆ ë¹ ë¥¸ê°€? ì´ëŸ¬í•œ ì§ˆë¬¸ë“¤ì€ ê°œë³„ì ìœ¼ë¡œ ë‹µí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì „ì²´ ê·¸ë¦¼ì„ ë” ë§ì´ ë³¼ ìˆ˜ ìˆì„ìˆ˜ë¡ ì„±ëŠ¥ ë³‘ëª©ì„ ì‹ë³„í•˜ëŠ” ë° ë” ëª…í™•í•´ì§‘ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì‚¬ìš© ë°©ë²•â€‹","type":1,"pageTitle":"ê´€ì¸¡ì„±","url":"/ai-on-eks/ko/docs/guidance/observability#ì‚¬ìš©-ë°©ë²•","content":" JARK ì¸í”„ë¼ì—ëŠ” ì´ ì•„í‚¤í…ì²˜ê°€ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¸í”„ë¼ì— ì¶”ê°€í•˜ë ¤ë©´ blueprint.tfvarsì—ì„œ 2ê°œì˜ ë³€ìˆ˜ë¥¼ trueë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:  enable_argocd = true enable_ai_ml_observability_stack = true   ì²« ë²ˆì§¸ ë³€ìˆ˜ëŠ” ê´€ì¸¡ì„± ì•„í‚¤í…ì²˜ë¥¼ ë°°í¬í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ArgoCDë¥¼ ë°°í¬í•˜ê³ , ë‘ ë²ˆì§¸ ë³€ìˆ˜ëŠ” ì•„í‚¤í…ì²˜ë¥¼ ë°°í¬í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì‚¬ìš©ë²•â€‹","type":1,"pageTitle":"ê´€ì¸¡ì„±","url":"/ai-on-eks/ko/docs/guidance/observability#ì‚¬ìš©ë²•","content":" ì•„í‚¤í…ì²˜ëŠ” ì „ì ìœ¼ë¡œ monitoring ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ë°°í¬ë©ë‹ˆë‹¤. Grafanaì— ì ‘ê·¼í•˜ë ¤ë©´: kubectl port-forward -n monitoring svc/kube-prometheus-stack-grafana 3000:80. ê·¸ëŸ° ë‹¤ìŒ https://localhost:3000 ì„ ì—´ì–´ ì‚¬ìš©ì ì´ë¦„ adminê³¼ ë¹„ë°€ë²ˆí˜¸ prom-operatorë¡œ grafanaì— ë¡œê·¸ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ì ì´ë¦„/ë¹„ë°€ë²ˆí˜¸ë¥¼ ë³€ê²½í•˜ëŠ” ë°©ë²•ì€ Readmeì˜ ë³´ì•ˆ ì„¹ì…˜ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h2"},{"title":"í›ˆë ¨â€‹","type":1,"pageTitle":"ê´€ì¸¡ì„±","url":"/ai-on-eks/ko/docs/guidance/observability#í›ˆë ¨","content":" Ray í›ˆë ¨ ì‘ì—… ë¡œê·¸ì™€ ë©”íŠ¸ë¦­ì€ ê´€ì¸¡ì„± ì•„í‚¤í…ì²˜ì— ì˜í•´ ìë™ìœ¼ë¡œ ìˆ˜ì§‘ë˜ë©° í›ˆë ¨ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì˜ˆì œâ€‹  ì´ì— ëŒ€í•œ ì „ì²´ ì˜ˆì œëŠ” AI/ML ê´€ì¸¡ì„± ì €ì¥ì†Œì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì—¬ê¸°ì˜ ë¸”ë£¨í”„ë¦°íŠ¸ë„ ì´ ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•˜ë„ë¡ ì—…ë°ì´íŠ¸í•  ì˜ˆì •ì…ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì¶”ë¡ â€‹","type":1,"pageTitle":"ê´€ì¸¡ì„±","url":"/ai-on-eks/ko/docs/guidance/observability#ì¶”ë¡ ","content":" Ray ì¶”ë¡  ë©”íŠ¸ë¦­ì€ ê´€ì¸¡ì„± ì¸í”„ë¼ì— ì˜í•´ ìë™ìœ¼ë¡œ ìˆ˜ì§‘ë˜ì–´ì•¼ í•˜ë©° ì¶”ë¡  ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ë¡œê¹…ì„ ìœ„í•´ ê³„ì¸¡í•˜ë ¤ë©´ ëª‡ ê°€ì§€ í•­ëª©ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤:  FluentBit êµ¬ì„±â€‹  apiVersion: v1 kind: ConfigMap metadata: name: fluentbit-config namespace: default data: fluent-bit.conf: |- [INPUT] Name tail Path /tmp/ray/session_latest/logs/* Tag ray Path_Key true Refresh_Interval 5 [FILTER] Name modify Match ray Add POD_LABELS ${POD_LABELS} [OUTPUT] Name stdout Format json   ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ì´ê²ƒì„ ë°°í¬í•©ë‹ˆë‹¤. FluentBit ì‚¬ì´ë“œì¹´ì— ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ê¸° ìœ„í•´ ê° ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— í•˜ë‚˜ë§Œ í•„ìš”í•©ë‹ˆë‹¤.  FluentBit ì‚¬ì´ë“œì¹´â€‹  FluentBitê°€ ë¡œê·¸ë¥¼ STDOUTì— ì“¸ ìˆ˜ ìˆë„ë¡ Ray ì¶”ë¡  ì„œë¹„ìŠ¤ì— ì‚¬ì´ë“œì¹´ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.   - name: fluentbit image: fluent/fluent-bit:3.2.2 env: - name: POD_LABELS valueFrom: fieldRef: fieldPath: metadata.labels['ray.io/cluster'] resources: requests: cpu: 100m memory: 128Mi limits: cpu: 100m memory: 128Mi volumeMounts: - mountPath: /tmp/ray name: ray-logs - mountPath: /fluent-bit/etc/fluent-bit.conf subPath: fluent-bit.conf name: fluentbit-config   ì´ ì„¹ì…˜ì„ workerGroupSpecs ì»¨í…Œì´ë„ˆì— ì¶”ê°€í•©ë‹ˆë‹¤.  FluentBit ë³¼ë¥¨â€‹  ë§ˆì§€ë§‰ìœ¼ë¡œ configmap ë³¼ë¥¨ì„ volumes ì„¹ì…˜ì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤:   - name: fluentbit-config configMap: name: fluentbit-config   vLLM ë©”íŠ¸ë¦­â€‹  vLLMì€ ë˜í•œ Time to First Token, ì²˜ë¦¬ëŸ‰, ì§€ì—° ì‹œê°„, ìºì‹œ í™œìš©ë„ ë“±ê³¼ ê°™ì€ ìœ ìš©í•œ ë©”íŠ¸ë¦­ì„ ì¶œë ¥í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì— ì ‘ê·¼í•˜ë ¤ë©´ ë©”íŠ¸ë¦­ ê²½ë¡œë¥¼ ìœ„í•œ ë¼ìš°íŠ¸ë¥¼ Podì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤:  # Imports import re from prometheus_client import make_asgi_app from fastapi import FastAPI from starlette.routing import Mount app = FastAPI() class Deployment: def __init__(self, **kwargs): ... route = Mount(&quot;/metrics&quot;, make_asgi_app()) # Workaround for 307 Redirect for /metrics route.path_regex = re.compile('^/metrics(?P&lt;path&gt;.*)$') app.routes.append(route)   ì´ë ‡ê²Œ í•˜ë©´ ë°°í¬ëœ ëª¨ë‹ˆí„°ê°€ vLLM ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ê³  ì¶”ë¡  ëŒ€ì‹œë³´ë“œì— í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì˜ˆì œâ€‹  ì´ì— ëŒ€í•œ ì „ì²´ ì˜ˆì œëŠ” AI/ML ê´€ì¸¡ì„± ì €ì¥ì†Œì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì—¬ê¸°ì˜ ë¸”ë£¨í”„ë¦°íŠ¸ë„ ì´ ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•˜ë„ë¡ ì—…ë°ì´íŠ¸í•  ì˜ˆì •ì…ë‹ˆë‹¤. ","version":"Next","tagName":"h3"},{"title":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/networking","content":"","keywords":"","version":"Next"},{"title":"VPC ë° IP ê³ ë ¤ ì‚¬í•­â€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#vpc-ë°-ip-ê³ ë ¤-ì‚¬í•­","content":" ","version":"Next","tagName":"h2"},{"title":"EKS í´ëŸ¬ìŠ¤í„°ì—ì„œ ëŒ€ëŸ‰ì˜ IP ì£¼ì†Œ ì‚¬ìš©ì„ ê³„íší•˜ì‹­ì‹œì˜¤.â€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#eks-í´ëŸ¬ìŠ¤í„°ì—ì„œ-ëŒ€ëŸ‰ì˜-ip-ì£¼ì†Œ-ì‚¬ìš©ì„-ê³„íší•˜ì‹­ì‹œì˜¤","content":" AWS VPC CNIëŠ” Podì— í• ë‹¹í•  IP ì£¼ì†Œì˜ &quot;ì›œ í’€&quot;ì„ EKS ì›Œì»¤ ë…¸ë“œì— ìœ ì§€í•©ë‹ˆë‹¤. Podì— ë” ë§ì€ IP ì£¼ì†Œê°€ í•„ìš”í•  ë•Œ CNIëŠ” EC2 APIì™€ í†µì‹ í•˜ì—¬ ë…¸ë“œì— ì£¼ì†Œë¥¼ í• ë‹¹í•´ì•¼ í•©ë‹ˆë‹¤. ë†’ì€ ë³€ë™ì„± ë˜ëŠ” ëŒ€ê·œëª¨ ìŠ¤ì¼€ì¼ ì•„ì›ƒ ê¸°ê°„ ë™ì•ˆ ì´ëŸ¬í•œ EC2 API í˜¸ì¶œì´ ì†ë„ ì œí•œì„ ë°›ì•„ Pod í”„ë¡œë¹„ì €ë‹ì´ ì§€ì—°ë˜ê³  ê²°ê³¼ì ìœ¼ë¡œ ì›Œí¬ë¡œë“œ ì‹¤í–‰ì´ ì§€ì—°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í™˜ê²½ì„ ìœ„í•œ VPCë¥¼ ì„¤ê³„í•  ë•Œ ì´ ì›œ í’€ì„ ìˆ˜ìš©í•˜ê¸° ìœ„í•´ Podë§Œì„ ìœ„í•œ ê²ƒë³´ë‹¤ ë” ë§ì€ IP ì£¼ì†Œë¥¼ ê³„íší•˜ì‹­ì‹œì˜¤.  ê¸°ë³¸ VPC CNI êµ¬ì„±ì—ì„œëŠ” ë” í° ë…¸ë“œê°€ ë” ë§ì€ IP ì£¼ì†Œë¥¼ ì†Œë¹„í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 10ê°œì˜ Podë¥¼ ì‹¤í–‰í•˜ëŠ” m5.8xlarge ë…¸ë“œëŠ” ì´ 60ê°œì˜ IPë¥¼ ë³´ìœ í•©ë‹ˆë‹¤(WARM_ENI=1ì„ ì¶©ì¡±í•˜ê¸° ìœ„í•´). m5.16xlarge ë…¸ë“œëŠ” 100ê°œì˜ IPë¥¼ ë³´ìœ í•©ë‹ˆë‹¤. VPC CNIë¥¼ êµ¬ì„±í•˜ì—¬ ì´ ì›œ í’€ì„ ìµœì†Œí™”í•˜ë©´ ë…¸ë“œì—ì„œì˜ EC2 API í˜¸ì¶œì´ ì¦ê°€í•˜ê³  ì†ë„ ì œí•œ ìœ„í—˜ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì¶”ê°€ IP ì£¼ì†Œ ì‚¬ìš©ì„ ê³„íší•˜ë©´ ì†ë„ ì œí•œ ë¬¸ì œì™€ IP ì£¼ì†Œ ì‚¬ìš© ê´€ë¦¬ë¥¼ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"IP ê³µê°„ì´ ì œí•œëœ ê²½ìš° ë³´ì¡° CIDR ì‚¬ìš©ì„ ê³ ë ¤í•˜ì‹­ì‹œì˜¤.â€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#ip-ê³µê°„ì´-ì œí•œëœ-ê²½ìš°-ë³´ì¡°-cidr-ì‚¬ìš©ì„-ê³ ë ¤í•˜ì‹­ì‹œì˜¤","content":" ì—¬ëŸ¬ ì—°ê²°ëœ VPC ë˜ëŠ” ì‚¬ì´íŠ¸ì— ê±¸ì¹œ ë„¤íŠ¸ì›Œí¬ë¡œ ì‘ì—…í•˜ëŠ” ê²½ìš° ë¼ìš°íŒ… ê°€ëŠ¥í•œ ì£¼ì†Œ ê³µê°„ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ VPCê°€ ì•„ë˜ì™€ ê°™ì´ ì‘ì€ ì„œë¸Œë„·ìœ¼ë¡œ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ VPCì—ì„œëŠ” CNI êµ¬ì„±ì„ ì¡°ì •í•˜ì§€ ì•Šê³ ëŠ” m5.16xlarge ë…¸ë“œë¥¼ í•˜ë‚˜ ì´ìƒ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.    VPC ê°„ì— ë¼ìš°íŒ…í•  ìˆ˜ ì—†ëŠ” ë²”ìœ„(ì˜ˆ: RFC 6598 ë²”ìœ„, 100.64.0.0/10)ì—ì„œ ì¶”ê°€ VPC CIDRì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° 100.64.0.0/16, 100.65.0.0/16, 100.66.0.0/16ì„ VPCì— ì¶”ê°€í•œ ë‹¤ìŒ(ìµœëŒ€ CIDR í¬ê¸°ì´ë¯€ë¡œ) í•´ë‹¹ CIDRë¡œ ìƒˆ ì„œë¸Œë„·ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ EKS í´ëŸ¬ìŠ¤í„° ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì€ ê·¸ëŒ€ë¡œ ë‘ê³  ë…¸ë“œ ê·¸ë£¹ì„ ìƒˆ ì„œë¸Œë„·ì— ë‹¤ì‹œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.    ì´ êµ¬ì„±ì„ ì‚¬ìš©í•˜ë©´ ì—°ê²°ëœ VPCì—ì„œ EKS í´ëŸ¬ìŠ¤í„° ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ê³¼ ê³„ì† í†µì‹ í•  ìˆ˜ ìˆì§€ë§Œ ë…¸ë“œì™€ PodëŠ” ì›Œí¬ë¡œë“œì™€ ì›œ í’€ì„ ìˆ˜ìš©í•  ì¶©ë¶„í•œ IP ì£¼ì†Œë¥¼ ê°–ê²Œ ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"VPC CNI íŠœë‹â€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#vpc-cni-íŠœë‹","content":" ","version":"Next","tagName":"h2"},{"title":"VPC CNI ë° EC2 ì†ë„ ì œí•œâ€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#vpc-cni-ë°-ec2-ì†ë„-ì œí•œ","content":" EKS ì›Œì»¤ ë…¸ë“œê°€ ì‹œì‘ë˜ë©´ ì²˜ìŒì—ëŠ” EC2 ì¸ìŠ¤í„´ìŠ¤ í†µì‹ ì„ ìœ„í•œ ë‹¨ì¼ IP ì£¼ì†Œê°€ ìˆëŠ” ë‹¨ì¼ ENIê°€ ì—°ê²°ë©ë‹ˆë‹¤. VPC CNIê°€ ì‹œì‘ë˜ë©´ Kubernetes Podì— í• ë‹¹í•  ìˆ˜ ìˆëŠ” IP ì£¼ì†Œì˜ ì›œ í’€ì„ í”„ë¡œë¹„ì €ë‹í•˜ë ¤ê³  í•©ë‹ˆë‹¤(EKS ëª¨ë²” ì‚¬ë¡€ ê°€ì´ë“œì—ì„œ ìì„¸í•œ ë‚´ìš© í™•ì¸).  VPC CNIëŠ” ì›Œì»¤ ë…¸ë“œì— ì¶”ê°€ IPì™€ ENIë¥¼ í• ë‹¹í•˜ê¸° ìœ„í•´ AWS EC2 API í˜¸ì¶œ(ì˜ˆ: AssignPrivateIpV4Address ë° DescribeNetworkInterfaces)ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤. EKS í´ëŸ¬ìŠ¤í„°ê°€ ë…¸ë“œ ë˜ëŠ” Pod ìˆ˜ë¥¼ ìŠ¤ì¼€ì¼ ì•„ì›ƒí•  ë•Œ ì´ëŸ¬í•œ EC2 API í˜¸ì¶œì´ ê¸‰ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í˜¸ì¶œ ê¸‰ì¦ì€ ì„œë¹„ìŠ¤ ì„±ëŠ¥ì„ ë•ê³  ëª¨ë“  Amazon EC2 ê³ ê°ì—ê²Œ ê³µì •í•œ ì‚¬ìš©ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ EC2 APIì—ì„œ ì†ë„ ì œí•œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì†ë„ ì œí•œìœ¼ë¡œ ì¸í•´ CNIê°€ ë” ë§ì€ IPë¥¼ í• ë‹¹í•˜ë ¤ê³  ì‹œë„í•˜ëŠ” ë™ì•ˆ IP ì£¼ì†Œ í’€ì´ ê³ ê°ˆë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ëŸ¬í•œ ì‹¤íŒ¨ëŠ” ì•„ë˜ì™€ ê°™ì€ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚¤ë©°, VPC CNIê°€ IP ì£¼ì†Œë¥¼ í”„ë¡œë¹„ì €ë‹í•  ìˆ˜ ì—†ì–´ ì»¨í…Œì´ë„ˆ ë„¤íŠ¸ì›Œí¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í”„ë¡œë¹„ì €ë‹ì´ ì‹¤íŒ¨í–ˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  Failed to create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container &quot;xxxxxxxxxxxxxxxxxxxxxx&quot; network for pod &quot;test-pod&quot;: networkPlugin cni failed to set up pod test-pod_default&quot; network: add cmd: failed to assign an IP address to container   ì´ ì‹¤íŒ¨ëŠ” Pod ì‹œì‘ì„ ì§€ì—°ì‹œí‚¤ê³  IP ì£¼ì†Œê°€ í• ë‹¹ë  ë•Œê¹Œì§€ ì´ ì‘ì—…ì´ ì¬ì‹œë„ë˜ë©´ì„œ kubeletê³¼ ì›Œì»¤ ë…¸ë“œì— ì••ë ¥ì„ ê°€í•©ë‹ˆë‹¤. ì´ ì§€ì—°ì„ í”¼í•˜ê¸° ìœ„í•´ í•„ìš”í•œ EC2 API í˜¸ì¶œ ìˆ˜ë¥¼ ì¤„ì´ë„ë¡ CNIë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„° ë˜ëŠ” ë³€ë™ì´ ë§ì€ í´ëŸ¬ìŠ¤í„°ì—ì„œ WARM_IP_TARGET ì‚¬ìš©ì„ í”¼í•˜ì‹­ì‹œì˜¤â€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#ëŒ€ê·œëª¨-í´ëŸ¬ìŠ¤í„°-ë˜ëŠ”-ë³€ë™ì´-ë§ì€-í´ëŸ¬ìŠ¤í„°ì—ì„œ-warm_ip_target-ì‚¬ìš©ì„-í”¼í•˜ì‹­ì‹œì˜¤","content":" WARM_IP_TARGETì€ ì‘ì€ í´ëŸ¬ìŠ¤í„° ë˜ëŠ” Pod ë³€ë™ì´ ë§¤ìš° ë‚®ì€ í´ëŸ¬ìŠ¤í„°ì—ì„œ &quot;ë‚­ë¹„ë˜ëŠ”&quot; IPë¥¼ ì œí•œí•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ VPC CNIì˜ ì´ í™˜ê²½ ë³€ìˆ˜ëŠ” ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„°ì—ì„œ EC2 API í˜¸ì¶œ ìˆ˜ë¥¼ ì¦ê°€ì‹œì¼œ ì†ë„ ì œí•œì˜ ìœ„í—˜ê³¼ ì˜í–¥ì„ ë†’ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.  Pod ë³€ë™ì´ ë§ì€ í´ëŸ¬ìŠ¤í„°ì˜ ê²½ìš° ê° ë…¸ë“œì—ì„œ ì‹¤í–‰í•  ì˜ˆìƒ Pod ìˆ˜ë³´ë‹¤ ì•½ê°„ ë†’ì€ ê°’ìœ¼ë¡œ MINIMUM_IP_TARGETì„ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ CNIê°€ ë‹¨ì¼(ë˜ëŠ” ì†Œìˆ˜ì˜) í˜¸ì¶œë¡œ ëª¨ë“  IP ì£¼ì†Œë¥¼ í”„ë¡œë¹„ì €ë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.   [... ] # EKS Addons cluster_addons = { vpc-cni = { configuration_values = jsonencode({ env = { MINIMUM_IP_TARGET = &quot;30&quot; } }) } } [...]   ","version":"Next","tagName":"h3"},{"title":"ëŒ€í˜• ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì—ì„œ MAX_ENI ë° max-podsë¡œ ë…¸ë“œë‹¹ IP ìˆ˜ë¥¼ ì œí•œí•˜ì‹­ì‹œì˜¤â€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#ëŒ€í˜•-ì¸ìŠ¤í„´ìŠ¤-ìœ í˜•ì—ì„œ-max_eni-ë°-max-podsë¡œ-ë…¸ë“œë‹¹-ip-ìˆ˜ë¥¼-ì œí•œí•˜ì‹­ì‹œì˜¤","content":" 16xlarge ë˜ëŠ” 24xlargeì™€ ê°™ì€ ëŒ€í˜• ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì„ ì‚¬ìš©í•  ë•Œ ENIë‹¹ í• ë‹¹í•  ìˆ˜ ìˆëŠ” IP ì£¼ì†Œ ìˆ˜ê°€ ìƒë‹¹íˆ í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸°ë³¸ CNI êµ¬ì„± WARM_ENI=1ì„ ì‚¬ìš©í•˜ëŠ” c5.18xlarge ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì€ ì†Œìˆ˜ì˜ Podë¥¼ ì‹¤í–‰í•  ë•Œ 100ê°œì˜ IP ì£¼ì†Œ(ENIë‹¹ 50ê°œ IP * 2ê°œ ENI)ë¥¼ ë³´ìœ í•˜ê²Œ ë©ë‹ˆë‹¤.  ì¼ë¶€ ì›Œí¬ë¡œë“œì˜ ê²½ìš° CPU, ë©”ëª¨ë¦¬ ë˜ëŠ” ê¸°íƒ€ ë¦¬ì†ŒìŠ¤ê°€ 50ê°œ ì´ìƒì˜ IPê°€ í•„ìš”í•˜ê¸° ì „ì— í•´ë‹¹ c5.18xlargeì˜ Pod ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤. ì´ ê²½ìš° í•´ë‹¹ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ìµœëŒ€ 30-40ê°œì˜ Podë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆê¸°ë¥¼ ì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.   [... ] # EKS Addons cluster_addons = { vpc-cni = { configuration_values = jsonencode({ env = { MAX_ENI = &quot;1&quot; } }) } } [...]   CNIì— MAX_ENI=1 ì˜µì…˜ì„ ì„¤ì •í•˜ë©´ ê° ë…¸ë“œê°€ í”„ë¡œë¹„ì €ë‹í•  ìˆ˜ ìˆëŠ” IP ì£¼ì†Œ ìˆ˜ê°€ ì œí•œë˜ì§€ë§Œ kubernetesê°€ ë…¸ë“œì— ìŠ¤ì¼€ì¤„ë§í•˜ë ¤ëŠ” Pod ìˆ˜ëŠ” ì œí•œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë” ë§ì€ IP ì£¼ì†Œë¥¼ í”„ë¡œë¹„ì €ë‹í•  ìˆ˜ ì—†ëŠ” ë…¸ë“œì— Podê°€ ìŠ¤ì¼€ì¤„ë§ë˜ëŠ” ìƒí™©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  IPë¥¼ ì œí•œí•˜ê³  k8sê°€ ë„ˆë¬´ ë§ì€ Podë¥¼ ìŠ¤ì¼€ì¤„ë§í•˜ì§€ ì•Šë„ë¡ í•˜ë ¤ë©´ ë‹¤ìŒì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤:  CNI êµ¬ì„± í™˜ê²½ ë³€ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ MAX_ENI=1 ì„¤ì •ì›Œì»¤ ë…¸ë“œì˜ kubeletì—ì„œ --max-pods ì˜µì…˜ ì—…ë°ì´íŠ¸  --max-pods ì˜µì…˜ì„ êµ¬ì„±í•˜ë ¤ë©´ ì›Œì»¤ ë…¸ë“œì˜ userdataë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ bootstrap.sh ìŠ¤í¬ë¦½íŠ¸ì˜ --kubelet-extra-argsë¥¼ í†µí•´ ì´ ì˜µì…˜ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” kubeletì˜ max-pods ê°’ì„ êµ¬ì„±í•˜ë©°, --use-max-pods false ì˜µì…˜ì€ ìì²´ ê°’ì„ ì œê³µí•  ë•Œ ì´ ë™ì‘ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤:   eks_managed_node_groups = { system = { instance_types = [&quot;m5.xlarge&quot;] min_size = 0 max_size = 5 desired_size = 3 pre_bootstrap_user_data = &lt;&lt;-EOT EOT bootstrap_extra_args = &quot;--use-max-pods false --kubelet-extra-args '--max-pods=&lt;your_value&gt;'&quot; }   í•œ ê°€ì§€ ë¬¸ì œëŠ” ENIë‹¹ IP ìˆ˜ê°€ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤(ì˜ˆë¥¼ ë“¤ì–´ m5d.2xlargeëŠ” ENIë‹¹ 15ê°œ IPë¥¼ ê°€ì§ˆ ìˆ˜ ìˆê³  m5d.4xlargeëŠ” ENIë‹¹ 30ê°œ IPë¥¼ ë³´ìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤). ì´ëŠ” max-podsì— ëŒ€í•œ ê°’ì„ í•˜ë“œì½”ë”©í•˜ë©´ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì„ ë³€ê²½í•˜ê±°ë‚˜ í˜¼í•© ì¸ìŠ¤í„´ìŠ¤ í™˜ê²½ì—ì„œ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  EKS ìµœì í™” AMI ë¦´ë¦¬ìŠ¤ì—ëŠ” AWS ê¶Œì¥ max-pods ê°’ì„ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìŠ¤í¬ë¦½íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í˜¼í•© ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•´ ì´ ê³„ì‚°ì„ ìë™í™”í•˜ë ¤ë©´ ì¸ìŠ¤í„´ìŠ¤ ë©”íƒ€ë°ì´í„°ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì„ ìë™ ê²€ìƒ‰í•˜ê¸° ìœ„í•´ --instance-type-from-imds í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì¸ìŠ¤í„´ìŠ¤ì˜ userdataë„ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.   eks_managed_node_groups = { system = { instance_types = [&quot;m5.xlarge&quot;] min_size = 0 max_size = 5 desired_size = 3 pre_bootstrap_user_data = &lt;&lt;-EOT /etc/eks/max-pod-calc.sh --instance-type-from-imds â€”cni-version 1.13.4 â€”cni-max-eni 1 EOT bootstrap_extra_args = &quot;--use-max-pods false --kubelet-extra-args '--max-pods=&lt;your_value&gt;'&quot; }   Karpenterë¥¼ ì‚¬ìš©í•œ Maxpodsâ€‹  ê¸°ë³¸ì ìœ¼ë¡œ Karpenterê°€ í”„ë¡œë¹„ì €ë‹í•œ ë…¸ë“œëŠ” ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì— ë”°ë¼ ë…¸ë“œì˜ ìµœëŒ€ Pod ìˆ˜ë¥¼ ê°–ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ì–¸ê¸‰í•œ --max-pods ì˜µì…˜ì„ êµ¬ì„±í•˜ë ¤ë©´ Provisioner ìˆ˜ì¤€ì—ì„œ .spec.kubeletConfiguration ë‚´ì— maxPodsë¥¼ ì§€ì •í•˜ì—¬ ì •ì˜í•©ë‹ˆë‹¤. ì´ ê°’ì€ Karpenter Pod ìŠ¤ì¼€ì¤„ë§ ì¤‘ì— ì‚¬ìš©ë˜ê³  kubelet ì‹œì‘ ì‹œ --max-podsë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.  ì•„ë˜ëŠ” ì˜ˆì œ Provisioner ì‚¬ì–‘ì…ë‹ˆë‹¤:  apiVersion: karpenter.sh/v1alpha5 kind: Provisioner metadata: name: default spec: providerRef: name: default requirements: - key: &quot;karpenter.k8s.aws/instance-category&quot; operator: In values: [ &quot;c&quot;, &quot;m&quot;, &quot;r&quot; ] - key: &quot;karpenter.sh/capacity-type&quot; # If not included, the webhook for the AWS cloud provider will default to on-demand operator: In values: [ &quot;spot&quot;, &quot;on-demand&quot; ] # Karpenter provides the ability to specify a few additional Kubelet args. # These are all optional and provide support for additional customization and use cases. kubeletConfiguration: maxPods: 30   ","version":"Next","tagName":"h3"},{"title":"ì• í”Œë¦¬ì¼€ì´ì…˜â€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#ì• í”Œë¦¬ì¼€ì´ì…˜","content":" ","version":"Next","tagName":"h2"},{"title":"DNS ì¡°íšŒ ë° ndotsâ€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#dns-ì¡°íšŒ-ë°-ndots","content":" ê¸°ë³¸ DNS êµ¬ì„±ì„ ì‚¬ìš©í•˜ëŠ” Kubernetes Podì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ resolv.conf íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤:  nameserver 10.100.0.10 search namespace.svc.cluster.local svc.cluster.local cluster.local ec2.internal options ndots:5   search ì¤„ì— ë‚˜ì—´ëœ ë„ë©”ì¸ ì´ë¦„ì€ ì™„ì „í•œ ë„ë©”ì¸ ì´ë¦„(FQDN)ì´ ì•„ë‹Œ DNS ì´ë¦„ì— ì¶”ê°€ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Podê°€ servicename.namespaceë¥¼ ì‚¬ìš©í•˜ì—¬ Kubernetes ì„œë¹„ìŠ¤ì— ì—°ê²°í•˜ë ¤ê³  í•˜ë©´ DNS ì´ë¦„ì´ ì „ì²´ kubernetes ì„œë¹„ìŠ¤ ì´ë¦„ê³¼ ì¼ì¹˜í•  ë•Œê¹Œì§€ ë„ë©”ì¸ì´ ìˆœì„œëŒ€ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤:  servicename.namespace.namespace.svc.cluster.local &lt;--- Fails with NXDOMAIN servicename.namespace.svc.cluster.local &lt;-- Succeed   ë„ë©”ì¸ì´ ì™„ì „í•œì§€ ì—¬ë¶€ëŠ” resolv.confì˜ ndots ì˜µì…˜ì— ì˜í•´ ê²°ì •ë©ë‹ˆë‹¤. ì´ ì˜µì…˜ì€ search ë„ë©”ì¸ì„ ê±´ë„ˆë›°ê¸° ì „ì— ë„ë©”ì¸ ì´ë¦„ì— ìˆì–´ì•¼ í•˜ëŠ” ì ì˜ ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¶”ê°€ ê²€ìƒ‰ì€ S3 ë° RDS ì—”ë“œí¬ì¸íŠ¸ì™€ ê°™ì€ ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì—°ê²°ì— ì§€ì—°ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Kubernetesì˜ ê¸°ë³¸ ndots ì„¤ì •ì€ 5ì…ë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ì´ í´ëŸ¬ìŠ¤í„°ì˜ ë‹¤ë¥¸ Podì™€ í†µì‹ í•˜ì§€ ì•ŠëŠ” ê²½ìš° ndotsë¥¼ &quot;2&quot;ì™€ ê°™ì€ ë‚®ì€ ê°’ìœ¼ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì¢‹ì€ ì‹œì‘ì ì…ë‹ˆë‹¤. ì™œëƒí•˜ë©´ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë™ì¼í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë‚´ì—ì„œ ê·¸ë¦¬ê³  í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ë‹¤ë¥¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ ì„œë¹„ìŠ¤ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ë©´ì„œë„ s3.us-east-2.amazonaws.comê³¼ ê°™ì€ ë„ë©”ì¸ì„ FQDNìœ¼ë¡œ ì¸ì‹(search ë„ë©”ì¸ ê±´ë„ˆë›°ê¸°)í•  ìˆ˜ ìˆê²Œ í•´ì£¼ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  ë‹¤ìŒì€ Kubernetes ë¬¸ì„œì—ì„œ ndotsê°€ &quot;2&quot;ë¡œ ì„¤ì •ëœ ì˜ˆì œ Pod ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì…ë‹ˆë‹¤:  apiVersion: v1 kind: Pod metadata: namespace: default name: dns-example spec: containers: - name: test image: nginx dnsConfig: options: - name: ndots value: &quot;2&quot;   ì •ë³´ Pod ë°°í¬ì—ì„œ ndotsë¥¼ &quot;2&quot;ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì€ í•©ë¦¬ì ì¸ ì‹œì‘ì ì´ì§€ë§Œ ëª¨ë“  ìƒí™©ì—ì„œ ë³´í¸ì ìœ¼ë¡œ ì‘ë™í•˜ì§€ëŠ” ì•Šìœ¼ë©° ì „ì²´ í´ëŸ¬ìŠ¤í„°ì— ì ìš©í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ndots êµ¬ì„±ì€ Pod ë˜ëŠ” Deployment ìˆ˜ì¤€ì—ì„œ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° ìˆ˜ì¤€ CoreDNS êµ¬ì„±ì—ì„œ ì´ ì„¤ì •ì„ ì¤„ì´ëŠ” ê²ƒì€ ê¶Œì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"AZ ê°„ ë„¤íŠ¸ì›Œí¬ ìµœì í™”â€‹","type":1,"pageTitle":"AIë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí‚¹","url":"/ai-on-eks/ko/docs/guidance/networking#az-ê°„-ë„¤íŠ¸ì›Œí¬-ìµœì í™”","content":" ì¼ë¶€ ì›Œí¬ë¡œë“œëŠ” ë‹¤ì¤‘ ë…¸ë“œ ì¶”ë¡ , ë‹¤ì¤‘ ë…¸ë“œ í›ˆë ¨ ë˜ëŠ” ë‹¤ì¤‘ ë³µì œë³¸ ì¶”ë¡ ê³¼ ê°™ì´ í´ëŸ¬ìŠ¤í„°ì˜ Pod ê°„ì— ë°ì´í„°ë¥¼ êµí™˜í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Podê°€ ì—¬ëŸ¬ ê°€ìš© ì˜ì—­(AZ)ì— ë¶„ì‚°ë˜ì–´ ìˆìœ¼ë©´ AZ ê°„ ì´ê·¸ë ˆìŠ¤ë¡œ ì¸í•´ ì¶”ê°€ ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì›Œí¬ë¡œë“œì˜ ê²½ìš° Podë¥¼ ë™ì¼í•œ AZì— ë°°ì¹˜í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. Podë¥¼ ë™ì¼í•œ AZì— ê°™ì€ ìœ„ì¹˜ì— ë°°ì¹˜í•˜ë©´ ë‘ ê°€ì§€ ì£¼ìš” ëª©ì ì„ ë‹¬ì„±í•©ë‹ˆë‹¤:  AZ ê°„ íŠ¸ë˜í”½ ë¹„ìš© ì ˆê°ì‹¤í–‰ê¸°/Pod ê°„ ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œê°„ ê°ì†Œ  Podë¥¼ ë™ì¼í•œ AZì— ë°°ì¹˜í•˜ê¸° ìœ„í•´ podAffinity ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§ ì œì•½ ì¡°ê±´ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìŠ¤ì¼€ì¤„ë§ ì œì•½ ì¡°ê±´ preferredDuringSchedulingIgnoredDuringExecutionì€ Pod ì‚¬ì–‘ì—ì„œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Sparkì—ì„œëŠ” ë“œë¼ì´ë²„ ë° ì‹¤í–‰ê¸° Podì— ëŒ€í•œ ì‚¬ìš©ì ì •ì˜ í…œí”Œë¦¿ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  spec: executor: affinity: podAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: topologyKey: topology.kubernetes.io/zone labelSelector: matchLabels: &quot;ray.io/cluster&quot;: &quot;ray-cluster-name&quot; ...   Podê°€ ìƒì„±ëœ í›„ Kubernetes Topology Aware Routingì„ í™œìš©í•˜ì—¬ Kubernetes ì„œë¹„ìŠ¤ê°€ ë” íš¨ìœ¨ì ì¸ ë°©ì‹ìœ¼ë¡œ íŠ¸ë˜í”½ì„ ë¼ìš°íŒ…í•˜ë„ë¡ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤: https://aws.amazon.com/blogs/containers/exploring-the-effect-of-topology-aware-hints-on-network-traffic-in-amazon-elastic-kubernetes-service/  ì •ë³´ ëª¨ë“  ì‹¤í–‰ê¸°ë¥¼ ë‹¨ì¼ AZì— ë°°ì¹˜í•˜ë©´ í•´ë‹¹ AZê°€ ë‹¨ì¼ ì¥ì•  ì§€ì ì´ ë©ë‹ˆë‹¤. ì´ëŠ” ë„¤íŠ¸ì›Œí¬ ë¹„ìš©ê³¼ ì§€ì—° ì‹œê°„ì„ ë‚®ì¶”ëŠ” ê²ƒê³¼ AZ ì¥ì• ë¡œ ì¸í•œ ì›Œí¬ë¡œë“œ ì¤‘ë‹¨ ì´ë²¤íŠ¸ ì‚¬ì´ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ì›Œí¬ë¡œë“œê°€ ì œí•œëœ ìš©ëŸ‰ì˜ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ëŠ” ê²½ìš° ìš©ëŸ‰ ë¶€ì¡± ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ AZë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì •ë³´ inference-chartsë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ì²˜ë¦¬ëŸ‰ì„ ë†’ì´ê³  ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•´ í† í´ë¡œì§€ ì¸ì‹ì´ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë©ë‹ˆë‹¤. inference.modelServer.deployment.topologySpreadConstraints.enabled: false ë° inference.modelServer.deployment.podAffinity.enabled: falseë¥¼ ì„¤ì •í•˜ì—¬ ë¹„í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ","version":"Next","tagName":"h3"},{"title":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë¶„ë¦¬","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size/decoupling-model-artifacts","content":"","keywords":"","version":"Next"},{"title":"init ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ Amazon S3ì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œâ€‹","type":1,"pageTitle":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë¶„ë¦¬","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size/decoupling-model-artifacts#init-ì»¨í…Œì´ë„ˆë¥¼-ì‚¬ìš©í•˜ì—¬-amazon-s3ì—ì„œ-ëª¨ë¸-ì•„í‹°íŒ©íŠ¸-ë‹¤ìš´ë¡œë“œ","content":" ì´ ì†”ë£¨ì…˜ì€ ëª¨ë¸ íŒŒì¼ì´ë‚˜ ê´€ë ¨ ì•„í‹°íŒ©íŠ¸ë¥¼ ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ë¡œ ì¶”ì¶œí•˜ëŠ” ê°„ë‹¨í•œ ì ‘ê·¼ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤. ì•„í‹°íŒ©íŠ¸ëŠ” ê°œë°œ ë˜ëŠ” CI/CD ë‹¨ê³„ì—ì„œ íƒœê·¸ê°€ ì§€ì •ë˜ê³  ë²„ì „ì´ ê´€ë¦¬ë˜ë©° Amazon S3 ë²„í‚·ì— ë°°ì¹˜ë˜ê³  ë³´ì¡´ì„ ì œì–´í•˜ê¸° ìœ„í•œ ì ì ˆí•œ ë¼ì´í”„ì‚¬ì´í´ ì •ì±…ì´ ì ìš©ë©ë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì°¸ì¡°ë˜ë©´ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ ì „ì— ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” Kubernetes ë„¤ì´í‹°ë¸Œ init ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ Pod ì´ˆê¸°í™” ì¤‘ì— ê³µìœ  ë³¼ë¥¨ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤.  ì•„í‚¤í…ì²˜ ê°œìš”  ê·¸ë¦¼ 1ì˜ ë‹¤ì´ì–´ê·¸ë¨ì€ ë°ì´í„° íë¦„ì˜ ì¼ë¶€ë¡œ ìƒì„±, ì €ì¥ ë° ê²€ìƒ‰ë˜ëŠ” í˜ë¥´ì†Œë‚˜, AWS ì„œë¹„ìŠ¤, Kubernetes êµ¬ì„± ìš”ì†Œ ë° ì•„í‹°íŒ©íŠ¸ë¥¼ í¬í•¨í•œ ì†”ë£¨ì…˜ ì•„í‚¤í…ì²˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê·¸ë¦¼ 1: Amazon S3ì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ê²€ìƒ‰í•˜ê¸° ìœ„í•œ init ì»¨í…Œì´ë„ˆ ì•„í‚¤í…ì²˜  êµ¬í˜„ ê°€ì´ë“œ  ìœ„ì˜ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì— ë”°ë¼ ê° íŒ€ì˜ ì£¼ìš” ê³ ìˆ˜ì¤€ ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  DevOps/MLOps/í”Œë«í¼ íŒ€:  init ì»¨í…Œì´ë„ˆë¥¼ í¬í•¨í•˜ë„ë¡ Kubernetes ë°°í¬ ë§¤ë‹ˆí˜ìŠ¤íŠ¸(ì˜ˆ: YAML íŒŒì¼, Helm ì°¨íŠ¸)ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.ë¨¼ì € ì‹¤í–‰ë˜ëŠ” init ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ EC2 ë³¼ë¥¨ì— ë‹¤ìš´ë¡œë“œí•˜ëŠ” ë‹¨ê³„ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.Kubernetes ë°°í¬ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ ë³€ê²½í•˜ì—¬: init ì»¨í…Œì´ë„ˆì™€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ ê°„ì— ê³µìœ ë˜ëŠ” ë³¼ë¥¨ì„ ì •ì˜í•©ë‹ˆë‹¤.ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆì˜ ì˜ˆìƒ ê²½ë¡œ ì•„ë˜ì— ë³¼ë¥¨ì„ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤. init ì»¨í…Œì´ë„ˆê°€ ë²„í‚·ì˜ ì ì ˆí•œ ì ‘ë‘ì‚¬ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ Pod IAM ê¶Œí•œì„ ì¡°ì •í•©ë‹ˆë‹¤.ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì €ì¥í•  Amazon S3 ë²„í‚·ì„ ìƒì„±í•©ë‹ˆë‹¤.ë¹Œë“œ ìŠ¤í…Œì´ì§€ ë™ì•ˆ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì œì™¸í•˜ë„ë¡ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì •ì˜ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.  ML ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ€:  SDLCì˜ ì¼ë¶€ë¡œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ Amazon S3 ë²„í‚·ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.ì´ì „ê³¼ ê°™ì´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë³€ê²½ ì‚¬í•­ì„ Amazon ECRë¡œ ê³„ì† í‘¸ì‹œí•©ë‹ˆë‹¤.ì´ì „ê³¼ ê°™ì´ Kubernetes ë°°í¬ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ Kubernetes ë°°í¬ë¥¼ ê³„ì† ì •ì˜í•©ë‹ˆë‹¤.  ë‹¤ìŒ ì½”ë“œëŠ” ì´ë¯¸ ì¡°ì •ëœ Kubernetes ë°°í¬ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤:  apiVersion: apps/v1 kind: Deployment metadata: name: my-inference-app namespace: apps spec: selector: matchLabels: app.kubernetes.io/name: my-inference-app replicas: 1 template: metadata: labels: app.kubernetes.io/name: my-inference-app spec: serviceAccountName: my-inference-app initContainers: - name: download image: peakcom/s5cmd command: - /bin/sh - -c - '/s5cmd sync s3://my-ml-bucket/model-artifacts/my-model-1.2.3/* /model-artifacts/my-model-1.2.3' resources: ... volumeMounts: - mountPath: /model-artifacts name: model-artifacts containers: - name: app image: &lt;account-id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/my-inference-app:3.5.0 ports: - name: app-port containerPort: 6060 resources: ... volumeMounts: - mountPath: /app/model-artifacts name: model-artifacts volumes: - emptyDir: {} name: model-artifacts   ìœ„ì˜ ì˜ˆëŠ” ìœ„ì—ì„œ ì„¤ëª…í•œ ë‹¨ê³„ë¥¼ ë”°ë¥´ë©° Amazon S3ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ë° íƒì›”í•œ ì„±ëŠ¥ì„ ì œê³µí•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ë„êµ¬ì¸ s5cmdë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. êµ¬í˜„ì€ í˜„ì¬ ëª¨ë“  ê²ƒì´ ì´ë¯¸ì§€ì— í¬í•¨ëœ ì†”ë£¨ì…˜ì´ my-model-1.2.3 ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ /app/model-artifacts ì•„ë˜ì˜ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì— ë²ˆë“¤í•˜ê³  ë™ì¼í•œ ìœ„ì¹˜ì— ë°°ì¹˜í•˜ì—¬ í•´ë‹¹ ë™ì‘ì„ ëª¨ë°©í•œë‹¤ëŠ” ì‚¬ì‹¤ì— ì˜ì¡´í•©ë‹ˆë‹¤.  ìœ„ì˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì— ë‚˜ì—´ëœ my-inference-app ì„œë¹„ìŠ¤ ê³„ì •ì€ my-ml-bucket ë²„í‚·ì˜ í•´ë‹¹ ì ‘ë‘ì‚¬ì—ì„œ ì½ì„ ìˆ˜ ìˆëŠ” ì ì ˆí•œ IAM ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. Amazon EKSì—ì„œ ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ê¶Œì¥ë˜ëŠ” ë°©ë²•ì€ Amazon EKS Pod Identity ì• ë“œì˜¨ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. Amazon EKS Pod IdentityëŠ” AWS APIë¥¼ í†µí•´ Kubernetes ì„œë¹„ìŠ¤ ê³„ì •ê³¼ AWS IAM ì—­í•  ê°„ì˜ ì—°ê²°ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ë°°í¬ë˜ë©´ Pod Identity ì• ë“œì˜¨ì€ í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ë…¸ë“œì— ì—ì´ì „íŠ¸(DaemonSetì„ í†µí•´)ë¥¼ ë°°ì¹˜í•˜ê³  í•´ë‹¹ ì„œë¹„ìŠ¤ ê³„ì •ì´ ìˆëŠ” Podê°€ ëŸ°íƒ€ì„ì— í•´ë‹¹ ì—ì´ì „íŠ¸ì—ì„œ í•„ìš”í•œ ìê²© ì¦ëª…ì„ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.  ì£¼ìš” ì´ì   ì´ ì†”ë£¨ì…˜ì€ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì—¬ AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ê³ ìˆ˜ì¤€ ì ‘ê·¼ ë°©ì‹ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí‚¹ ì¡°ê±´ê³¼ s5cmdì˜ ìš°ìˆ˜í•œ ì„±ëŠ¥ì— ë”°ë¼ ì´ë¯¸ì§€ í’€ì„ ì§ì ‘ ê°œì„ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  ì¶”ê°€ ì´ì   ì£¼ìš” ì´ì  ì™¸ì—ë„ ì†”ë£¨ì…˜ì€ ë‹¤ìŒê³¼ ê°™ì€ ì ì¬ì ì¸ ì¶”ê°€ ì´ì ì„ ë„ì…í•©ë‹ˆë‹¤:  ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë¹Œë“œí•˜ì§€ ì•Šê³  ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë³„ë„ë¡œ ëª¨ë¸ ë²„ì „ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ê¸°ëŠ¥ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë¹Œë“œí•˜ê±°ë‚˜ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ì§€ ì•Šê³  ëª¨ë¸ì„ A/B í…ŒìŠ¤íŠ¸, í•« ìŠ¤ì™€í”„ ë˜ëŠ” ë¡¤ë°±í•˜ëŠ” ê¸°ëŠ¥ëª¨ë“  ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì— íŒ¨í‚¤ì§•í•˜ì§€ ì•Šê³  ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°„ì— ëª¨ë¸ì„ ê³µìœ í•˜ëŠ” ê¸°ëŠ¥ìŠ¤í† ë¦¬ì§€ ë¹„ìš© ì ˆê° ë° Intelligent-Tieringì„ í¬í•¨í•œ Amazon S3 ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ í™œìš© ê¸°ëŠ¥Amazon EKS Pod Identity ì„¸ì…˜ íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì— ëŒ€í•œ ì„¸ë¶„í™”ëœ ì ‘ê·¼ ì œì–´ ê¸°ëŠ¥ì‹¤í—˜ ë° í…ŒìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ëŠ” ë” ë¹ ë¥¸ ì»¨í…Œì´ë„ˆ ë¹Œë“œML ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ€ ì›Œí¬í”Œë¡œìš°ì˜ ìµœì†Œ ë³€ê²½ê°„ë‹¨í•œ êµì°¨ ë¦¬ì „ ë³µì œ  íŠ¸ë ˆì´ë“œì˜¤í”„  íŠ¸ë ˆì´ë“œì˜¤í”„ëŠ” ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤:  í•„ìš”í•œ CI/CD ë³€ê²½ì„ ìˆ˜í–‰í•˜ê³  ì¬ì‹œë„, ì˜¤ë¥˜ ì²˜ë¦¬, ë°±ì˜¤í”„ ë“±ì„ í¬í•¨í•œ ë‹¤ìš´ë¡œë“œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¶”ê°€ì ì¸ ìš´ì˜ ë³µì¡ì„±ë³¸ì§ˆì ìœ¼ë¡œ ECR ê¸°ëŠ¥ì„ ë³µì œí•˜ëŠ” ì¶”ê°€ ìŠ¤í† ë¦¬ì§€ ë° ì •ë¦¬ ê´€ë¦¬ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì¶”ê°€ ë³µì œë³¸ì´ ì¢…ì¢… ë™ì¼í•œ EC2 ì¸ìŠ¤í„´ìŠ¤ì— ì°©ë¥™í•˜ëŠ” ê²½ìš°, í˜¸ìŠ¤íŠ¸ì˜ ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ ìºì‹œì— ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì–´ ìˆìœ¼ë©´ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œê°„ì— ë” ìœ ìµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë³€í˜• ë° í•˜ì´ë¸Œë¦¬ë“œ ì†”ë£¨ì…˜  ì´ ì†”ë£¨ì…˜ì€ í’€ í”„ë¡œì„¸ìŠ¤ ê°€ì†í™” ì†”ë£¨ì…˜ ê·¸ë£¹ê³¼ ì˜ í†µí•©ë˜ì–´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸°ì™€ í’€ ì‹œê°„ì„ ëª¨ë‘ ê°œì„ í•©ë‹ˆë‹¤.  ì•„í‹°íŒ©íŠ¸ë¥¼ ë©”ëª¨ë¦¬ë¡œ ì§ì ‘ ì½ì–´ ë¡œì»¬ ë””ìŠ¤í¬ì— ì €ì¥í•˜ëŠ” ì¤‘ê°„ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ëŠ” AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê²½ìš° &quot;Mountpoint CSI ë“œë¼ì´ë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ Amazon S3ì—ì„œ ì§ì ‘ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ë©”ëª¨ë¦¬ë¡œ ì½ê¸°&quot; ì†”ë£¨ì…˜ì´ ë‹¤ìš´ë¡œë“œ ì„±ëŠ¥ì„ ë”ìš± ê°œì„ í•˜ê¸° ìœ„í•´ ëŒ€ì²´í•˜ê±°ë‚˜ ì¶”ê°€ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Amazon íŒŒì¼ ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ í˜¸ìŠ¤íŒ…â€‹","type":1,"pageTitle":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë¶„ë¦¬","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size/decoupling-model-artifacts#amazon-íŒŒì¼-ìŠ¤í† ë¦¬ì§€-ì„œë¹„ìŠ¤ë¥¼-ì‚¬ìš©í•˜ì—¬-ëª¨ë¸-ì•„í‹°íŒ©íŠ¸-í˜¸ìŠ¤íŒ…","content":" ì´ ì„¹ì…˜ì—ì„œëŠ” ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ ë¶„ë¦¬í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ Amazon FSx ì„œë¹„ìŠ¤ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. Amazon FSxëŠ” FSx for OpenZFS, FSx for Lustre, FSx for NetApp ONTAPê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì„œë¹„ìŠ¤ëŠ” ê¸°ë°˜ ê¸°ìˆ ì´ ë‹¤ë¥´ë©° ì„±ëŠ¥ê³¼ í™•ì¥ íŠ¹ì„±ì´ ë‹¤ë¦…ë‹ˆë‹¤. ì´ëŸ¬í•œ ì„œë¹„ìŠ¤ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ì ì ˆí•œ Amazon FSx ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì€ ì‚¬ìš© ì‚¬ë¡€ì˜ íŠ¹ì„±ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ëª¨ë¸ í¬ê¸°, ëª¨ë¸ ìˆ˜, ì—…ë°ì´íŠ¸ ë¹ˆë„ ë° ëª¨ë¸ì„ ê°€ì ¸ì˜¤ëŠ” í´ë¼ì´ì–¸íŠ¸ ìˆ˜ì™€ ê°™ì€ ìš”ì†Œê°€ ì„ íƒí•œ ì„œë¹„ìŠ¤ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì •ë³´ ì´ ì„¹ì…˜ì€ ì§„í–‰ ì¤‘ì´ë©° í–¥í›„ ë” ë§ì€ FSx ì„œë¹„ìŠ¤ë³„ ê°€ì´ë“œê°€ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"Trident CSI ë“œë¼ì´ë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ Amazon FSx for NetApp ONTAPì˜ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ì— ëŒ€í•œ ì ‘ê·¼ ì œê³µâ€‹","type":1,"pageTitle":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë¶„ë¦¬","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size/decoupling-model-artifacts#trident-csi-ë“œë¼ì´ë²„ë¥¼-ì‚¬ìš©í•˜ì—¬-amazon-fsx-for-netapp-ontapì˜-ëª¨ë¸-ì•„í‹°íŒ©íŠ¸ì—-ëŒ€í•œ-ì ‘ê·¼-ì œê³µ","content":" ì•„í‚¤í…ì²˜ ê°œìš”  ê·¸ë¦¼ 2ì˜ ë‹¤ì´ì–´ê·¸ë¨ì€ ë°ì´í„° íë¦„ì˜ ì¼ë¶€ë¡œ ìƒì„±, ì €ì¥ ë° ê²€ìƒ‰ë˜ëŠ” í˜ë¥´ì†Œë‚˜, AWS ì„œë¹„ìŠ¤, Kubernetes êµ¬ì„± ìš”ì†Œ ë° ì•„í‹°íŒ©íŠ¸ë¥¼ í¬í•¨í•œ ì†”ë£¨ì…˜ ì•„í‚¤í…ì²˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.  ê·¸ë¦¼ 2: Trident CSI ë“œë¼ì´ë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ FSx for NetApp ONTAPì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥ ë° ì ‘ê·¼  êµ¬í˜„ ê°€ì´ë“œ  ìœ„ì˜ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì— ë”°ë¼ ê° íŒ€ì˜ ì£¼ìš” ê³ ìˆ˜ì¤€ ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  DevOps/MLOps/í”Œë«í¼ íŒ€:  FSx for NetApp ONTAP íŒŒì¼ ì‹œìŠ¤í…œ, ìŠ¤í† ë¦¬ì§€ ê°€ìƒ ë¨¸ì‹ (SVM) ë° ìê²© ì¦ëª… ì‹œí¬ë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.Trident CSI ë“œë¼ì´ë²„ë¥¼ ì„¤ì¹˜í•˜ê³  í•„ìš”í•œ IAM ê¶Œí•œì„ ì œê³µí•˜ë©° Trident CSI ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.íŒŒì¼ ì‹œìŠ¤í…œ, SVM ë° ìê²© ì¦ëª…ì„ ì‚¬ìš©í•˜ì—¬ Trident NAS ë°±ì—”ë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.ìœ„ì˜ ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ê³µìœ ë˜ëŠ” ë™ì  í”„ë¡œë¹„ì „ PVCë¥¼ ì •ì˜í•˜ê³  ë°°í¬í•©ë‹ˆë‹¤.PVCë¥¼ ë§ˆìš´íŠ¸í•˜ê³  í•´ë‹¹ ë³¼ë¥¨ì— ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” Kubernetes ì‘ì—…ì„ êµ¬í˜„í•©ë‹ˆë‹¤.S3ì— ì—…ë¡œë“œë˜ê³  ê²Œì‹œë¨ìœ¼ë¡œ &quot;í‘œì‹œ&quot;ëœ(ì˜ˆ: íƒœê·¸ë¥¼ í†µí•´) ê° ëª¨ë¸ì— ëŒ€í•´ ì‘ì—…ì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.ë¹Œë“œ ìŠ¤í…Œì´ì§€ ë™ì•ˆ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì œì™¸í•˜ë„ë¡ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì •ì˜ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.ì• í”Œë¦¬ì¼€ì´ì…˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ ë³€ê²½í•˜ì—¬: ê³µìœ  PVCë¥¼ ê°€ì ¸ì˜¤ëŠ” PVCë¥¼ í¬í•¨í•©ë‹ˆë‹¤.ì• í”Œë¦¬ì¼€ì´ì…˜ Podì— ëŒ€í•œ ë³¼ë¥¨ì„ ì •ì˜í•©ë‹ˆë‹¤.ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆì˜ ì˜ˆìƒ ê²½ë¡œ ì•„ë˜ì— ë³¼ë¥¨ì„ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤.  ML ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ€:  SDLCì˜ ì¼ë¶€ë¡œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ Amazon S3 ë²„í‚· ë˜ëŠ” Git LFSì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.ì´ì „ê³¼ ê°™ì´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë³€ê²½ ì‚¬í•­ì„ Amazon ECRë¡œ ê³„ì† í‘¸ì‹œí•©ë‹ˆë‹¤.ì´ì „ê³¼ ê°™ì´ Kubernetes ë°°í¬ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ Kubernetes ë°°í¬ë¥¼ ê³„ì† ì •ì˜í•©ë‹ˆë‹¤.  ìœ„ì˜ ë‹¨ê³„ë¥¼ ë” ì„¤ëª…í•˜ê¸° ìœ„í•´ êµ¬í˜„ì˜ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì— ëŒ€í•œ ê´€ë ¨ ì½”ë“œ ì˜ˆì œ ëª¨ìŒì´ ì•„ë˜ì— ìˆìŠµë‹ˆë‹¤.  ë‹¤ìŒì€ Trident CSI ë“œë¼ì´ë²„ì— ì˜í•´ ì²˜ë¦¬ë  ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ì…ë‹ˆë‹¤:  apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: ontap-nas provisioner: csi.trident.netapp.io volumeBindingMode: WaitForFirstConsumer parameters: backendType: ontap-nas fsType: ext4 allowVolumeExpansion: True reclaimPolicy: Delete   ë‹¤ìŒì€ FSx for NetApp ONTAPê³¼ì˜ ë°±ì—”ë“œ í†µí•©ì„ ìœ„í•œ Trident ë°±ì—”ë“œ êµ¬ì„±ì…ë‹ˆë‹¤:  apiVersion: trident.netapp.io/v1 kind: TridentBackendConfig metadata: name: svm1-nas namespace: kube-system spec: version: 1 backendName: svm1-nas storageDriverName: ontap-nas managementLIF: ${SVM_MGMT_DNS} svm: svm1 aws: fsxFilesystemID: ${FSXN_ID} apiRegion: ${AWS_REGION} credentials: name: ${SVM_ADMIN_CREDS_SECRET_ARN} type: awsarn   ë‹¤ìŒì€ Tridentì— ì˜í•´ ì²˜ë¦¬ë˜ê³  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê°„ì— ê³µìœ ë  ìˆ˜ ìˆëŠ” PVCì˜ ì˜ˆì…ë‹ˆë‹¤:  kind: PersistentVolumeClaim apiVersion: v1 metadata: name: some-model namespace: kube-system annotations: trident.netapp.io/shareToNamespace: apps spec: storageClassName: ontap-nas accessModes: - ReadWriteMany resources: requests: storage: 20Gi   ê·¸ëŸ° ë‹¤ìŒ PVCë¥¼ ë§ˆìš´íŠ¸í•˜ê³  S3ì˜ ë°ì´í„°ë¡œ ë™ì  PV ë’¤ì˜ FSx for NetApp ONTAP ë³¼ë¥¨ì„ ì±„ìš°ëŠ” Jobì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  apiVersion: batch/v1 kind: Job metadata: name: fsxn-loader-some-model namespace: kube-system labels: job-type: fsxn-loader pvc: some-model spec: backoffLimit: 1 ttlSecondsAfterFinished: 30 template: metadata: labels: job-type: fsxn-loader pvc: some-model spec: restartPolicy: Never containers: - name: loader image: peakcom/s5cmd command: - /bin/sh - -c - '/s5cmd sync --delete s3://${MODELS_BUCKET}/${MODELS_FOLDER}/some-model/* /model' resources: ... volumeMounts: - name: model mountPath: /model volumes: - name: model persistentVolumeClaim: claimName: some-model   ì´ì œ PVCê°€ í´ëŸ¬ìŠ¤í„°ì— ì¡´ì¬í•˜ë©° TridentVolumeReference CRì— ì˜í•´ ì •ì˜ëœ Trident PVC ê³µìœ ë¥¼ í†µí•´ apps ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  apiVersion: trident.netapp.io/v1 kind: TridentVolumeReference metadata: name: some-model namespace:apps spec: pvcName: some-model pvcNamespace: kube-system --- kind: PersistentVolumeClaim apiVersion: v1 metadata: name: some-model namespace: apps annotations: trident.netapp.io/shareFromPVC: kube-system/some-model spec: storageClassName: ontap-nas accessModes: - ReadOnlyMany resources: requests: storage: 20Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: some-app namespace: apps spec: selector: matchLabels: app.kubernetes.io/name: some-app replicas: 1 template: metadata: labels: app.kubernetes.io/name: some-app spec: containers: - name: app image: some-app:1.2.3 ... volumeMounts: - name: data-volume mountPath: /app/models/some-model volumes: - name: data-volume persistentVolumeClaim: claimName: some-model   ì£¼ìš” ì´ì   ì´ ì†”ë£¨ì…˜ì€ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì—¬ AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ê³ ìˆ˜ì¤€ ì ‘ê·¼ ë°©ì‹ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë˜ëŠ” ì‹œê°„ì„ ê°œì„ í•©ë‹ˆë‹¤(ë” ì´ìƒ ë‹¤ìš´ë¡œë“œí•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ).  ì¶”ê°€ ì´ì   ì£¼ìš” ì´ì  ì™¸ì—ë„ ì†”ë£¨ì…˜ì€ ë‹¤ìŒê³¼ ê°™ì€ ì ì¬ì ì¸ ì¶”ê°€ ì´ì ì„ ë„ì…í•©ë‹ˆë‹¤:  ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë¹Œë“œí•˜ì§€ ì•Šê³  ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë³„ë„ë¡œ ëª¨ë¸ ë²„ì „ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ê¸°ëŠ¥ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë¹Œë“œí•˜ê±°ë‚˜ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ì§€ ì•Šê³  ëª¨ë¸ì„ A/B í…ŒìŠ¤íŠ¸, í•« ìŠ¤ì™€í”„ ë˜ëŠ” ë¡¤ë°±í•˜ëŠ” ê¸°ëŠ¥ëª¨ë“  ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì— íŒ¨í‚¤ì§•í•˜ì§€ ì•Šê³  ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°„ì— ëª¨ë¸ì„ ê³µìœ í•˜ëŠ” ê¸°ëŠ¥ëª¨ë¸ ë³µì‚¬ í•„ìš”ì„±ì„ ì¤„ì´ê³  ìƒˆë¡œìš´ ì‘ì—…ì„ ìƒì„±í•˜ëŠ” Trident í´ë¡ , ê³µìœ  ë° ìŠ¤ëƒ…ìƒ· ê´€ë ¨ ê¸°ëŠ¥ì„ í†µí•œ Kubernetes ê¸°ë°˜ í”„ë¡œë¹„ì €ë‹ ë° ì ‘ê·¼ ì œì–´ëª¨ë¸ì— ëŒ€í•œ POSIX ê¸°ë°˜ ì ‘ê·¼ ì œì–´ ê¸°ëŠ¥ì‹¤í—˜ ë° í…ŒìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ëŠ” ë” ë¹ ë¥¸ ì»¨í…Œì´ë„ˆ ë¹Œë“œML ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ€ ì›Œí¬í”Œë¡œìš°ì˜ ìµœì†Œ ë³€ê²½  íŠ¸ë ˆì´ë“œì˜¤í”„  íŠ¸ë ˆì´ë“œì˜¤í”„ëŠ” ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤:  í•„ìš”í•œ CI/CD ë³€ê²½ì„ ìˆ˜í–‰í•˜ê³  ë¡œë” í”„ë¡œì„¸ìŠ¤ë¥¼ ìœ ì§€í•˜ëŠ” ì¶”ê°€ì ì¸ ìš´ì˜ ë³µì¡ì„±ìš´ì˜ ë° ìœ ì§€ ê´€ë¦¬í•´ì•¼ í•  ì¶”ê°€ ì†Œí”„íŠ¸ì›¨ì–´(Trident)ìŠ¤í† ë¦¬ì§€ ë¹„ìš©ì„ ì¤„ì´ê¸° ìœ„í•´ ì‚¬ìš©ì ì •ì˜ S3/FSx for NetApp ONTAP TTL/ë³´ì¡´ ê´€ë ¨ ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•´ì•¼ í•  í•„ìš”ì„±ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ì˜ ì½ê¸° ì„±ëŠ¥ì„ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œê°„ê³¼ ë¹„êµí•˜ì—¬ ì¸¡ì •í•´ì•¼ í•¨ë” ë³µì¡í•œ êµì°¨ ë¦¬ì „ ë³µì œ  ë³€í˜• ë° í•˜ì´ë¸Œë¦¬ë“œ ì†”ë£¨ì…˜  ì´ ì†”ë£¨ì…˜ì€ í’€ í”„ë¡œì„¸ìŠ¤ ê°€ì†í™” ì†”ë£¨ì…˜ ê·¸ë£¹ê³¼ ì˜ í†µí•©ë˜ì–´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸°ì™€ í’€ ì‹œê°„ì„ ëª¨ë‘ ê°œì„ í•©ë‹ˆë‹¤.  ì•„í‹°íŒ©íŠ¸ë¥¼ ë©”ëª¨ë¦¬ë¡œ ì½ì–´ ë¡œì»¬ ë””ìŠ¤í¬ì— ì €ì¥í•˜ëŠ” ì¤‘ê°„ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ëŠ” AI/ML ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê²½ìš° &quot;Mountpoint CSI ë“œë¼ì´ë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ Amazon S3ì—ì„œ ì§ì ‘ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ë©”ëª¨ë¦¬ë¡œ ì½ê¸°&quot; ì†”ë£¨ì…˜ê³¼ ìœ ì‚¬í•˜ê²Œ ë‹¤ìš´ë¡œë“œ ì„±ëŠ¥ì„ ë”ìš± ê°œì„ í•˜ê¸° ìœ„í•´ ëŒ€ì²´ë¡œ(ë˜ëŠ” ì¶”ê°€ë¡œ) ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ìš©ì ì •ì˜ Amazon AMIì— ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë² ì´í‚¹â€‹","type":1,"pageTitle":"ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë¶„ë¦¬","url":"/ai-on-eks/ko/docs/guidance/container-startup-time/reduce-container-image-size/decoupling-model-artifacts#ì‚¬ìš©ì-ì •ì˜-amazon-amiì—-ëª¨ë¸-ì•„í‹°íŒ©íŠ¸-ë² ì´í‚¹","content":" ì•„í‚¤í…ì²˜ ê°œìš”    ê·¸ë¦¼ 3: ì‚¬ìš©ì ì •ì˜ Amazon AMIì— ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë² ì´í‚¹  ì´ ì†”ë£¨ì…˜ì€ ë§¤ìš° ë“œë¬¼ê²Œ ë³€ê²½ë˜ëŠ” ëª¨ë¸ì´ ìˆê³  ì‹œì‘ ì‹œê°„ ì§€ì—°ì— ë§¤ìš° ë¯¼ê°í•˜ë©° ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ ì œí•œëœ í™˜ê²½ì— ì í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  êµ¬í˜„ ê°€ì´ë“œ  ìœ„ì˜ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì— ë”°ë¼ ê° íŒ€ì˜ ì£¼ìš” ê³ ìˆ˜ì¤€ ë‹¨ê³„ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  DevOps/MLOps/í”Œë«í¼ íŒ€:  EC2 Image Builder ë ˆì‹œí”¼ ë˜ëŠ” Packer í…œí”Œë¦¿ì„ ìƒì„±í•˜ê³  Gitì— í‘¸ì‹œí•©ë‹ˆë‹¤.AMI ë² ì´í‚¹ ë‹¨ê³„ë¥¼ í¬í•¨í•˜ë„ë¡ CI/CD í”„ë¡œì„¸ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.AMIë¥¼ ì‚¬ìš©í•˜ëŠ” í•´ë‹¹ Karpenter ë…¸ë“œ í’€ì„ ìƒì„±í•©ë‹ˆë‹¤.ë§¤ê°œë³€ìˆ˜ë¡œ ì œê³µë  ë…¸ë“œ í’€ì— ëŒ€í•œ ë…¸ë“œ ì…€ë ‰í„°ë¥¼ í¬í•¨í•˜ë„ë¡ ì• í”Œë¦¬ì¼€ì´ì…˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.  ML ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ€:  SDLCì˜ ì¼ë¶€ë¡œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ Amazon S3 ë²„í‚· ë˜ëŠ” Git LFSì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.ì´ì „ê³¼ ê°™ì´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë³€ê²½ ì‚¬í•­ì„ Amazon ECRë¡œ ê³„ì† í‘¸ì‹œí•©ë‹ˆë‹¤.Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë°°í¬ì— ëŒ€í•œ ë§¤ê°œë³€ìˆ˜ë¡œ ì ì ˆí•œ ëª¨ë¸ë³„ ë…¸ë“œ í’€ ë ˆì´ë¸”ì„ ì œê³µí•©ë‹ˆë‹¤.  ì£¼ìš” ì´ì   ì†”ë£¨ì…˜ì€ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤:  ëª¨ë¸ì´ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•˜ë¯€ë¡œ ë‹¤ìš´ë¡œë“œ ì§€ì—° ì—†ìŒë„¤íŠ¸ì›Œí¬ ì¢…ì†ì„± ì—†ìŒ  ì¶”ê°€ ì´ì   ì£¼ìš” ì´ì  ì™¸ì—ë„ ì†”ë£¨ì…˜ì€ ë‹¤ìŒê³¼ ê°™ì€ ì ì¬ì ì¸ ì¶”ê°€ ì´ì ì„ ë„ì…í•©ë‹ˆë‹¤:  Kubernetes ì•„í‹°íŒ©íŠ¸ì— ëŒ€í•œ ë³€ê²½ ì—†ìŒKarpenter ë“œë¦¬í”„íŠ¸ ê°ì§€ë¥¼ í†µí•œ ìƒˆ ëª¨ë¸ ë²„ì „ì— ëŒ€í•œ ê°„ì†Œí™”ëœ ë¡¤ì•„ì›ƒS3 ë˜ëŠ” FSxì™€ ê°™ì€ ì¶”ê°€ ì„œë¹„ìŠ¤ì— ì˜ì¡´í•  í•„ìš” ì—†ìŒ  íŠ¸ë ˆì´ë“œì˜¤í”„  íŠ¸ë ˆì´ë“œì˜¤í”„ëŠ” ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤:  Image Builder ë˜ëŠ” Packerë¥¼ CI/CD í”„ë¡œì„¸ìŠ¤ì— í†µí•©í•˜ëŠ” ìƒë‹¹í•œ ì¶”ê°€ ìš´ì˜ ë³µì¡ì„±ì‹¤í–‰ ì¤‘ì¸ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ AMIì— ì ‘ê·¼í•´ì•¼ í•˜ëŠ” ë” ë³µì¡í•œ ì„¤ì •ìœ¼ë¡œ ì¸í•œ ëŠë¦° ë¹Œë“œ ì‹œê°„ê³¼ ì‹¤í—˜, ë””ë²„ê¹… ë° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë” ê¸´ í”¼ë“œë°± ë£¨í”„ëª¨ë“  ëª¨ë¸ì„ í•¨ê»˜ ë°°ì¹˜í•˜ëŠ” ê²½ìš° ìŠ¤í† ë¦¬ì§€ ë¹„ìš© ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í•´ë‹¹ AMIì— ìŠ¤ì¼€ì¤„ë§í•˜ëŠ” ê´€ë¦¬ê°€ í•„ìš”í•œ AMIë³„ ëª¨ë¸ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ì¸í•œ ê·¹ë‹¨ì ì¸ í´ëŸ¬ìŠ¤í„° ì„¸ë¶„í™”  ë³€í˜• ë° í•˜ì´ë¸Œë¦¬ë“œ ì†”ë£¨ì…˜  ì´ ì†”ë£¨ì…˜ì€ í’€ í”„ë¡œì„¸ìŠ¤ ê°€ì†í™” ì†”ë£¨ì…˜ ê·¸ë£¹ê³¼ ì˜ í†µí•©ë˜ì–´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸°ì™€ í’€ ì‹œê°„ì„ ëª¨ë‘ ê°œì„ í•©ë‹ˆë‹¤.  ì´ê²ƒì€ ì„œë¹™ í”„ë ˆì„ì›Œí¬ì™€ì˜ ì •í™•ì„± íšŒê·€ ë˜ëŠ” í˜¸í™˜ì„± ë¬¸ì œë¥¼ ë„ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ","version":"Next","tagName":"h2"},{"title":"ì†Œê°œ","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/infra","content":"","keywords":"","version":"Next"},{"title":"ê°œìš”â€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#ê°œìš”","content":" AI on EKSëŠ” Amazon EKSì—ì„œ AI/ML ì›Œí¬ë¡œë“œë¥¼ ë°°í¬í•˜ê¸° ìœ„í•œ í¬ê´„ì ì¸ ì¸í”„ë¼ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. í•™ìŠµ, ì¶”ë¡  ë˜ëŠ” ë²”ìš© AI/ML ì›Œí¬ë¡œë“œì— ìµœì í™”ëœ ì‚¬ì „ êµ¬ì„± ì†”ë£¨ì…˜ ì¤‘ ì„ íƒí•˜ì„¸ìš”.  ","version":"Next","tagName":"h2"},{"title":"í•™ìŠµ ì¸í”„ë¼â€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#í•™ìŠµ-ì¸í”„ë¼","content":" AI/ML ëª¨ë¸ í•™ìŠµ ì›Œí¬ë¡œë“œì— ìµœì í™”ëœ ì¸í”„ë¼ ì†”ë£¨ì…˜:  JARK Stack on EKS - JupyterHub, Ray, Kubeflowë¥¼ í¬í•¨í•œ NVIDIA GPU ê¸°ë°˜ AI ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ì™„ì „í•œ ìŠ¤íƒJupyterHub on EKS - ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ë° MLì„ ìœ„í•œ ëŒ€í™”í˜• ê°œë°œ í™˜ê²½  ","version":"Next","tagName":"h3"},{"title":"ì¶”ë¡  ì¸í”„ë¼â€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#ì¶”ë¡ -ì¸í”„ë¼","content":" AI/ML ëª¨ë¸ ì¶”ë¡  ì›Œí¬ë¡œë“œì— ìµœì í™”ëœ ì¸í”„ë¼ ì†”ë£¨ì…˜:  ì¶”ë¡  ì¤€ë¹„ í´ëŸ¬ìŠ¤í„° - ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ìœ„í•´ ì‚¬ì „ êµ¬ì„±ëœ EKS í´ëŸ¬ìŠ¤í„°Nvidia NIM on EKS - Nvidia NIM ë°°í¬ ìƒ˜í”ŒNvidia Dynamo on EKS - Nvidia Dynamo ë°°í¬ ìƒ˜í”Œ  ","version":"Next","tagName":"h3"},{"title":"ê¸°íƒ€â€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#ê¸°íƒ€","content":" ì¶”ê°€ ì¸í”„ë¼ ì†”ë£¨ì…˜ ë° ìœ í‹¸ë¦¬í‹°:  EMR Spark Rapids - Amazon EMRì—ì„œ GPU ê°€ì† Apache Sparkë¬¸ì œ í•´ê²° - ì¼ë°˜ì ì¸ ë¬¸ì œ ë° ì†”ë£¨ì…˜  ","version":"Next","tagName":"h3"},{"title":"ì‹œì‘í•˜ê¸°â€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#ì‹œì‘í•˜ê¸°","content":" ì‚¬ìš© ì‚¬ë¡€ ì„ íƒ: ì›Œí¬ë¡œë“œ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ í•™ìŠµ ë˜ëŠ” ì¶”ë¡  ì„ íƒì¸í”„ë¼ ë°°í¬: ì„ íƒí•œ ì†”ë£¨ì…˜ì˜ ë°°í¬ ê°€ì´ë“œë¥¼ ë”°ë¼ ì§„í–‰ì›Œí¬ë¡œë“œ ë°°í¬: ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ AI/ML ì›Œí¬ë¡œë“œ ë°°í¬ìµœì í™”: ê°€ì´ë˜ìŠ¤ ëª¨ë²” ì‚¬ë¡€ ì ìš©  ","version":"Next","tagName":"h3"},{"title":"ì•„í‚¤í…ì²˜ íŒ¨í„´â€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#ì•„í‚¤í…ì²˜-íŒ¨í„´","content":" ëª¨ë“  ì¸í”„ë¼ ì†”ë£¨ì…˜ì€ ë‹¤ìŒ í•µì‹¬ ì›ì¹™ì„ ë”°ë¦…ë‹ˆë‹¤:  ëª¨ë“ˆì‹ ì„¤ê³„: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“ˆë¡œ ì†”ë£¨ì…˜ êµ¬ì„±ëª¨ë²” ì‚¬ë¡€: ë³´ì•ˆ, ê´€ì¸¡ì„±, í™•ì¥ì„±ì´ ë‚´ì¥í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ: Kubernetesì™€ AWS ì„œë¹„ìŠ¤ í™œìš©ê²€ì¦ë¨: ì—”í„°í”„ë¼ì´ì¦ˆ ì›Œí¬ë¡œë“œì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ì™„ë£Œ  ","version":"Next","tagName":"h3"},{"title":"ë¦¬ì†ŒìŠ¤â€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#ë¦¬ì†ŒìŠ¤","content":" ê° ìŠ¤íƒì€ base ìŠ¤íƒì˜ ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì†í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì»´í¬ë„ŒíŠ¸ì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë©ë‹ˆë‹¤:  2ê°œ ê°€ìš© ì˜ì—­ì— ì„œë¸Œë„·ì´ ìˆëŠ” VPCìµœì†Œ ì¸í”„ë¼ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ 2ê°œ ë…¸ë“œë¥¼ ê°€ì§„ 1ê°œ ì½”ì–´ ë…¸ë“œê·¸ë£¹ì´ ìˆëŠ” EKS í´ëŸ¬ìŠ¤í„°CPU, GPU, AWS Neuron NodePoolì„ ê°–ì¶˜ Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§GPU/Neuron ë””ë°”ì´ìŠ¤ ë“œë¼ì´ë²„GPU/Neuron ëª¨ë‹ˆí„°ë§ ì—ì´ì „íŠ¸  ","version":"Next","tagName":"h2"},{"title":"ë³€ìˆ˜â€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#ë³€ìˆ˜","content":" ","version":"Next","tagName":"h2"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#ë°°í¬","content":" ë³€ìˆ˜ ì´ë¦„\tì„¤ëª…\tê¸°ë³¸ê°’name\tKubernetes í´ëŸ¬ìŠ¤í„° ì´ë¦„\tai-stack region\tí´ëŸ¬ìŠ¤í„° ë¦¬ì „\tus-east-1 eks_cluster_version\tì‚¬ìš©í•  EKS ë²„ì „\t1.32 vpc_cidr\tVPCì— ì‚¬ìš©ë˜ëŠ” CIDR\t10.1.0.0/21 secondary_cidr_blocks\tVPC ë³´ì¡° CIDR\t100.64.0.0/16 enable_database_subnets\të°ì´í„°ë² ì´ìŠ¤ ì„œë¸Œë„· í™œì„±í™” ì—¬ë¶€\tfalse enable_aws_cloudwatch_metrics\tAWS CloudWatch Metrics ì• ë“œì˜¨ í™œì„±í™”\tfalse bottlerocket_data_disk_snapshot_id\të°°í¬ëœ ë…¸ë“œì— ìŠ¤ëƒ…ìƒ· ID ì—°ê²°\t&quot;&quot; enable_aws_efs_csi_driver\tAWS EFS CSI ë“œë¼ì´ë²„ í™œì„±í™”\tfalse enable_aws_efa_k8s_device_plugin\tAWS EFA ë””ë°”ì´ìŠ¤ í”ŒëŸ¬ê·¸ì¸ í™œì„±í™”\tfalse enable_aws_fsx_csi_driver\tFSx ë””ë°”ì´ìŠ¤ í”ŒëŸ¬ê·¸ì¸ í™œì„±í™”\tfalse deploy_fsx_volume\tê°„ë‹¨í•œ FSx ë³¼ë¥¨ ë°°í¬\tfalse fsx_pvc_namespace\tFSx PVCë¥¼ í”„ë¡œë¹„ì €ë‹í•  ë„¤ì„ìŠ¤í˜ì´ìŠ¤\tdefault enable_amazon_prometheus\tAmazon Managed Prometheus í™œì„±í™”\tfalse enable_amazon_emr\tAmazon EMR ì„¤ì •\tfalse enable_kube_prometheus_stack\tKube Prometheus ì• ë“œì˜¨ í™œì„±í™”\tfalse enable_kubecost\tKubecost í™œì„±í™”\tfalse enable_ai_ml_observability_stack\tAI/ML ê´€ì¸¡ì„± ì• ë“œì˜¨ í™œì„±í™”\tfalse enable_argo_workflows\tArgo Workflow í™œì„±í™”\tfalse enable_argo_events\tArgo Events í™œì„±í™”\tfalse enable_argocd\tArgoCD ì• ë“œì˜¨ í™œì„±í™”\tfalse enable_mlflow_tracking\tMLFlow Tracking í™œì„±í™”\tfalse enable_jupyterhub\tJupyterHub í™œì„±í™”\tfalse enable_volcano\tVolcano í™œì„±í™”\tfalse enable_kuberay_operator\tKubeRay í™œì„±í™”\tfalse huggingface_token\tí™˜ê²½ì—ì„œ ì‚¬ìš©í•  Hugging Face í† í°\tDUMMY_TOKEN_REPLACE_ME enable_rayserve_ha_elastic_cache_redis\tElastiCacheë¥¼ ì‚¬ìš©í•œ Rayserve ê³ ê°€ìš©ì„± í™œì„±í™”\tfalse enable_torchx_etcd\ttorchxìš© etcd í™œì„±í™”\tfalse enable_mpi_operator\tMPI Operator í™œì„±í™”\tfalse enable_aibrix_stack\tAIBrix ìŠ¤íƒ í™œì„±í™”\tfalse aibrix_stack_version\tAIBrix ìŠ¤íƒ ë²„ì „\tv0.2.1 enable_aws_load_balancer_controller\tAWS Load Balancer Controller í™œì„±í™”\ttrue enable_service_mutator_webhook\tAWS Load Balancer Controllerìš© service-mutator ì›¹í›… í™œì„±í™”\tfalse enable_ingress_nginx\tingress-nginx ì• ë“œì˜¨ í™œì„±í™”\ttrue enable_cert_manager\tCert Manager í™œì„±í™”\tfalse enable_slurm_operator\tSlinky Slurm Operator í™œì„±í™” (Cert Manager í¬í•¨)\tfalse  ","version":"Next","tagName":"h3"},{"title":"JupyterHubâ€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#jupyterhub","content":" ë³€ìˆ˜ ì´ë¦„\tì„¤ëª…\tê¸°ë³¸ê°’jupyter_hub_auth_mechanism\tJupyterHubì— ì‚¬ìš©í•  ì¸ì¦ ë©”ì»¤ë‹ˆì¦˜ [dummy | cognito | oauth]\tdummy cognito_custom_domain\tHosted UI ì¸ì¦ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìœ„í•œ Cognito ë„ë©”ì¸ ì ‘ë‘ì‚¬\teks acm_certificate_domain\tACM ì¸ì¦ì„œì— ì‚¬ìš©ë˜ëŠ” ë„ë©”ì¸ ì´ë¦„\t&quot;&quot; jupyterhub_domain\tJupyterHub ë„ë©”ì¸ ì´ë¦„ (cognito ë˜ëŠ” oauth ì‚¬ìš© ì‹œì—ë§Œ)\t&quot;&quot; oauth_jupyter_client_id\tJupyterHubìš© OAuth í´ë¼ì´ì–¸íŠ¸ ID. OAuth ì‚¬ìš© ì‹œì—ë§Œ í•„ìš”\t&quot;&quot; oauth_jupyter_client_secret\tOAuth í´ë¼ì´ì–¸íŠ¸ ì‹œí¬ë¦¿. OAuth ì‚¬ìš© ì‹œì—ë§Œ í•„ìš”\t&quot;&quot; oauth_username_key\tì‚¬ìš©ì ì´ë¦„ì„ ìœ„í•œ OAuth í•„ë“œ (ì˜ˆ: preferred_username). OAuth ì‚¬ìš© ì‹œì—ë§Œ í•„ìš”\t&quot;&quot;  ","version":"Next","tagName":"h3"},{"title":"ì»¤ìŠ¤í…€ ìŠ¤íƒâ€‹","type":1,"pageTitle":"ì†Œê°œ","url":"/ai-on-eks/ko/docs/infra#ì»¤ìŠ¤í…€-ìŠ¤íƒ","content":" ìœ„ì˜ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ìì‹ ì˜ í•„ìš”ì— ë§ëŠ” ìƒˆë¡œìš´ í™˜ê²½ì„ ì‰½ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. infra í´ë”ì— ê°„ë‹¨í•œ blueprint.tfvarsê°€ í¬í•¨ëœ custom í´ë”ê°€ ìˆìŠµë‹ˆë‹¤. ìœ„ì˜ ë³€ìˆ˜ë¥¼ ì ì ˆí•œ ê°’ìœ¼ë¡œ ì¶”ê°€í•˜ë©´ ì›í•˜ëŠ” ì• ë“œì˜¨ì´ ë°°í¬ëœ í™˜ê²½ì„ ìƒì„±í•˜ì—¬ ê¸°í˜¸ì— ë§ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë³€ìˆ˜ë¥¼ ì¶”ê°€í•œ í›„ infra/custom ë£¨íŠ¸ì— ìˆëŠ” install.shë¥¼ ì‹¤í–‰í•˜ì„¸ìš”. ","version":"Next","tagName":"h2"},{"title":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/infra/agents-on-eks","content":"","keywords":"","version":"Next"},{"title":"ì™œ í•„ìš”í•œê°€?â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ì™œ-í•„ìš”í•œê°€","content":" ëŒ€ê·œëª¨ AI ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ê³  ìš´ì˜í•˜ë ¤ë©´ ì¶”ë¡  ì¸í”„ë¼ ì´ìƒì˜ ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ì—ëŠ” ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:  ì†ŒìŠ¤ ì œì–´ ë° CI/CD: ì—ì´ì „íŠ¸ ì½”ë“œ ë° êµ¬ì„±ì˜ ë²„ì „ ê´€ë¦¬ê´€ì¸¡ì„±: ì—ì´ì „íŠ¸ ë™ì‘ ì¶”ì , ì„±ëŠ¥ í‰ê°€ ë° ë¬¸ì œ ë””ë²„ê¹…ì˜êµ¬ ë©”ëª¨ë¦¬: ì„ë² ë”© ì €ì¥ ë° ê²€ìƒ‰ ì¦ê°• ìƒì„±(RAG) í™œì„±í™”ë„êµ¬ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜: MCP(Model Context Protocol) ì„œë²„ ê´€ë¦¬ ë° ê²€ìƒ‰  ì´ ì¸í”„ë¼ëŠ” ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†Œë¥¼ ì‘ì§‘ë ¥ ìˆëŠ” í”Œë«í¼ìœ¼ë¡œ í†µí•©í•˜ì—¬ íŒ€ì´ ì‹ ë¢°ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì—ì´ì „íŠ¸ ê°œë°œì„ ë¹ ë¥´ê²Œ ë°˜ë³µí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì‚¬ìš© ì‚¬ë¡€â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ì‚¬ìš©-ì‚¬ë¡€","content":" ì—ì´ì „íŠ¸ ê°œë°œ: í†µí•©ëœ ì†ŒìŠ¤ ì œì–´ ë° CI/CD íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ AI ì—ì´ì „íŠ¸ë¥¼ ë¹Œë“œí•˜ê³  í…ŒìŠ¤íŠ¸ì—ì´ì „íŠ¸ í‰ê°€: Langfuseë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ ì‹¤í–‰ì„ ì¶”ì í•˜ê³ , ì¶œë ¥ì„ í‰ê°€í•˜ê³ , ì‹œê°„ì— ë”°ë¥¸ ì„±ëŠ¥ì„ ì¶”ì RAG ì• í”Œë¦¬ì¼€ì´ì…˜: Milvusë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì‹ ì¦ê°• ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ì„ë² ë”© ì €ì¥ ë° ê²€ìƒ‰MCP ë„êµ¬ ê´€ë¦¬: ê²Œì´íŠ¸ì›¨ì´ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ í†µí•´ MCP ì„œë²„ ê²€ìƒ‰ ë° ê´€ë¦¬ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ: ê³µìœ  ì¸í”„ë¼ë¡œ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ë°°í¬í•˜ê³  ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜  ","version":"Next","tagName":"h2"},{"title":"ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ì•„í‚¤í…ì²˜","content":" ì´ ì¸í”„ë¼ëŠ” ë‹¤ìŒì„ ìƒì„±í•©ë‹ˆë‹¤:  Amazon VPC: ì—¬ëŸ¬ ê°€ìš© ì˜ì—­ì— ê±¸ì¹œ í¼ë¸”ë¦­ ë° í”„ë¼ì´ë¹— ì„œë¸Œë„·Amazon EKS í´ëŸ¬ìŠ¤í„°: ì¤‘ìš”í•œ ì• ë“œì˜¨ì„ ìœ„í•œ ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ í¬í•¨Karpenter: ì›Œí¬ë¡œë“œ ìš”êµ¬ì— ë”°ë¥¸ ì§€ëŠ¥í˜• ë…¸ë“œ ì˜¤í† ìŠ¤ì¼€ì¼ë§GitLab: ì†ŒìŠ¤ ì œì–´, ì»¨í…Œì´ë„ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë° CI/CD íŒŒì´í”„ë¼ì¸Langfuse: ì—ì´ì „íŠ¸ ê´€ì¸¡ì„±, ì¶”ì  ë° í‰ê°€Milvus: ë²¡í„° ì €ì¥ ë° ìœ ì‚¬ì„± ê²€ìƒ‰MCP Gateway Registry: ë„êµ¬ ê²€ìƒ‰ ë° ê´€ë¦¬  ","version":"Next","tagName":"h2"},{"title":"í•µì‹¬ êµ¬ì„± ìš”ì†Œâ€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#í•µì‹¬-êµ¬ì„±-ìš”ì†Œ","content":" êµ¬ì„± ìš”ì†Œ\tëª©ì GitLab\tì—ì´ì „íŠ¸ ì½”ë“œë¥¼ ìœ„í•œ ì†ŒìŠ¤ ì œì–´, ì»¨í…Œì´ë„ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë° CI/CD Langfuse\tLLM ê´€ì¸¡ì„±, ì¶”ì , í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë° í‰ê°€ Milvus\tì„ë² ë”© ë° ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìœ„í•œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ MCP Gateway Registry\tModel Context Protocol ì„œë²„ì˜ ê²€ìƒ‰ ë° ê´€ë¦¬ Karpenter\tKubernetes ë…¸ë“œ ì˜¤í† ìŠ¤ì¼€ì¼ë§ ArgoCD\tGitOps ì§€ì†ì  ë°°í¬  ","version":"Next","tagName":"h3"},{"title":"ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ì‚¬ì „-ìš”êµ¬-ì‚¬í•­","content":" ","version":"Next","tagName":"h2"},{"title":"ë„ë©”ì¸ ë° ì¸ì¦ì„œ ì„¤ì •â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ë„ë©”ì¸-ë°-ì¸ì¦ì„œ-ì„¤ì •","content":" GitLabì€ ìœ íš¨í•œ TLS ì¸ì¦ì„œê°€ í•„ìš”í•˜ë©°, ì´ë¥¼ ìœ„í•´ì„œëŠ” ë„ë©”ì¸ì„ ì†Œìœ í•´ì•¼ í•©ë‹ˆë‹¤. ê¸°ì¡´ ë„ë©”ì¸ì˜ ì„œë¸Œë„ë©”ì¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Route53 í˜¸ìŠ¤íŒ… ì˜ì—­ ìƒì„± AWS ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ í˜¸ìŠ¤íŒ… ì˜ì—­ì„ ìƒì„±í•˜ì„¸ìš”. ì„œë¸Œë„ë©”ì¸ì˜ ê²½ìš° subdomain.domain.tld íŒ¨í„´ì„ ë”°ë¼ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤. (ì„ íƒ ì‚¬í•­) ì„œë¸Œë„ë©”ì¸ìœ¼ë¡œ êµ¬ì„± ì„œë¸Œë„ë©”ì¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ê¸°ë³¸ ë„ë©”ì¸ì— í˜¸ìŠ¤íŒ… ì˜ì—­ì„ ì„œë¸Œë„ë©”ì¸ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤. ACM ì¸ì¦ì„œ ìƒì„± ACM ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ ë„ë©”ì¸ì— ëŒ€í•œ ì¸ì¦ì„œë¥¼ ìƒì„±í•˜ì„¸ìš”.  ","version":"Next","tagName":"h3"},{"title":"í•„ìš”í•œ ë„êµ¬â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#í•„ìš”í•œ-ë„êµ¬","content":" ì ì ˆí•œ ê¶Œí•œìœ¼ë¡œ êµ¬ì„±ëœ AWS CLITerraform &gt;= 1.0kubectlHelm &gt;= 3.0  ","version":"Next","tagName":"h3"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"1ë‹¨ê³„: ë³µì œ ë° ì´ë™â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#1ë‹¨ê³„-ë³µì œ-ë°-ì´ë™","content":" git clone https://github.com/awslabs/ai-on-eks.git cd ai-on-eks/infra/solutions/agents-on-eks   ","version":"Next","tagName":"h3"},{"title":"2ë‹¨ê³„: ë³€ìˆ˜ êµ¬ì„±â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#2ë‹¨ê³„-ë³€ìˆ˜-êµ¬ì„±","content":" ë„ë©”ì¸ì„ ì„¤ì •í•˜ë ¤ë©´ terraform/blueprint.tfvarsë¥¼ í¸ì§‘í•©ë‹ˆë‹¤:  name = &quot;aioeks-agents&quot; enable_langfuse = true enable_gitlab = true enable_external_dns = true enable_milvus = true enable_mcp_gateway_registry = true max_user_namespaces = 16384 acm_certificate_domain = &quot;agents.example.com&quot; # ë„ë©”ì¸ìœ¼ë¡œ ì—…ë°ì´íŠ¸ allowed_inbound_cidrs = &quot;0.0.0.0/0&quot; # ì¸ë°”ìš´ë“œ IP ì œí•œ   ","version":"Next","tagName":"h3"},{"title":"3ë‹¨ê³„: ë°°í¬â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#3ë‹¨ê³„-ë°°í¬","content":" ./install.sh   ë°°í¬ëŠ” ì•½ 20ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"4ë‹¨ê³„: kubectl êµ¬ì„±â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#4ë‹¨ê³„-kubectl-êµ¬ì„±","content":" ë°°í¬ í›„ í´ëŸ¬ìŠ¤í„°ì— ì•¡ì„¸ìŠ¤í•˜ë„ë¡ kubectlì„ êµ¬ì„±í•©ë‹ˆë‹¤:  aws eks update-kubeconfig --name aioeks-agents --region us-west-2   ","version":"Next","tagName":"h3"},{"title":"ì„œë¹„ìŠ¤ ì•¡ì„¸ìŠ¤â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ì„œë¹„ìŠ¤-ì•¡ì„¸ìŠ¤","content":" ","version":"Next","tagName":"h2"},{"title":"GitLabâ€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#gitlab","content":" GitLabì€ https://gitlab.&lt;your-domain&gt;ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. root ë¹„ë°€ë²ˆí˜¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤:  kubectl get secret gitlab-gitlab-initial-root-password -n gitlab -o jsonpath='{.data.password}' | base64 -d   ","version":"Next","tagName":"h3"},{"title":"Langfuseâ€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#langfuse","content":" í¬íŠ¸ í¬ì›Œë”©ì„ í†µí•´ Langfuseì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤:  kubectl port-forward svc/langfuse 3000:3000 -n langfuse   ê·¸ëŸ° ë‹¤ìŒ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:3000ì„ ì—½ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"Milvusâ€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#milvus","content":" í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ milvus.milvus.svc.cluster.local:19530ìœ¼ë¡œ Milvusì— ì—°ê²°í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"MCP Gateway Registryâ€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#mcp-gateway-registry","content":" MCP Gateway RegistryëŠ” https://mcpregistry.&lt;your-domain&gt;ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"êµ¬ì„± ì˜µì…˜â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#êµ¬ì„±-ì˜µì…˜","content":" ë³€ìˆ˜\tì„¤ëª…\tê¸°ë³¸ê°’name\tí´ëŸ¬ìŠ¤í„° ì´ë¦„\taioeks-agents region\tAWS ë¦¬ì „\tus-west-2 eks_cluster_version\tEKS ë²„ì „\t1.34 acm_certificate_domain\tTLS ì¸ì¦ì„œìš© ë„ë©”ì¸\t&quot;&quot; (í•„ìˆ˜) allowed_inbound_cidrs\të¡œë“œ ë°¸ëŸ°ì„œë¥¼ í†µí•´ í—ˆìš©ë˜ëŠ” CIDR ë²”ìœ„\t0.0.0.0/0 enable_langfuse\tLangfuse ë°°í¬\ttrue enable_gitlab\tGitLab ë°°í¬\ttrue enable_milvus\tMilvus ë°°í¬\ttrue enable_mcp_gateway_registry\tMCP Gateway Registry ë°°í¬\ttrue enable_external_dns\tRoute53ìš© External DNS í™œì„±í™”\ttrue  ","version":"Next","tagName":"h2"},{"title":"ì¸ë°”ìš´ë“œ ì•¡ì„¸ìŠ¤ ì œí•œâ€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ì¸ë°”ìš´ë“œ-ì•¡ì„¸ìŠ¤-ì œí•œ","content":" allowed_inbound_cidrs ë³€ìˆ˜ëŠ” ë¡œë“œ ë°¸ëŸ°ì„œë¥¼ í†µí•´ ì„œë¹„ìŠ¤ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ” IP ë²”ìœ„ë¥¼ ì œì–´í•©ë‹ˆë‹¤. ì¡°ì§ì˜ IP ë²”ìœ„ë¡œ ì œí•œí•˜ì„¸ìš”:  allowed_inbound_cidrs = &quot;10.0.0.0/8,192.168.1.0/24&quot;   CI/CD íŒŒì´í”„ë¼ì¸ì„ ìœ„í•´ CIDRì— ê°œë°œì IPì™€ GitLab Runner ë…¸ë“œ IPê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.  ","version":"Next","tagName":"h3"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ì •ë¦¬","content":" ì¸í”„ë¼ë¥¼ ì‚­ì œí•˜ë ¤ë©´:  cd terraform/_LOCAL ./cleanup.sh   ","version":"Next","tagName":"h2"},{"title":"ë‹¤ìŒ ë‹¨ê³„â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ ì—ì´ì „íŠ¸","url":"/ai-on-eks/ko/docs/infra/agents-on-eks#ë‹¤ìŒ-ë‹¨ê³„","content":" ì—ì´ì „íŠ¸ ì½”ë“œë¥¼ ìœ„í•œ GitLab CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì„±ì¶”ì ì„ ìœ„í•œ Langfuse í”„ë¡œì íŠ¸ ë° API í‚¤ ì„¤ì •ì„ë² ë”© ì €ì¥ì„ ìœ„í•œ Milvus ì»¬ë ‰ì…˜ ìƒì„±ê²Œì´íŠ¸ì›¨ì´ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— MCP ì„œë²„ ë“±ë¡ ","version":"Next","tagName":"h2"},{"title":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/infra/inference","content":"","keywords":"","version":"Next"},{"title":"ë¼ì´í”„ì‚¬ì´í´ ê°œìš”â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ë¼ì´í”„ì‚¬ì´í´-ê°œìš”","content":" ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´ì€ ì„¸ ê°€ì§€ í•µì‹¬ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:    ê° ë‹¨ê³„ëŠ” íŠ¹ì • ê³¼ì œë¥¼ í•´ê²°í•˜ê³  ëŒ€ê·œëª¨ LLM ì¶”ë¡  ì„±ê³µì— í•„ìš”í•œ êµ¬ì„± ìš”ì†Œë¥¼ ì œê³µí•©ë‹ˆë‹¤.    ","version":"Next","tagName":"h2"},{"title":"1ë‹¨ê³„: ì¸í”„ë¼ ì„¤ì •â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#1ë‹¨ê³„-ì¸í”„ë¼-ì„¤ì •","content":" ","version":"Next","tagName":"h2"},{"title":"ì¸í”„ë¼ê°€ ì¤‘ìš”í•œ ì´ìœ â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ì¸í”„ë¼ê°€-ì¤‘ìš”í•œ-ì´ìœ ","content":" LLMì„ ë°°í¬í•˜ê¸° ì „ì— AI/ML ì›Œí¬ë¡œë“œì˜ ê³ ìœ í•œ ìš”êµ¬ì‚¬í•­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ê²¬ê³ í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì¸í”„ë¼ê°€ í•„ìš”í•©ë‹ˆë‹¤:  GPU/Neuron ë¦¬ì†ŒìŠ¤ ê´€ë¦¬: LLMì—ëŠ” ì ì ˆí•œ ë””ë°”ì´ìŠ¤ í”ŒëŸ¬ê·¸ì¸ê³¼ ë“œë¼ì´ë²„ê°€ ìˆëŠ” íŠ¹ìˆ˜ ê°€ì†ê¸°(NVIDIA GPU ë˜ëŠ” AWS Inferentia/Trainium ì¹©)ê°€ í•„ìš”í•©ë‹ˆë‹¤ì˜¤í† ìŠ¤ì¼€ì¼ë§ ê¸°ëŠ¥: ë¹„ìš©ì„ ìµœì í™”í•˜ë©´ì„œ ë‹¤ì–‘í•œ ì¶”ë¡  ìˆ˜ìš”ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë™ì  ì›Œí¬ë¡œë“œ ìŠ¤ì¼€ì¼ë§ê´€ì¸¡ì„± ê¸°ë°˜: GPU/Neuron í™œìš©ë¥ , ëª¨ë¸ ì„±ëŠ¥ ë° ì‹œìŠ¤í…œ ìƒíƒœì— ëŒ€í•œ ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘ë¶„ì‚° ì»´í“¨íŒ… ì§€ì›: ëª¨ë¸ì´ ë‹¨ì¼ ë…¸ë“œ ìš©ëŸ‰ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ë©€í‹° ë…¸ë“œ ì¶”ë¡  ì¸í”„ë¼  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜: ì¶”ë¡  ì¤€ë¹„ í´ëŸ¬ìŠ¤í„°â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ì†”ë£¨ì…˜-ì¶”ë¡ -ì¤€ë¹„-í´ëŸ¬ìŠ¤í„°","content":" ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°ëŠ” AI/ML ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ìœ„í•´ íŠ¹ë³„íˆ ì„¤ê³„ëœ ì‚¬ì „ êµ¬ì„±ëœ ì¸í”„ë¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ì œê³µ ë‚´ìš©â€‹  ì‚¬ì „ ì„¤ì¹˜ëœ êµ¬ì„± ìš”ì†Œ: ë¶„ì‚° Ray ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ KubeRay Operatorë©€í‹° ë…¸ë“œ ë¶„ì‚° ì¶”ë¡ ì„ ìœ„í•œ LeaderWorkerSetGPU ê´€ë¦¬ë¥¼ ìœ„í•œ NVIDIA Device PluginInferentia/Trainium ì§€ì›ì„ ìœ„í•œ AWS Neuron Device Pluginì§€ëŠ¥í˜• ë…¸ë“œ ì˜¤í† ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ Karpenter ë‚´ì¥ ê´€ì¸¡ì„±: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì„ ìœ„í•œ PrometheusAI/ML ì „ìš© ëŒ€ì‹œë³´ë“œê°€ ìˆëŠ” GrafanaGPU ë©”íŠ¸ë¦­ì„ ìœ„í•œ DCGM Exporterì‹œìŠ¤í…œ ìˆ˜ì¤€ ë©”íŠ¸ë¦­ì„ ìœ„í•œ Node Exporter AIBrix í†µí•©: ê³ ê¸‰ ì¶”ë¡  ìµœì í™” ê¸°ëŠ¥íŠ¸ë˜í”½ ê´€ë¦¬ë¥¼ ìœ„í•œ ê²Œì´íŠ¸ì›¨ì´ ë° ë¼ìš°íŒ…ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë„êµ¬  ì£¼ìš” ê³ ë ¤ì‚¬í•­â€‹  ì¸í”„ë¼ë¥¼ ì„¤ì •í•  ë•Œ ë‹¤ìŒì„ ê³ ë ¤í•˜ì„¸ìš”:  í•˜ë“œì›¨ì–´ ì„ íƒ: ëª¨ë¸ ìš”êµ¬ì‚¬í•­ê³¼ ë¹„ìš© ì œì•½ì— ë”°ë¼ NVIDIA GPU(P4d, P5, G5)ì™€ AWS Neuron(Inf2, Trn1) ì¤‘ ì„ íƒìŠ¤ì¼€ì¼ë§ ì „ëµ: ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ë‹¨ì¼ ë…¸ë“œ ë˜ëŠ” ë©€í‹° ë…¸ë“œ ì¶”ë¡  í•„ìš” ì—¬ë¶€ ê²°ì •ë„¤íŠ¸ì›Œí¬ êµ¬ì„±: ëª¨ë¸ ë¡œë”© ë° ì¶”ë¡  íŠ¸ë˜í”½ì„ ìœ„í•œ ì¶©ë¶„í•œ ëŒ€ì—­í­ìœ¼ë¡œ ì ì ˆí•œ VPC ì„¤ì • ë³´ì¥ìŠ¤í† ë¦¬ì§€ ìš”êµ¬ì‚¬í•­: ëª¨ë¸ í¬ê¸° ë° ì•¡ì„¸ìŠ¤ íŒ¨í„´ì— ë”°ë¼ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ìŠ¤í† ë¦¬ì§€(S3, EFS ë˜ëŠ” FSx) ê³„íš  ì‹œì‘í•˜ê¸°â€‹  ì¸í”„ë¼ë¥¼ í”„ë¡œë¹„ì €ë‹í•˜ë ¤ë©´ ì¶”ë¡  ì¤€ë¹„ í´ëŸ¬ìŠ¤í„° ë°°í¬ ê°€ì´ë“œë¥¼ ë”°ë¥´ì„¸ìš”.    ","version":"Next","tagName":"h3"},{"title":"2ë‹¨ê³„: ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#2ë‹¨ê³„-ëª¨ë¸-ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"ë°°í¬ íŒ¨í„´ì´ ì¤‘ìš”í•œ ì´ìœ â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ë°°í¬-íŒ¨í„´ì´-ì¤‘ìš”í•œ-ì´ìœ ","content":" ì¸í”„ë¼ê°€ ì¤€ë¹„ë˜ë©´ LLM ë°°í¬ì—ëŠ” ë‹¤ìŒì— ëŒ€í•œ ì‹ ì¤‘í•œ ê³ ë ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤:  í”„ë ˆì„ì›Œí¬ ì„ íƒ: ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬(vLLM, Ray-vLLM, Triton)ëŠ” ì„±ëŠ¥, ê¸°ëŠ¥ ë° ë³µì¡ì„±ì—ì„œ ì„œë¡œ ë‹¤ë¥¸ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì œê³µëª¨ë¸ í˜¸í™˜ì„±: ëª¨ë“  ëª¨ë¸ì´ ëª¨ë“  í”„ë ˆì„ì›Œí¬ì—ì„œ ì‘ë™í•˜ëŠ” ê²ƒì€ ì•„ë‹˜; ì¼ë¶€ëŠ” íŠ¹ì • ìµœì í™” í•„ìš”ë¦¬ì†ŒìŠ¤ í• ë‹¹: ì ì ˆí•œ GPU/Neuron ë©”ëª¨ë¦¬ í• ë‹¹ ë° ìš”ì²­/ì œí•œ êµ¬ì„±ìŠ¤ì¼€ì¼ë§ ë™ì‘: ì˜¤í† ìŠ¤ì¼€ì¼ë§ì´ ìˆëŠ” ë‹¨ì¼ ë ˆí”Œë¦¬ì¹´ vs ë‹¤ì¤‘ ë ˆí”Œë¦¬ì¹´ ë°°í¬  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜: ì¶”ë¡  ì°¨íŠ¸â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ì†”ë£¨ì…˜-ì¶”ë¡ -ì°¨íŠ¸","content":" AI on EKS ì¶”ë¡  ì°¨íŠ¸ëŠ” ì¸ê¸° ëª¨ë¸ì„ ìœ„í•œ ì‚¬ì „ êµ¬ì„±ëœ ê°’ì´ í¬í•¨ëœ Helm ê¸°ë°˜ ë°°í¬ë¥¼ ì œê³µí•˜ë©°, ì—¬ëŸ¬ ë°°í¬ í”„ë ˆì„ì›Œí¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.  ì§€ì› í”„ë ˆì„ì›Œí¬â€‹  vLLM: ìµœì í™”ëœ CUDA ì»¤ë„ë¡œ ë¹ ë¥¸ ë‹¨ì¼ ë…¸ë“œ ì¶”ë¡ Ray-vLLM: ì˜¤í† ìŠ¤ì¼€ì¼ë§ ë° ë¡œë“œ ë°¸ëŸ°ì‹±ì´ ìˆëŠ” ë¶„ì‚° ì¶”ë¡ Triton-vLLM: ê³ ê¸‰ ê¸°ëŠ¥ì´ ìˆëŠ” í”„ë¡œë•ì…˜ ë ˆë”” ì¶”ë¡  ì„œë²„LeaderWorkerSet-vLLM: ë‹¨ì¼ ë…¸ë“œì— ë§ì§€ ì•ŠëŠ” ëª¨ë¸ì„ ìœ„í•œ ë©€í‹° ë…¸ë“œ ì¶”ë¡ Diffusers: ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì„ ìœ„í•œ Hugging Face Diffusers  ì˜ˆì œ: Llama 3.2 1B ë°°í¬â€‹  ì¶”ë¡  ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ Llama ëª¨ë¸ì„ ë°°í¬í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤:  1ë‹¨ê³„: Hugging Face í† í° ì‹œí¬ë¦¿ ìƒì„±  kubectl create secret generic hf-token \\ --from-literal=token=your_huggingface_token   2ë‹¨ê³„: ëª¨ë¸ ë°°í¬  # GPUì—ì„œ vLLMìœ¼ë¡œ Llama 3.2 1B ë°°í¬ helm install llama-inference ./blueprints/inference/inference-charts \\ --values ./blueprints/inference/inference-charts/values-llama-32-1b-vllm.yaml   3ë‹¨ê³„: ë°°í¬ í™•ì¸  # íŒŒë“œ ìƒíƒœ í™•ì¸ kubectl get pods -l app=llama-inference # ì„œë¹„ìŠ¤ ì—”ë“œí¬ì¸íŠ¸ í™•ì¸ kubectl get svc llama-inference   4ë‹¨ê³„: ì¶”ë¡  í…ŒìŠ¤íŠ¸  # ì„œë¹„ìŠ¤ì— í¬íŠ¸ í¬ì›Œë”© kubectl port-forward svc/llama-inference 8000:8000 # í…ŒìŠ¤íŠ¸ ìš”ì²­ ì „ì†¡ curl http://localhost:8000/v1/completions \\ -H &quot;Content-Type: application/json&quot; \\ -d '{ &quot;model&quot;: &quot;meta-llama/Llama-3.2-1B&quot;, &quot;prompt&quot;: &quot;ì–‘ì ì»´í“¨íŒ…ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”:&quot;, &quot;max_tokens&quot;: 100 }'   ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ì „ êµ¬ì„± ëª¨ë¸â€‹  ì¶”ë¡  ì°¨íŠ¸ì—ëŠ” ë‹¤ìŒ ëª¨ë¸ì„ ìœ„í•œ ì¦‰ì‹œ ë°°í¬ ê°€ëŠ¥í•œ êµ¬ì„±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:  ì–¸ì–´ ëª¨ë¸:  DeepSeek R1 Distill Llama 8BLlama 3.2 1B, Llama 4 Scout 17BMistral Small 24BGPT OSS 20BQwen3 1.7B  Diffusion ëª¨ë¸:  FLUX.1 SchnellStable Diffusion XL, Stable Diffusion 3.5Kolors, OmniGen  Neuron ìµœì í™”:  AWS Inferentiaì—ì„œì˜ Llama 2 13B  ì£¼ìš” ê³ ë ¤ì‚¬í•­â€‹  ëª¨ë¸ì„ ë°°í¬í•  ë•Œ ë‹¤ìŒì„ ê³ ë ¤í•˜ì„¸ìš”:  ëª¨ë¸ í¬ê¸° vs í•˜ë“œì›¨ì–´: ì„ íƒí•œ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì´ ëª¨ë¸ì— ì¶©ë¶„í•œ GPU/Neuron ë©”ëª¨ë¦¬ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸ë°°ì¹˜ í¬ê¸° êµ¬ì„±: ìµœì ì˜ ì²˜ë¦¬ëŸ‰ vs ì§€ì—° ì‹œê°„ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ìœ„í•´ ë°°ì¹˜ í¬ê¸° íŠœë‹ì–‘ìí™” ì˜µì…˜: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ ì–‘ìí™”ëœ ëª¨ë¸(INT8, INT4) ì‚¬ìš© ê³ ë ¤ë ˆí”Œë¦¬ì¹´ ìˆ˜: ë‹¨ì¼ ë ˆí”Œë¦¬ì¹´ë¡œ ì‹œì‘í•˜ê³  ê´€ì°°ëœ ë¶€í•˜ì— ë”°ë¼ í™•ì¥í—¬ìŠ¤ ì²´í¬: ì ì ˆí•œ liveness ë° readiness í”„ë¡œë¸Œ êµ¬ì„±  ì‹œì‘í•˜ê¸°â€‹  ìƒì„¸í•œ êµ¬ì„± ì˜µì…˜ê³¼ ê³ ê¸‰ ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤ëŠ” ì¶”ë¡  ì°¨íŠ¸ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.    ","version":"Next","tagName":"h3"},{"title":"3ë‹¨ê³„: ìµœì í™”â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#3ë‹¨ê³„-ìµœì í™”","content":" ","version":"Next","tagName":"h2"},{"title":"ìµœì í™”ê°€ ì¤‘ìš”í•œ ì´ìœ â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ìµœì í™”ê°€-ì¤‘ìš”í•œ-ì´ìœ ","content":" ëª¨ë¸ì„ ë°°í¬í•œ í›„ ìµœì í™”ëŠ” ë‹¤ìŒì„ ë³´ì¥í•©ë‹ˆë‹¤:  ë¹„ìš© íš¨ìœ¨ì„±: ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ë©´ì„œ ì¸í”„ë¼ ë¹„ìš© ìµœì†Œí™”ì„±ëŠ¥ íŠœë‹: ëª©í‘œ ì§€ì—° ì‹œê°„ ë° ì²˜ë¦¬ëŸ‰ SLO ë‹¬ì„±ë¦¬ì†ŒìŠ¤ í™œìš©: GPU/Neuron í™œìš©ë¥ ì„ ê·¹ëŒ€í™”í•˜ì—¬ ê³ ê°€ í•˜ë“œì›¨ì–´ì—ì„œ ìµœëŒ€ ê°€ì¹˜ í™•ë³´ìš´ì˜ ìš°ìˆ˜ì„±: ëª¨ë‹ˆí„°ë§, ì•Œë¦¼ ë° ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ëª¨ë²” ì‚¬ë¡€ êµ¬í˜„  ","version":"Next","tagName":"h3"},{"title":"ìµœì í™” ê¸°ë²•â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ìµœì í™”-ê¸°ë²•","content":" ê°€ì´ë˜ìŠ¤ ì„¹ì…˜ì€ í”„ë¡œë•ì…˜ AI/ML ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ í¬ê´„ì ì¸ ëª¨ë²” ì‚¬ë¡€ì™€ ìµœì í™” ê¸°ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ê° ê¸°ë²•ì€ íŠ¹ì • ì„±ëŠ¥ ë˜ëŠ” ë¹„ìš© ê³¼ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤:  ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œê°„ ìµœì í™”â€‹  ëª¨ë¸ ë¡œë”© ì‹œê°„ì„ ìˆ˜ ë¶„ì—ì„œ ìˆ˜ ì´ˆë¡œ ì¤„ì—¬ ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì‘ë‹µì„±ê³¼ ê°œë°œ ë°˜ë³µ ì†ë„ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.  ì£¼ìš” ê¸°ë²•:  ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸°: í’€ ì‹œê°„ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ìµœì í™”ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë¶„ë¦¬: ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì—ì„œ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¶„ë¦¬í’€ í”„ë¡œì„¸ìŠ¤ ê°€ì†í™”: containerd ìŠ¤ëƒ…ìƒ·í„° ë° ì´ë¯¸ì§€ í”„ë¦¬íŒ¨ì¹­ ì‚¬ìš©ë…¸ë“œì— í”„ë¦¬íŒ¨ì¹˜: ì›Œí¬ë¡œë“œ ìŠ¤ì¼€ì¤„ë§ ì „ì— ëª¨ë¸ ì´ë¯¸ì§€ë¡œ ë…¸ë“œ ì˜ˆì—´  íš¨ê³¼: ì‹œì‘ ì‹œê°„ì„ 60-80% ë‹¨ì¶•í•˜ì—¬ ë” ë¹ ë¥¸ ì˜¤í† ìŠ¤ì¼€ì¼ë§ê³¼ ë‚®ì€ ë¹„ìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.  ì‚¬ìš© ì‹œê¸°: ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì›Œí¬ë¡œë“œ, ê°œë°œ í™˜ê²½ ë° ë¹„ìš©ì— ë¯¼ê°í•œ ë°°í¬ì— ì¤‘ìš”í•©ë‹ˆë‹¤.    ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹ (DRA)â€‹  ì„¸ë°€í•œ ë¦¬ì†ŒìŠ¤ ì œì–´ì™€ í–¥ìƒëœ í™œìš©ë¥ ì„ ìœ„í•œ ì°¨ì„¸ëŒ€ GPU ìŠ¤ì¼€ì¤„ë§ì…ë‹ˆë‹¤.  ì£¼ìš” ê¸°ëŠ¥:  ì„¸ë°€í•œ GPU ì œì–´: ì „ì²´ ë””ë°”ì´ìŠ¤ ëŒ€ì‹  íŠ¹ì • GPU ë©”ëª¨ë¦¬ ì–‘ ìš”ì²­ì›Œí¬ë¡œë“œë³„ ê³µìœ : íŒŒë“œë³„ë¡œ MPS, íƒ€ì„ ìŠ¬ë¼ì´ì‹±, MIG ë˜ëŠ” ì „ìš© ëª¨ë“œ ì„ íƒí† í´ë¡œì§€ ì¸ì‹ ìŠ¤ì¼€ì¤„ë§: NVLink ë° GPU ì¸í„°ì»¤ë„¥íŠ¸ ìµœì í™”P6e í•„ìˆ˜: Amazon EC2 P6e-GB200 UltraServerì— í•„ìˆ˜  íš¨ê³¼: GPU í™œìš©ë¥ ì„ 30-40%ì—ì„œ 70-90%ë¡œ ì¦ê°€ì‹œì¼œ ì¸í”„ë¼ ë¹„ìš©ì„ 50% ì´ìƒ ì ˆê°í•©ë‹ˆë‹¤.  ì‚¬ìš© ì‹œê¸°:  ë‹¨ì¼ GPUì—ì„œ ì—¬ëŸ¬ ì†Œê·œëª¨ ëª¨ë¸ ì‹¤í–‰ì •ë°€í•œ GPU ë©”ëª¨ë¦¬ í• ë‹¹ í•„ìš”ìµœì‹  GPU ì¸ìŠ¤í„´ìŠ¤(P6e) ì‚¬ìš©ì›Œí¬ë¡œë“œ ì „ì²´ì—ì„œ GPU í™œìš©ë¥  ìµœì í™”    ê´€ì¸¡ì„± ë° ëª¨ë‹ˆí„°ë§â€‹  ì„±ëŠ¥ ìµœì í™” ë° ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì¶”ë¡  ì›Œí¬ë¡œë“œì˜ ì¢…í•©ì ì¸ ê°€ì‹œì„±ì…ë‹ˆë‹¤.  í¬í•¨ ë‚´ìš©:  GPU/Neuron ë©”íŠ¸ë¦­: í™œìš©ë¥ , ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë° ì˜¨ë„ ì¶”ì ëª¨ë¸ ì„±ëŠ¥: ì§€ì—° ì‹œê°„, ì²˜ë¦¬ëŸ‰ ë° ì˜¤ë¥˜ìœ¨ ëª¨ë‹ˆí„°ë§ì‹œìŠ¤í…œ ìƒíƒœ: CPU, ë©”ëª¨ë¦¬, ë„¤íŠ¸ì›Œí¬ ë° ìŠ¤í† ë¦¬ì§€ ë©”íŠ¸ë¦­ì»¤ìŠ¤í…€ ëŒ€ì‹œë³´ë“œ: ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ì‚¬ì „ êµ¬ì¶•ëœ Grafana ëŒ€ì‹œë³´ë“œ  ì£¼ìš” ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­:  GPU í™œìš©ë¥  (ë¹„ìš© íš¨ìœ¨ì„±ì„ ìœ„í•œ ëª©í‘œ: &gt;70%)ì¶”ë¡  ì§€ì—° ì‹œê°„ (P50, P95, P99)ì´ˆë‹¹ ìš”ì²­ ìˆ˜ (ì²˜ë¦¬ëŸ‰)í ê¹Šì´ (ì˜¤í† ìŠ¤ì¼€ì¼ë§ ê²°ì •ìš©)ëª¨ë¸ ë¡œë”© ì‹œê°„  íš¨ê³¼: ë°ì´í„° ê¸°ë°˜ ìµœì í™” ê²°ì •ê³¼ ì‚¬ì „ ë¬¸ì œ ê°ì§€ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.    ë„¤íŠ¸ì›Œí‚¹ ìµœì í™”â€‹  ê³ ì²˜ë¦¬ëŸ‰ ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí¬ êµ¬ì„±ì„ ìµœì í™”í•©ë‹ˆë‹¤.  ì£¼ìš” ì˜ì—­:  VPC ì„¤ê³„: ì ì ˆí•œ ì„œë¸Œë„· í¬ê¸° ì¡°ì • ë° ê°€ìš© ì˜ì—­ ë¶„ë°°ë¡œë“œ ë°¸ëŸ°ì‹±: ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìœ„í•œ ALB/NLB êµ¬ì„±ì„œë¹„ìŠ¤ ë©”ì‹œ: ê³ ê¸‰ íŠ¸ë˜í”½ ê´€ë¦¬ë¥¼ ìœ„í•œ Istio/Linkerdë„¤íŠ¸ì›Œí¬ ì •ì±…: ì›Œí¬ë¡œë“œ ê°„ ë³´ì•ˆ ë° ê²©ë¦¬  íš¨ê³¼: ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œê°„ì„ 20-40% ì¤„ì´ê³  ì•ˆì •ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.    EKS ëª¨ë²” ì‚¬ë¡€â€‹  ë³´ì•ˆ, ì•ˆì •ì„±, ì„±ëŠ¥ ë° ë¹„ìš© ìµœì í™”ë¥¼ ìœ„í•œ ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤.  ë‹¤ë£¨ëŠ” ì£¼ì œ:  ë³´ì•ˆ ë° ê·œì • ì¤€ìˆ˜ì•ˆì •ì„± ë° ê°€ìš©ì„±ì„±ëŠ¥ ìµœì í™”ë¹„ìš© ìµœì í™”    ","version":"Next","tagName":"h3"},{"title":"ìµœì í™” ì›Œí¬í”Œë¡œìš°â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ìµœì í™”-ì›Œí¬í”Œë¡œìš°","content":" ì¶”ë¡  ë°°í¬ë¥¼ ìµœì í™”í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ì›Œí¬í”Œë¡œìš°ë¥¼ ë”°ë¥´ì„¸ìš”:    ì‹œì‘í•˜ê¸°â€‹  ê° ìµœì í™” ê¸°ë²•ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ë ¤ë©´ ê°€ì´ë˜ìŠ¤ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.    ","version":"Next","tagName":"h3"},{"title":"ì „ì²´ ë¼ì´í”„ì‚¬ì´í´ ì˜ˆì œâ€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ì „ì²´-ë¼ì´í”„ì‚¬ì´í´-ì˜ˆì œ","content":" ì¸í”„ë¼ë¶€í„° ìµœì í™”ëœ í”„ë¡œë•ì…˜ê¹Œì§€ Llama 3.2 1Bë¥¼ ë°°í¬í•˜ëŠ” ì „ì²´ ì˜ˆì œì…ë‹ˆë‹¤:  ","version":"Next","tagName":"h2"},{"title":"1ë‹¨ê³„: ì¸í”„ë¼ ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#1ë‹¨ê³„-ì¸í”„ë¼-ë°°í¬","content":" # ë¦¬í¬ì§€í† ë¦¬ í´ë¡  git clone https://github.com/awslabs/ai-on-eks.git cd ai-on-eks/infra/solutions/inference-ready-cluster # ë°°í¬ êµ¬ì„± cp blueprint.tfvars.example blueprint.tfvars # blueprint.tfvarsë¥¼ ì„¤ì •ì— ë§ê²Œ í¸ì§‘ # ì¸í”„ë¼ ë°°í¬ terraform init terraform apply -var-file=blueprint.tfvars   ","version":"Next","tagName":"h3"},{"title":"2ë‹¨ê³„: ëª¨ë¸ ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#2ë‹¨ê³„-ëª¨ë¸-ë°°í¬-1","content":" # kubeconfig ì—…ë°ì´íŠ¸ aws eks update-kubeconfig --name &lt;cluster-name&gt; --region &lt;region&gt; # Hugging Face í† í° ì‹œí¬ë¦¿ ìƒì„± kubectl create secret generic hf-token \\ --from-literal=token=&lt;your-token&gt; # Llama 3.2 1B ë°°í¬ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update helm install qwen3-1-7b ai-on-eks/inference-charts \\ -f https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-llama-32-1b-vllm.yaml   ","version":"Next","tagName":"h3"},{"title":"3ë‹¨ê³„: ìµœì í™” (ì§€ì†ì )â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#3ë‹¨ê³„-ìµœì í™”-ì§€ì†ì ","content":" # ëª¨ë‹ˆí„°ë§ì„ ìœ„í•´ Grafana ì ‘ê·¼ kubectl port-forward -n monitoring svc/kube-prometheus-stack-grafana 3000:80 # GPU í™œìš©ë¥  ëª¨ë‹ˆí„°ë§ ë° ë ˆí”Œë¦¬ì¹´ ì¡°ì • kubectl scale deployment llama-inference --replicas=3 # í ê¹Šì´ ê¸°ë°˜ ì˜¤í† ìŠ¤ì¼€ì¼ë§ í™œì„±í™” kubectl autoscale deployment llama-inference \\ --min=2 --max=10 --cpu-percent=70     ","version":"Next","tagName":"h3"},{"title":"ë‹¤ìŒ ë‹¨ê³„â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ë‹¤ìŒ-ë‹¨ê³„","content":" ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´ ì „ì²´ë¥¼ ì´í•´í–ˆìœ¼ë‹ˆ, ì¶œë°œì ì„ ì„ íƒí•˜ì„¸ìš”:  EKSê°€ ì²˜ìŒì´ì‹ ê°€ìš”? ì¸í”„ë¼ ì„¤ì •ë¶€í„° ì‹œì‘í•˜ì„¸ìš”ì¸í”„ë¼ê°€ ìˆìœ¼ì‹ ê°€ìš”? ëª¨ë¸ ë°°í¬ë¡œ ë°”ë¡œ ì´ë™í•˜ì„¸ìš”ëª¨ë¸ì´ ì‹¤í–‰ ì¤‘ì¸ê°€ìš”? ê°€ì´ë˜ìŠ¤ë¡œ ìµœì í™”í•˜ì„¸ìš”  ","version":"Next","tagName":"h2"},{"title":"ì¶”ê°€ ë¦¬ì†ŒìŠ¤â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ì¶”ê°€-ë¦¬ì†ŒìŠ¤","content":" AI on EKS GitHub ë¦¬í¬ì§€í† ë¦¬AWS EKS ë¬¸ì„œNVIDIA GPU OperatorAWS Neuron ë¬¸ì„œvLLM ë¬¸ì„œRay ë¬¸ì„œ  ","version":"Next","tagName":"h2"},{"title":"ì»¤ë®¤ë‹ˆí‹° ë° ì§€ì›â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œì˜ ëª¨ë¸ ì¶”ë¡  ë¼ì´í”„ì‚¬ì´í´","url":"/ai-on-eks/ko/docs/infra/inference#ì»¤ë®¤ë‹ˆí‹°-ë°-ì§€ì›","content":" GitHub Issues - ë²„ê·¸ ë¦¬í¬íŠ¸ ë˜ëŠ” ê¸°ëŠ¥ ìš”ì²­GitHub Discussions - ì§ˆë¬¸ ë° ê²½í—˜ ê³µìœ AWS re:Post - AWS ì „ë¬¸ê°€ ë° ì»¤ë®¤ë‹ˆí‹°ì˜ ë„ì›€ ë°›ê¸° ","version":"Next","tagName":"h2"},{"title":"EKS ê¸°ë°˜ AIBrix","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/infra/inference/aibrix","content":"","keywords":"","version":"Next"},{"title":"AIBrixë€?â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ AIBrix","url":"/ai-on-eks/ko/docs/infra/inference/aibrix#aibrixë€","content":" AIBrixëŠ” í™•ì¥ ê°€ëŠ¥í•œ GenAI ì¶”ë¡  ì¸í”„ë¼ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ë¹Œë”© ë¸”ë¡ì„ ì œê³µí•˜ë„ë¡ ì„¤ê³„ëœ ì˜¤í”ˆì†ŒìŠ¤ ì´ë‹ˆì…”í‹°ë¸Œì…ë‹ˆë‹¤. AIBrixëŠ” íŠ¹íˆ ì—”í„°í”„ë¼ì´ì¦ˆ ìš”êµ¬ ì‚¬í•­ì— ë§ì¶¤í™”ëœ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ì¶”ë¡ ì„ ë°°í¬, ê´€ë¦¬ ë° í™•ì¥í•˜ëŠ” ë° ìµœì í™”ëœ í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” ê¸°ëŠ¥ ë° ì´ì â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ AIBrix","url":"/ai-on-eks/ko/docs/infra/inference/aibrix#ì£¼ìš”-ê¸°ëŠ¥-ë°-ì´ì ","content":" LLM ê²Œì´íŠ¸ì›¨ì´ ë° ë¼ìš°íŒ…: ì—¬ëŸ¬ ëª¨ë¸ê³¼ ë³µì œë³¸ì— ê±¸ì³ íŠ¸ë˜í”½ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  ì§€ì‹œí•©ë‹ˆë‹¤.ê³ ë°€ë„ LoRA ê´€ë¦¬: ëª¨ë¸ì˜ ê²½ëŸ‰, ì €ë­í¬ ì ì‘ì— ëŒ€í•œ ê°„ì†Œí™”ëœ ì§€ì›.ë¶„ì‚° ì¶”ë¡ : ì—¬ëŸ¬ ë…¸ë“œì— ê±¸ì³ ëŒ€ê·œëª¨ ì›Œí¬ë¡œë“œë¥¼ ì²˜ë¦¬í•˜ëŠ” í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜.LLM ì•± ë§ì¶¤í˜• ì˜¤í† ìŠ¤ì¼€ì¼ëŸ¬: ì‹¤ì‹œê°„ ìˆ˜ìš”ì— ë”°ë¼ ì¶”ë¡  ë¦¬ì†ŒìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ í™•ì¥í•©ë‹ˆë‹¤.í†µí•© AI ëŸ°íƒ€ì„: ë©”íŠ¸ë¦­ í‘œì¤€í™”, ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ê´€ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë‹¤ëª©ì  ì‚¬ì´ë“œì¹´.ì´ê¸°ì¢… GPU ì¶”ë¡ : ì´ê¸°ì¢… GPUë¥¼ ì‚¬ìš©í•œ ë¹„ìš© íš¨ìœ¨ì ì¸ SLO ê¸°ë°˜ LLM ì¶”ë¡ .GPU í•˜ë“œì›¨ì–´ ì¥ì•  ê°ì§€: GPU í•˜ë“œì›¨ì–´ ë¬¸ì œì˜ ì‚¬ì „ ê°ì§€.  ì†”ë£¨ì…˜ ë°°í¬ ğŸ‘ˆ  ë°°í¬ í™•ì¸ ğŸ‘ˆ  ì •ë¦¬ ğŸ‘ˆ ","version":"Next","tagName":"h3"},{"title":"ë¬¸ì œ í•´ê²°","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting","content":"","keywords":"","version":"Next"},{"title":"ì˜¤ë¥˜: local-exec provisioner errorâ€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ì˜¤ë¥˜-local-exec-provisioner-error","content":" local-exec provisioner ì‹¤í–‰ ì¤‘ ë‹¤ìŒ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°:  Error: local-exec provisioner error \\ with module.eks-blueprints.module.emr_on_eks[&quot;data_team_b&quot;].null_resource.update_trust_policy,\\ on .terraform/modules/eks-blueprints/modules/emr-on-eks/main.tf line 105, in resource &quot;null_resource&quot; \\ &quot;update_trust_policy&quot;:â”‚ 105: provisioner &quot;local-exec&quot; {â”‚ â”‚ Error running command 'set -eâ”‚ â”‚ aws emr-containers update-role-trust-policy \\ â”‚ --cluster-name emr-on-eks \\â”‚ --namespace emr-data-team-b \\â”‚ --role-name emr-on-eks-emr-eks-data-team-b   ","version":"Next","tagName":"h2"},{"title":"EKS ê¸°ë°˜ EMR NVIDIA RAPIDS Accelerator for Apache Spark","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/infra/misc/emr-spark-rapids","content":"","keywords":"","version":"Next"},{"title":"NVIDIA RAPIDS Accelerator for Apache Sparkì— ëŒ€í•œ EMR ì§€ì›â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ EMR NVIDIA RAPIDS Accelerator for Apache Spark","url":"/ai-on-eks/ko/docs/infra/misc/emr-spark-rapids#nvidia-rapids-accelerator-for-apache-sparkì—-ëŒ€í•œ-emr-ì§€ì›","content":" Amazon EMRê³¼ NVIDIA RAPIDS Accelerator for Apache Sparkì˜ í†µí•© Amazon EMR on EKSëŠ” ì´ì œ NVIDIA RAPIDS Accelerator for Apache Sparkì™€ í•¨ê»˜ GPU ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì‚¬ìš©ì— ëŒ€í•œ ì§€ì›ì„ í™•ì¥í•©ë‹ˆë‹¤. ì¸ê³µ ì§€ëŠ¥(AI) ë° ë¨¸ì‹  ëŸ¬ë‹(ML)ì˜ ì‚¬ìš©ì´ ë°ì´í„° ë¶„ì„ ì˜ì—­ì—ì„œ ê³„ì† í™•ì¥ë¨ì— ë”°ë¼ GPUê°€ ì œê³µí•  ìˆ˜ ìˆëŠ” ë¹ ë¥´ê³  ë¹„ìš© íš¨ìœ¨ì ì¸ ë°ì´í„° ì²˜ë¦¬ì— ëŒ€í•œ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. NVIDIA RAPIDS Accelerator for Apache Sparkë¥¼ í†µí•´ ì‚¬ìš©ìëŠ” GPUì˜ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ í™œìš©í•˜ì—¬ ìƒë‹¹í•œ ì¸í”„ë¼ ë¹„ìš© ì ˆê°ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ê¸°ëŠ¥â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ EMR NVIDIA RAPIDS Accelerator for Apache Spark","url":"/ai-on-eks/ko/docs/infra/misc/emr-spark-rapids#ê¸°ëŠ¥","content":" ì£¼ìš” ê¸°ëŠ¥ ë°ì´í„° ì¤€ë¹„ ì‘ì—…ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ê²½í—˜í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì˜ í›„ì† ë‹¨ê³„ë¡œ ë¹ ë¥´ê²Œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ í›ˆë ¨ì„ ê°€ì†í™”í•  ë¿ë§Œ ì•„ë‹ˆë¼ ë°ì´í„° ê³¼í•™ìì™€ ì—”ì§€ë‹ˆì–´ê°€ ìš°ì„ ìˆœìœ„ ì‘ì—…ì— ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. Spark 3ì€ ë°ì´í„° ìˆ˜ì§‘ì—ì„œ ëª¨ë¸ í›ˆë ¨, ì‹œê°í™”ì— ì´ë¥´ê¸°ê¹Œì§€ ì—”ë“œíˆ¬ì—”ë“œ íŒŒì´í”„ë¼ì¸ì˜ ì›í™œí•œ ì¡°ì •ì„ ë³´ì¥í•©ë‹ˆë‹¤. ë™ì¼í•œ GPU ê°€ì† ì„¤ì •ì´ Sparkì™€ ë¨¸ì‹  ëŸ¬ë‹ ë˜ëŠ” ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ ëª¨ë‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë³„ë„ì˜ í´ëŸ¬ìŠ¤í„°ê°€ í•„ìš” ì—†ìœ¼ë©° ì „ì²´ íŒŒì´í”„ë¼ì¸ì— GPU ê°€ì†ì„ ì œê³µí•©ë‹ˆë‹¤. Spark 3ì€ Catalyst ì¿¼ë¦¬ ì˜µí‹°ë§ˆì´ì €ì—ì„œ ì»¬ëŸ¼ ì²˜ë¦¬ì— ëŒ€í•œ ì§€ì›ì„ í™•ì¥í•©ë‹ˆë‹¤. RAPIDS AcceleratorëŠ” ì´ ì‹œìŠ¤í…œì— ì—°ê²°í•˜ì—¬ SQL ë° DataFrame ì—°ì‚°ìì˜ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¿¼ë¦¬ ê³„íšì´ ì‹¤í–‰ë˜ë©´ ì´ëŸ¬í•œ ì—°ì‚°ìëŠ” í–¥ìƒëœ ì„±ëŠ¥ì„ ìœ„í•´ Spark í´ëŸ¬ìŠ¤í„° ë‚´ì˜ GPUë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. NVIDIAëŠ” Spark ì‘ì—… ê°„ì˜ ë°ì´í„° êµí™˜ì„ ìµœì í™”í•˜ë„ë¡ ì„¤ê³„ëœ í˜ì‹ ì ì¸ Spark ì…”í”Œ êµ¬í˜„ì„ ë„ì…í–ˆìŠµë‹ˆë‹¤. ì´ ì…”í”Œ ì‹œìŠ¤í…œì€ UCX, RDMA ë° NCCLì„ í¬í•¨í•œ GPU ê°•í™” í†µì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì–´ ë°ì´í„° ì „ì†¡ ì†ë„ì™€ ì „ë°˜ì ì¸ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.  ì†”ë£¨ì…˜ ë°°í¬ ğŸ‘ˆ  ","version":"Next","tagName":"h3"},{"title":"XGBoost Spark ì‘ì—… ì‹œì‘â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ EMR NVIDIA RAPIDS Accelerator for Apache Spark","url":"/ai-on-eks/ko/docs/infra/misc/emr-spark-rapids#xgboost-spark-ì‘ì—…-ì‹œì‘","content":" í›ˆë ¨ ë°ì´í„°ì…‹â€‹  Fannie Mae's Single-Family Loan Performance DataëŠ” 2013ë…„ë¶€í„° ì‹œì‘í•˜ëŠ” ì¢…í•©ì ì¸ ë°ì´í„°ì…‹ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ Fannie Maeì˜ ë‹¨ì¼ ê°€ì¡± ì‚¬ì—… ì¥ë¶€ ì¼ë¶€ì˜ ì‹ ìš© ì„±ê³¼ì— ëŒ€í•œ ê·€ì¤‘í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ íˆ¬ììê°€ Fannie Maeê°€ ì†Œìœ í•˜ê±°ë‚˜ ë³´ì¦í•˜ëŠ” ë‹¨ì¼ ê°€ì¡± ëŒ€ì¶œì˜ ì‹ ìš© ì„±ê³¼ë¥¼ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.  1ë‹¨ê³„: ì‚¬ìš©ì ì§€ì • Docker ì´ë¯¸ì§€ ë¹Œë“œâ€‹  us-west-2ì— ìœ„ì¹˜í•œ EMR on EKS ECR ë¦¬í¬ì§€í† ë¦¬ì—ì„œ Spark Rapids ê¸°ë³¸ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¤ë ¤ë©´ ë¡œê·¸ì¸í•©ë‹ˆë‹¤:  aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 895885662937.dkr.ecr.us-west-2.amazonaws.com   ë‹¤ë¥¸ ë¦¬ì „ì— ìˆëŠ” ê²½ìš° ì´ ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.  ë¡œì»¬ì—ì„œ Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:  ì œê³µëœ Dockerfileì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§€ì • Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤. 0.10ê³¼ ê°™ì€ ì´ë¯¸ì§€ íƒœê·¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.  ì •ë³´ ë¹Œë“œ í”„ë¡œì„¸ìŠ¤ëŠ” ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²°ê³¼ ì´ë¯¸ì§€ í¬ê¸°ëŠ” ì•½ 23.5GBì…ë‹ˆë‹¤.  cd infra/emr-spark-rapids/examples/xgboost docker build -t emr-6.10.0-spark-rapids-custom:0.10 -f Dockerfile .   &lt;ACCOUNTID&gt;ë¥¼ AWS ê³„ì • IDë¡œ ë°”ê¿‰ë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ECR ë¦¬í¬ì§€í† ë¦¬ì— ë¡œê·¸ì¸í•©ë‹ˆë‹¤:  aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin &lt;ACCOUNTID&gt;.dkr.ecr.us-west-2.amazonaws.com   Docker ì´ë¯¸ì§€ë¥¼ ECRì— í‘¸ì‹œí•˜ë ¤ë©´ ë‹¤ìŒì„ ì‚¬ìš©í•©ë‹ˆë‹¤:  $ docker tag emr-6.10.0-spark-rapids-custom:0.10 &lt;ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/emr-6.10.0-spark-rapids-custom:0.10 $ docker push &lt;ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/emr-6.10.0-spark-rapids-custom:0.10   3ë‹¨ê³„ì—ì„œ ì‘ì—… ì‹¤í–‰ ì¤‘ì— ì´ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"2ë‹¨ê³„: ì…ë ¥ ë°ì´í„° íšë“(Fannie Mae's Single-Family Loan Performance Data)â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ EMR NVIDIA RAPIDS Accelerator for Apache Spark","url":"/ai-on-eks/ko/docs/infra/misc/emr-spark-rapids#2ë‹¨ê³„-ì…ë ¥-ë°ì´í„°-íšë“fannie-maes-single-family-loan-performance-data","content":" ì´ ë°ì´í„°ì…‹ì€ Fannie Mae's Single-Family Loan Performance Dataì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤. ëª¨ë“  ê¶Œë¦¬ëŠ” Fannie Maeì— ìˆìŠµë‹ˆë‹¤.  Fannie Mae ì›¹ì‚¬ì´íŠ¸ë¡œ ì´ë™í•©ë‹ˆë‹¤Single-Family Loan Performance Dataë¥¼ í´ë¦­í•©ë‹ˆë‹¤ ì›¹ì‚¬ì´íŠ¸ë¥¼ ì²˜ìŒ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ìƒˆ ì‚¬ìš©ìë¡œ ë“±ë¡í•©ë‹ˆë‹¤ìê²© ì¦ëª…ì„ ì‚¬ìš©í•˜ì—¬ ë¡œê·¸ì¸í•©ë‹ˆë‹¤ HPë¥¼ ì„ íƒí•©ë‹ˆë‹¤Download Dataë¥¼ í´ë¦­í•˜ê³  Single-Family Loan Performance Dataë¥¼ ì„ íƒí•©ë‹ˆë‹¤ì—°ë„ ë° ë¶„ê¸°ë³„ë¡œ ì •ë ¬ëœ Acquisition and Performance íŒŒì¼ì˜ í‘œ í˜•ì‹ ëª©ë¡ì´ í‘œì‹œë©ë‹ˆë‹¤. íŒŒì¼ì„ í´ë¦­í•˜ì—¬ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. ì˜ˆì œ ì‘ì—…ì—ì„œ ì‚¬ìš©í•  3ë…„ ë¶„ëŸ‰ì˜ ë°ì´í„°(2020, 2021, 2022 - ê° ì—°ë„ì— 4ê°œì˜ íŒŒì¼, ê° ë¶„ê¸°ì— í•˜ë‚˜ì”©)ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆ: 2017Q1.zipë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ì˜ ì••ì¶•ì„ í’€ì–´ ë¡œì»¬ ë¨¸ì‹ ì— csv íŒŒì¼ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ì˜ˆ: 2017Q1.csvCSV íŒŒì¼ë§Œ ${S3_BUCKET}/${EMR_VIRTUAL_CLUSTER_ID}/spark-rapids-emr/input/fannie-mae-single-family-loan-performance/ ì•„ë˜ì˜ S3 ë²„í‚·ì— ë³µì‚¬í•©ë‹ˆë‹¤. ì•„ë˜ ì˜ˆì œëŠ” 3ë…„ ë¶„ëŸ‰ì˜ ë°ì´í„°(ê° ë¶„ê¸°ì— í•˜ë‚˜ì˜ íŒŒì¼, ì´ 12ê°œ íŒŒì¼)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì°¸ê³ : ${S3_BUCKET} ë° ${EMR_VIRTUAL_CLUSTER_ID} ê°’ì€ Terraform ì¶œë ¥ì—ì„œ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.   aws s3 ls s3://emr-spark-rapids-&lt;aws-account-id&gt;-us-west-2/949wt7zuphox1beiv0i30v65i/spark-rapids-emr/input/fannie-mae-single-family-loan-performance/ 2023-06-24 21:38:25 2301641519 2000Q1.csv 2023-06-24 21:38:25 9739847213 2020Q2.csv 2023-06-24 21:38:25 10985541111 2020Q3.csv 2023-06-24 21:38:25 11372073671 2020Q4.csv 2023-06-23 16:38:36 9603950656 2021Q1.csv 2023-06-23 16:38:36 7955614945 2021Q2.csv 2023-06-23 16:38:36 5365827884 2021Q3.csv 2023-06-23 16:38:36 4390166275 2021Q4.csv 2023-06-22 19:20:08 2723499898 2022Q1.csv 2023-06-22 19:20:08 1426204690 2022Q2.csv 2023-06-22 19:20:08 595639825 2022Q3.csv 2023-06-22 19:20:08 180159771 2022Q4.csv   ","version":"Next","tagName":"h3"},{"title":"3ë‹¨ê³„: EMR Spark XGBoost ì‘ì—… ì‹¤í–‰â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ EMR NVIDIA RAPIDS Accelerator for Apache Spark","url":"/ai-on-eks/ko/docs/infra/misc/emr-spark-rapids#3ë‹¨ê³„-emr-spark-xgboost-ì‘ì—…-ì‹¤í–‰","content":" ì—¬ê¸°ì„œëŠ” ì‘ì—…ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ë„ìš°ë¯¸ ì…¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‚¬ìš©ì ì…ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.  ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Terraform ì¶œë ¥ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” íŠ¹ì • ì…ë ¥ì„ ìš”ì²­í•©ë‹ˆë‹¤. ì•„ë˜ ì˜ˆì‹œë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.  cd infra/emr-spark-rapids/examples/xgboost chmod +x execute_spark_rapids_xgboost.sh ./execute_spark_rapids_xgboost.sh # ì•„ë˜ì— í‘œì‹œëœ ì˜ˆì‹œ ì…ë ¥ Did you copy the fannie-mae-single-family-loan-performance data to S3 bucket(y/n): y Enter the customized Docker image URI: public.ecr.aws/o7d8v7g9/emr-6.10.0-spark-rapids:0.11 Enter EMR Virtual Cluster AWS Region: us-west-2 Enter the EMR Virtual Cluster ID: 949wt7zuphox1beiv0i30v65i Enter the EMR Execution Role ARN: arn:aws:iam::&lt;ACCOUNTID&gt;:role/emr-spark-rapids-emr-eks-data-team-a Enter the CloudWatch Log Group name: /emr-on-eks-logs/emr-spark-rapids/emr-ml-team-a Enter the S3 Bucket for storing PySpark Scripts, Pod Templates, Input data and Output data.&lt;bucket-name&gt;: emr-spark-rapids-&lt;ACCOUNTID&gt;-us-west-2 Enter the number of executor instances (4 to 8): 8   íŒŒë“œ ìƒíƒœ í™•ì¸    ì •ë³´ ì²« ë²ˆì§¸ ì‹¤í–‰ì€ EMR Job Pod, Driver ë° Executor íŒŒë“œìš© ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•˜ë¯€ë¡œ ë” ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° íŒŒë“œëŠ” Docker ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ë° ìµœëŒ€ 8ë¶„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ìºì‹± ë•ë¶„ì— í›„ì† ì‹¤í–‰ì€ ë” ë¹ ë¦…ë‹ˆë‹¤(ë³´í†µ 30ì´ˆ ë¯¸ë§Œ).  ","version":"Next","tagName":"h3"},{"title":"4ë‹¨ê³„: ì‘ì—… ê²°ê³¼ í™•ì¸â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ EMR NVIDIA RAPIDS Accelerator for Apache Spark","url":"/ai-on-eks/ko/docs/infra/misc/emr-spark-rapids#4ë‹¨ê³„-ì‘ì—…-ê²°ê³¼-í™•ì¸","content":" CloudWatch ë¡œê·¸ ë˜ëŠ” S3 ë²„í‚·ì—ì„œ Spark ë“œë¼ì´ë²„ íŒŒë“œ ë¡œê·¸ë¥¼ í™•ì¸í•˜ë ¤ë©´ ë¡œê·¸ì¸í•©ë‹ˆë‹¤.  ë¡œê·¸ íŒŒì¼ì˜ ìƒ˜í”Œ ì¶œë ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:  /emr-on-eks-logs/emr-spark-rapids/emr-ml-team-a spark-rapids-emr/949wt7zuphox1beiv0i30v65i/jobs/0000000327fe50tosa4/containers/spark-0000000327fe50tosa4/spark-0000000327fe50tosa4-driver/stdout   ìœ„ ë¡œê·¸ íŒŒì¼ì˜ ìƒ˜í”Œ ì¶œë ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:  Raw Dataframe CSV Rows count : 215386024 Raw Dataframe Parquet Rows count : 215386024 ETL takes 222.34674382209778  Training takes 95.90932035446167 seconds If features_cols param set, then features_col param is ignored.  Transformation takes 63.999391317367554 seconds +--------------+--------------------+--------------------+----------+ |delinquency_12| rawPrediction| probability|prediction| +--------------+--------------------+--------------------+----------+ | 0|[10.4500541687011...|[0.99997103214263...| 0.0| | 0|[10.3076572418212...|[0.99996662139892...| 0.0| | 0|[9.81707763671875...|[0.99994546175003...| 0.0| | 0|[9.10498714447021...|[0.99988889694213...| 0.0| | 0|[8.81903457641601...|[0.99985212087631...| 0.0| +--------------+--------------------+--------------------+----------+ only showing top 5 rows  Evaluation takes 3.8372223377227783 seconds Accuracy is 0.996563056111921  ","version":"Next","tagName":"h3"},{"title":"Fannie Mae Single Loan Performance Datasetìš© ML íŒŒì´í”„ë¼ì¸â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ EMR NVIDIA RAPIDS Accelerator for Apache Spark","url":"/ai-on-eks/ko/docs/infra/misc/emr-spark-rapids#fannie-mae-single-loan-performance-datasetìš©-ml-íŒŒì´í”„ë¼ì¸","content":" 1ë‹¨ê³„: ëˆ„ë½ëœ ê°’, ë²”ì£¼í˜• ë³€ìˆ˜ ë° ê¸°íƒ€ ë°ì´í„° ë¶ˆì¼ì¹˜ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë°ì´í„°ì…‹ì„ ì „ì²˜ë¦¬í•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ë°ì´í„° ë³´ê°„, ì›-í•« ì¸ì½”ë”© ë° ë°ì´í„° ì •ê·œí™”ì™€ ê°™ì€ ê¸°ìˆ ì´ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  2ë‹¨ê³„: ëŒ€ì¶œ ì„±ê³¼ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ë” ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆëŠ” ê¸°ì¡´ ê¸°ëŠ¥ì—ì„œ ì¶”ê°€ ê¸°ëŠ¥ì„ ìƒì„±í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ëŒ€ì¶œ ëŒ€ë¹„ ê°€ì¹˜ ë¹„ìœ¨, ì°¨ìš©ì¸ì˜ ì‹ ìš© ì ìˆ˜ ë²”ìœ„ ë˜ëŠ” ëŒ€ì¶œ ì‹œì‘ ì—°ë„ì™€ ê°™ì€ ê¸°ëŠ¥ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  3ë‹¨ê³„: ë°ì´í„°ì…‹ì„ ë‘ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤: í•˜ë‚˜ëŠ” XGBoost ëª¨ë¸ í›ˆë ¨ìš©ì´ê³  ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ì„±ëŠ¥ í‰ê°€ìš©ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ë³´ì´ì§€ ì•ŠëŠ” ë°ì´í„°ì— ì–¼ë§ˆë‚˜ ì˜ ì¼ë°˜í™”ë˜ëŠ”ì§€ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  4ë‹¨ê³„: í›ˆë ¨ ë°ì´í„°ì…‹ì„ XGBoostì— ê³µê¸‰í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤. XGBoostëŠ” ëŒ€ì¶œ ì†ì„±ê³¼ í•´ë‹¹ ëŒ€ì¶œ ì„±ê³¼ ë ˆì´ë¸”ì„ ë¶„ì„í•˜ì—¬ ê·¸ë“¤ ì‚¬ì´ì˜ íŒ¨í„´ê³¼ ê´€ê³„ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. ëª©í‘œëŠ” ì£¼ì–´ì§„ ê¸°ëŠ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì¶œì´ ì±„ë¬´ ë¶ˆì´í–‰ì´ ë  ê°€ëŠ¥ì„±ì´ ìˆëŠ”ì§€ ë˜ëŠ” ì˜ ìˆ˜í–‰ë  ê°€ëŠ¥ì„±ì´ ìˆëŠ”ì§€ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.  5ë‹¨ê³„: ëª¨ë¸ì´ í›ˆë ¨ë˜ë©´ í‰ê°€ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ëª¨ë¸ì´ ëŒ€ì¶œ ì„±ê³¼ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì˜ˆì¸¡í•˜ëŠ”ì§€ ì¸¡ì •í•˜ê¸° ìœ„í•´ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ë˜ëŠ” ìˆ˜ì‹ ê¸° ì‘ë™ íŠ¹ì„± ê³¡ì„  ì•„ë˜ ë©´ì (AUC-ROC)ê³¼ ê°™ì€ ë©”íŠ¸ë¦­ì„ ë¶„ì„í•˜ëŠ” ê²ƒì´ í¬í•¨ë©ë‹ˆë‹¤.  6ë‹¨ê³„: ì„±ëŠ¥ì´ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šìœ¼ë©´ ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ê°œì„ í•˜ê±°ë‚˜ ê³¼ì í•©ê³¼ ê°™ì€ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ í•™ìŠµë¥ , íŠ¸ë¦¬ ê¹Šì´ ë˜ëŠ” ì •ê·œí™” íŒŒë¼ë¯¸í„°ì™€ ê°™ì€ XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  7ë‹¨ê³„: ë§ˆì§€ë§‰ìœ¼ë¡œ í›ˆë ¨ë˜ê³  ê²€ì¦ëœ XGBoost ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡­ê³  ë³´ì´ì§€ ì•ŠëŠ” ëŒ€ì¶œ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì˜ˆì¸¡ì€ ëŒ€ì¶œ ì±„ë¬´ ë¶ˆì´í–‰ê³¼ ê´€ë ¨ëœ ì ì¬ì  ìœ„í—˜ì„ ì‹ë³„í•˜ê±°ë‚˜ ëŒ€ì¶œ ì„±ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"DCGM Exporter, Prometheus ë° Grafanaë¥¼ ì‚¬ìš©í•œ GPU ëª¨ë‹ˆí„°ë§â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ EMR NVIDIA RAPIDS Accelerator for Apache Spark","url":"/ai-on-eks/ko/docs/infra/misc/emr-spark-rapids#dcgm-exporter-prometheus-ë°-grafanaë¥¼-ì‚¬ìš©í•œ-gpu-ëª¨ë‹ˆí„°ë§","content":" ê´€ì¸¡ì„±ì€ GPUì™€ ê°™ì€ í•˜ë“œì›¨ì–´ ë¦¬ì†ŒìŠ¤ë¥¼ ê´€ë¦¬í•˜ê³  ìµœì í™”í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. íŠ¹íˆ GPU ì‚¬ìš©ë¥ ì´ ë†’ì€ ë¨¸ì‹  ëŸ¬ë‹ ì›Œí¬ë¡œë“œì—ì„œ ê·¸ë ‡ìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ìœ¼ë¡œ GPU ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ê³ , ì¶”ì„¸ë¥¼ ì‹ë³„í•˜ê³ , ì´ìƒì„ ê°ì§€í•˜ëŠ” ê¸°ëŠ¥ì€ ì„±ëŠ¥ íŠœë‹, ë¬¸ì œ í•´ê²° ë° íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ í™œìš©ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  NVIDIA GPU OperatorëŠ” GPU ê´€ì¸¡ì„±ì—ì„œ í•µì‹¬ ì—­í• ì„ í•©ë‹ˆë‹¤. Kubernetesì—ì„œ GPU ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë° í•„ìš”í•œ êµ¬ì„± ìš”ì†Œì˜ ë°°í¬ë¥¼ ìë™í™”í•©ë‹ˆë‹¤. ê·¸ êµ¬ì„± ìš”ì†Œ ì¤‘ í•˜ë‚˜ì¸ DCGM(Data Center GPU Manager) ExporterëŠ” ì„ ë„ì ì¸ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì†”ë£¨ì…˜ì¸ Prometheusê°€ ìˆ˜ì§‘í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ GPU ë©”íŠ¸ë¦­ì„ ë‚´ë³´ë‚´ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì—ëŠ” GPU ì˜¨ë„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, GPU ì‚¬ìš©ë¥  ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. DCGM Exporterë¥¼ ì‚¬ìš©í•˜ë©´ GPUë³„ë¡œ ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ GPU ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì„¸ë¶„í™”ëœ ê°€ì‹œì„±ì„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  NVIDIA GPU OperatorëŠ” DCGM Exporterì™€ í•¨ê»˜ GPU ë©”íŠ¸ë¦­ì„ Prometheus ì„œë²„ë¡œ ë‚´ë³´ëƒ…ë‹ˆë‹¤. ìœ ì—°í•œ ì¿¼ë¦¬ ì–¸ì–´ë¥¼ í†µí•´ Prometheusë¥¼ ì‚¬ìš©í•˜ë©´ ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© íŒ¨í„´ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ê·¸ëŸ¬ë‚˜ PrometheusëŠ” ì¥ê¸° ë°ì´í„° ì €ì¥ìš©ìœ¼ë¡œ ì„¤ê³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ Amazon Managed Service for Prometheus(AMP)ê°€ ë“±ì¥í•©ë‹ˆë‹¤. ê¸°ë³¸ ì¸í”„ë¼ë¥¼ ê´€ë¦¬í•  í•„ìš” ì—†ì´ ëŒ€ê·œëª¨ë¡œ ìš´ì˜ ë°ì´í„°ë¥¼ ì‰½ê²Œ ë¶„ì„í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì™„ì „ ê´€ë¦¬í˜•, ì•ˆì „í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ Prometheus ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì„ ì‹œê°í™”í•˜ê³  ìœ ìš©í•œ ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“œëŠ” ê²ƒì€ Grafanaê°€ ë›°ì–´ë‚œ ë¶€ë¶„ì…ë‹ˆë‹¤. GrafanaëŠ” ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡ì„±ì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ í”Œë«í¼ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ì„ ì§ê´€ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ìœ„í•œ í’ë¶€í•œ ì‹œê°í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Prometheusì™€ ê²°í•©í•˜ë©´ GrafanaëŠ” DCGM Exporterê°€ ìˆ˜ì§‘í•œ GPU ë©”íŠ¸ë¦­ì„ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë°©ì‹ìœ¼ë¡œ í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  NVIDIA GPU OperatorëŠ” ë©”íŠ¸ë¦­ì„ Prometheus ì„œë²„ë¡œ ë‚´ë³´ë‚´ë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, Prometheus ì„œë²„ëŠ” ì´ëŸ¬í•œ ë©”íŠ¸ë¦­ì„ Amazon Managed Prometheus(AMP)ì— ì›ê²© ì“°ê¸°í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ë¸”ë£¨í”„ë¦°íŠ¸ì˜ ì¼ë¶€ë¡œ ë°°í¬ëœ Grafana WebUIì— ë¡œê·¸ì¸í•˜ê³  AMPë¥¼ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë¦¬ì†ŒìŠ¤ ìµœì í™”ë¥¼ ìš©ì´í•˜ê²Œ í•˜ëŠ” ì‰½ê²Œ ì†Œí™”í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ GPU ë©”íŠ¸ë¦­ì„ ì œê³µí•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ GPU ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  NVIDIA GPU Operator: Kubernetes í´ëŸ¬ìŠ¤í„°ì— ì„¤ì¹˜ëœ NVIDIA GPU OperatorëŠ” GPU ë¦¬ì†ŒìŠ¤ì˜ ìˆ˜ëª… ì£¼ê¸°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤. ê° GPU ì¥ì°© ë…¸ë“œì— NVIDIA ë“œë¼ì´ë²„ì™€ DCGM Exporterë¥¼ ë°°í¬í•©ë‹ˆë‹¤.DCGM Exporter: DCGM ExporterëŠ” ê° ë…¸ë“œì—ì„œ ì‹¤í–‰ë˜ì–´ GPU ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ê³  Prometheusì— ë…¸ì¶œí•©ë‹ˆë‹¤.Prometheus: PrometheusëŠ” DCGM Exporterë¥¼ í¬í•¨í•œ ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ëŠ” ì‹œê³„ì—´ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ì •ê¸°ì ìœ¼ë¡œ ìµìŠ¤í¬í„°ì—ì„œ ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì™€ ì €ì¥í•©ë‹ˆë‹¤. ì´ ì„¤ì •ì—ì„œëŠ” ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ì„ AMPì— ì›ê²© ì“°ê¸°í•˜ë„ë¡ Prometheusë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.Amazon Managed Service for Prometheus(AMP): AMPëŠ” AWSì—ì„œ ì œê³µí•˜ëŠ” ì™„ì „ ê´€ë¦¬í˜• Prometheus ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. Prometheus ë°ì´í„°ì˜ ì¥ê¸° ì €ì¥, í™•ì¥ì„± ë° ë³´ì•ˆì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.Grafana: GrafanaëŠ” ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ì— ëŒ€í•´ AMPë¥¼ ì¿¼ë¦¬í•˜ê³  ìœ ìš©í•œ ëŒ€ì‹œë³´ë“œì— í‘œì‹œí•  ìˆ˜ ìˆëŠ” ì‹œê°í™” ë„êµ¬ì…ë‹ˆë‹¤.  ì´ ë¸”ë£¨í”„ë¦°íŠ¸ì—ì„œëŠ” DCGMì„ í™œìš©í•˜ì—¬ GPU ë©”íŠ¸ë¦­ì„ Prometheusì™€ Amazon Managed Prometheus(AMP) ëª¨ë‘ì— ì”ë‹ˆë‹¤. GPU ë©”íŠ¸ë¦­ì„ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ Grafanaë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  kubectl port-forward svc/grafana 3000:80 -n grafana   ì‚¬ìš©ì ì´ë¦„ìœ¼ë¡œ adminì„ ì‚¬ìš©í•˜ì—¬ Grafanaì— ë¡œê·¸ì¸í•˜ê³  ë‹¤ìŒ AWS CLI ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ Secrets Managerì—ì„œ ë¹„ë°€ë²ˆí˜¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤:  aws secretsmanager get-secret-value --secret-id emr-spark-rapids-grafana --region us-west-2   ë¡œê·¸ì¸í•œ í›„ AMP ë°ì´í„° ì†ŒìŠ¤ë¥¼ Grafanaì— ì¶”ê°€í•˜ê³  ì˜¤í”ˆì†ŒìŠ¤ GPU ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì•„ë˜ ìŠ¤í¬ë¦°ìƒ·ê³¼ ê°™ì´ Grafana ëŒ€ì‹œë³´ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”íŠ¸ë¦­ì„ íƒìƒ‰í•˜ê³  ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ì •ë¦¬ ğŸ‘ˆ  ì£¼ì˜ AWS ê³„ì •ì— ì›ì¹˜ ì•ŠëŠ” ìš”ê¸ˆì´ ì²­êµ¬ë˜ì§€ ì•Šë„ë¡ ì´ ë°°í¬ ì¤‘ì— ìƒì„±ëœ ëª¨ë“  AWS ë¦¬ì†ŒìŠ¤ë¥¼ ì‚­ì œí•˜ì„¸ìš” ","version":"Next","tagName":"h3"},{"title":"ë¬¸ì œ ì„¤ëª…:â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ë¬¸ì œ-ì„¤ëª…","content":" ì˜¤ë¥˜ ë©”ì‹œì§€ëŠ” ì‚¬ìš© ì¤‘ì¸ AWS CLI ë²„ì „ì— emr-containers ëª…ë ¹ì´ ì—†ìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ë¬¸ì œëŠ” AWS CLI ë²„ì „ 2.0.54ì—ì„œ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"í•´ê²° ë°©ë²•â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#í•´ê²°-ë°©ë²•","content":" ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ AWS CLI ë²„ì „ì„ 2.0.54 ì´ìƒìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”:  pip install --upgrade awscliv2   AWS CLI ë²„ì „ì„ ì—…ë°ì´íŠ¸í•˜ë©´ í”„ë¡œë¹„ì €ë‹ í”„ë¡œì„¸ìŠ¤ ì¤‘ì— í•„ìš”í•œ emr-containers ëª…ë ¹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©° ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë¬¸ì œê°€ ê³„ì†ë˜ê±°ë‚˜ ì¶”ê°€ ì§€ì›ì´ í•„ìš”í•œ ê²½ìš° ìì„¸í•œ ë‚´ìš©ì€ AWS CLI GitHub ì´ìŠˆë¥¼ ì°¸ì¡°í•˜ê±°ë‚˜ ì§€ì› íŒ€ì— ë¬¸ì˜í•˜ì—¬ ì¶”ê°€ ì•ˆë‚´ë¥¼ ë°›ìœ¼ì„¸ìš”.  ","version":"Next","tagName":"h3"},{"title":"Terraform Destroy ì¤‘ íƒ€ì„ì•„ì›ƒâ€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#terraform-destroy-ì¤‘-íƒ€ì„ì•„ì›ƒ","content":" ","version":"Next","tagName":"h2"},{"title":"ë¬¸ì œ ì„¤ëª…:â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ë¬¸ì œ-ì„¤ëª…-1","content":" ê³ ê°ì€ í™˜ê²½ì„ ì‚­ì œí•˜ëŠ” ë™ì•ˆ íŠ¹íˆ VPCê°€ ì‚­ì œë  ë•Œ íƒ€ì„ì•„ì›ƒì„ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” vpc-cni êµ¬ì„± ìš”ì†Œì™€ ê´€ë ¨ëœ ì•Œë ¤ì§„ ë¬¸ì œì…ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì¦ìƒ:â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ì¦ìƒ","content":" í™˜ê²½ì´ ì‚­ì œëœ í›„ì—ë„ ENI(Elastic Network Interface)ê°€ ì„œë¸Œë„·ì— ì—°ê²°ëœ ìƒíƒœë¡œ ìœ ì§€ë©ë‹ˆë‹¤. ENIì™€ ì—°ê²°ëœ EKS ê´€ë¦¬í˜• ë³´ì•ˆ ê·¸ë£¹ì´ EKSì— ì˜í•´ ì‚­ì œë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"í•´ê²° ë°©ë²•:â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#í•´ê²°-ë°©ë²•-1","content":" ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ë©´ ì•„ë˜ ê¶Œì¥ í•´ê²° ë°©ë²•ì„ ë”°ë¥´ì„¸ìš”:  ì œê³µëœ cleanup.sh ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ì†ŒìŠ¤ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì •ë¦¬í•©ë‹ˆë‹¤. ë¸”ë£¨í”„ë¦°íŠ¸ì— í¬í•¨ëœ cleanup.sh ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‚¨ì•„ìˆëŠ” ENI ë° ê´€ë ¨ ë³´ì•ˆ ê·¸ë£¹ì˜ ì œê±°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì˜¤ë¥˜: could not download chartâ€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ì˜¤ë¥˜-could-not-download-chart","content":" ì°¨íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ë ¤ê³  í•  ë•Œ ë‹¤ìŒ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°:  â”‚ Error: could not download chart: failed to download &quot;oci://public.ecr.aws/karpenter/karpenter&quot; at version &quot;v0.18.1&quot; â”‚ â”‚ with module.eks_blueprints_kubernetes_addons.module.karpenter[0].module.helm_addon.helm_release.addon[0], â”‚ on .terraform/modules/eks_blueprints_kubernetes_addons/modules/kubernetes-addons/helm-addon/main.tf line 1, in resource &quot;helm_release&quot; &quot;addon&quot;: â”‚ 1: resource &quot;helm_release&quot; &quot;addon&quot; { â”‚   ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:  ","version":"Next","tagName":"h2"},{"title":"ë¬¸ì œ ì„¤ëª…:â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ë¬¸ì œ-ì„¤ëª…-2","content":" ì˜¤ë¥˜ ë©”ì‹œì§€ëŠ” ì§€ì •ëœ ì°¨íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ ë¬¸ì œëŠ” Karpenter ì„¤ì¹˜ ì¤‘ Terraformì˜ ë²„ê·¸ë¡œ ì¸í•´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"í•´ê²° ë°©ë²•:â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#í•´ê²°-ë°©ë²•-2","content":" ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  ECRë¡œ ì¸ì¦: ì°¨íŠ¸ê°€ ìˆëŠ” ECR(Elastic Container Registry)ë¡œ ì¸ì¦í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:  aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws   terraform apply ì¬ì‹¤í–‰: Terraform êµ¬ì„±ì„ ë‹¤ì‹œ ì ìš©í•˜ê¸° ìœ„í•´ --auto-approve í”Œë˜ê·¸ì™€ í•¨ê»˜ terraform apply ëª…ë ¹ì„ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤:  terraform apply --auto-approve   ECRë¡œ ì¸ì¦í•˜ê³  terraform apply ëª…ë ¹ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì„¤ì¹˜ í”„ë¡œì„¸ìŠ¤ ì¤‘ì— í•„ìš”í•œ ì°¨íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"EKS í´ëŸ¬ìŠ¤í„°ì™€ ì¸ì¦í•˜ê¸° ìœ„í•œ Terraform apply/destroy ì˜¤ë¥˜â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#eks-í´ëŸ¬ìŠ¤í„°ì™€-ì¸ì¦í•˜ê¸°-ìœ„í•œ-terraform-applydestroy-ì˜¤ë¥˜","content":" ERROR: â•· â”‚ Error: Get &quot;http://localhost/api/v1/namespaces/kube-system/configmaps/aws-auth&quot;: dial tcp [::1]:80: connect: connection refused â”‚ â”‚ with module.eks.kubernetes_config_map_v1_data.aws_auth[0], â”‚ on .terraform/modules/eks/main.tf line 550, in resource &quot;kubernetes_config_map_v1_data&quot; &quot;aws_auth&quot;: â”‚ 550: resource &quot;kubernetes_config_map_v1_data&quot; &quot;aws_auth&quot; { â”‚ â•µ   í•´ê²° ë°©ë²•:ì´ ìƒí™©ì—ì„œ Terraformì€ ë°ì´í„° ë¦¬ì†ŒìŠ¤ë¥¼ ìƒˆë¡œ ê³ ì¹˜ê³  EKS í´ëŸ¬ìŠ¤í„°ì™€ ì¸ì¦í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.ì—¬ê¸°ì—ì„œ ë…¼ì˜ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”  ë¨¼ì € exec í”ŒëŸ¬ê·¸ì¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ ì ‘ê·¼ ë°©ì‹ì„ ì‹œë„í•˜ì„¸ìš”.  provider &quot;kubernetes&quot; { host = module.eks_blueprints.eks_cluster_endpoint cluster_ca_certificate = base64decode(module.eks_blueprints.eks_cluster_certificate_authority_data) exec { api_version = &quot;client.authentication.k8s.io/v1beta1&quot; command = &quot;aws&quot; args = [&quot;eks&quot;, &quot;get-token&quot;, &quot;--cluster-name&quot;, module.eks_blueprints.eks_cluster_id] } }   ìœ„ì˜ ë³€ê²½ í›„ì—ë„ ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ë¡œì»¬ kube config íŒŒì¼ì„ ì‚¬ìš©í•˜ëŠ” ëŒ€ì²´ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³ : ì´ ì ‘ê·¼ ë°©ì‹ì€ í”„ë¡œë•ì…˜ì— ì´ìƒì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¡œì»¬ kube configë¡œ í´ëŸ¬ìŠ¤í„°ë¥¼ ì ìš©/ì‚­ì œí•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.  í´ëŸ¬ìŠ¤í„°ìš© ë¡œì»¬ kubeconfig ìƒì„±  aws eks update-kubeconfig --name &lt;EKS_CLUSTER_NAME&gt; --region &lt;CLUSTER_REGION&gt;   config_pathë§Œ ì‚¬ìš©í•˜ì—¬ ì•„ë˜ êµ¬ì„±ìœ¼ë¡œ providers.tf íŒŒì¼ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.  provider &quot;kubernetes&quot; { config_path = &quot;&lt;HOME_PATH&gt;/.kube/config&quot; } provider &quot;helm&quot; { kubernetes { config_path = &quot;&lt;HOME_PATH&gt;/.kube/config&quot; } } provider &quot;kubectl&quot; { config_path = &quot;&lt;HOME_PATH&gt;/.kube/config&quot; }   ","version":"Next","tagName":"h2"},{"title":"EMR Containers Virtual Cluster (dhwtlq9yx34duzq5q3akjac00) delete: unexpected state 'ARRESTED'â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#emr-containers-virtual-cluster-dhwtlq9yx34duzq5q3akjac00-delete-unexpected-state-arrested","content":" &quot;waiting for EMR Containers Virtual Cluster (xwbc22787q6g1wscfawttzzgb) delete: unexpected state 'ARRESTED', wanted target ''. last error: %!s(nil)&quot;ë¼ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ë‚˜íƒ€ë‚˜ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¼ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  ì°¸ê³ : &lt;REGION&gt;ì„ ê°€ìƒ í´ëŸ¬ìŠ¤í„°ê°€ ìœ„ì¹˜í•œ ì ì ˆí•œ AWS ë¦¬ì „ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”.  í„°ë¯¸ë„ ë˜ëŠ” ëª…ë ¹ í”„ë¡¬í”„íŠ¸ë¥¼ ì—½ë‹ˆë‹¤.ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ &quot;ARRESTED&quot; ìƒíƒœì˜ ê°€ìƒ í´ëŸ¬ìŠ¤í„°ë¥¼ ë‚˜ì—´í•©ë‹ˆë‹¤:  aws emr-containers list-virtual-clusters --region &lt;REGION&gt; --states ARRESTED \\ --query 'virtualClusters[0].id' --output text   ì´ ëª…ë ¹ì€ &quot;ARRESTED&quot; ìƒíƒœì˜ ê°€ìƒ í´ëŸ¬ìŠ¤í„° IDë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.  ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ê°€ìƒ í´ëŸ¬ìŠ¤í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤:  aws emr-containers list-virtual-clusters --region &lt;REGION&gt; --states ARRESTED \\ --query 'virtualClusters[0].id' --output text | xargs -I{} aws emr-containers delete-virtual-cluster \\ --region &lt;REGION&gt; --id {}   &lt;VIRTUAL_CLUSTER_ID&gt;ë¥¼ ì´ì „ ë‹¨ê³„ì—ì„œ ì–»ì€ ê°€ìƒ í´ëŸ¬ìŠ¤í„° IDë¡œ ë°”ê¾¸ì„¸ìš”.  ì´ ëª…ë ¹ì„ ì‹¤í–‰í•˜ë©´ &quot;ARRESTED&quot; ìƒíƒœì˜ ê°€ìƒ í´ëŸ¬ìŠ¤í„°ë¥¼ ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì˜ˆê¸°ì¹˜ ì•Šì€ ìƒíƒœ ë¬¸ì œê°€ í•´ê²°ë˜ê³  ì¶”ê°€ ì‘ì—…ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¢…ë£Œ ë¬¸ì œâ€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ë„¤ì„ìŠ¤í˜ì´ìŠ¤-ì¢…ë£Œ-ë¬¸ì œ","content":" ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ &quot;Terminating&quot; ìƒíƒœì—ì„œ ë©ˆì¶”ê³  ì‚­ì œí•  ìˆ˜ ì—†ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ finalizerë¥¼ ì œê±°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  ì°¸ê³ : &lt;namespace&gt;ë¥¼ ì‚­ì œí•˜ë ¤ëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”.  NAMESPACE=&lt;namespace&gt; kubectl get namespace $NAMESPACE -o json | sed 's/&quot;kubernetes&quot;//' | kubectl replace --raw &quot;/api/v1/namespaces/$NAMESPACE/finalize&quot; -f -   ì´ ëª…ë ¹ì€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì„¸ë¶€ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³ , &quot;kubernetes&quot; finalizerë¥¼ ì œê±°í•˜ê³ , ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œ finalizerë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ replace ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì¢…ë£Œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ë£Œí•˜ê³  ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ë¬¸ì œê°€ ê³„ì†ë˜ê±°ë‚˜ ì¶”ê°€ ì§€ì›ì´ í•„ìš”í•œ ê²½ìš° ì§€ì› íŒ€ì— ì—°ë½í•˜ì—¬ ì¶”ê°€ ì•ˆë‚´ ë° ë¬¸ì œ í•´ê²° ë‹¨ê³„ë¥¼ ë°›ìœ¼ì„¸ìš”.  ","version":"Next","tagName":"h2"},{"title":"KMS Alias AlreadyExistsExceptionâ€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#kms-alias-alreadyexistsexception","content":" Terraform ì„¤ì¹˜ ë˜ëŠ” ì¬ë°°í¬ ì¤‘ì— ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: AlreadyExistsException: An alias with the name ... already exists. ì´ëŠ” ìƒì„±í•˜ë ¤ëŠ” KMS ë³„ì¹­ì´ AWS ê³„ì •ì— ì´ë¯¸ ì¡´ì¬í•  ë•Œ ë°œìƒí•©ë‹ˆë‹¤.  â”‚ Error: creating KMS Alias (alias/eks/trainium-inferentia): AlreadyExistsException: An alias with the name arn:aws:kms:us-west-2:23423434:alias/eks/trainium-inferentia already exists â”‚ â”‚ with module.eks.module.kms.aws_kms_alias.this[&quot;cluster&quot;], â”‚ on .terraform/modules/eks.kms/main.tf line 452, in resource &quot;aws_kms_alias&quot; &quot;this&quot;: â”‚ 452: resource &quot;aws_kms_alias&quot; &quot;this&quot; { â”‚   í•´ê²° ë°©ë²•:  ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ë©´ aws kms delete-alias ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ KMS ë³„ì¹­ì„ ì‚­ì œí•©ë‹ˆë‹¤. ëª…ë ¹ì„ ì‹¤í–‰í•˜ê¸° ì „ì— ë³„ì¹­ ì´ë¦„ê³¼ ë¦¬ì „ì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.  aws kms delete-alias --alias-name &lt;KMS_ALIAS_NAME&gt; --region &lt;ENTER_REGION&gt;   ","version":"Next","tagName":"h2"},{"title":"ì˜¤ë¥˜: creating CloudWatch Logs Log Groupâ€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ì˜¤ë¥˜-creating-cloudwatch-logs-log-group","content":" Terraformì´ AWS ê³„ì •ì— ì´ë¯¸ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— CloudWatch Logs ë¡œê·¸ ê·¸ë£¹ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  â•· â”‚ Error: creating CloudWatch Logs Log Group (/aws/eks/trainium-inferentia/cluster): operation error CloudWatch Logs: CreateLogGroup, https response error StatusCode: 400, RequestID: 5c34c47a-72c6-44b2-a345-925824f24d38, ResourceAlreadyExistsException: The specified log group already exists â”‚ â”‚ with module.eks.aws_cloudwatch_log_group.this[0], â”‚ on .terraform/modules/eks/main.tf line 106, in resource &quot;aws_cloudwatch_log_group&quot; &quot;this&quot;: â”‚ 106: resource &quot;aws_cloudwatch_log_group&quot; &quot;this&quot; {   í•´ê²° ë°©ë²•:  ë¡œê·¸ ê·¸ë£¹ ì´ë¦„ê³¼ ë¦¬ì „ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ ê¸°ì¡´ ë¡œê·¸ ê·¸ë£¹ì„ ì‚­ì œí•©ë‹ˆë‹¤.  aws logs delete-log-group --log-group-name &lt;LOG_GROUP_NAME&gt; --region &lt;ENTER_REGION&gt;   ","version":"Next","tagName":"h2"},{"title":"Karpenter ì˜¤ë¥˜ - Service Linked Role ëˆ„ë½â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#karpenter-ì˜¤ë¥˜---service-linked-role-ëˆ„ë½","content":" Karpenterê°€ ìƒˆ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ë ¤ê³  í•  ë•Œ ì•„ë˜ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.  &quot;error&quot;:&quot;launching nodeclaim, creating instance, with fleet error(s), AuthFailure.ServiceLinkedRoleCreationNotPermitted: The provided credentials do not have permission to create the service-linked role for EC2 Spot Instances.&quot;}   í•´ê²° ë°©ë²•:  ServiceLinkedRoleCreationNotPermitted ì˜¤ë¥˜ë¥¼ í”¼í•˜ë ¤ë©´ ì‚¬ìš© ì¤‘ì¸ AWS ê³„ì •ì— ì„œë¹„ìŠ¤ ì—°ê²° ì—­í• ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.  aws iam create-service-linked-role --aws-service-name spot.amazonaws.com   ","version":"Next","tagName":"h2"},{"title":"ë°°í¬ í›„ Karpenterê°€ CrashLoopBackOff ìƒíƒœ - STS ì˜¤ë¥˜â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ë°°í¬-í›„-karpenterê°€-crashloopbackoff-ìƒíƒœ---sts-ì˜¤ë¥˜","content":" ë°°í¬ í›„ karpenter íŒŒë“œë¥¼ í™•ì¸í•  ë•Œ ë‹¤ìŒ ë¡œê·¸ì™€ í•¨ê»˜ CrashLoopBackOff ìƒíƒœì…ë‹ˆë‹¤:  {&quot;level&quot;:&quot;ERROR&quot;,&quot;time&quot;:&quot;2025-09-30T12:52:27.746Z&quot;,&quot;logger&quot;:&quot;controller&quot;,&quot;message&quot;:&quot;ec2 api connectivity check failed&quot;,&quot;commit&quot;:&quot;13242ea&quot;,&quot;error&quot;:&quot;operation error EC2: DescribeInstanceTypes, get identity: get credentials: failed to refresh cached credentials, failed to retrieve credentials, operation error STS: AssumeRoleWithWebIdentity, https response error StatusCode: 403, RequestID: xxx, RegionDisabledException: STS is not activated in this region for account:xxxxx. Your account administrator can activate STS in this region using the IAM Console.&quot;}   ","version":"Next","tagName":"h2"},{"title":"í•´ê²° ë°©ë²•:â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#í•´ê²°-ë°©ë²•-3","content":" &quot;STS is not activated in this region for account&quot; ë©”ì‹œì§€ëŠ” AWS ê³„ì • ê´€ë¦¬ìê°€ ìš”ì²­ì´ ì´ë£¨ì–´ì§€ëŠ” íŠ¹ì • ë¦¬ì „ì—ì„œ ì„ì‹œ ìê²© ì¦ëª…ì„ ìƒì„±í•˜ê¸° ìœ„í•œ ìš”ì²­ì´ ì„±ê³µí•˜ê¸° ì „ì— AWS Security Token Service(STS)ë¥¼ í™œì„±í™”í•´ì•¼ í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ê³„ì • ì„¤ì • í˜ì´ì§€ì˜ AWS IAM ì½˜ì†”ì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ì „ì— ëŒ€í•´ STSë¥¼ í™œì„±í™”í•  ìˆ˜ ìˆìœ¼ë©°, ì—¬ê¸°ì—ì„œ í˜„ì¬ í™œì„±í™”ëœ ë¦¬ì „ë„ í‘œì‹œë©ë‹ˆë‹¤.  ë¬¸ì„œ ë§í¬: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_enable-regions.html  ","version":"Next","tagName":"h2"},{"title":"ì˜¤ë¥˜: AmazonEKS_CNI_IPv6_Policy does not existâ€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ì˜¤ë¥˜-amazoneks_cni_ipv6_policy-does-not-exist","content":" IPv6ë¥¼ ì§€ì›í•˜ëŠ” ì†”ë£¨ì…˜ì„ ë°°í¬í•  ë•Œ ë‹¤ìŒ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°:  â”‚ Error: attaching IAM Policy (arn:aws:iam::1234567890:policy/AmazonEKS_CNI_IPv6_Policy) to IAM Role (core-node-group-eks-node-group-20241111182906854800000003): operation error IAM: AttachRolePolicy, https response error StatusCode: 404, RequestID: 9c99395a-ce3d-4a05-b119-538470a3a9f7, NoSuchEntity: Policy arn:aws:iam::1234567890:policy/AmazonEKS_CNI_IPv6_Policy does not exist or is not attachable.   ","version":"Next","tagName":"h2"},{"title":"ë¬¸ì œ ì„¤ëª…:â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#ë¬¸ì œ-ì„¤ëª…-3","content":" Amazon VPC CNI í”ŒëŸ¬ê·¸ì¸ì€ IPv6 ì£¼ì†Œë¥¼ í• ë‹¹í•˜ê¸° ìœ„í•´ IAM ê¶Œí•œì´ í•„ìš”í•˜ë¯€ë¡œ IAM ì •ì±…ì„ ìƒì„±í•˜ê³  CNIê°€ ì‚¬ìš©í•  ì—­í• ê³¼ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê° IAM ì •ì±… ì´ë¦„ì€ ë™ì¼í•œ AWS ê³„ì •ì—ì„œ ê³ ìœ í•´ì•¼ í•©ë‹ˆë‹¤. ì •ì±…ì´ terraform ìŠ¤íƒì˜ ì¼ë¶€ë¡œ ìƒì„±ë˜ê³  ì—¬ëŸ¬ ë²ˆ ë°°í¬ë˜ë©´ ì¶©ëŒì´ ë°œìƒí•©ë‹ˆë‹¤.  ì´ ì˜¤ë¥˜ë¥¼ í•´ê²°í•˜ë ¤ë©´ ì•„ë˜ ëª…ë ¹ìœ¼ë¡œ ì •ì±…ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. AWS ê³„ì •ë‹¹ í•œ ë²ˆë§Œ ìˆ˜í–‰í•˜ë©´ ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"í•´ê²° ë°©ë²•:â€‹","type":1,"pageTitle":"ë¬¸ì œ í•´ê²°","url":"/ai-on-eks/ko/docs/infra/misc/troubleshooting#í•´ê²°-ë°©ë²•-4","content":" ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë³µì‚¬í•˜ì—¬ vpc-cni-ipv6-policy.jsonì´ë¼ëŠ” íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.  { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;ec2:AssignIpv6Addresses&quot;, &quot;ec2:DescribeInstances&quot;, &quot;ec2:DescribeTags&quot;, &quot;ec2:DescribeNetworkInterfaces&quot;, &quot;ec2:DescribeInstanceTypes&quot; ], &quot;Resource&quot;: &quot;&quot; }, { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;ec2:CreateTags&quot; ], &quot;Resource&quot;: [ &quot;arn:aws:ec2::*:network-interface/*&quot; ] } ] }   IAM ì •ì±…ì„ ìƒì„±í•©ë‹ˆë‹¤.  aws iam create-policy --policy-name AmazonEKS_CNI_IPv6_Policy --policy-document file://vpc-cni-ipv6-policy.json   ë¸”ë£¨í”„ë¦°íŠ¸ì˜ install.sh ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤ ","version":"Next","tagName":"h3"},{"title":"EKS ê¸°ë°˜ JARK","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/infra/training/jark","content":"","keywords":"","version":"Next"},{"title":"JARKë€?â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ JARK","url":"/ai-on-eks/ko/docs/infra/training/jark#jarkë€","content":" JARKëŠ” JupyterHub, Argo Workflows, Ray, Kubernetesë¡œ êµ¬ì„±ëœ ê°•ë ¥í•œ ìŠ¤íƒìœ¼ë¡œ, Amazon EKSì—ì„œ ìƒì„±í˜• AI ëª¨ë¸ì˜ ë°°í¬ ë° ê´€ë¦¬ë¥¼ ê°„ì†Œí™”í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ìŠ¤íƒì€ AI ë° Kubernetes ì—ì½”ì‹œìŠ¤í…œì—ì„œ ê°€ì¥ íš¨ê³¼ì ì¸ ë„êµ¬ë“¤ì„ ê²°í•©í•˜ì—¬ ëŒ€ê·œëª¨ AI ëª¨ë¸ì˜ í›ˆë ¨, íŒŒì¸íŠœë‹ ë° ì¶”ë¡ ì„ ìœ„í•œ ê°•ë ¥í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.  JARKëŠ” AI/ML ê´€ì¸¡ì„±ì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê´€ì¸¡ì„± ì•„í‚¤í…ì²˜ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ê´€ì¸¡ì„± ì„¹ì…˜ì„ ì°¸ì¡°í•˜ì„¸ìš”.  ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” ê¸°ëŠ¥ ë° ì´ì â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ JARK","url":"/ai-on-eks/ko/docs/infra/training/jark#ì£¼ìš”-ê¸°ëŠ¥-ë°-ì´ì ","content":" JupyterHub: ëª¨ë¸ ê°œë°œ ë° í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì— í•„ìˆ˜ì ì¸ ë…¸íŠ¸ë¶ ì‹¤í–‰ì„ ìœ„í•œ í˜‘ì—… í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.  Argo Workflows: ë°ì´í„° ì¤€ë¹„ë¶€í„° ëª¨ë¸ ë°°í¬ê¹Œì§€ ì „ì²´ AI ëª¨ë¸ íŒŒì´í”„ë¼ì¸ì„ ìë™í™”í•˜ì—¬ ì¼ê´€ë˜ê³  íš¨ìœ¨ì ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.  Ray: ì—¬ëŸ¬ ë…¸ë“œì— ê±¸ì³ AI ëª¨ë¸ í›ˆë ¨ ë° ì¶”ë¡ ì„ í™•ì¥í•˜ì—¬ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì„ ë” ì‰½ê²Œ ì²˜ë¦¬í•˜ê³  í›ˆë ¨ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.  Kubernetes: ê³ ê°€ìš©ì„±ê³¼ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±ìœ¼ë¡œ ì»¨í…Œì´ë„ˆí™”ëœ AI ëª¨ë¸ì„ ì‹¤í–‰, í™•ì¥ ë° ê´€ë¦¬í•˜ëŠ” ë° í•„ìš”í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ ì œê³µí•˜ì—¬ ìŠ¤íƒì„ êµ¬ë™í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"JARKë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ì´ìœ â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ JARK","url":"/ai-on-eks/ko/docs/infra/training/jark#jarkë¥¼-ì‚¬ìš©í•´ì•¼-í•˜ëŠ”-ì´ìœ ","content":" JARK ìŠ¤íƒì€ AI ëª¨ë¸ ë°°í¬ ë° ê´€ë¦¬ì˜ ë³µì¡í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‹¨ìˆœí™”í•˜ë ¤ëŠ” íŒ€ê³¼ ì¡°ì§ì— ì´ìƒì ì…ë‹ˆë‹¤. ìµœì²¨ë‹¨ ìƒì„±í˜• ëª¨ë¸ì„ ì‘ì—…í•˜ë“  ê¸°ì¡´ AI ì›Œí¬ë¡œë“œë¥¼ í™•ì¥í•˜ë“ , Amazon EKS ê¸°ë°˜ JARKëŠ” ì„±ê³µì— í•„ìš”í•œ ìœ ì—°ì„±, í™•ì¥ì„± ë° ì œì–´ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"Kubernetes ê¸°ë°˜ Rayâ€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ JARK","url":"/ai-on-eks/ko/docs/infra/training/jark#kubernetes-ê¸°ë°˜-ray","content":" RayëŠ” í™•ì¥ ê°€ëŠ¥í•˜ê³  ë¶„ì‚°ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë¶„ì‚° ì»´í“¨íŒ…ì„ ìœ„í•œ ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ APIë¥¼ ì œê³µí•˜ì—¬ ë³‘ë ¬ ë° ë¶„ì‚° Python ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë° ê¸°ì—¬ì ì»¤ë®¤ë‹ˆí‹°ê°€ ì„±ì¥í•˜ê³  ìˆìœ¼ë©°, Anyscale, Inc.ì˜ Ray íŒ€ì—ì„œ ì ê·¹ì ìœ¼ë¡œ ìœ ì§€ ê´€ë¦¬ ë° ê°œë°œí•˜ê³  ìˆìŠµë‹ˆë‹¤.    ì¶œì²˜: https://docs.ray.io/en/latest/cluster/key-concepts.html  í”„ë¡œë•ì…˜ì—ì„œ ì—¬ëŸ¬ ë¨¸ì‹ ì— Rayë¥¼ ë°°í¬í•˜ë ¤ë©´ ì‚¬ìš©ìê°€ ë¨¼ì € Ray Clusterë¥¼ ë°°í¬í•´ì•¼ í•©ë‹ˆë‹¤. Ray ClusterëŠ” í—¤ë“œ ë…¸ë“œì™€ ì›Œì»¤ ë…¸ë“œë¡œ êµ¬ì„±ë˜ë©°, ë‚´ì¥ëœ Ray Autoscalerë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  Amazon EKSë¥¼ í¬í•¨í•œ Kubernetesì—ì„œ Ray Cluster ë°°í¬ëŠ” KubeRay Operatorë¥¼ í†µí•´ ì§€ì›ë©ë‹ˆë‹¤. ì´ ì˜¤í¼ë ˆì´í„°ëŠ” Ray í´ëŸ¬ìŠ¤í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” Kubernetes ë„¤ì´í‹°ë¸Œ ë°©ì‹ì„ ì œê³µí•©ë‹ˆë‹¤. KubeRay Operator ì„¤ì¹˜ì—ëŠ” ì—¬ê¸°ì— ë¬¸ì„œí™”ëœ ëŒ€ë¡œ RayCluster, RayJob ë° RayServiceìš© ì˜¤í¼ë ˆì´í„° ë° CRD ë°°í¬ê°€ í¬í•¨ë©ë‹ˆë‹¤.  Kubernetesì—ì„œ Rayë¥¼ ë°°í¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì—¬ëŸ¬ ì´ì ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:  í™•ì¥ì„±: Kubernetesë¥¼ ì‚¬ìš©í•˜ë©´ ì›Œí¬ë¡œë“œ ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ Ray í´ëŸ¬ìŠ¤í„°ë¥¼ í™•ì¥í•˜ê±°ë‚˜ ì¶•ì†Œí•  ìˆ˜ ìˆì–´ ëŒ€ê·œëª¨ ë¶„ì‚° ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‚´ê²°í•¨ì„±: KubernetesëŠ” ë…¸ë“œ ì¥ì• ë¥¼ ì²˜ë¦¬í•˜ê³  Ray í´ëŸ¬ìŠ¤í„°ì˜ ê³ ê°€ìš©ì„±ì„ ë³´ì¥í•˜ëŠ” ë‚´ì¥ ë©”ì»¤ë‹ˆì¦˜ì„ ì œê³µí•©ë‹ˆë‹¤. ë¦¬ì†ŒìŠ¤ í• ë‹¹: Kubernetesë¥¼ ì‚¬ìš©í•˜ë©´ Ray ì›Œí¬ë¡œë“œì— ëŒ€í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì‰½ê²Œ í• ë‹¹í•˜ê³  ê´€ë¦¬í•˜ì—¬ ìµœì ì˜ ì„±ëŠ¥ì„ ìœ„í•´ í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì‹ì„±: Kubernetesì—ì„œ Rayë¥¼ ë°°í¬í•˜ë©´ ì—¬ëŸ¬ í´ë¼ìš°ë“œ ë° ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°ì´í„° ì„¼í„°ì—ì„œ ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆì–´ í•„ìš”ì— ë”°ë¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§: KubernetesëŠ” ë©”íŠ¸ë¦­ ë° ë¡œê¹…ì„ í¬í•¨í•œ í’ë¶€í•œ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ë¬¸ì œ í•´ê²° ë° ì„±ëŠ¥ ìµœì í™”ë¥¼ ì‰½ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì „ë°˜ì ìœ¼ë¡œ Kubernetesì—ì„œ Rayë¥¼ ë°°í¬í•˜ë©´ ë¶„ì‚° ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë°°í¬ ë° ê´€ë¦¬ë¥¼ ë‹¨ìˆœí™”í•  ìˆ˜ ìˆì–´ ëŒ€ê·œëª¨ ë¨¸ì‹  ëŸ¬ë‹ ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ë§ì€ ì¡°ì§ì—ì„œ ì¸ê¸° ìˆëŠ” ì„ íƒì…ë‹ˆë‹¤.  ë°°í¬ë¥¼ ì§„í–‰í•˜ê¸° ì „ì— ê³µì‹ ë¬¸ì„œì˜ ê´€ë ¨ ì„¹ì…˜ì„ ì½ì–´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.    ì¶œì²˜: https://docs.ray.io/en/latest/cluster/kubernetes/index.html  ì†”ë£¨ì…˜ ë°°í¬ ğŸ‘ˆ  ë°°í¬ í™•ì¸ ğŸ‘ˆ  ì •ë¦¬ ğŸ‘ˆ ","version":"Next","tagName":"h3"},{"title":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster","content":"","keywords":"","version":"Next"},{"title":"ì™œ?â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ì™œ","content":" ì´ ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°ëŠ” ì—¬ì •ì˜ ì–´ëŠ ë‹¨ê³„ì— ìˆë“  ëˆ„êµ¬ë‚˜ ì¶”ë¡ ì„ ìœ„í•´ EKSë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. LLMì€ ë°°í¬í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤: ëª¨ë¸ í¬ê¸°, ì•„í‚¤í…ì²˜, ê¸°ëŠ¥ ë° ìš”êµ¬ ì‚¬í•­ì— ë”°ë¼ ëª¨ë¸ì„ ì ì ˆíˆ ë°°í¬, ì‹¤í–‰ ë° í™•ì¥í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ë„êµ¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë˜í•œ í…ìŠ¤íŠ¸ -&gt; ì´ë¯¸ì§€ í™•ì‚° ëª¨ë¸ì´ë‚˜ ë” ì „í†µì ì¸ ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ê³¼ ê°™ì´ LLMë§Œì´ ì•„ë‹Œ ëª¨ë¸ì„ ì‹¤í–‰í•˜ê³  ì‹¶ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  ì´ ì¸í”„ë¼ëŠ” ì²« ë²ˆì§¸ ì§€ì› ê³„ì¸µì…ë‹ˆë‹¤. ì´ ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” Inference Charts ë° ê°€ì´ë˜ìŠ¤ì™€ í•¨ê»˜ AI on EKSëŠ” ì›í•˜ëŠ” ì¶”ë¡ ì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë“  ë„êµ¬ì™€ ì§€ì‹ì„ ê°–ì¶”ë„ë¡ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ì‚¬ìš© ì‚¬ë¡€â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ì‚¬ìš©-ì‚¬ë¡€","content":" ë‹¨ì¼ ëª¨ë¸ í…ŒìŠ¤íŠ¸: ëª¨ë¸ì„ ë°°í¬í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ì—¬ ë¬´ì—‡ì„ í•˜ëŠ”ì§€ ë˜ëŠ” ì–¼ë§ˆë‚˜ ì˜ ìˆ˜í–‰í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì‹¶ì€ ê²½ìš°.ë‹¤ì¤‘ ë…¸ë“œ ë¶„ì‚° ì¶”ë¡ : ëª¨ë¸ì´ ë„ˆë¬´ ì»¤ì„œ ë‹¨ì¼ ë…¸ë“œì— ë§ì§€ ì•ŠëŠ” ê²½ìš°.ëª¨ë¸ ì˜¤í† ìŠ¤ì¼€ì¼ë§: ë“¤ì–´ì˜¤ëŠ” ìš”ì²­ê³¼ í ê¸¸ì´ì— ë”°ë¼ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ìˆ˜ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•´ì•¼ í•˜ëŠ” ê²½ìš°.ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹: ë‹¤ì–‘í•œ íŠ¸ë˜í”½ íŒ¨í„´ìœ¼ë¡œ ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì—ì„œ ëª¨ë¸ì´ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ ì´í•´í•˜ê³  ì‹¶ì€ ê²½ìš°. ì´ë¥¼ í†µí•´ ì„œë¹„ìŠ¤ ìˆ˜ì¤€ ëª©í‘œ(SLO)ë¥¼ ì¶©ì¡±í•˜ë„ë¡ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì™€ ë³µì œë³¸ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.ë‹¤ì¤‘ ëª¨ë¸ ì•„í‚¤í…ì²˜: LLMê³¼ í…ìŠ¤íŠ¸-&gt;ì´ë¯¸ì§€ í™•ì‚° ëª¨ë¸ì„ ëª¨ë‘ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì€ ê²½ìš°.  ","version":"Next","tagName":"h2"},{"title":"ì†Œê°œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ì†Œê°œ","content":" ì´ ì¸í”„ë¼ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ê¸°ëŠ¥ì„ ê°–ì¶˜ AI/ML ì¶”ë¡  ì›Œí¬ë¡œë“œì— ìµœì í™”ëœ Amazon EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:  KubeRay Operator: í™•ì¥ ê°€ëŠ¥í•œ ì¶”ë¡ ì„ ìœ„í•œ ë¶„ì‚° Ray ì›Œí¬ë¡œë“œ í™œì„±í™”LeaderWorkerSet: ë‹¤ì¤‘ ë…¸ë“œ ë¶„ì‚° ì¶”ë¡  í™œì„±í™”AIBrix ìŠ¤íƒ: ê³ ê¸‰ ì¶”ë¡  ìµœì í™” ë° ê´€ë¦¬ ê¸°ëŠ¥GPU/Neuron ì§€ì›: NVIDIA GPU ë° AWS Neuron(Inferentia/Trainium) ì›Œí¬ë¡œë“œ ëª¨ë‘ ì¤€ë¹„AI/ML ê´€ì¸¡ì„± ìŠ¤íƒ: ML ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ í¬ê´„ì ì¸ ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡ì„±ì˜¤í† ìŠ¤ì¼€ì¼ë§: ë¹„ìš© ìµœì í™”ë¥¼ ìœ„í•œ Karpenter ê¸°ë°˜ ë…¸ë“œ ì˜¤í† ìŠ¤ì¼€ì¼ë§  í´ëŸ¬ìŠ¤í„°ëŠ” AI on EKS Inference Chartsì™€ ì›í™œí•˜ê²Œ ì‘ë™í•˜ë„ë¡ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì–´ ì¶”ë¡  ì›Œí¬ë¡œë“œ ë°°í¬ë¥¼ ìœ„í•œ ì™„ì „í•œ ì—”ë“œíˆ¬ì—”ë“œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë¦¬ì†ŒìŠ¤â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ë¦¬ì†ŒìŠ¤","content":" ì´ ì¸í”„ë¼ëŠ” ë‹¤ìŒ AWS ë¦¬ì†ŒìŠ¤ë¥¼ ë°°í¬í•©ë‹ˆë‹¤:  ","version":"Next","tagName":"h2"},{"title":"í•µì‹¬ ì¸í”„ë¼â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#í•µì‹¬-ì¸í”„ë¼","content":" ì—¬ëŸ¬ AZì— ê±¸ì³ í¼ë¸”ë¦­ ë° í”„ë¼ì´ë¹— ì„œë¸Œë„·ì´ ìˆëŠ” Amazon VPCAmazon EKS Cluster (ê¸°ë³¸ì ìœ¼ë¡œ v1.33)EKS Managed Node Groups: EKS ì»´í“¨íŒ… ë…¸ë“œë¡œ ì‚¬ìš©ë˜ëŠ” EC2 ì¸ìŠ¤í„´ìŠ¤ì˜ ì˜¤í†  ìŠ¤ì¼€ì¼ë§ ê·¸ë£¹.í”„ë¼ì´ë¹— ì„œë¸Œë„· ì¸í„°ë„· ì•¡ì„¸ìŠ¤ë¥¼ ìœ„í•œ NAT ê²Œì´íŠ¸ì›¨ì´í¼ë¸”ë¦­ ì„œë¸Œë„· ì•¡ì„¸ìŠ¤ë¥¼ ìœ„í•œ ì¸í„°ë„· ê²Œì´íŠ¸ì›¨ì´ì ì ˆí•œ ì¸ê·¸ë ˆìŠ¤/ì´ê·¸ë ˆìŠ¤ ê·œì¹™ì´ ìˆëŠ” ë³´ì•ˆ ê·¸ë£¹  ","version":"Next","tagName":"h3"},{"title":"EKS ì• ë“œì˜¨â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#eks-ì• ë“œì˜¨","content":" ì¸ê·¸ë ˆìŠ¤ ê´€ë¦¬ë¥¼ ìœ„í•œ AWS Load Balancer Controllerì˜êµ¬ ìŠ¤í† ë¦¬ì§€ë¥¼ ìœ„í•œ EBS CSI DriveríŒŒë“œ ë„¤íŠ¸ì›Œí‚¹ì„ ìœ„í•œ VPC CNIì„œë¹„ìŠ¤ ê²€ìƒ‰ì„ ìœ„í•œ CoreDNSì„œë¹„ìŠ¤ ë„¤íŠ¸ì›Œí‚¹ì„ ìœ„í•œ Kube-proxyë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­ì„ ìœ„í•œ Metrics Serverë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ Amazon CloudWatch Observability  ","version":"Next","tagName":"h3"},{"title":"AI/ML ê´€ë ¨ êµ¬ì„± ìš”ì†Œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#aiml-ê´€ë ¨-êµ¬ì„±-ìš”ì†Œ","content":" ë¶„ì‚° Ray ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ KubeRay Operatorë‹¤ì¤‘ ë…¸ë“œ ë¶„ì‚° ì¶”ë¡ ì„ ìœ„í•œ LeaderWorkerSetGPU ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ ìœ„í•œ NVIDIA Device PluginInferentia/Trainium ì§€ì›ì„ ìœ„í•œ AWS Neuron Device Pluginì§€ëŠ¥í˜• ë…¸ë“œ ì˜¤í† ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ Karpenter  ","version":"Next","tagName":"h3"},{"title":"ê´€ì¸¡ì„± ìŠ¤íƒâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ê´€ì¸¡ì„±-ìŠ¤íƒ","content":" ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì„ ìœ„í•œ Prometheusì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œë¥¼ ìœ„í•œ Grafanaì•Œë¦¼ì„ ìœ„í•œ AlertManagerë…¸ë“œ ìˆ˜ì¤€ ë©”íŠ¸ë¦­ì„ ìœ„í•œ Node ExporterGPU ë©”íŠ¸ë¦­ì„ ìœ„í•œ DCGM Exporter (GPU ë…¸ë“œê°€ ìˆì„ ë•Œ)  ","version":"Next","tagName":"h3"},{"title":"AIBrix êµ¬ì„± ìš”ì†Œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#aibrix-êµ¬ì„±-ìš”ì†Œ","content":" ì¶”ë¡  ìµœì í™”ë¥¼ ìœ„í•œ AIBrix CoreíŠ¸ë˜í”½ ê´€ë¦¬ë¥¼ ìœ„í•œ ê²Œì´íŠ¸ì›¨ì´ ë° ë¼ìš°íŒ…ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” ë„êµ¬  ","version":"Next","tagName":"h3"},{"title":"ë°°í¬â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ë°°í¬","content":" ","version":"Next","tagName":"h2"},{"title":"ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ì•„í‚¤í…ì²˜-ë‹¤ì´ì–´ê·¸ë¨","content":"   ","version":"Next","tagName":"h3"},{"title":"ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ì‚¬ì „-ìš”êµ¬-ì‚¬í•­","content":" ì ì ˆí•œ ê¶Œí•œìœ¼ë¡œ êµ¬ì„±ëœ AWS CLITerraform (&gt;= 1.0)í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ë¥¼ ìœ„í•œ kubectlì°¨íŠ¸ ë°°í¬ë¥¼ ìœ„í•œ Helm (&gt;= 3.0)  ","version":"Next","tagName":"h3"},{"title":"0ë‹¨ê³„: ë³µì œ ë° ì´ë™â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#0ë‹¨ê³„-ë³µì œ-ë°-ì´ë™","content":" git clone https://github.com/awslabs/ai-on-eks.git cd infra/solutions/inference-ready-cluster   ","version":"Next","tagName":"h3"},{"title":"1ë‹¨ê³„: (ì„ íƒ ì‚¬í•­) ë³€ìˆ˜ êµ¬ì„±â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#1ë‹¨ê³„-ì„ íƒ-ì‚¬í•­-ë³€ìˆ˜-êµ¬ì„±","content":" ë°°í¬ë¥¼ ì‚¬ìš©ì ì§€ì •í•˜ë ¤ë©´ terraform/blueprint.tfvars íŒŒì¼ì„ í¸ì§‘í•©ë‹ˆë‹¤:  name = &quot;my-inference-cluster&quot; region = &quot;us-west-2&quot; enable_kuberay_operator = true enable_ai_ml_observability_stack = true enable_aibrix_stack = true enable_leader_worker_set = true availability_zones_count = 4   ëª¨ë“  ë³€ìˆ˜ëŠ” variables.tf íŒŒì¼ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤  ","version":"Next","tagName":"h3"},{"title":"2ë‹¨ê³„: ì¸í”„ë¼ ë°°í¬â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#2ë‹¨ê³„-ì¸í”„ë¼-ë°°í¬","content":" # ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ./install.sh   ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìë™ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:  ê¸°ë³¸ Terraform êµ¬ì„± ë³µì‚¬Terraform ì´ˆê¸°í™”ì¸í”„ë¼ ê³„íš ë° ì ìš©kubectl ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±  ","version":"Next","tagName":"h3"},{"title":"3ë‹¨ê³„: VPCâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#3ë‹¨ê³„-vpc","content":" ì§€ì •ëœ êµ¬ì„±ì— ë”°ë¼ Amazon Virtual Private Network(VPC)ê°€ í”„ë¡œë¹„ì €ë‹ë˜ê³  êµ¬ì„±ë©ë‹ˆë‹¤. ì•ˆì •ì„±ì— ëŒ€í•œ ëª¨ë²” ì‚¬ë¡€ì— ë”°ë¼ ë…¸ë“œ íšë“ ë° ê³ ê°€ìš©ì„±ì˜ ìµœìƒì˜ ê¸°íšŒë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ 4ê°œì˜ ê°€ìš© ì˜ì—­(AZ)ì´ êµ¬ì„±ë©ë‹ˆë‹¤. í† í´ë¡œì§€ ì¸ì‹ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì„±ëŠ¥/ë¹„ìš©ì„ ìœ„í•´ AI/ML ì›Œí¬ë¡œë“œë¥¼ ë™ì¼í•œ AZì— ìœ ì§€í•˜ì§€ë§Œ ê°€ìš©ì„±ì„ ìœ„í•´ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"4ë‹¨ê³„: EKSâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#4ë‹¨ê³„-eks","content":" Amazon Elastic Kubernetes Service(EKS) í´ëŸ¬ìŠ¤í„°ëŠ” ì»´í“¨íŒ… ë…¸ë“œì—ì„œ ì¤‘ìš”í•œ í´ëŸ¬ìŠ¤í„° ì• ë“œì˜¨(CoreDNS, AWS Load Balancer Controller ë° Karpenter)ì„ ì‹¤í–‰í•˜ëŠ” Managed Nodes Group(MNG)ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹ë©ë‹ˆë‹¤. KarpenterëŠ” êµ¬ì„±ì— ë”°ë¼ ê°€ì¥ ë¹„ìš© íš¨ìœ¨ì ì¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìš°ì„ ì‹œí•˜ë©´ì„œ ë‹¤ë¥¸ EKS ì• ë“œì˜¨ ë° ì‚¬ìš©ìê°€ ë°°í¬í•  ì¶”ë¡  ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ ì»´í“¨íŒ… ìš©ëŸ‰ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"5ë‹¨ê³„: EKS ì• ë“œì˜¨â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#5ë‹¨ê³„-eks-ì• ë“œì˜¨","content":" í™˜ê²½ë³„ Terraform êµ¬ì„± íŒŒì¼ì— ì •ì˜ëœ êµ¬ì„±ì— ë”°ë¼ ë‹¤ë¥¸ ì¤‘ìš”í•œ EKS ì• ë“œì˜¨(LWS, KubeRay ë“±)ì´ ë°°í¬ë©ë‹ˆë‹¤(ìœ„ì˜ 1ë‹¨ê³„ ì°¸ì¡°)  ","version":"Next","tagName":"h3"},{"title":"6ë‹¨ê³„: ê´€ì¸¡ì„±â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#6ë‹¨ê³„-ê´€ì¸¡ì„±","content":" í™˜ê²½ì—ì„œ ë©”íŠ¸ë¦­ê³¼ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´ FluentBit, Prometheus ë° Grafanaë¥¼ í¬í•¨í•œ ê´€ì¸¡ì„± ìŠ¤íƒì´ ë°°í¬ë©ë‹ˆë‹¤. AI/ML ê´€ë ¨ ì›Œí¬ë¡œë“œë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´ Service ë° Pod Monitorê°€ ë°°í¬ë©ë‹ˆë‹¤. Grafana ëŒ€ì‹œë³´ë“œëŠ” ë©”íŠ¸ë¦­ê³¼ ë¡œê·¸ë¥¼ ë‚˜ë€íˆ ìë™ìœ¼ë¡œ ì‹œê°í™”í•˜ë„ë¡ êµ¬ì„±ë©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"7ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° ì¤€ë¹„ ì™„ë£Œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#7ë‹¨ê³„-í´ëŸ¬ìŠ¤í„°-ì¤€ë¹„-ì™„ë£Œ","content":" ì‚¬ìš©ìëŠ” EKS APIì— ì•¡ì„¸ìŠ¤í•˜ê³  AWS Network Load Balancer(NLB) ì—”ë“œí¬ì¸íŠ¸ì™€ ìƒí˜¸ ì‘ìš©í•˜ì—¬ Kubernetes CLIë¥¼ ì‚¬ìš©í•˜ì—¬ AI on EKS inference charts ë˜ëŠ” ë‹¤ë¥¸ ë¦¬í¬ì§€í† ë¦¬ë¥¼ í†µí•´ ì»¨í…Œì´ë„ˆí™”ëœ AI/ML ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"8ë‹¨ê³„: ë°°í¬ í™•ì¸â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#8ë‹¨ê³„-ë°°í¬-í™•ì¸","content":" ëª¨ë“  ê²ƒì´ ì œëŒ€ë¡œ ë°°í¬ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤  kubectl get svc,pod,deployment -A   ë‹¤ìŒ ì¶œë ¥ì´ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤(ì„¹ì…˜ì„ í™•ì¥í•˜ì—¬ ì¶œë ¥ í™•ì¸)  Details NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE aibrix-system service/aibrix-controller-manager-metrics-service ClusterIP 172.20.218.39 &lt;none&gt; 8080/TCP 13d aibrix-system service/aibrix-gateway-plugins ClusterIP 172.20.142.245 &lt;none&gt; 50052/TCP 13d aibrix-system service/aibrix-gpu-optimizer ClusterIP 172.20.14.220 &lt;none&gt; 8080/TCP 13d aibrix-system service/aibrix-kuberay-operator ClusterIP 172.20.240.255 &lt;none&gt; 8080/TCP 13d aibrix-system service/aibrix-metadata-service ClusterIP 172.20.252.24 &lt;none&gt; 8090/TCP 13d aibrix-system service/aibrix-redis-master ClusterIP 172.20.155.43 &lt;none&gt; 6379/TCP 13d argocd service/argocd-applicationset-controller ClusterIP 172.20.139.94 &lt;none&gt; 7000/TCP 13d argocd service/argocd-dex-server ClusterIP 172.20.127.60 &lt;none&gt; 5556/TCP,5557/TCP 13d argocd service/argocd-redis ClusterIP 172.20.48.202 &lt;none&gt; 6379/TCP 13d argocd service/argocd-repo-server ClusterIP 172.20.232.147 &lt;none&gt; 8081/TCP 13d argocd service/argocd-server ClusterIP 172.20.233.191 &lt;none&gt; 80/TCP,443/TCP 13d default service/etcd-client ClusterIP 172.20.47.224 &lt;none&gt; 2379/TCP 12d default service/etcd-server ClusterIP 172.20.69.95 &lt;none&gt; 2379/TCP,2380/TCP 12d default service/kubernetes ClusterIP 172.20.0.1 &lt;none&gt; 443/TCP 13d envoy-gateway-system service/envoy-aibrix-system-aibrix-eg-903790dc ClusterIP 172.20.249.100 &lt;none&gt; 80/TCP 13d envoy-gateway-system service/envoy-gateway ClusterIP 172.20.113.229 &lt;none&gt; 18000/TCP,18001/TCP,18002/TCP,19001/TCP 13d ingress-nginx service/ingress-nginx-controller LoadBalancer 172.20.27.209 k8s-ingressn-ingressn-ffa534dcb1-b4b54bcc24eaeddd.elb.us-west-2.amazonaws.com 80:31646/TCP,443:32024/TCP 13d ingress-nginx service/ingress-nginx-controller-admission ClusterIP 172.20.249.118 &lt;none&gt; 443/TCP 13d karpenter service/karpenter ClusterIP 172.20.149.70 &lt;none&gt; 8080/TCP 13d kube-system service/aws-load-balancer-webhook-service ClusterIP 172.20.83.104 &lt;none&gt; 443/TCP 13d kube-system service/eks-extension-metrics-api ClusterIP 172.20.87.142 &lt;none&gt; 443/TCP 13d kube-system service/k8s-neuron-scheduler ClusterIP 172.20.248.128 &lt;none&gt; 12345/TCP 13d kube-system service/kube-dns ClusterIP 172.20.0.10 &lt;none&gt; 53/UDP,53/TCP,9153/TCP 13d kube-system service/kube-prometheus-stack-kubelet ClusterIP None &lt;none&gt; 10250/TCP,10255/TCP,4194/TCP 13d kuberay-operator service/kuberay-operator ClusterIP 172.20.117.159 &lt;none&gt; 8080/TCP 13d lws-system service/lws-controller-manager-metrics-service ClusterIP 172.20.17.186 &lt;none&gt; 8443/TCP 13d lws-system service/lws-webhook-service ClusterIP 172.20.173.201 &lt;none&gt; 443/TCP 13d monitoring service/alertmanager-operated ClusterIP None &lt;none&gt; 9093/TCP,9094/TCP,9094/UDP 13d monitoring service/dcgm-exporter ClusterIP 172.20.79.5 &lt;none&gt; 9400/TCP 13d monitoring service/fluent-bit ClusterIP 172.20.111.213 &lt;none&gt; 2020/TCP 13d monitoring service/kube-prometheus-stack-alertmanager ClusterIP 172.20.45.163 &lt;none&gt; 9093/TCP,8080/TCP 13d monitoring service/kube-prometheus-stack-coredns ClusterIP None &lt;none&gt; 9153/TCP 13d monitoring service/kube-prometheus-stack-grafana ClusterIP 172.20.251.144 &lt;none&gt; 80/TCP 13d monitoring service/kube-prometheus-stack-kube-controller-manager ClusterIP None &lt;none&gt; 10257/TCP 13d monitoring service/kube-prometheus-stack-kube-etcd ClusterIP None &lt;none&gt; 2381/TCP 13d monitoring service/kube-prometheus-stack-kube-proxy ClusterIP None &lt;none&gt; 10249/TCP 13d monitoring service/kube-prometheus-stack-kube-scheduler ClusterIP None &lt;none&gt; 10259/TCP 13d monitoring service/kube-prometheus-stack-kube-state-metrics ClusterIP 172.20.81.57 &lt;none&gt; 8080/TCP 13d monitoring service/kube-prometheus-stack-operator ClusterIP 172.20.163.90 &lt;none&gt; 443/TCP 13d monitoring service/kube-prometheus-stack-prometheus ClusterIP 172.20.1.251 &lt;none&gt; 9090/TCP,8080/TCP 13d monitoring service/kube-prometheus-stack-prometheus-node-exporter ClusterIP 172.20.88.160 &lt;none&gt; 9100/TCP 13d monitoring service/my-cluster ClusterIP 172.20.54.44 &lt;none&gt; 9200/TCP,9300/TCP,9600/TCP,9650/TCP 13d monitoring service/my-cluster-dashboards ClusterIP 172.20.161.35 &lt;none&gt; 5601/TCP 13d monitoring service/my-cluster-masters ClusterIP None &lt;none&gt; 9200/TCP,9300/TCP 13d monitoring service/opencost ClusterIP 172.20.162.78 &lt;none&gt; 9003/TCP,9090/TCP 13d monitoring service/opensearch-discovery ClusterIP None &lt;none&gt; 9300/TCP 13d monitoring service/opensearch-operator-controller-manager-metrics-service ClusterIP 172.20.183.236 &lt;none&gt; 8443/TCP 13d monitoring service/prometheus-operated ClusterIP None &lt;none&gt; 9090/TCP 13d NAMESPACE NAME READY STATUS RESTARTS AGE aibrix-system pod/aibrix-controller-manager-5948f8f8b7-qjm7z 1/1 Running 0 13d aibrix-system pod/aibrix-gateway-plugins-5978d98445-qj2jw 1/1 Running 0 13d aibrix-system pod/aibrix-gpu-optimizer-64c978ddd8-bw7hk 1/1 Running 0 13d aibrix-system pod/aibrix-kuberay-operator-8b65d7cc4-xrcm6 1/1 Running 0 13d aibrix-system pod/aibrix-metadata-service-5499dc64b7-69tzc 1/1 Running 0 13d aibrix-system pod/aibrix-redis-master-576767646c-w9lhl 1/1 Running 0 13d ...   ","version":"Next","tagName":"h3"},{"title":"EKSì—ì„œì˜ ì¶”ë¡ â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#eksì—ì„œì˜-ì¶”ë¡ ","content":" EKSëŠ” AI/ML ì¶”ë¡ ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ê°•ë ¥í•œ í”Œë«í¼ì…ë‹ˆë‹¤. EKSì—ì„œì˜ ë§ì€ ì¶”ë¡  ê°€ëŠ¥ì„±ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ì¶”ë¡  ì„¹ì…˜ì„ í™•ì¸í•˜ì„¸ìš”.  ","version":"Next","tagName":"h2"},{"title":"Inference Charts í†µí•©â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#inference-charts-í†µí•©","content":" ì´ ì¸í”„ë¼ëŠ” AI on EKS Inference Chartsì™€ í•¨ê»˜ ì‘ë™í•˜ë„ë¡ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„°ëŠ” ì¶”ë¡  ì›Œí¬ë¡œë“œì˜ ì›í™œí•œ ë°°í¬ë¥¼ ìœ„í•œ ëª¨ë“  í•„ìš”í•œ êµ¬ì„± ìš”ì†Œì™€ êµ¬ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.  Inference Charts ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹  ì¸í”„ë¼ëŠ” ìë™ìœ¼ë¡œ ë‹¤ìŒì„ ì œê³µí•©ë‹ˆë‹¤:  KubeRay Operator - Ray-vLLM ë°°í¬ì— í•„ìš”GPU/Neuron Device Plugins - í•˜ë“œì›¨ì–´ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ìš©ê´€ì¸¡ì„± ìŠ¤íƒ - ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ Prometheus ë° GrafanaAIBrix í†µí•© - ì¶”ë¡  ìµœì í™” ë° ê´€ë¦¬ìš©  ì§€ì›ë˜ëŠ” ì¶”ë¡  íŒ¨í„´â€‹  í´ëŸ¬ìŠ¤í„°ëŠ” inference chartsì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë“  ì¶”ë¡  íŒ¨í„´ì„ ì§€ì›í•©ë‹ˆë‹¤:  vLLM ë°°í¬â€‹  Kubernetes Deploymentë¥¼ ì‚¬ìš©í•œ ì§ì ‘ vLLM ë°°í¬ë‹¨ì¼ ë…¸ë“œ ì¶”ë¡  ì›Œí¬ë¡œë“œì— ì í•©GPU ë° Neuron ê°€ì†ê¸° ëª¨ë‘ ì§€ì›  Ray-vLLM ë°°í¬â€‹  Ray Serveì˜ ë¶„ì‚° vLLMì›Œí¬ë¡œë“œ ìˆ˜ìš”ì— ë”°ë¥¸ ìë™ í™•ì¥Prometheus/Grafana í†µí•©ì„ í†µí•œ ê³ ê¸‰ ê´€ì¸¡ì„±ìµœì ì˜ ì„±ëŠ¥ì„ ìœ„í•œ í† í´ë¡œì§€ ì¸ì‹ ìŠ¤ì¼€ì¤„ë§  AIBrix ë°°í¬â€‹  AIBrix ì§€ì› LLM ë°°í¬ì—¬ëŸ¬ ë³µì œë³¸ì— ëŒ€í•œ íš¨ìœ¨ì ì¸ LLM ë¼ìš°íŒ…í˜¼í•© GPU ë° Neuron ê°€ì†ê¸° ì§€ì›  ","version":"Next","tagName":"h3"},{"title":"ì˜ˆì œ ë°°í¬â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ì˜ˆì œ-ë°°í¬","content":" í´ëŸ¬ìŠ¤í„°ê°€ ì¤€ë¹„ë˜ë©´ ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  # Hugging Face í† í° ì‹œí¬ë¦¿ ìƒì„± kubectl create secret generic hf-token --from-literal=token=your_hf_token # vLLMìœ¼ë¡œ GPU Qwen 3 1.7B ëª¨ë¸ ë°°í¬ helm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/ helm repo update helm install qwen3-1-7b ai-on-eks/inference-charts -f https://raw.githubusercontent.com/awslabs/ai-on-eks-charts/refs/heads/main/charts/inference-charts/values-qwen3-1.7b-vllm.yaml   ì‚¬ìš© ê°€ëŠ¥í•œ í•­ëª©ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ inference charts ì„¹ì…˜ì„ í™•ì¸í•˜ì„¸ìš”.  ","version":"Next","tagName":"h3"},{"title":"ê´€ì¸¡ì„± í†µí•©â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ê´€ì¸¡ì„±-í†µí•©","content":" ì¸í”„ë¼ëŠ” ì¶”ë¡  ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ í¬ê´„ì ì¸ ê´€ì¸¡ì„±ì„ ì œê³µí•©ë‹ˆë‹¤:  Prometheus Metrics: ì¶”ë¡  ë©”íŠ¸ë¦­ì˜ ìë™ ìˆ˜ì§‘Grafana Dashboards: Ray ë° vLLMìš© ì‚¬ì „ êµ¬ì„±ëœ ëŒ€ì‹œë³´ë“œLog Aggregation: Fluent Bitì„ ì‚¬ìš©í•œ ì¤‘ì•™ ì§‘ì¤‘ì‹ ë¡œê¹…GPU/Neuron ëª¨ë‹ˆí„°ë§: í•˜ë“œì›¨ì–´ ì‚¬ìš©ë¥  ë©”íŠ¸ë¦­  Grafana ëŒ€ì‹œë³´ë“œ ì•¡ì„¸ìŠ¤:  kubectl port-forward -n monitoring svc/kube-prometheus-stack-grafana 3000:80   ê´€ì¸¡ì„± ê¸°ëŠ¥ ì‚¬ìš©ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ê´€ì¸¡ì„±ì„ ì°¸ì¡°í•˜ì„¸ìš”.  ","version":"Next","tagName":"h3"},{"title":"ë¹„ìš© ìµœì í™”â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ë¹„ìš©-ìµœì í™”","content":" í´ëŸ¬ìŠ¤í„°ì—ëŠ” ì—¬ëŸ¬ ë¹„ìš© ìµœì í™” ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:  Karpenter ì˜¤í† ìŠ¤ì¼€ì¼ë§: ìë™ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ë° ë””í”„ë¡œë¹„ì €ë‹ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ ì§€ì›: ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë…¸ë“œ ê·¸ë£¹ êµ¬ì„±í† í´ë¡œì§€ ì¸ì‹: AZ ì „ë°˜ì— ê±¸ì³ íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ í™œìš©ë¦¬ì†ŒìŠ¤ ì œí•œ: ì›Œí¬ë¡œë“œì— ëŒ€í•œ ì ì ˆí•œ ë¦¬ì†ŒìŠ¤ ìš”ì²­ ë° ì œí•œ  ","version":"Next","tagName":"h3"},{"title":"ë¬¸ì œ í•´ê²°â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ë¬¸ì œ-í•´ê²°","content":" ì´ ì„¹ì…˜ì—ì„œëŠ” ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•˜ê³  ìš´ì˜í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì¼ë°˜ì ì¸ ë¬¸ì œì™€ ìì„¸í•œ í•´ê²° ë°©ë²• ë° ì§„ë‹¨ ë‹¨ê³„ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ë°°í¬ ë¬¸ì œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ë°°í¬-ë¬¸ì œ","content":" 1. Terraform Apply ì‹¤íŒ¨â€‹  ì¦ìƒ:  terraform apply ì¤‘ ë¦¬ì†ŒìŠ¤ ìƒì„± ì˜¤ë¥˜ë¡œ Terraform ì‹¤íŒ¨ìˆœì°¨ ë°°í¬ ì¤‘ ëª¨ë“ˆë³„ ì‹¤íŒ¨  ì¼ë°˜ì ì¸ ì›ì¸ ë° í•´ê²° ë°©ë²•:  AWS ê¶Œí•œ ë¶€ì¡±:  # AWS ìê²© ì¦ëª… ë° ê¶Œí•œ í™•ì¸ aws sts get-caller-identity aws iam get-user # í•„ìš”í•œ ê¶Œí•œ í¬í•¨: # - EKS í´ëŸ¬ìŠ¤í„° ìƒì„± ë° ê´€ë¦¬ # - EC2 ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ # - VPC ë° ë„¤íŠ¸ì›Œí‚¹ ë¦¬ì†ŒìŠ¤ # - IAM ì—­í•  ìƒì„± ë° ì—°ê²° # - KMS í‚¤ ê´€ë¦¬   ì„œë¹„ìŠ¤ í• ë‹¹ëŸ‰ ì œí•œ:  # EC2 ì„œë¹„ìŠ¤ í• ë‹¹ëŸ‰ í™•ì¸ aws service-quotas get-service-quota --service-code ec2 --quota-code L-1216C47A # Running On-Demand instances aws service-quotas get-service-quota --service-code ec2 --quota-code L-34B43A08 # Running On-Demand G instances aws service-quotas get-service-quota --service-code ec2 --quota-code L-6E869C2A # Running On-Demand Inf instances # í•„ìš”í•œ ê²½ìš° í• ë‹¹ëŸ‰ ì¦ê°€ ìš”ì²­ aws service-quotas request-service-quota-increase --service-code ec2 --quota-code L-34B43A08 --desired-value 32   ë¦¬ì „ ê°€ìš©ì„±:  # ë¦¬ì „ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸ aws ec2 describe-instance-type-offerings --location-type availability-zone --filters Name=instance-type,Values=g5.xlarge,inf2.xlarge   2. EKS í´ëŸ¬ìŠ¤í„° ìƒì„± ë¬¸ì œâ€‹  ì¦ìƒ:  EKS í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” &quot;CREATING&quot; ìƒíƒœì—ì„œ ë©ˆì¶¤ë…¸ë“œ ê·¸ë£¹ì´ í´ëŸ¬ìŠ¤í„°ì— ì¡°ì¸ ì‹¤íŒ¨  ì§„ë‹¨ ë‹¨ê³„:  # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸ aws eks describe-cluster --name inference-cluster --region us-west-2   ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•:  VPCì— 4ê°œì˜ ê°€ìš© ì˜ì—­ì— ê±¸ì³ ì¶©ë¶„í•œ IP ì£¼ì†Œê°€ ìˆëŠ”ì§€ í™•ì¸í¼ë¸”ë¦­ ì„œë¸Œë„·ì—ì„œ NAT ê²Œì´íŠ¸ì›¨ì´ ìƒì„± í™•ì¸ë³´ì•ˆ ê·¸ë£¹ êµ¬ì„±ì´ í•„ìš”í•œ EKS í†µì‹ ì„ í—ˆìš©í•˜ëŠ”ì§€ í™•ì¸  ","version":"Next","tagName":"h3"},{"title":"ë…¸ë“œ ë° íŒŒë“œ ë¬¸ì œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ë…¸ë“œ-ë°-íŒŒë“œ-ë¬¸ì œ","content":" 3. Pending ìƒíƒœì—ì„œ ë©ˆì¶˜ íŒŒë“œâ€‹  ì¦ìƒ:  ì¶”ë¡  ì›Œí¬ë¡œë“œê°€ &quot;Pending&quot; ìƒíƒœë¡œ ìœ ì§€Karpenterê°€ ë…¸ë“œë¥¼ í”„ë¡œë¹„ì €ë‹í•˜ì§€ ì•ŠìŒ  ì§„ë‹¨ ëª…ë ¹:  # íŒŒë“œ ì´ë²¤íŠ¸ ë° ë¦¬ì†ŒìŠ¤ ìš”ì²­ í™•ì¸ kubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt; # Karpenter ë¡œê·¸ í™•ì¸ kubectl logs -n karpenter deployment/karpenter # ì‚¬ìš© ê°€ëŠ¥í•œ ë…¸ë“œ ë° ìš©ëŸ‰ í™•ì¸ kubectl get nodes -o wide kubectl describe nodes   ì¼ë°˜ì ì¸ ì›ì¸ ë° í•´ê²° ë°©ë²•:  GPU/Neuron í• ë‹¹ëŸ‰ ë¶€ì¡±:  # Karpenter NodePool êµ¬ì„± í™•ì¸ kubectl get nodepool -o yaml   4. GPU ê°ì§€ ë° Device Plugin ë¬¸ì œâ€‹  ì¦ìƒ:  GPU ë…¸ë“œì— 0ê°œì˜ í• ë‹¹ ê°€ëŠ¥í•œ GPU í‘œì‹œNVIDIA device pluginì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ  ì§„ë‹¨ ë‹¨ê³„:  # ë…¸ë“œì—ì„œ GPU ê°€ì‹œì„± í™•ì¸ kubectl get nodes -o json | jq '.items[] | {name: .metadata.name, gpus: .status.allocatable[&quot;nvidia.com/gpu&quot;]}' # ë…¸ë“œ ë ˆì´ë¸” í™•ì¸ kubectl get nodes --show-labels | grep gpu   í•´ê²° ë°©ë²•:  # í•„ìš”í•œ ê²½ìš° NVIDIA device plugin ì¬ì‹œì‘ kubectl delete pods -n nvidia-device-plugin -l app.kubernetes.io/name=nvidia-device-plugin   5. AWS Neuron ì„¤ì • ë¬¸ì œâ€‹  ì¦ìƒ:  inf2/trn1 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ Neuron ì¥ì¹˜ê°€ ê°ì§€ë˜ì§€ ì•ŠìŒNeuron device plugin ì‹¤íŒ¨  ì§„ë‹¨ ëª…ë ¹:  # Neuron device plugin í™•ì¸ kubectl get pods -n kube-system | grep neuron # Neuron ì¥ì¹˜ í™•ì¸ kubectl get nodes -o json | jq '.items[] | {name: .metadata.name, neuron: .status.allocatable[&quot;aws.amazon.com/neuron&quot;]}' # Neuron ìŠ¤ì¼€ì¤„ëŸ¬ í™•ì¸ kubectl get pods -n kube-system | grep my-scheduler   í•´ê²° ë°©ë²•:  # Neuron ëŸ°íƒ€ì„ ì„¤ì¹˜ í™•ì¸ kubectl describe node &lt;inf2-node&gt; | grep neuron # Neuron device plugin ë¡œê·¸ í™•ì¸ kubectl logs -n kube-system &lt;neuron-device-plugin-pod&gt;   ","version":"Next","tagName":"h3"},{"title":"ëª¨ë¸ ë°°í¬ ë¬¸ì œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ëª¨ë¸-ë°°í¬-ë¬¸ì œ","content":" 6. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨â€‹  ì¦ìƒ:  ì´ë¯¸ì§€ í’€ ë˜ëŠ” ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜ë¡œ íŒŒë“œ ì‹œì‘ ì‹¤íŒ¨Hugging Face ì¸ì¦ ì‹¤íŒ¨  ì§„ë‹¨ ë‹¨ê³„:  # ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜ì— ëŒ€í•œ íŒŒë“œ ë¡œê·¸ í™•ì¸ kubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; # Hugging Face í† í° ì‹œí¬ë¦¿ í™•ì¸ kubectl get secret hf-token -o yaml kubectl get secret hf-token -o jsonpath='{.data.token}' | base64 -d   í•´ê²° ë°©ë²•:  # Hugging Face í† í° ì‹œí¬ë¦¿ ì¬ìƒì„± kubectl delete secret hf-token kubectl create secret generic hf-token --from-literal=token=&lt;your-hf-token&gt; # íŒŒë“œì—ì„œ ì¸í„°ë„· ì—°ê²° í™•ì¸ kubectl run test-pod --image=curlimages/curl -it --rm -- curl -I https://huggingface.co   7. ë©”ëª¨ë¦¬ ë¶€ì¡±(OOM) ë¬¸ì œâ€‹  ì¦ìƒ:  OOMKilled ìƒíƒœë¡œ íŒŒë“œê°€ ì¢…ë£Œë¨ëª¨ë¸ì´ ì™„ì „íˆ ë¡œë“œë˜ì§€ ì•ŠìŒ  ì§„ë‹¨ ëª…ë ¹:  # íŒŒë“œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸ kubectl top pods -n &lt;namespace&gt; # ë…¸ë“œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ kubectl top nodes # OOM ì¢…ë£Œì— ëŒ€í•œ íŒŒë“œ ì´ë²¤íŠ¸ ê²€í†  kubectl get events --field-selector reason=OOMKilling   í•´ê²° ë°©ë²•:  # ë” í° GPUë¥¼ ì–»ê¸° ìœ„í•´ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì¦ê°€ # ë” í° ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ë˜ëŠ” ëª¨ë¸ ìƒ¤ë”© ì‚¬ìš© ê³ ë ¤   ","version":"Next","tagName":"h3"},{"title":"ë„¤íŠ¸ì›Œí‚¹ ë° ë¡œë“œ ë°¸ëŸ°ì„œ ë¬¸ì œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ë„¤íŠ¸ì›Œí‚¹-ë°-ë¡œë“œ-ë°¸ëŸ°ì„œ-ë¬¸ì œ","content":" 8. ì„œë¹„ìŠ¤ ì—°ê²° ë¬¸ì œâ€‹  ì¦ìƒ:  ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ì—†ìŒë¡œë“œ ë°¸ëŸ°ì„œê°€ í”„ë¡œë¹„ì €ë‹ë˜ì§€ ì•ŠìŒ  ì§„ë‹¨ ë‹¨ê³„:  # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ kubectl get svc -A # AWS Load Balancer Controller í™•ì¸ kubectl logs -n kube-system deployment/aws-load-balancer-controller # ë³´ì•ˆ ê·¸ë£¹ ë° NACL í™•ì¸ aws ec2 describe-security-groups --filters &quot;Name=group-name,Values=*inference-cluster*&quot;   í•´ê²° ë°©ë²•:  # AWS Load Balancer Controller ì¬ì‹œì‘ kubectl rollout restart deployment/aws-load-balancer-controller -n kube-system # ì¸ê·¸ë ˆìŠ¤ ì£¼ì„ ë° êµ¬ì„± í™•ì¸ kubectl describe ingress &lt;ingress-name&gt;   ","version":"Next","tagName":"h3"},{"title":"ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡ì„± ë¬¸ì œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ëª¨ë‹ˆí„°ë§-ë°-ê´€ì¸¡ì„±-ë¬¸ì œ","content":" 9. Prometheus/Grafana ì‘ë™ ì•ˆ í•¨â€‹  ì¦ìƒ:  ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ì—†ìŒë©”íŠ¸ë¦­ì´ ìˆ˜ì§‘ë˜ì§€ ì•ŠìŒ  ì§„ë‹¨ ëª…ë ¹:  # ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ íŒŒë“œ í™•ì¸ kubectl get pods -n monitoring # Prometheus ëŒ€ìƒ í™•ì¸ kubectl port-forward -n monitoring svc/kube-prometheus-stack-prometheus 9090:9090 # http://localhost:9090/targetsë¡œ ì´ë™ # Grafana ì•¡ì„¸ìŠ¤ í™•ì¸ kubectl port-forward -n monitoring svc/kube-prometheus-stack-grafana 3000:80 # http://localhost:3000ìœ¼ë¡œ ì´ë™   í•´ê²° ë°©ë²•:  # ëª¨ë‹ˆí„°ë§ êµ¬ì„± ìš”ì†Œ ì¬ì‹œì‘ kubectl rollout restart deployment/kube-prometheus-stack-grafana -n monitoring # ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„° í™•ì¸ kubectl get servicemonitor -A   ","version":"Next","tagName":"h3"},{"title":"ì„±ëŠ¥ ë° í™•ì¥ ë¬¸ì œâ€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ì„±ëŠ¥-ë°-í™•ì¥-ë¬¸ì œ","content":" 10. ëŠë¦° ëª¨ë¸ ì¶”ë¡ â€‹  ì¦ìƒ:  ëª¨ë¸ ì‘ë‹µì—ì„œ ë†’ì€ ì§€ì—° ì‹œê°„ë‚®ì€ ì²˜ë¦¬ëŸ‰ ì„±ëŠ¥  ì§„ë‹¨ ë‹¨ê³„:  # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  í™•ì¸ kubectl top pods -n &lt;namespace&gt; --containers # GPU ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§ (GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°) kubectl exec -it &lt;pod-name&gt; -- nvidia-smi   í•´ê²° ë°©ë²•:  ëª¨ë¸ì´ ì ì ˆí•œ í•˜ë“œì›¨ì–´ ê°€ì†ì„ ì‚¬ìš©í•˜ê³  ìˆëŠ”ì§€ í™•ì¸ì—¬ëŸ¬ ëª¨ë¸ì´ ë¦¬ì†ŒìŠ¤ë¥¼ ë†“ê³  ê²½ìŸí•˜ëŠ”ì§€ í™•ì¸ì§€ì—° ì‹œê°„ì— ë§ê²Œ ëª¨ë¸ íŒŒë¼ë¯¸í„° ìµœì í™”ëª¨ë¸ì„ í™•ì¥í•˜ê³  ë¡œë“œ ë°¸ëŸ°ì‹± ì‚¬ìš©  ","version":"Next","tagName":"h3"},{"title":"ì¼ë°˜ ë””ë²„ê¹… ëª…ë ¹â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ì¼ë°˜-ë””ë²„ê¹…-ëª…ë ¹","content":" # í´ëŸ¬ìŠ¤í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸° kubectl cluster-info kubectl get nodes -o wide # ëª¨ë“  ì‹œìŠ¤í…œ íŒŒë“œ í™•ì¸ kubectl get pods -A | grep -v Running # ìµœê·¼ ì´ë²¤íŠ¸ ë³´ê¸° kubectl get events --sort-by='.lastTimestamp' -A # Karpenter í”„ë¡œë¹„ì €ë‹ í™•ì¸ kubectl logs -n karpenter deployment/karpenter --tail=100 # EKS ì• ë“œì˜¨ í™•ì¸ aws eks describe-addon --cluster-name inference-cluster --addon-name vpc-cni   ","version":"Next","tagName":"h3"},{"title":"ì¶”ê°€ ë„ì›€ ë°›ê¸°â€‹","type":1,"pageTitle":"ì¶”ë¡  ì¤€ë¹„ EKS í´ëŸ¬ìŠ¤í„°","url":"/ai-on-eks/ko/docs/infra/inference/inference-ready-cluster#ì¶”ê°€-ë„ì›€-ë°›ê¸°","content":" ë¬¸ì œê°€ ê³„ì†ë˜ëŠ” ê²½ìš°:  AWS ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸: AWS Service Health Dashboard ë°©ë¬¸CloudWatch ë¡œê·¸ ê²€í† : CloudWatchì—ì„œ EKS ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë¡œê·¸ í™•ì¸ë¬¸ì„œ ì°¸ì¡°: EKS ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì°¸ì¡°ì»¤ë®¤ë‹ˆí‹° ì§€ì›: AI on EKS GitHub Issuesì— ì§ˆë¬¸ ê²Œì‹œ ","version":"Next","tagName":"h3"},{"title":"intro","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/intro","content":"intro","keywords":"","version":"Next"},{"title":"EKS ê¸°ë°˜ JupyterHub","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/infra/training/jupyterhub","content":"","keywords":"","version":"Next"},{"title":"EKS ê¸°ë°˜ JupyterHubâ€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ JupyterHub","url":"/ai-on-eks/ko/docs/infra/training/jupyterhub#eks-ê¸°ë°˜-jupyterhub-1","content":" Amazon Elastic Kubernetes Service(EKS)ì— JupyterHubë¥¼ ë°°í¬í•˜ë©´ JupyterHubì˜ ë‹¤ì–‘ì„±ê³¼ Kubernetesì˜ í™•ì¥ì„± ë° ìœ ì—°ì„±ì´ ê²°í•©ë©ë‹ˆë‹¤. ì´ ë¸”ë£¨í”„ë¦°íŠ¸ë¥¼ í†µí•´ ì‚¬ìš©ìëŠ” JupyterHub í”„ë¡œí•„ì˜ ë„ì›€ìœ¼ë¡œ EKSì—ì„œ ë‹¤ì¤‘ í…Œë„ŒíŠ¸ JupyterHub í”Œë«í¼ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ì‚¬ìš©ìë¥¼ ìœ„í•œ EFS ê³µìœ  íŒŒì¼ ì‹œìŠ¤í…œì„ í™œìš©í•˜ì—¬ ë…¸íŠ¸ë¶ ê³µìœ ë¥¼ ì‰½ê²Œ í•˜ê³  ê°œë³„ EFS ìŠ¤í† ë¦¬ì§€ë¥¼ ì œê³µí•˜ì—¬ ì‚¬ìš©ì íŒŒë“œê°€ ì‚­ì œë˜ê±°ë‚˜ ë§Œë£Œë˜ë”ë¼ë„ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ ë¡œê·¸ì¸í•˜ë©´ ê¸°ì¡´ EFS ë³¼ë¥¨ ì•„ë˜ì˜ ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ì™€ ë°ì´í„°ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  EKSì˜ ê¸°ëŠ¥ì„ í™œìš©í•˜ë©´ ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ê²Œ JupyterHub í™˜ê²½ì„ ì›í™œí•˜ê²Œ í™•ì¥í•˜ì—¬ íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ í™œìš©ê³¼ ìµœì ì˜ ì„±ëŠ¥ì„ ë³´ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. EKSë¥¼ ì‚¬ìš©í•˜ë©´ ìë™ í™•ì¥, ê³ ê°€ìš©ì„±, ì—…ë°ì´íŠ¸ ë° ì—…ê·¸ë ˆì´ë“œì˜ ì‰¬ìš´ ë°°í¬ì™€ ê°™ì€ Kubernetes ê¸°ëŠ¥ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì‚¬ìš©ìì—ê²Œ ì‹ ë¢°í•  ìˆ˜ ìˆê³  ê°•ë ¥í•œ JupyterHub ê²½í—˜ì„ ì œê³µí•˜ì—¬ íš¨ê³¼ì ìœ¼ë¡œ í˜‘ì—…, íƒìƒ‰ ë° ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.  EKSì—ì„œ JupyterHubë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì´ ê°€ì´ë“œì˜ ì§€ì¹¨ì— ë”°ë¼ JupyterHub í™˜ê²½ì„ ì„¤ì •í•˜ê³  êµ¬ì„±í•˜ì„¸ìš”.  ì†”ë£¨ì…˜ ë°°í¬ ğŸ‘ˆ  ë¦¬ì†ŒìŠ¤ í™•ì¸ ğŸ‘ˆ  ","version":"Next","tagName":"h2"},{"title":"ìœ í˜• 1 ë°°í¬: JupyterHub ë¡œê·¸ì¸â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ JupyterHub","url":"/ai-on-eks/ko/docs/infra/training/jupyterhub#ìœ í˜•-1-ë°°í¬-jupyterhub-ë¡œê·¸ì¸","content":" í¬íŠ¸ í¬ì›Œë“œë¡œ JupyterHub ë…¸ì¶œ:  ì›¹ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ ë¡œì»¬ì—ì„œ ë³´ê¸° ìœ„í•´ JupyterHub ì„œë¹„ìŠ¤ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆë„ë¡ ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. í˜„ì¬ dummy ë°°í¬ëŠ” ClusterIPê°€ ìˆëŠ” Web UI ì„œë¹„ìŠ¤ë§Œ ì„¤ì •í•œë‹¤ëŠ” ì ì— ìœ ì˜í•˜ì„¸ìš”. ì´ë¥¼ ë‚´ë¶€ ë˜ëŠ” ì¸í„°ë„· ì—°ê²° ë¡œë“œ ë°¸ëŸ°ì„œë¡œ ì‚¬ìš©ì ì§€ì •í•˜ë ¤ë©´ JupyterHub Helm ì°¨íŠ¸ ê°’ íŒŒì¼ì—ì„œ í•„ìš”í•œ ì¡°ì •ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  kubectl port-forward svc/proxy-public 8080:80 -n jupyterhub   ë¡œê·¸ì¸: ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8080/ë¡œ ì´ë™í•©ë‹ˆë‹¤. ì‚¬ìš©ì ì´ë¦„ìœ¼ë¡œ user-1ì„ ì…ë ¥í•˜ê³  ì•„ë¬´ ë¹„ë°€ë²ˆí˜¸ë‚˜ ì„ íƒí•©ë‹ˆë‹¤.  ì„œë²„ ì˜µì…˜ ì„ íƒ: ë¡œê·¸ì¸í•˜ë©´ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë…¸íŠ¸ë¶ ì¸ìŠ¤í„´ìŠ¤ í”„ë¡œí•„ì´ í‘œì‹œë©ë‹ˆë‹¤. Data Engineering (CPU) ì„œë²„ëŠ” ì „í†µì ì¸ CPU ê¸°ë°˜ ë…¸íŠ¸ë¶ ì‘ì—…ìš©ì…ë‹ˆë‹¤. Elyra ì„œë²„ëŠ” íŒŒì´í”„ë¼ì¸ì„ ë¹ ë¥´ê²Œ ê°œë°œí•  ìˆ˜ ìˆëŠ” Elyra ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤: . Trainium ë° Inferentia ì„œë²„ëŠ” ë…¸íŠ¸ë¶ ì„œë²„ë¥¼ Trainium ë° Inferentia ë…¸ë“œì— ë°°í¬í•˜ì—¬ ê°€ì†í™”ëœ ì›Œí¬ë¡œë“œë¥¼ í—ˆìš©í•©ë‹ˆë‹¤. Time Slicing ë° MIGëŠ” GPU ê³µìœ ë¥¼ ìœ„í•œ ë‘ ê°€ì§€ ë‹¤ë¥¸ ì „ëµì…ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ Data Science (GPU) ì„œë²„ëŠ” NVIDIA GPUì—ì„œ ì‹¤í–‰ë˜ëŠ” ì „í†µì ì¸ ì„œë²„ì…ë‹ˆë‹¤.  ì´ íƒ€ì„ìŠ¬ë¼ì´ì‹± ê¸°ëŠ¥ ì‹œì—°ì„ ìœ„í•´ Data Science (GPU + Time-Slicing â€“ G5) í”„ë¡œí•„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ì˜µì…˜ì„ ì„ íƒí•˜ê³  Start ë²„íŠ¼ì„ ì„ íƒí•˜ì„¸ìš”.    g5.2xlarge ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ìœ¼ë¡œ Karpenterê°€ ìƒì„±í•œ ìƒˆ ë…¸ë“œëŠ” NVIDIA device pluginì—ì„œ ì œê³µí•˜ëŠ” íƒ€ì„ìŠ¬ë¼ì´ì‹± ê¸°ëŠ¥ì„ í™œìš©í•˜ë„ë¡ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ ë‹¨ì¼ GPUë¥¼ ì—¬ëŸ¬ í• ë‹¹ ê°€ëŠ¥í•œ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ íš¨ìœ¨ì ì¸ GPU í™œìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ê²½ìš° NVIDIA device plugin Helm ì°¨íŠ¸ êµ¬ì„± ë§µì—ì„œ 4ê°œì˜ í• ë‹¹ ê°€ëŠ¥í•œ GPUë¥¼ ì •ì˜í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ë…¸ë“œ ìƒíƒœì…ë‹ˆë‹¤:  GPU: ë…¸ë“œëŠ” NVIDIA device pluginì˜ íƒ€ì„ìŠ¬ë¼ì´ì‹± ê¸°ëŠ¥ì„ í†µí•´ 4ê°œì˜ GPUë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë…¸ë“œê°€ ë‹¤ì–‘í•œ ì›Œí¬ë¡œë“œì— GPU ë¦¬ì†ŒìŠ¤ë¥¼ ë” ìœ ì—°í•˜ê²Œ í• ë‹¹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  status: capacity: cpu: '8' # ë…¸ë“œì— 8ê°œì˜ CPUê°€ ìˆìŠµë‹ˆë‹¤ ephemeral-storage: 439107072Ki # ë…¸ë“œì˜ ì´ ì„ì‹œ ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ì€ 439107072 KiBì…ë‹ˆë‹¤ hugepages-1Gi: '0' # ë…¸ë“œì— 0ê°œì˜ 1Gi hugepageê°€ ìˆìŠµë‹ˆë‹¤ hugepages-2Mi: '0' # ë…¸ë“œì— 0ê°œì˜ 2Mi hugepageê°€ ìˆìŠµë‹ˆë‹¤ memory: 32499160Ki # ë…¸ë“œì˜ ì´ ë©”ëª¨ë¦¬ ìš©ëŸ‰ì€ 32499160 KiBì…ë‹ˆë‹¤ nvidia.com/gpu: '4' # ë…¸ë“œì— íƒ€ì„ìŠ¬ë¼ì´ì‹±ì„ í†µí•´ êµ¬ì„±ëœ ì´ 4ê°œì˜ GPUê°€ ìˆìŠµë‹ˆë‹¤ pods: '58' # ë…¸ë“œëŠ” ìµœëŒ€ 58ê°œì˜ íŒŒë“œë¥¼ ìˆ˜ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ allocatable: cpu: 7910m # 7910 ë°€ë¦¬ì½”ì–´ì˜ CPUê°€ í• ë‹¹ ê°€ëŠ¥í•©ë‹ˆë‹¤ ephemeral-storage: '403607335062' # 403607335062 KiBì˜ ì„ì‹œ ìŠ¤í† ë¦¬ì§€ê°€ í• ë‹¹ ê°€ëŠ¥í•©ë‹ˆë‹¤ hugepages-1Gi: '0' # 0ê°œì˜ 1Gi hugepageê°€ í• ë‹¹ ê°€ëŠ¥í•©ë‹ˆë‹¤ hugepages-2Mi: '0' # 0ê°œì˜ 2Mi hugepageê°€ í• ë‹¹ ê°€ëŠ¥í•©ë‹ˆë‹¤ memory: 31482328Ki # 31482328 KiBì˜ ë©”ëª¨ë¦¬ê°€ í• ë‹¹ ê°€ëŠ¥í•©ë‹ˆë‹¤ nvidia.com/gpu: '4' # 4ê°œì˜ GPUê°€ í• ë‹¹ ê°€ëŠ¥í•©ë‹ˆë‹¤ pods: '58' # 58ê°œì˜ íŒŒë“œê°€ í• ë‹¹ ê°€ëŠ¥í•©ë‹ˆë‹¤   ë‘ ë²ˆì§¸ ì‚¬ìš©ì(user-2) í™˜ê²½ ì„¤ì •:  GPU íƒ€ì„ìŠ¬ë¼ì´ì‹±ì´ ì‘ë™í•˜ëŠ” ê²ƒì„ ì‹œì—°í•˜ê¸° ìœ„í•´ ë‹¤ë¥¸ Jupyter Notebook ì¸ìŠ¤í„´ìŠ¤ë¥¼ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤. ì´ë²ˆì—ëŠ” ë‘ ë²ˆì§¸ ì‚¬ìš©ìì˜ íŒŒë“œê°€ ì´ì „ì— ì„¤ì •í•œ GPU íƒ€ì„ìŠ¬ë¼ì´ì‹± êµ¬ì„±ì„ í™œìš©í•˜ì—¬ ì²« ë²ˆì§¸ ì‚¬ìš©ìì™€ ë™ì¼í•œ ë…¸ë“œì— ì˜ˆì•½ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì´ë¥¼ ë‹¬ì„±í•˜ë ¤ë©´ ì•„ë˜ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:  ì‹œí¬ë¦¿ ë¸Œë¼ìš°ì € ì°½ì—ì„œ JupyterHub ì—´ê¸°: ìƒˆ ì‹œí¬ë¦¿ ì°½ì˜ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8080/ë¡œ ì´ë™í•©ë‹ˆë‹¤. ì‚¬ìš©ì ì´ë¦„ìœ¼ë¡œ user-2ë¥¼ ì…ë ¥í•˜ê³  ì•„ë¬´ ë¹„ë°€ë²ˆí˜¸ë‚˜ ì„ íƒí•©ë‹ˆë‹¤.  ì„œë²„ ì˜µì…˜ ì„ íƒ: ë¡œê·¸ì¸ í›„ ì„œë²„ ì˜µì…˜ í˜ì´ì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤. Data Science (GPU + Time-Slicing â€“ G5) ë¼ë””ì˜¤ ë²„íŠ¼ì„ ì„ íƒí•˜ê³  Startë¥¼ ì„ íƒí•©ë‹ˆë‹¤.    íŒŒë“œ ë°°ì¹˜ í™•ì¸: ì´ íŒŒë“œ ë°°ì¹˜ëŠ” user-1ê³¼ ë‹¬ë¦¬ ëª‡ ì´ˆë°–ì— ê±¸ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤. Kubernetes ìŠ¤ì¼€ì¤„ëŸ¬ê°€ user-1 íŒŒë“œì—ì„œ ìƒì„±í•œ ê¸°ì¡´ g5.2xlarge ë…¸ë“œì— íŒŒë“œë¥¼ ë°°ì¹˜í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. user-2ë„ ë™ì¼í•œ ë„ì»¤ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ë„ì»¤ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì§€ì—°ì´ ì—†ê³  ë¡œì»¬ ìºì‹œë¥¼ í™œìš©í–ˆìŠµë‹ˆë‹¤.  í„°ë¯¸ë„ì„ ì—´ê³  ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ìƒˆ Jupyter Notebook íŒŒë“œê°€ ì–´ë””ì— ì˜ˆì•½ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤:  kubectl get pods -n jupyterhub -owide | grep -i user   user-1ê³¼ user-2 íŒŒë“œê°€ ëª¨ë‘ ë™ì¼í•œ ë…¸ë“œì—ì„œ ì‹¤í–‰ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì´ëŠ” GPU íƒ€ì„ìŠ¬ë¼ì´ì‹± êµ¬ì„±ì´ ì˜ˆìƒëŒ€ë¡œ ì‘ë™í•˜ê³  ìˆìŒì„ í™•ì¸í•©ë‹ˆë‹¤.  ì •ë³´ ìì„¸í•œ ë‚´ìš©ì€ AWS ë¸”ë¡œê·¸: Building multi-tenant JupyterHub Platforms on Amazon EKSë¥¼ í™•ì¸í•˜ì„¸ìš”  ","version":"Next","tagName":"h3"},{"title":"ìœ í˜• 2 ë°°í¬(ì„ íƒ ì‚¬í•­): Amazon Cognitoë¥¼ í†µí•´ JupyterHub ë¡œê·¸ì¸â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ JupyterHub","url":"/ai-on-eks/ko/docs/infra/training/jupyterhub#ìœ í˜•-2-ë°°í¬ì„ íƒ-ì‚¬í•­-amazon-cognitoë¥¼-í†µí•´-jupyterhub-ë¡œê·¸ì¸","content":" ë¡œë“œ ë°¸ëŸ°ì„œ DNS ì´ë¦„ìœ¼ë¡œ JupyterHub ë„ë©”ì¸ì— ëŒ€í•œ CNAME DNS ë ˆì½”ë“œë¥¼ ChangeIPì— ì¶”ê°€í•©ë‹ˆë‹¤.    ì •ë³´ ChangeIPì˜ CNAME ê°’ í•„ë“œì— ë¡œë“œ ë°¸ëŸ°ì„œ DNS ì´ë¦„ì„ ì¶”ê°€í•  ë•Œ ë¡œë“œ ë°¸ëŸ°ì„œ DNS ì´ë¦„ ëì— ì (.)ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.  ì´ì œ ë¸Œë¼ìš°ì €ì—ì„œ ë„ë©”ì¸ URLì„ ì…ë ¥í•˜ë©´ JupyterHub ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ë¦¬ë””ë ‰ì…˜ë©ë‹ˆë‹¤.    Cognito ê°€ì… ë° ë¡œê·¸ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ë”°ë¼ ë¡œê·¸ì¸í•©ë‹ˆë‹¤.    ì„±ê³µì ì¸ ë¡œê·¸ì¸ì€ ë¡œê·¸ì¸í•œ ì‚¬ìš©ìë¥¼ ìœ„í•œ JupyterHub í™˜ê²½ì„ ì—½ë‹ˆë‹¤.    JupyterHubì—ì„œ ê³µìœ  ë° ê°œì¸ ë””ë ‰í„°ë¦¬ ì„¤ì •ì„ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:  ëŸ°ì²˜ ëŒ€ì‹œë³´ë“œì—ì„œ í„°ë¯¸ë„ ì°½ì„ ì—½ë‹ˆë‹¤.    ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤  df -h   ìƒì„±ëœ EFS ë§ˆìš´íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ê° ì‚¬ìš©ìì˜ ê°œì¸ í™ˆ ë””ë ‰í„°ë¦¬ëŠ” /home/jovyanì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê³µìœ  ë””ë ‰í„°ë¦¬ëŠ” /home/sharedì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤  ","version":"Next","tagName":"h3"},{"title":"ìœ í˜• 3 ë°°í¬(ì„ íƒ ì‚¬í•­): OAuth(Keycloak)ë¥¼ í†µí•´ JupyterHub ë¡œê·¸ì¸â€‹","type":1,"pageTitle":"EKS ê¸°ë°˜ JupyterHub","url":"/ai-on-eks/ko/docs/infra/training/jupyterhub#ìœ í˜•-3-ë°°í¬ì„ íƒ-ì‚¬í•­-oauthkeycloakë¥¼-í†µí•´-jupyterhub-ë¡œê·¸ì¸","content":" ì°¸ê³ : OAuth ì œê³µì—…ì²´ì— ë”°ë¼ ì•½ê°„ ë‹¤ë¥´ê²Œ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ë¡œë“œ ë°¸ëŸ°ì„œ DNS ì´ë¦„ìœ¼ë¡œ JupyterHub ë„ë©”ì¸ì— ëŒ€í•œ CNAME DNS ë ˆì½”ë“œë¥¼ ChangeIPì— ì¶”ê°€í•©ë‹ˆë‹¤.    ì •ë³´ ChangeIPì˜ CNAME ê°’ í•„ë“œì— ë¡œë“œ ë°¸ëŸ°ì„œ DNS ì´ë¦„ì„ ì¶”ê°€í•  ë•Œ ë¡œë“œ ë°¸ëŸ°ì„œ DNS ì´ë¦„ ëì— ì (.)ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.  ì´ì œ ë¸Œë¼ìš°ì €ì—ì„œ ë„ë©”ì¸ URLì„ ì…ë ¥í•˜ë©´ JupyterHub ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ë¦¬ë””ë ‰ì…˜ë©ë‹ˆë‹¤.    Keycloak ê°€ì… ë° ë¡œê·¸ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ë”°ë¼ ë¡œê·¸ì¸í•©ë‹ˆë‹¤.    ì„±ê³µì ì¸ ë¡œê·¸ì¸ì€ ë¡œê·¸ì¸í•œ ì‚¬ìš©ìë¥¼ ìœ„í•œ JupyterHub í™˜ê²½ì„ ì—½ë‹ˆë‹¤.    ì •ë¦¬ ğŸ‘ˆ ","version":"Next","tagName":"h3"},{"title":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","type":0,"sectionRef":"#","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation","content":"","keywords":"","version":"Next"},{"title":"Kubernetesì—ì„œì˜ GPU ìŠ¤ì¼€ì¤„ë§ ê³¼ì œâ€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#kubernetesì—ì„œì˜-gpu-ìŠ¤ì¼€ì¤„ë§-ê³¼ì œ","content":" ","version":"Next","tagName":"h2"},{"title":"í˜„ì¬ ìƒíƒœ: ê¸°ì¡´ GPU í• ë‹¹â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#í˜„ì¬-ìƒíƒœ-ê¸°ì¡´-gpu-í• ë‹¹","content":" KubernetesëŠ” ë¹ ë¥´ê²Œ ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì—ì„œ AI/ML ì›Œí¬ë¡œë“œë¥¼ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•˜ëŠ” ì‚¬ì‹¤ìƒì˜ í‘œì¤€ìœ¼ë¡œ ì§„í™”í–ˆìœ¼ë©°, Amazon EKSëŠ” ëŒ€ê·œëª¨ GPU ê°€ì† ì¸í”„ë¼ë¥¼ ê´€ë¦¬í•˜ëŠ” ì„ ë„ì ì¸ í”Œë«í¼ìœ¼ë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤. ì¡°ì§ë“¤ì€ P4d, P5 ë° ìµœì‹  P6 ì‹œë¦¬ì¦ˆì™€ ê°™ì€ GPU ì¸ìŠ¤í„´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì†Œê·œëª¨ ì¶”ë¡  ì„œë¹„ìŠ¤ë¶€í„° ëŒ€ê·œëª¨ ë¶„ì‚° í•™ìŠµ ì‘ì—…ê¹Œì§€ ëª¨ë“  ê²ƒì„ EKS í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‹¤í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.  ê·¸ëŸ¬ë‚˜ Kubernetesê°€ ì»¨í…Œì´ë„ˆí™”ëœ ì›Œí¬ë¡œë“œë¥¼ ê´€ë¦¬í•˜ëŠ” ë° ì •êµí•¨ì—ë„ ë¶ˆêµ¬í•˜ê³ , ê¸°ì¡´ GPU ìŠ¤ì¼€ì¤„ë§ ëª¨ë¸ì€ ë†€ë¼ìš¸ ì •ë„ë¡œ ì›ì‹œì ì´ë©° ìƒë‹¹í•œ ìš´ì˜ ê³¼ì œë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤. í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì€ GPUë¥¼ ë‹¨ìœ„ë¡œë§Œ í• ë‹¹í•  ìˆ˜ ìˆëŠ” ë‹¨ìˆœí•˜ê³  ì›ìì ì¸ ë¦¬ì†ŒìŠ¤ë¡œ ì·¨ê¸‰í•˜ë©°, ì´ëŠ” í˜„ëŒ€ AI ì›Œí¬ë¡œë“œì˜ ë‹¤ì–‘í•˜ê³  ì§„í™”í•˜ëŠ” ìš”êµ¬ ì‚¬í•­ê³¼ ê·¼ë³¸ì ìœ¼ë¡œ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.  ê¸°ì¡´ GPU ìŠ¤ì¼€ì¤„ë§ ì‘ë™ ë°©ì‹:  PodëŠ” ê°„ë‹¨í•œ ì •ìˆ˜ ê°’ì„ ì‚¬ìš©í•˜ì—¬ GPUë¥¼ ìš”ì²­: nvidia.com/gpu: 1ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” GPUë¥¼ ë¶ˆíˆ¬ëª…í•˜ê³  ë¶„í•  ë¶ˆê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤ë¡œ ì·¨ê¸‰ê° ì›Œí¬ë¡œë“œëŠ” ì „ì²´ GPU ë””ë°”ì´ìŠ¤ì— ëŒ€í•œ ë…ì  ì ‘ê·¼ ê¶Œí•œ íšë“ì‹¤ì œ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ ì‚¬í•­ì´ë‚˜ GPU í† í´ë¡œì§€ì— ëŒ€í•œ ì¸ì‹ ì—†ìŒ  ì´ ì ‘ê·¼ ë°©ì‹ì˜ ë¬¸ì œì :í˜„ëŒ€ AI ì›Œí¬ë¡œë“œëŠ” ì´ ì´ì§„ ëª¨ë¸ì— ë§ì§€ ì•ŠëŠ” ë‹¤ì–‘í•œ ìš”êµ¬ ì‚¬í•­ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:  ì†Œê·œëª¨ ì¶”ë¡  ì‘ì—…ì€ 2-4GB GPU ë©”ëª¨ë¦¬ë§Œ í•„ìš”í•˜ì§€ë§Œ ì „ì²´ 80GB A100ì´ í• ë‹¹ë¨ëŒ€ê·œëª¨ í•™ìŠµ ì‘ì—…ì€ NVLink ë˜ëŠ” IMEXë¥¼ í†µí•œ ì¡°ì •ëœ ë©€í‹° GPU í†µì‹ ì´ í•„ìš”í˜¼í•© ì›Œí¬ë¡œë“œëŠ” GPUë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê³µìœ í•  ìˆ˜ ìˆì§€ë§Œ ë³„ë„ì˜ ë””ë°”ì´ìŠ¤ë¡œ ê°•ì œë¨  ","version":"Next","tagName":"h3"},{"title":"GPU í™œìš© ìœ„ê¸°â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#gpu-í™œìš©-ìœ„ê¸°","content":" ë¼ì´ë¸Œ í™˜ê²½ì˜ ì‹¬ê°í•œ ë¹„íš¨ìœ¨ì„± ë†’ì€ ìˆ˜ìš”ì˜ í´ëŸ¬ìŠ¤í„°ì—ì„œë„ GPU í™œìš©ë¥ ì€ ì¢…ì¢… 40% ë¯¸ë§Œì…ë‹ˆë‹¤. ì´ëŠ” êµ¬ì„± ë¬¸ì œê°€ ì•„ë‹™ë‹ˆë‹¤: Kubernetesê°€ GPU ë¦¬ì†ŒìŠ¤ë¥¼ ì¶”ìƒí™”í•˜ëŠ” ë°©ì‹ì˜ ê·¼ë³¸ì ì¸ í•œê³„ì…ë‹ˆë‹¤.  ë¹„íš¨ìœ¨ì ì¸ GPU í• ë‹¹ì˜ ì¼ë°˜ì ì¸ ì¦ìƒ:  í ê¸°ì•„ ìƒíƒœ(Queue starvation) - ì†Œê·œëª¨ ì¶”ë¡  ì‘ì—…ì´ ì¥ì‹œê°„ ì‹¤í–‰ë˜ëŠ” í•™ìŠµ ì‘ì—… ë’¤ì—ì„œ ëŒ€ê¸°ë¦¬ì†ŒìŠ¤ ë‹¨í¸í™”(Resource fragmentation) - GPU ë©”ëª¨ë¦¬ê°€ ë…¸ë“œ ì „ì²´ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ì¡°ê°ìœ¼ë¡œ ë¶„ì‚°í† í´ë¡œì§€ ë¬´ì¸ì‹(Topology blindness) - ë©€í‹° GPU ì‘ì—…ì´ ìµœì ì´ ì•„ë‹Œ ë°°ì¹˜ë¥¼ ë°›ì•„ NVLink ì„±ëŠ¥ ì €í•˜ë¹„ìš© í­ë°œ(Cost explosion) - ì¡°ì§ì´ ìŠ¤ì¼€ì¤„ë§ ë¹„íš¨ìœ¨ì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´ GPUë¥¼ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹  ğŸ’  ","version":"Next","tagName":"h3"},{"title":"ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(DRA) ì†Œê°œâ€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#ë™ì -ë¦¬ì†ŒìŠ¤-í• ë‹¹dra-ì†Œê°œ","content":" ","version":"Next","tagName":"h2"},{"title":"DRAê°€ ë³€ê²½í•˜ëŠ” ê²ƒâ€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#draê°€-ë³€ê²½í•˜ëŠ”-ê²ƒ","content":" ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹ì€ GPU ìŠ¤ì¼€ì¤„ë§ì„ ê²½ì§ëœ ë””ë°”ì´ìŠ¤ ì¤‘ì‹¬ ëª¨ë¸ì—ì„œ ìœ ì—°í•œ ì›Œí¬ë¡œë“œ ì¸ì‹ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ê·¼ë³¸ì ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤:  ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹:  resources: limits: nvidia.com/gpu: 1 # ì „ì²´ GPU íšë“, ì»¤ìŠ¤í„°ë§ˆì´ì§• ë¶ˆê°€   DRA ì ‘ê·¼ ë°©ì‹:  resourceClaims: - name: gpu-claim source: resourceClaimTemplateName: gpu-template # ìƒì„¸í•œ ìš”êµ¬ ì‚¬í•­   ResourceClaimTemplate êµ¬ì„±ì€ ì•„ë˜ ì˜ˆì œ ì„¹ì…˜ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìš”êµ¬ ì‚¬í•­ ì¤‘ìš”: ResourceClaimsëŠ” ì´ë¥¼ ì°¸ì¡°í•˜ëŠ” Podì™€ ë™ì¼í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê°„ ë¦¬ì†ŒìŠ¤ í´ë ˆì„ì€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì£¼ìš” DRA í˜ì‹ â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#ì£¼ìš”-dra-í˜ì‹ ","content":" ğŸ¯ ì„¸ë°€í•œ ë¦¬ì†ŒìŠ¤ ì œì–´ íŠ¹ì • GPU ë©”ëª¨ë¦¬ ì–‘ ìš”ì²­ (ì˜ˆ: ì‚¬ìš© ê°€ëŠ¥í•œ 80Gi ì¤‘ 16Gi)ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ê³¼ ë…ë¦½ì ìœ¼ë¡œ ì»´í“¨íŒ… ìš”êµ¬ ì‚¬í•­ ì§€ì •ë©€í‹° GPU ì›Œí¬ë¡œë“œì— ëŒ€í•œ í† í´ë¡œì§€ ì œì•½ ì •ì˜ ì°¸ê³ : ResourceClaimsì™€ PodëŠ” ë™ì¼í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤ ğŸ”„ ì›Œí¬ë¡œë“œë³„ ê³µìœ  ì „ëµ MPS - ë©”ëª¨ë¦¬ ê²©ë¦¬ë¥¼ í†µí•œ ë™ì‹œ ì†Œê·œëª¨ ì›Œí¬ë¡œë“œ Time-slicing - ì„œë¡œ ë‹¤ë¥¸ í”¼í¬ ì‚¬ìš© íŒ¨í„´ì„ ê°€ì§„ ì›Œí¬ë¡œë“œ MIG - ë©€í‹° í…Œë„ŒíŠ¸ í™˜ê²½ì—ì„œì˜ í•˜ë“œì›¨ì–´ ìˆ˜ì¤€ ê²©ë¦¬ Exclusive - ì„±ëŠ¥ì´ ì¤‘ìš”í•œ í•™ìŠµ ì‘ì—… ğŸŒ í† í´ë¡œì§€ ì¸ì‹ ìŠ¤ì¼€ì¤„ë§ GPU ê°„ NVLink ì—°ê²° ì´í•´Amazon EC2 P6e-GB200 UltraServer í´ëŸ¬ìŠ¤í„°ì— IMEX í™œìš©ë¶„ì‚° í•™ìŠµ ì›Œí¬ë¡œë“œì— ëŒ€í•œ ë°°ì¹˜ ìµœì í™” ğŸš€ ë¯¸ë˜ ëŒ€ë¹„ ì•„í‚¤í…ì²˜ Amazon EC2 P6e-GB200 UltraServersì™€ ê°™ì€ ì°¨ì„¸ëŒ€ ì‹œìŠ¤í…œì— í•„ìˆ˜ë©€í‹° ë…¸ë“œ NVLinkì™€ ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ í™œì„±í™”ìƒˆë¡œìš´ GPU ì•„í‚¤í…ì²˜ ë° ê³µìœ  ê¸°ìˆ  ì§€ì›  .dra-innovations-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(320px, 1fr)); gap: 1.5rem; margin: 2rem 0; } .innovation-card { background: var(--ifm-background-surface-color); border: 1px solid var(--ifm-color-emphasis-300); border-radius: 12px; padding: 1.5rem; transition: all 0.3s ease; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1); } .innovation-card:hover { transform: translateY(-4px); box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15); } .innovation-card--primary { border-left: 4px solid var(--ifm-color-primary); } .innovation-card--secondary { border-left: 4px solid var(--ifm-color-secondary); } .innovation-card--success { border-left: 4px solid var(--ifm-color-success); } .innovation-card--warning { border-left: 4px solid var(--ifm-color-warning); } .innovation-card__header { display: flex; align-items: center; margin-bottom: 1rem; } .innovation-card__icon { font-size: 2rem; margin-right: 0.75rem; } .innovation-card__header h4 { margin: 0; font-size: 1.25rem; font-weight: 600; } .innovation-card__content { color: var(--ifm-color-content-secondary); } .innovation-card__features { margin: 0; padding-left: 1rem; } .innovation-card__features li { margin-bottom: 0.5rem; } .innovation-card__note { background: var(--ifm-color-warning-contrast-background); border: 1px solid var(--ifm-color-warning-contrast-border); border-radius: 6px; padding: 0.75rem; margin-top: 1rem; font-size: 0.875rem; } .strategy-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 0.75rem; } .strategy-item { background: var(--ifm-color-emphasis-100); padding: 0.75rem; border-radius: 6px; font-size: 0.875rem; border-left: 3px solid var(--ifm-color-secondary); } @media (max-width: 768px) { .dra-innovations-grid { grid-template-columns: 1fr; } .strategy-grid { grid-template-columns: 1fr; } }  ","version":"Next","tagName":"h3"},{"title":"IMEX, ComputeDomains ë° Amazon EC2 P6e-GB200 ë©€í‹° ë…¸ë“œ ìŠ¤ì¼€ì¤„ë§ ì´í•´â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#imex-computedomains-ë°-amazon-ec2-p6e-gb200-ë©€í‹°-ë…¸ë“œ-ìŠ¤ì¼€ì¤„ë§-ì´í•´","content":" **IMEX (NVIDIA Internode Memory Exchange/Management Service)**ëŠ” NVLink ë©€í‹° ë…¸ë“œ ë°°í¬ì—ì„œ GPU ë©”ëª¨ë¦¬ ê³µìœ ë¥¼ ìœ„í•œ NVIDIAì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. Amazon EC2 P6e-GB200 UltraServer êµ¬ì„±ì—ì„œ IMEXëŠ” ë…¸ë“œ ê°„ ë©”ëª¨ë¦¬ ë‚´ë³´ë‚´ê¸° ë° ê°€ì ¸ì˜¤ê¸° ì‘ì—…ì„ ì¡°ì •í•˜ì—¬ ìˆ˜ì‹­ì–µ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§„ ëŒ€ê·œëª¨ AI ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ ì—¬ëŸ¬ ì»´í“¨íŒ… ë…¸ë“œì—ì„œ ì§ì ‘ GPU-to-GPU ë©”ëª¨ë¦¬ ì ‘ê·¼ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.  ComputeDomainsëŠ” NVLink ë˜ëŠ” IMEXì™€ ê°™ì€ ê³ ëŒ€ì—­í­ ì—°ê²°ì„ í†µí•´ íš¨ìœ¨ì ìœ¼ë¡œ í†µì‹ í•  ìˆ˜ ìˆëŠ” ìƒí˜¸ ì—°ê²°ëœ GPUì˜ ë…¼ë¦¬ì  ê·¸ë£¹ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. DRAëŠ” ComputeDomainsë¥¼ ì‚¬ìš©í•˜ì—¬ GPU í† í´ë¡œì§€ë¥¼ ì´í•´í•˜ê³  ë©€í‹° GPU ì¡°ì •ì´ í•„ìš”í•œ ì›Œí¬ë¡œë“œê°€ ì ì ˆí•˜ê²Œ ì—°ê²°ëœ í•˜ë“œì›¨ì–´ì— ìŠ¤ì¼€ì¤„ë§ë˜ë„ë¡ í•©ë‹ˆë‹¤.  Amazon EC2 P6e-GB200 ë©€í‹° ë…¸ë“œ ìŠ¤ì¼€ì¤„ë§ì€ DRAì˜ í† í´ë¡œì§€ ì¸ì‹ì„ í™œìš©í•˜ì—¬ ì—¬ëŸ¬ ìˆ˜í¼ì¹© ë…¸ë“œì—ì„œ ì›Œí¬ë¡œë“œë¥¼ ì¡°ì •í•©ë‹ˆë‹¤. ê¸°ì¡´ GPU ìŠ¤ì¼€ì¤„ë§ì€ ì´ëŸ¬í•œ ë³µì¡í•œ ì¸í„°ì»¤ë„¥íŠ¸ ê´€ê³„ë¥¼ ì´í•´í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì ì ˆí•œ GPU í† í´ë¡œì§€ ì„ íƒì´ í•™ìŠµ ì„±ëŠ¥ì— ì§ì ‘ì ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” Amazon EC2 P6e-GB200 UltraServer ì‹œìŠ¤í…œì—ì„œ ë¶„ì‚° í•™ìŠµ ì‘ì—…ì˜ ìµœì  ë°°ì¹˜ë¥¼ ìœ„í•´ DRAê°€ í•„ìˆ˜ì ì…ë‹ˆë‹¤.  ìì„¸í•œ êµ¬ì„± ì˜ˆì œ ë° êµ¬í˜„ ê°€ì´ë“œëŠ” AWS EKS AI/ML Best Practices ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.  ","version":"Next","tagName":"h3"},{"title":"EKS êµ¬í˜„ ê³ ë ¤ ì‚¬í•­â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#eks-êµ¬í˜„-ê³ ë ¤-ì‚¬í•­","content":" DRAì˜ ê¸°ëŠ¥ê³¼ IMEX ë° ComputeDomainsì™€ ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ì„ ì´í•´í–ˆìœ¼ë¯€ë¡œ, Amazon EKSì—ì„œ DRAë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•œ ì‹¤ì§ˆì ì¸ ê³ ë ¤ ì‚¬í•­ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì„¹ì…˜ì—ì„œëŠ” ë…¸ë“œ í”„ë¡œë¹„ì €ë‹, ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ ë° DRA ë°°í¬ ì„±ê³µì„ ê²°ì •í•  EKS íŠ¹ì • êµ¬ì„±ì— ëŒ€í•œ ì£¼ìš” ê²°ì • ì‚¬í•­ì„ ë‹¤ë£¹ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"P-ì‹œë¦¬ì¦ˆ GPU ì¸ìŠ¤í„´ìŠ¤ì™€ DRAë¥¼ ìœ„í•œ ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ vs Karpenterâ€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#p-ì‹œë¦¬ì¦ˆ-gpu-ì¸ìŠ¤í„´ìŠ¤ì™€-draë¥¼-ìœ„í•œ-ê´€ë¦¬í˜•-ë…¸ë“œ-ê·¸ë£¹-vs-karpenter","content":" DRAë¥¼ ìœ„í•œ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ë°©ë²• ì„ íƒì€ ë‹¨ìˆœíˆ ê¸°ìˆ ì  í˜¸í™˜ì„±ì— ê´€í•œ ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤. ì´ëŠ” ê·¼ë³¸ì ìœ¼ë¡œ ì—”í„°í”„ë¼ì´ì¦ˆ AI ì›Œí¬ë¡œë“œì—ì„œ GPU ìš©ëŸ‰ì´ êµ¬ë§¤ë˜ê³  í™œìš©ë˜ëŠ” ë°©ì‹ì— ê´€í•œ ê²ƒì…ë‹ˆë‹¤. ê´€ë¦¬í˜• ë° ìì²´ ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì€ í˜„ì¬ DRAì— ê¶Œì¥ë˜ëŠ” ì ‘ê·¼ ë°©ì‹ì¸ë°, ì´ëŠ” ê³ ê¸‰ GPU ì¸ìŠ¤í„´ìŠ¤ì˜ ê²½ì œì„± ë° ìš´ì˜ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: ëŒ€ë¶€ë¶„ì˜ ëŒ€í˜• GPU ì¸ìŠ¤í„´ìŠ¤(P4d (A100), P5 (H100), B200ì´ íƒ‘ì¬ëœ P6, GB200ì´ íƒ‘ì¬ëœ P6e)ëŠ” ì˜¨ë””ë§¨ë“œ ê°€ê²©ì´ ì•„ë‹Œ AWS Capacity Block Reservationsë¥¼ í†µí•´ ì£¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ì¡°ì§ì´ Capacity Blocksë¥¼ êµ¬ë§¤í•˜ë©´ GPUê°€ ì‹¤ì œë¡œ í™œìš©ë˜ëŠ”ì§€ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ì˜ˆì•½ì´ ë§Œë£Œë  ë•Œê¹Œì§€ ëª¨ë“  GPU ì‹œê°„ì— ëŒ€í•´ ë¹„ìš©ì„ ì§€ë¶ˆí•˜ê¸°ë¡œ ì•½ì†í•©ë‹ˆë‹¤. ì´ëŠ” ì›Œí¬ë¡œë“œ ìˆ˜ìš”ì— ë”°ë¥¸ ë™ì  ìŠ¤ì¼€ì¼ë§ì´ë¼ëŠ” Karpenterì˜ í•µì‹¬ ê°€ì¹˜ ì œì•ˆê³¼ ê·¼ë³¸ì ì¸ ë¶ˆì¼ì¹˜ë¥¼ ë§Œë“­ë‹ˆë‹¤. ë‚®ì€ ìˆ˜ìš” ê¸°ê°„ì— ë…¸ë“œë¥¼ ì¶•ì†Œí•´ë„ ë¹„ìš©ì´ ì ˆì•½ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ ì´ë¯¸ ì§€ë¶ˆí•˜ê³  ìˆëŠ” ì˜ˆì•½ëœ ìš©ëŸ‰ì„ ë‚­ë¹„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.  ë˜í•œ, KarpenterëŠ” ì•„ì§ DRA ìŠ¤ì¼€ì¤„ë§ì„ ì§€ì›í•˜ì§€ ì•Šì•„ (Issue #1231ì—ì„œ í™œë°œíˆ ê°œë°œ ì¤‘) DRA ì›Œí¬ë¡œë“œì™€ í˜¸í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. KarpenterëŠ” ì¼ë°˜ ì»´í“¨íŒ… ì›Œí¬ë¡œë“œì˜ ë™ì  ìŠ¤ì¼€ì¼ë§ì„ í†µí•œ ë¹„ìš© ìµœì í™”ì— íƒì›”í•˜ì§€ë§Œ, Capacity Block ì˜ˆì•½ì€ ROIë¥¼ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ &quot;ìƒì‹œ ê°€ë™&quot; í™œìš© ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤: ë°”ë¡œ ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì´ ì •ì  ìš©ëŸ‰ ëª¨ë¸ë¡œ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.  ë¯¸ë˜ëŠ” ë” ë‚™ê´€ì ì…ë‹ˆë‹¤: Karpenterì˜ ë¡œë“œë§µì—ëŠ” Capacity Block ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•œ ì •ì  ë…¸ë“œ ê¸°ëŠ¥ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì»¤ë®¤ë‹ˆí‹°ëŠ” ì›Œí¬ë¡œë“œ ì—†ì´ ìˆ˜ë™ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ ë° ì •ì  í”„ë¡œë¹„ì €ë‹, ìˆ˜ë™ ë…¸ë“œ í”„ë¡œë¹„ì €ë‹ê³¼ ê°™ì€ RFCë¥¼ í†µí•œ ì •ì  í”„ë¡œë¹„ì €ë‹ ê¸°ëŠ¥ì„ ì ê·¹ì ìœ¼ë¡œ ê°œë°œí•˜ê³  ìˆìŠµë‹ˆë‹¤. DRA ì§€ì›ì´ ì´ëŸ¬í•œ ì •ì  í”„ë¡œë¹„ì €ë‹ ê¸°ëŠ¥ê³¼ í•¨ê»˜ ì¶”ê°€ë˜ë©´ KarpenterëŠ” Capacity Block ML ì˜ˆì•½ ì¸ìŠ¤í„´ìŠ¤ì™€ í•¨ê»˜ DRA ì›Œí¬ë¡œë“œì— ì„ í˜¸ë˜ëŠ” ì„ íƒì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë•Œê¹Œì§€ëŠ” NVIDIA ë“œë¼ì´ë²„ê°€ ì‚¬ì „ ì„¤ì¹˜ëœ EKS ìµœì í™” AMIë¥¼ ì‚¬ìš©í•˜ëŠ” ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì´ DRA êµ¬í˜„ì„ ìœ„í•œ ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê¸°ë°˜ì„ ì œê³µí•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"DRAì™€ ê¸°ì¡´ GPU í• ë‹¹ ê³µì¡´â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#draì™€-ê¸°ì¡´-gpu-í• ë‹¹-ê³µì¡´","content":" ì˜ˆ, ì¶©ëŒì„ í”¼í•˜ê¸° ìœ„í•´ ì‹ ì¤‘í•œ êµ¬ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤. DRAì™€ ê¸°ì¡´ GPU í• ë‹¹ì€ ë™ì¼í•œ í´ëŸ¬ìŠ¤í„°ì—ì„œ ê³µì¡´í•  ìˆ˜ ìˆì§€ë§Œ, ë¦¬ì†ŒìŠ¤ ì´ì¤‘ í• ë‹¹ ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‹ ì¤‘í•œ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. NVIDIAì˜ DRA ë“œë¼ì´ë²„ëŠ” ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì„ íƒì  í™œì„±í™”ê°€ ê°€ëŠ¥í•œ GPU Operatorì™€ í•¨ê»˜í•˜ëŠ” ì¶”ê°€ êµ¬ì„± ìš”ì†Œë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.  ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ìœ„í•œ ê¶Œì¥ ì ‘ê·¼ ë°©ì‹: NVIDIA DRA ë“œë¼ì´ë²„ë¥¼ ì²˜ìŒì—ëŠ” íŠ¹ì • í•˜ìœ„ ì‹œìŠ¤í…œë§Œ í™œì„±í™”í•˜ë„ë¡ êµ¬ì„±í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, GPU í• ë‹¹ì— ê¸°ì¡´ ë””ë°”ì´ìŠ¤ í”ŒëŸ¬ê·¸ì¸ì„ ì‚¬ìš©í•˜ë©´ì„œ ë©€í‹° ë…¸ë“œ NVLink ê¸°ëŠ¥ì„ ìœ„í•´ DRAì˜ ComputeDomain í•˜ìœ„ ì‹œìŠ¤í…œì„ í™œì„±í™”í•˜ë„ë¡ resources.gpus.enabled=falseë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ íŒ€ì€ ê¸°ì¡´ GPU í• ë‹¹ ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í—˜ì— ë¹ ëœ¨ë¦¬ì§€ ì•Šê³  DRAì˜ ê³ ê¸‰ ê¸°ëŠ¥ì— ëŒ€í•œ ìš´ì˜ ê²½í—˜ì„ ìŒ“ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ê³µì¡´ì„ ìœ„í•œ ì£¼ìš” ê³ ë ¤ ì‚¬í•­:  ë™ì¼ ë””ë°”ì´ìŠ¤ ì¶©ëŒ ë°©ì§€: DRAì™€ ë””ë°”ì´ìŠ¤ í”ŒëŸ¬ê·¸ì¸ì´ ë™ì¼í•œ GPU ë””ë°”ì´ìŠ¤ë¥¼ ë™ì‹œì— ê´€ë¦¬í•´ì„œëŠ” ì•ˆ ë¨ì„ íƒì  êµ¬ì„± ìš”ì†Œ í™œì„±í™”: NVIDIA DRA ë“œë¼ì´ë²„ì˜ ëª¨ë“ˆì‹ ì„¤ê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ëŠ¥ì„ ì ì§„ì ìœ¼ë¡œ í™œì„±í™”ë…¸ë“œ ì…€ë ‰í„° ê´€ë¦¬: ë¦¬ì†ŒìŠ¤ í• ë‹¹ ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë…¸ë“œ ì…€ë ‰í„°ë¥¼ ì‹ ì¤‘í•˜ê²Œ êµ¬ì„±ê¸°ìˆ  í”„ë¦¬ë·° ìƒíƒœ: GPU í• ë‹¹ ë° ê³µìœ  ê¸°ëŠ¥ì€ ê¸°ìˆ  í”„ë¦¬ë·° ìƒíƒœ (ì—…ë°ì´íŠ¸ëŠ” NVIDIA DRA Driver GitHub í™•ì¸)  ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íšì˜ ê²½ìš°, ë©€í‹° ë…¸ë“œ NVLinkë¥¼ ìœ„í•œ ComputeDomainsì™€ ê°™ì€ DRAì˜ ê¸°ëŠ¥ìœ¼ë¡œ ì‹œì‘í•˜ê³ , í•µì‹¬ GPU í• ë‹¹ì—ëŠ” ê¸°ì¡´ ë””ë°”ì´ìŠ¤ í”ŒëŸ¬ê·¸ì¸ì„ ìœ ì§€í•©ë‹ˆë‹¤. DRAì˜ GPU í• ë‹¹ì´ ì™„ì „íˆ ì§€ì›ë˜ë©´ ë¯¸ì…˜ í¬ë¦¬í‹°ì»¬í•œ í•™ìŠµ ì‘ì—… ì „ì— ê°œë°œ ë° ì¶”ë¡  ì„œë¹„ìŠ¤ë¶€í„° ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ì›Œí¬ë¡œë“œë¥¼ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤. NVIDIAì™€ Kubernetes ì»¤ë®¤ë‹ˆí‹°ëŠ” DRAë¥¼ ë””ë°”ì´ìŠ¤ í”ŒëŸ¬ê·¸ì¸ì˜ ê¶ê·¹ì ì¸ ëŒ€ì²´ì œë¡œ ì„¤ê³„í–ˆì§€ë§Œ, ì „í™˜ì€ í´ëŸ¬ìŠ¤í„° ì•ˆì •ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ì‹ ì¤‘í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h3"},{"title":"ì‹œê°ì  ë¹„êµ: ê¸°ì¡´ ë°©ì‹ vs DRAâ€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#ì‹œê°ì -ë¹„êµ-ê¸°ì¡´-ë°©ì‹-vs-dra","content":" ì•„ë˜ ë‹¤ì´ì–´ê·¸ë¨ì€ DRAê°€ ìŠ¤ì¼€ì¤„ë§ íë¦„ì„ ê·¼ë³¸ì ìœ¼ë¡œ ì–´ë–»ê²Œ ë³€ê²½í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤:  ê¸°ì¡´ ëª¨ë¸: Podê°€ ë…¸ë“œ ë¦¬ì†ŒìŠ¤ ëª¨ë¸ì„ í†µí•´ ì „ì²´ GPUë¥¼ ì§ì ‘ ìš”ì²­í•©ë‹ˆë‹¤. ìŠ¤ì¼€ì¤„ë§ê³¼ í• ë‹¹ì€ ì •ì ì´ë©° ë¶€ë¶„ ì‚¬ìš©ì´ë‚˜ ì›Œí¬ë¡œë“œ ì˜ë„ë¥¼ í‘œí˜„í•  ì—¬ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.DRA ëª¨ë¸: PodëŠ” í…œí”Œë¦¿ì„ í†µí•´ ì˜ë„ë¥¼ í‘œí˜„í•©ë‹ˆë‹¤; í´ë ˆì„ì€ DRA ì¸ì‹ ìŠ¤ì¼€ì¤„ëŸ¬ì™€ ë””ë°”ì´ìŠ¤ ë“œë¼ì´ë²„ì˜ ë„ì›€ìœ¼ë¡œ ë™ì ìœ¼ë¡œ ìƒì„±ë˜ê³  í•´ê²°ë©ë‹ˆë‹¤. ì—¬ëŸ¬ ì›Œí¬ë¡œë“œê°€ GPUë¥¼ ì•ˆì „í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ê³µìœ í•˜ì—¬ í™œìš©ë¥ ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    ","version":"Next","tagName":"h3"},{"title":"ê¸°ìˆ  ì—­ëŸ‰ ë¹„êµâ€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#ê¸°ìˆ -ì—­ëŸ‰-ë¹„êµ","content":" Capability ğŸ”´ Traditional Device Plugin ğŸŸ¢ Dynamic Resource Allocation (DRA) ë¦¬ì†ŒìŠ¤ ìš”ì²­ ëª¨ë¸ âŒ ë‹¨ìˆœ ì •ìˆ˜ nvidia.com/gpu: 1 âœ… êµ¬ì¡°í™”ëœ í´ë ˆì„ ResourceClaimTemplate GPU ë©”ëª¨ë¦¬ ì§€ì • âŒ ì „ë¶€ ë˜ëŠ” ì „ë¬´ í• ë‹¹ âœ… ë©”ëª¨ë¦¬ ê¸°ë°˜ ì œì•½ ë° ì…€ë ‰í„° ê³µìœ  êµ¬ì„± âš ï¸ ì •ì  í´ëŸ¬ìŠ¤í„° ì „ì²´ ConfigMaps âœ… ì›Œí¬ë¡œë“œë³„ ê³µìœ  ì „ëµ ë©€í‹° GPU í† í´ë¡œì§€ ì¸ì‹ âŒ í† í´ë¡œì§€ ì¡°ì • ì—†ìŒ âœ… NVLink, IMEXìš© DeviceClass ì…€ë ‰í„° ëŸ°íƒ€ì„ ì¬êµ¬ì„± âŒ Pod ì‚­ì œ ë° ì¬ë°°í¬ í•„ìš” âœ… ì¬ì‹œì‘ ì—†ì´ ë™ì  ì¬í• ë‹¹ MIG ì§€ì› âš ï¸ ì œí•œì  - ì •ì  íŒŒí‹°ì…˜, ìˆ˜ë™ ì„¤ì • âœ… ë™ì  í´ë ˆì„ì„ í†µí•œ ì™„ì „í•œ MIG í”„ë¡œí•„  âš™ï¸  ","version":"Next","tagName":"h3"},{"title":"DRA ì‹¤ì œ ì‘ë™ ì›ë¦¬: ì™„ì „í•œ ê¸°ìˆ  íë¦„â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#dra-ì‹¤ì œ-ì‘ë™-ì›ë¦¬-ì™„ì „í•œ-ê¸°ìˆ -íë¦„","content":" ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(DRA)ì€ GPU ë° ê¸°íƒ€ ë””ë°”ì´ìŠ¤ ë¦¬ì†ŒìŠ¤ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ëª¨ë“ˆì‹ í”ŒëŸ¬ê·¸ ê°€ëŠ¥ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ Kubernetes ìŠ¤ì¼€ì¤„ë§ì„ í™•ì¥í•©ë‹ˆë‹¤. ë¶ˆíˆ¬ëª…í•œ í•˜ë“œì›¨ì–´ì˜ ì •ìˆ˜ ë‹¨ìœ„ë¥¼ í• ë‹¹í•˜ëŠ” ëŒ€ì‹ , DRAëŠ” ëŸ°íƒ€ì„ì— ë””ë°”ì´ìŠ¤ ìš”êµ¬ ì‚¬í•­ì„ í‘œí˜„, ë§¤ì¹­ ë° í”„ë¡œë¹„ì €ë‹í•˜ê¸° ìœ„í•´ ResourceClaims, ResourceClaimTemplates, DeviceClasses ë° ResourceSlicesë¥¼ ë„ì…í•©ë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"ë‹¨ê³„ë³„ DRA ì›Œí¬í”Œë¡œìš°â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#ë‹¨ê³„ë³„-dra-ì›Œí¬í”Œë¡œìš°","content":" DRAëŠ” ì •êµí•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì„ í†µí•´ Kubernetesê°€ GPU ë¦¬ì†ŒìŠ¤ë¥¼ ê´€ë¦¬í•˜ëŠ” ë°©ì‹ì„ ê·¼ë³¸ì ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤:  1. ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰ ë° ê´‘ê³ â€‹  NVIDIA DRA ë“œë¼ì´ë²„ê°€ ì‹œì‘ë˜ë©´ ê° ë…¸ë“œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ GPUë¥¼ ê²€ìƒ‰í•˜ê³  Kubernetes API ì„œë²„ì— ë””ë°”ì´ìŠ¤ ê¸°ëŠ¥ì„ ê´‘ê³ í•˜ëŠ” ResourceSlicesë¥¼ ìƒì„±í•©ë‹ˆë‹¤.  2. DeviceClass ë“±ë¡â€‹  ë“œë¼ì´ë²„ëŠ” GPU ë¦¬ì†ŒìŠ¤ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ê¸° ìœ„í•´ í•˜ë‚˜ ì´ìƒì˜ DeviceClass ê°ì²´ë¥¼ ë“±ë¡í•©ë‹ˆë‹¤:  gpu.nvidia.com: í‘œì¤€ GPU ë¦¬ì†ŒìŠ¤mig.nvidia.com: Multi-Instance GPU íŒŒí‹°ì…˜compute-domain.nvidia.com: ë…¸ë“œ ê°„ GPU ì¡°ì •  3. ë¦¬ì†ŒìŠ¤ í´ë ˆì„ ìƒì„±â€‹  ResourceClaimTemplatesëŠ” ê° Podì— ëŒ€í•´ ë‹¤ìŒì„ ì§€ì •í•˜ëŠ” ê°œë³„ ResourceClaimsë¥¼ ìƒì„±í•©ë‹ˆë‹¤:  íŠ¹ì • GPU ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ê³µìœ  ì „ëµ (MPS, time-slicing, exclusive)ë“œë¼ì´ë²„ ë²„ì „ ë° ì»´í“¨íŒ… ê¸°ëŠ¥ë©€í‹° GPU ì›Œí¬ë¡œë“œì— ëŒ€í•œ í† í´ë¡œì§€ ì œì•½  4. ì§€ëŠ¥í˜• ìŠ¤ì¼€ì¤„ë§â€‹  DRA ì¸ì‹ ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ë³´ë¥˜ ì¤‘ì¸ ResourceClaimsë¥¼ í‰ê°€í•˜ê³  ë…¸ë“œ ì „ì²´ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ResourceSlicesë¥¼ ì¿¼ë¦¬í•©ë‹ˆë‹¤:  CEL í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë””ë°”ì´ìŠ¤ ì†ì„± ë° ì œì•½ ì¡°ê±´ ë§¤ì¹­ë‹¤ë¥¸ ì‹¤í–‰ ì¤‘ì¸ Podì™€ì˜ ê³µìœ  ì „ëµ í˜¸í™˜ì„± í™•ì¸í† í´ë¡œì§€, ê°€ìš©ì„± ë° ì •ì±…ì„ ê³ ë ¤í•˜ì—¬ ìµœì ì˜ ë…¸ë“œ ì„ íƒ  5. ë™ì  í• ë‹¹â€‹  ì„ íƒëœ ë…¸ë“œì—ì„œ DRA ë“œë¼ì´ë²„ëŠ”:  ì»¨í…Œì´ë„ˆì— ëŒ€í•œ ë””ë°”ì´ìŠ¤ ì ‘ê·¼ ì„¤ì • (ì˜ˆ: MIG ì¸ìŠ¤í„´ìŠ¤ ë§ˆìš´íŠ¸ ë˜ëŠ” MPS êµ¬ì„±)í´ë ˆì„ êµ¬ì„±ì— ë”°ë¼ ê³µìœ  vs ë…ì  ì ‘ê·¼ í• ë‹¹ë™ì‹œ ì›Œí¬ë¡œë“œ ê°„ GPU ìŠ¬ë¼ì´ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ê²©ë¦¬  ","version":"Next","tagName":"h3"},{"title":"ì†”ë£¨ì…˜ ë°°í¬â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#ì†”ë£¨ì…˜-ë°°í¬","content":" ì´ ì˜ˆì œì—ì„œëŠ” DRAë¥¼ ì§€ì›í•˜ëŠ” Amazon EKSì— JARK í´ëŸ¬ìŠ¤í„°ë¥¼ í”„ë¡œë¹„ì €ë‹í•©ë‹ˆë‹¤ 1 ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ í•„ìˆ˜ ë„êµ¬ ë° ì¢…ì†ì„± ì„¤ì¹˜ 2 ë°°í¬ JARK ìŠ¤íƒ ì„¤ì¹˜ êµ¬ì„± ë° ì‹¤í–‰ 3 í™•ì¸ DRA ë°°í¬ í…ŒìŠ¤íŠ¸ ë° ê¸°ëŠ¥ ê²€ì¦ ì‚¬ì „ ìš”êµ¬ ì‚¬í•­â€‹ ë¨¸ì‹ ì— ë‹¤ìŒ ë„êµ¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤: AWS CLI - AWS ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤kubectl - Kubernetes ëª…ë ¹ì¤„ ë„êµ¬terraform - Infrastructure as Code ë„êµ¬ ë°°í¬â€‹ 1. ì €ì¥ì†Œ ë³µì œ:â€‹ ì €ì¥ì†Œ ë³µì œ git clone https://github.com/awslabs/ai-on-eks.git ì¸ì¦ í”„ë¡œí•„ ì¸ì¦ì— í”„ë¡œí•„ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° export AWS_PROFILE=&quot;&lt;PROFILE_name&gt;&quot;ì„ ì›í•˜ëŠ” í”„ë¡œí•„ ì´ë¦„ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤ 2. êµ¬ì„± ê²€í†  ë° ì‚¬ìš©ì ì •ì˜:â€‹ infra/base/terraform/variables.tfì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì• ë“œì˜¨ í™•ì¸í•„ìš”ì— ë”°ë¼ infra/jark-stack/terraform/blueprint.tfvarsì—ì„œ ì• ë“œì˜¨ ì„¤ì • ìˆ˜ì •blueprint.tfvarsì—ì„œ AWS ë¦¬ì „ ì—…ë°ì´íŠ¸ DRA êµ¬ì„± ìš”ì†Œ í™œì„±í™”: blueprint.tfvars íŒŒì¼ì—ì„œ ë‹¤ìŒ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•©ë‹ˆë‹¤: blueprint.tfvars enable_nvidia_dra_driver = true enable_nvidia_gpu_operator = true ìë™ ì„¤ì • NVIDIA GPU Operatorì—ëŠ” í•„ìš”í•œ ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ í¬í•¨ë©ë‹ˆë‹¤: NVIDIA Device PluginDCGM ExporterMIG ManagerGPU Feature DiscoveryNode Feature Discovery NVIDIA DRA DriverëŠ” GPU Operatorì™€ ë³‘ë ¬ë¡œ ë³„ë„ì˜ Helm ì°¨íŠ¸ë¡œ ë°°í¬ë©ë‹ˆë‹¤. 1 ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ í•„ìˆ˜ ë„êµ¬ ë° ì¢…ì†ì„± ì„¤ì¹˜ 2 ë°°í¬ JARK ìŠ¤íƒ ì„¤ì¹˜ êµ¬ì„± ë° ì‹¤í–‰ 3 í™•ì¸ DRA ë°°í¬ í…ŒìŠ¤íŠ¸ ë° ê¸°ëŠ¥ ê²€ì¦ 3. ë°°í¬ ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•˜ê³  ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:â€‹ DRAê°€ í¬í•¨ëœ JARK ìŠ¤íƒ ë°°í¬ cd ai-on-eks/infra/jark-stack &amp;&amp; chmod +x install.sh ./install.sh ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ êµ¬ì„± ìš”ì†Œë¥¼ ìë™ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í•˜ê³  êµ¬ì„±í•©ë‹ˆë‹¤: DRA(ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹) ê¸°ëŠ¥ ê²Œì´íŠ¸ê°€ í™œì„±í™”ëœ Amazon EKS í´ëŸ¬ìŠ¤í„°Amazon Linux 2023 GPU AMIë¥¼ ì‚¬ìš©í•˜ëŠ” ë‘ ê°œì˜ GPU ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹:G6 ë…¸ë“œ ê·¸ë£¹: MPS ë° time-slicing ì „ëµ í…ŒìŠ¤íŠ¸ìš©P4d(e) ë…¸ë“œ ê·¸ë£¹: MIG ê¸°ë°˜ GPU íŒŒí‹°ì…”ë‹ í…ŒìŠ¤íŠ¸ìš© ë‘ ë…¸ë“œ ê·¸ë£¹ ëª¨ë‘ ë¶ˆí•„ìš”í•œ ë¹„ìš©ì„ í”¼í•˜ê¸° ìœ„í•´ ë…¸ë“œ 0ê°œë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤. MPS/time-slicingì„ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ EKS ì½˜ì†”ì„ í†µí•´ g6 ë…¸ë“œ ê·¸ë£¹ì˜ min_size ë° desired_sizeë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤MIGë¥¼ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ Capacity Block Reservation(CBR)ì´ í•„ìš”í•œ ìµœì†Œ í•˜ë‚˜ì˜ p4d ë˜ëŠ” p4de ì¸ìŠ¤í„´ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. íŒŒì¼ í¸ì§‘: infra/base/terraform/eks.tf. ì‹¤ì œ capacity_reservation_idë¥¼ ì„¤ì •í•˜ê³  MIG ë…¸ë“œ ê·¸ë£¹ì˜ min_sizeë¥¼ 1ë¡œ ë³€ê²½í•©ë‹ˆë‹¤ 1 ì‚¬ì „ ìš”êµ¬ ì‚¬í•­ í•„ìˆ˜ ë„êµ¬ ë° ì¢…ì†ì„± ì„¤ì¹˜ 2 ë°°í¬ JARK ìŠ¤íƒ ì„¤ì¹˜ êµ¬ì„± ë° ì‹¤í–‰ 3 í™•ì¸ DRA ë°°í¬ í…ŒìŠ¤íŠ¸ ë° ê¸°ëŠ¥ ê²€ì¦ 4. ë°°í¬ í™•ì¸â€‹ DRA ë°°í¬ê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¦…ë‹ˆë‹¤: ë‹¨ê³„ 1: kubectl ì ‘ê·¼ êµ¬ì„± Kubernetes í´ëŸ¬ìŠ¤í„°ì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ ë¡œì»¬ kubeconfigë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤: aws eks update-kubeconfig --name jark-stack # EKS í´ëŸ¬ìŠ¤í„° ì´ë¦„ìœ¼ë¡œ êµì²´ ë‹¨ê³„ 2: ì›Œì»¤ ë…¸ë“œ í™•ì¸ ë¨¼ì € í´ëŸ¬ìŠ¤í„°ì—ì„œ ì›Œì»¤ ë…¸ë“œê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤: kubectl get nodes ì˜ˆìƒ ì¶œë ¥: ì½”ì–´ ë…¸ë“œ ê·¸ë£¹ì˜ ë‘ ê°œì˜ x86 ì¸ìŠ¤í„´ìŠ¤ì™€ EKS ì½˜ì†”ì„ í†µí•´ ìˆ˜ë™ìœ¼ë¡œ ìŠ¤ì¼€ì¼ ì—…í•œ GPU ì¸ìŠ¤í„´ìŠ¤(g6, p4d ë“±)ê°€ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¨ê³„ 3: DRA êµ¬ì„± ìš”ì†Œ í™•ì¸ NVIDIA GPU Operator ë° NVIDIA DRA Driverë¥¼ í¬í•¨í•œ ëª¨ë“  ë°°í¬ë¥¼ í™•ì¸í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤: kubectl get deployments -A ì˜ˆìƒ ì¶œë ¥: ì•„ë˜ ì˜ˆì œë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ì „ì— ëª¨ë“  Podê°€ Running ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì¸ìŠ¤í„´ìŠ¤ í˜¸í™˜ì„±: Time-slicing ë° MPS: ëª¨ë“  G5 ë˜ëŠ” G6 ì¸ìŠ¤í„´ìŠ¤MIG íŒŒí‹°ì…”ë‹: P-ì‹œë¦¬ì¦ˆ ì¸ìŠ¤í„´ìŠ¤ (P4d ì´ìƒ)IMEX ì‚¬ìš© ì‚¬ë¡€: P6e-GB200 UltraServers ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ì‹¤í–‰ë˜ë©´ ë‹¤ìŒ ì„¹ì…˜ì— ì–¸ê¸‰ëœ ë‹¤ì–‘í•œ DRA ì˜ˆì œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ","version":"Next","tagName":"h2"},{"title":"êµ¬ì„± ìš”ì†Œ ì•„í‚¤í…ì²˜â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#êµ¬ì„±-ìš”ì†Œ-ì•„í‚¤í…ì²˜","content":"   NVIDIA ë„êµ¬ NVIDIA DRA DriverëŠ” NVIDIA GPU Operatorì˜ ì¼ë¶€ê°€ ì•„ë‹Œ ë…ë¦½ì ì¸ Helm ì°¨íŠ¸ë¡œ ë³‘ë ¬ ì‹¤í–‰ë©ë‹ˆë‹¤. ë‘ êµ¬ì„± ìš”ì†ŒëŠ” í•¨ê»˜ ì‘ë™í•˜ì—¬ ì¢…í•©ì ì¸ GPU ê´€ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.  ğŸ²  ","version":"Next","tagName":"h3"},{"title":"GPU ê³µìœ  ì „ëµ: ê¸°ìˆ  ì‹¬ì¸µ ë¶„ì„â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#gpu-ê³µìœ -ì „ëµ-ê¸°ìˆ -ì‹¬ì¸µ-ë¶„ì„","content":" GPU ê³µìœ  ê¸°ìˆ ì„ ì´í•´í•˜ëŠ” ê²ƒì€ ë¦¬ì†ŒìŠ¤ í™œìš©ì„ ìµœì í™”í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤. ê° ì „ëµì€ ì„œë¡œ ë‹¤ë¥¸ ì´ì ì„ ì œê³µí•˜ê³  íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ë¥¼ í•´ê²°í•©ë‹ˆë‹¤.  ğŸ’ ê¸°ë³¸ í• ë‹¹âŒ› Time-SlicingğŸŒŠ Multi-Process Service (MPS)ğŸ—ï¸ Multi-Instance GPU (MIG) ê¸°ë³¸ GPU í• ë‹¹â€‹ ê³µìœ  ì—†ì´ í‘œì¤€ GPU í• ë‹¹ - ê° ì›Œí¬ë¡œë“œëŠ” ì™„ì „í•œ GPUì— ëŒ€í•œ ë…ì  ì ‘ê·¼ ê¶Œí•œì„ ê°–ìŠµë‹ˆë‹¤. ì´ëŠ” ìµœëŒ€ ì„±ëŠ¥ ê²©ë¦¬ë¥¼ ì œê³µí•˜ëŠ” ê¸°ì¡´ ëª¨ë¸ì…ë‹ˆë‹¤. ê¸°ë³¸ í• ë‹¹ ë°°í¬ ë°©ë²•: ResourceClaimTemplateê¸°ë³¸ Pod basic-gpu-claim-template.yaml apiVersion: v1 kind: Namespace metadata: name: gpu-test1 --- apiVersion: resource.k8s.io/v1beta1 kind: ResourceClaimTemplate metadata: namespace: gpu-test1 name: single-gpu spec: spec: devices: requests: - name: gpu deviceClassName: gpu.nvidia.com ì˜ˆì œ ë°°í¬: ê¸°ë³¸ GPU í• ë‹¹ ë°°í¬ kubectl apply -f basic-gpu-claim-template.yaml kubectl apply -f basic-gpu-pod.yaml kubectl get pods -n gpu-test1 -w ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€: ì „ì²´ GPU ë¦¬ì†ŒìŠ¤ê°€ í•„ìš”í•œ ëŒ€ê·œëª¨ ëª¨ë¸ í•™ìŠµGPU ì»´í“¨íŒ… ë° ë©”ëª¨ë¦¬ë¥¼ ì™„ì „íˆ í™œìš©í•˜ëŠ” ì›Œí¬ë¡œë“œìµœëŒ€ ì„±ëŠ¥ ê²©ë¦¬ê°€ í•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜GPU ê³µìœ ìš©ìœ¼ë¡œ ì„¤ê³„ë˜ì§€ ì•Šì€ ë ˆê±°ì‹œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì „ëµ ì„ íƒ ê°€ì´ë“œâ€‹ ì›Œí¬ë¡œë“œ ìœ í˜•\tê¶Œì¥ ì „ëµ\tì£¼ìš” ì´ì ì†Œê·œëª¨ ì¶”ë¡  ì‘ì—…\tTime-slicing ë˜ëŠ” MPS\të†’ì€ GPU í™œìš©ë¥  ë™ì‹œ ì†Œê·œëª¨ ëª¨ë¸\tMPS\tì§„ì •í•œ ë³‘ë ¬ ì²˜ë¦¬ ë©€í‹° í…Œë„ŒíŠ¸\tMIG\tí•˜ë“œì›¨ì–´ ê²©ë¦¬ ëŒ€ê·œëª¨ ëª¨ë¸ í•™ìŠµ\tê¸°ë³¸ í• ë‹¹\tìµœëŒ€ ì„±ëŠ¥ ê°œë°œ/í…ŒìŠ¤íŠ¸\tTime-slicing\tìœ ì—°ì„±ê³¼ ë‹¨ìˆœì„±    ","version":"Next","tagName":"h2"},{"title":"ì •ë¦¬â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#ì •ë¦¬","content":" ","version":"Next","tagName":"h2"},{"title":"DRA êµ¬ì„± ìš”ì†Œ ì œê±°â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#dra-êµ¬ì„±-ìš”ì†Œ-ì œê±°","content":" 1ï¸âƒ£ DRA ì˜ˆì œ ì •ë¦¬2ï¸âƒ£ JARK ìŠ¤íƒ ì •ë¦¬ ëª¨ë“  DRA ì˜ˆì œ ì›Œí¬ë¡œë“œ ì œê±°: DRA ì›Œí¬ë¡œë“œ ì •ë¦¬ # ì ì ˆí•œ ì •ë¦¬ë¥¼ ìœ„í•´ ë¨¼ì € ëª¨ë“  Pod ì‚­ì œ kubectl delete pod inference-pod-1 -n timeslicing-gpu --ignore-not-found kubectl delete pod training-pod-2 -n timeslicing-gpu --ignore-not-found kubectl delete pod mps-workload -n mps-gpu --ignore-not-found kubectl delete pod mig-workload -n mig-gpu --ignore-not-found kubectl delete pod basic-gpu-pod -n gpu-test1 --ignore-not-found # ResourceClaimTemplates ì‚­ì œ kubectl delete resourceclaimtemplate timeslicing-gpu-template -n timeslicing-gpu --ignore-not-found kubectl delete resourceclaimtemplate mps-gpu-template -n mps-gpu --ignore-not-found kubectl delete resourceclaimtemplate mig-gpu-template -n mig-gpu --ignore-not-found kubectl delete resourceclaimtemplate basic-gpu-template -n gpu-test1 --ignore-not-found # ë‚¨ì€ ResourceClaims ì‚­ì œ kubectl delete resourceclaims --all --all-namespaces --ignore-not-found # ConfigMaps ì‚­ì œ (ìŠ¤í¬ë¦½íŠ¸ í¬í•¨) kubectl delete configmap timeslicing-scripts-configmap -n timeslicing-gpu --ignore-not-found # ë§ˆì§€ë§‰ìœ¼ë¡œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‚­ì œ kubectl delete namespace timeslicing-gpu --ignore-not-found kubectl delete namespace mps-gpu --ignore-not-found kubectl delete namespace mig-gpu --ignore-not-found kubectl delete namespace gpu-test1 --ignore-not-found # ì •ë¦¬ í™•ì¸ kubectl get resourceclaims --all-namespaces kubectl get resourceclaimtemplates --all-namespaces   ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²° ğŸ” Pending ìƒíƒœì˜ Podâš ï¸ GPU ê³µìœ  ì¶©ëŒğŸ“Š ì„±ëŠ¥ ë¬¸ì œ ë¬¸ì œ: ResourceClaimsê°€ ìˆëŠ” Podê°€ Pending ìƒíƒœì—ì„œ ë©ˆì¶¤ ì§„ë‹¨: # ResourceClaim ìƒíƒœ í™•ì¸ kubectl get resourceclaims --all-namespaces -o wide # DRA ë“œë¼ì´ë²„ ë¡œê·¸ í™•ì¸ kubectl logs -n gpu-operator -l app=nvidia-dra-driver --tail=100 # DeviceClasses ì¡´ì¬ í™•ì¸ kubectl get deviceclasses í•´ê²°: # DRA ë“œë¼ì´ë²„ Pod ì¬ì‹œì‘ kubectl delete pods -n gpu-operator -l app=nvidia-dra-driver # ë…¸ë“œ GPU ê°€ìš©ì„± í™•ì¸ kubectl describe nodes | grep -A 10 &quot;Allocatable&quot;     ","version":"Next","tagName":"h3"},{"title":"ê²°ë¡ â€‹","type":1,"pageTitle":"Amazon EKSì—ì„œ GPUë¥¼ ìœ„í•œ ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹(Dynamic Resource Allocation)","url":"/ai-on-eks/ko/docs/guidance/dynamic-resource-allocation#ê²°ë¡ ","content":" ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹ì€ ê²½ì§ëœ GPU í• ë‹¹ì—ì„œ ì§€ëŠ¥ì ì¸ ì›Œí¬ë¡œë“œ ì¸ì‹ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¡œì˜ ê·¼ë³¸ì ì¸ ì „í™˜ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. êµ¬ì¡°í™”ëœ ResourceClaimsì™€ ë²¤ë”ë³„ ë“œë¼ì´ë²„ë¥¼ í™œìš©í•¨ìœ¼ë¡œì¨ DRAëŠ” ì—”í„°í”„ë¼ì´ì¦ˆ ê·œëª¨ì˜ ë¹„ìš© íš¨ìœ¨ì ì¸ AI/ML ìš´ì˜ì— í•„ìš”í•œ GPU í™œìš©ë¥ ì„ ì‹¤í˜„í•©ë‹ˆë‹¤.  ì¤€ë¹„ë˜ì…¨ë‚˜ìš”? GPU ì¸í”„ë¼ë¥¼ í˜ì‹ í•˜ì„¸ìš”! ë‹¨ìˆœí™”ëœ JARK ê¸°ë°˜ ë°°í¬ ì ‘ê·¼ ë°©ì‹ì„ í†µí•´ ì¡°ì§ì€ ì„¸ ë‹¨ê³„ë¡œ DRA ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ì—¬ GPU ì¸í”„ë¼ë¥¼ ì •ì  ë¦¬ì†ŒìŠ¤ í’€ì—ì„œ í˜„ëŒ€ AI ì›Œí¬ë¡œë“œì— ìµœì í™”ëœ ë™ì ì´ê³  ì§€ëŠ¥ì ì¸ í”Œë«í¼ìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  EKSì˜ ê´€ë¦¬í˜• ì¸í”„ë¼, NVIDIAì˜ ë“œë¼ì´ë²„ ì—ì½”ì‹œìŠ¤í…œ ë° Kubernetesì˜ ì„ ì–¸ì  ëª¨ë¸ì˜ ì¡°í•©ì€ ì†Œê·œëª¨ ì¶”ë¡  ì‘ì—…ë¶€í„° GB200 ìˆ˜í¼ì¹©ì—ì„œì˜ ë©€í‹° ë…¸ë“œ ë¶„ì‚° í•™ìŠµê¹Œì§€ ì°¨ì„¸ëŒ€ AI ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ê°•ë ¥í•œ ê¸°ë°˜ì„ ë§Œë“­ë‹ˆë‹¤. ","version":"Next","tagName":"h2"}],"options":{"id":"default"}}